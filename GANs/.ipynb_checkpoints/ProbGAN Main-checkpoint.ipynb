{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15e40c08-207d-4924-90fa-3bc93df68cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (1.10.2)\n",
      "Requirement already satisfied: easydict in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (1.13)\n",
      "Requirement already satisfied: seaborn in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (0.11.2)\n",
      "Requirement already satisfied: dataclasses in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from seaborn) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch easydict seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "533a775a-0ff1-433a-a858-67b359a01dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === üîß Environment Setup ===\n",
    "# Imports core libraries for data handling, ML, statistics, visualization, and system ops\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from easydict import EasyDict\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from scipy.stats import skew, kurtosis, jarque_bera, ks_2samp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b033d795-0139-43a6-a4cd-6b27c584b98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === üìà Load and Normalize Dataset ===\n",
    "# Read and compute returns, then scale for stable training\n",
    "raw_df = pd.read_csv(\"raw (FX + EQ).csv\").dropna()\n",
    "raw_returns = raw_df.pct_change().dropna().values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(raw_returns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08be6ed-1e52-4e08-b84d-b5c953df8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === üéõÔ∏è Generator Model for FX/EQ returns ===\n",
    "class FXEQGenerator(nn.Module):\n",
    "    def __init__(self, z_size=100, out_dim=20*1):\n",
    "        super(FXEQGenerator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_size, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z).view(-1, 20, 1)  # output: [batch, sequence_len, 1]\n",
    "\n",
    "\n",
    "# === üïµÔ∏è Discriminator Model ===\n",
    "class FXEQDiscriminator(nn.Module):\n",
    "    def __init__(self, in_dim=20*1):\n",
    "        super(FXEQDiscriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), -1))  # flatten input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ffa071f-c9cc-47fe-9381-a2957f7f802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === üì¶ Time Series Dataset with Windowing ===\n",
    "class FXEQDataset(Dataset):\n",
    "    def __init__(self, csv_path, window_size=20, scaler=None, asset_index=0, split='train', split_ratio=0.65):\n",
    "        self.data = pd.read_csv(csv_path).dropna()\n",
    "        self.returns = self.data.pct_change().dropna().values[:, asset_index]\n",
    "        self.returns = self.returns.reshape(-1, 1)\n",
    "\n",
    "        # Split into train/test\n",
    "        split_point = int(len(self.returns) * split_ratio)\n",
    "        if split == 'train':\n",
    "            self.returns = self.returns[:split_point]\n",
    "        elif split == 'test':\n",
    "            self.returns = self.returns[split_point:]\n",
    "\n",
    "        if scaler is not None:\n",
    "            self.returns = scaler.transform(self.returns)\n",
    "\n",
    "        self.returns = self.returns.squeeze()\n",
    "        self.window_size = window_size\n",
    "        self.samples = [self.returns[i:i+window_size] for i in range(len(self.returns) - window_size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.samples[idx], dtype=torch.float32).unsqueeze(1)  # shape: [window, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7316505-e71c-4bb4-b1e7-25c8057720c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === üî¢ Utility Functions ===\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint'):\n",
    "    torch.save(state, filename + '.pth.tar')\n",
    "\n",
    "def to_tensor(x):\n",
    "    return x.clone().detach().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b941d9fe-2bdb-4644-a754-8cbc17a81ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ARGUMENT PARSER --\n",
    "def parse():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \"\"\"\n",
    "    Hyper-parameter for Stochastic Gradient Hamiltonian Monte Carlo\n",
    "    \"\"\"\n",
    "    parser.add_argument('--sghmc_alpha', default=0.01, type=int, dest='sghmc_alpha', help='number of generators')\n",
    "    parser.add_argument('--g_noise_loss_lambda', default=3e-2, type=float, dest='g_noise_loss_lambda')\n",
    "    parser.add_argument('--d_noise_loss_lambda', default=3e-2, type=float, dest='d_noise_loss_lambda')\n",
    "    parser.add_argument('--d_hist_loss_lambda', default=1.0, type=float, dest='d_hist_loss_lambda')\n",
    "    \"\"\"\n",
    "    GAN objectives\n",
    "    NS: original GAN (Non-saturating version)\n",
    "    MM: original GAN (Min-max version)\n",
    "    W: Wasserstein GAN\n",
    "    LS: Least-Square GAN\n",
    "    \"\"\"\n",
    "    parser.add_argument('--gan_obj', default='NS', type=str, dest='gan_obj', help='[NS | MM | LS | W]')\n",
    "\n",
    "    \"\"\"\n",
    "    Paths\n",
    "    \"\"\"\n",
    "    parser.add_argument('--dataset', default='fxeq', type=str, dest='dataset',\n",
    "                        help='dataset: [cifar10, stl10, imagenet]')\n",
    "    parser.add_argument('--save_dir', default='none', type=str, dest='save_dir', help='save_path')\n",
    "\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd71a5e-f39e-4752-98d3-c4b9ac3e882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- MODEL CONSTRUCTOR --\n",
    "def construct_model(args, config):\n",
    "    \"\"\"Constructs generator and discriminator models based on dataset type and config\"\"\"\n",
    "    '''\n",
    "    :param args: Experiment Information\n",
    "    :param config: Neural Network Architecture Configurations\n",
    "    :return:\n",
    "        G: generator structure\n",
    "        D: discriminator structure\n",
    "    '''\n",
    "    D_unbound_output = args.gan_obj in ['W', 'LS']  # Whether discriminator output is bounded\n",
    "\n",
    "    if args.dataset == 'fxeq':\n",
    "        G = FXEQGenerator(z_size=config.z_size).to(device)\n",
    "        D = FXEQDiscriminator().to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only 'fxeq' dataset supported in this version\")\n",
    "\n",
    "    print('G #parameters: ', count_parameters(G))\n",
    "    print('D #parameters: ', count_parameters(D))\n",
    "    return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eef331b3-1d67-471c-a9d9-cc4f8378eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TRAINING FUNCTION --\n",
    "def train_net(G, D, args, config):\n",
    "    \"\"\"Train GAN model using selected GAN objective\"\"\"\n",
    "    is_multi_g = hasattr(G, 'gs')  # Used in multi-generator architectures\n",
    "    is_multi_d = hasattr(D, 'ds') or hasattr(D, 'forward_by_hist')  # Multi-discriminator support\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # SGHMC noise setup\n",
    "    noise_std = np.sqrt(2 * args.sghmc_alpha)\n",
    "    G_noise_sampler = [get_sghmc_noise(g) for g in G.gs] if is_multi_g else [get_sghmc_noise(G)]\n",
    "    D_noise_sampler = get_sghmc_noise(D)\n",
    "\n",
    "    # Output directory setup\n",
    "    if args.save_dir == 'none':\n",
    "        args.save_dir = f'./dump/train_{args.dataset}_{args.gan_obj}'\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    # Dataset and dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=config.get_dataset(),\n",
    "        batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=config.workers, pin_memory=True)\n",
    "\n",
    "    # Loss functions\n",
    "    criterion_bce = nn.BCEWithLogitsLoss().to(device)\n",
    "    criterion_mse = nn.MSELoss().to(device)\n",
    "\n",
    "    # Define GAN losses based on objective\n",
    "    if args.gan_obj == 'NS':  # Non-saturating GAN\n",
    "        phi_1 = lambda dreal, lreal, lfake: criterion_bce(dreal, lreal)\n",
    "        phi_2 = lambda dfake, lreal, lfake: criterion_bce(dfake, lfake)\n",
    "        phi_3 = lambda dfake, lreal, lfake: criterion_bce(dfake, lreal)\n",
    "    elif args.gan_obj == 'MM':  # Min-max GAN\n",
    "        phi_1 = lambda dreal, lreal, lfake: criterion_bce(dreal, lreal)\n",
    "        phi_2 = lambda dfake, lreal, lfake: criterion_bce(dfake, lfake)\n",
    "        phi_3 = lambda dfake, lreal, lfake: -criterion_bce(dfake, lfake)\n",
    "    elif args.gan_obj == 'LS':  # Least-squares GAN\n",
    "        phi_1 = lambda dreal, lreal, lfake: criterion_mse(dreal, lreal)\n",
    "        phi_2 = lambda dfake, lreal, lfake: criterion_mse(dfake, lfake)\n",
    "        phi_3 = lambda dfake, lreal, lfake: criterion_mse(dfake, lreal)\n",
    "    elif args.gan_obj == 'W':  # Wasserstein GAN\n",
    "        phi_1 = lambda dreal, lreal, lfake: -dreal.mean()\n",
    "        phi_2 = lambda dfake, lreal, lfake: dfake.mean()\n",
    "        phi_3 = lambda dfake, lreal, lfake: -dfake.mean()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown GAN objective\")\n",
    "\n",
    "    # Optimizers\n",
    "    optimizerD = torch.optim.Adam(D.parameters(), lr=config.base_lr, betas=(config.beta1, 0.999))\n",
    "    optimizerG = torch.optim.Adam(G.parameters(), lr=config.base_lr, betas=(config.beta1, 0.999))\n",
    "\n",
    "    # Tracking meters\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    D_losses = AverageMeter()\n",
    "    G_losses = AverageMeter()\n",
    "    G_n_losses = AverageMeter()\n",
    "\n",
    "    # Loss history lists for plotting\n",
    "    D_loss_list = []\n",
    "    G_loss_list = []\n",
    "    G_loss_by_hist_list = []\n",
    "    \n",
    "    # Fixed noise for sampling\n",
    "    fixed_noise = torch.randn(100, config.z_size).to(device)\n",
    "\n",
    "    # Start training loop\n",
    "    for epoch in range(config.epoches):\n",
    "        end = time.time()\n",
    "        G.train(); D.train()\n",
    "\n",
    "        for i, input in enumerate(train_loader):\n",
    "            data_time.update(time.time() - end)\n",
    "            batch_size = input.size(0)\n",
    "            g_batch_size = config.g_batch_size\n",
    "\n",
    "            # ----------------------- Train Discriminator -----------------------\n",
    "            real_input = Variable(input.to(device))\n",
    "            label_real = Variable(torch.ones(batch_size).to(device))\n",
    "            label_fake = Variable(torch.zeros(g_batch_size).to(device))\n",
    "\n",
    "            # Real loss\n",
    "            d_real = D(real_input).squeeze()\n",
    "            loss_real = phi_1(d_real, label_real, None)\n",
    "\n",
    "            # Fake generation\n",
    "            noise = torch.randn(g_batch_size, config.z_size).to(device)\n",
    "            fake_data = G(noise)\n",
    "            d_fake = D(fake_data).squeeze()\n",
    "            loss_fake = phi_2(d_fake, None, label_fake)\n",
    "\n",
    "            # Total discriminator loss\n",
    "            d_loss = loss_real + loss_fake\n",
    "            D_losses.update(d_loss.item())\n",
    "\n",
    "            # SGHMC noise loss for discriminator\n",
    "            d_loss += args.d_noise_loss_lambda * noise_loss(D, D_noise_sampler, noise_std)\n",
    "\n",
    "            # Optional gradient penalty (for WGAN)\n",
    "            if args.gan_obj == 'W':\n",
    "                d_loss += calc_gradient_penalty(D, real_input.data, fake_data[:batch_size].data)\n",
    "\n",
    "            D.zero_grad(); d_loss.backward(); optimizerD.step()\n",
    "\n",
    "            # ----------------------- Train Generator -----------------------\n",
    "            noise = torch.randn(g_batch_size, config.z_size).to(device)\n",
    "            fake_data = G(noise)\n",
    "            d_fake = D(fake_data).squeeze()\n",
    "\n",
    "            # Regenerate correct-size labels for generator training (g_batch_size)\n",
    "            label_real_g = torch.ones(g_batch_size).to(device)\n",
    "            label_fake_g = torch.zeros(g_batch_size).to(device)\n",
    "\n",
    "            g_loss = phi_3(d_fake, label_real_g, label_fake_g)\n",
    "\n",
    "            G_losses.update(g_loss.item())\n",
    "            g_loss += args.g_noise_loss_lambda * noise_loss(G, G_noise_sampler[0], noise_std)\n",
    "\n",
    "            # History-aware discriminator loss (if available)\n",
    "            if is_multi_d and hasattr(D, 'forward_by_hist'):\n",
    "                d_fake_hist = D.forward_by_hist(fake_data).squeeze()\n",
    "                g_hist_loss = phi_3(d_fake_hist, label_real_g, label_fake_g)\n",
    "                g_loss += g_hist_loss * args.d_hist_loss_lambda\n",
    "                G_n_losses.update(g_hist_loss.item())\n",
    "\n",
    "\n",
    "            D.zero_grad(); G.zero_grad(); g_loss.backward(); optimizerG.step()\n",
    "            batch_time.update(time.time() - end); end = time.time()\n",
    "\n",
    "            if is_multi_d and hasattr(D, 'update_hist') and i % 10 == 0:\n",
    "                D.update_hist()\n",
    "\n",
    "            # Print status\n",
    "            if (i + 1) % config.display == 0 or (i + 1) == len(train_loader):\n",
    "                print_log_2(epoch + 1, config.epoches, i + 1, len(train_loader), config.base_lr,\n",
    "                            config.display, batch_time, data_time, D_losses, G_losses, G_n_losses)\n",
    "                batch_time.reset(); data_time.reset()\n",
    "\n",
    "        # End of epoch evaluation + plotting\n",
    "        D_loss_list.append(D_losses.avg)\n",
    "        G_loss_list.append(G_losses.avg)\n",
    "        G_loss_by_hist_list.append(G_n_losses.avg)\n",
    "        D_losses.reset(); G_losses.reset(); G_n_losses.reset()\n",
    "\n",
    "        if (epoch + 1) % config.dump_ep == 0:\n",
    "            plot_result(G, fixed_noise, config.image_size, epoch + 1, args.save_dir, is_gray=(config.channel_size == 1))\n",
    "            plot_loss_my(D_loss_list, G_loss_list, G_loss_by_hist_list, epoch + 1, config.epoches, args.save_dir)\n",
    "            save_checkpoint({'epoch': epoch, 'state_dict': D.state_dict()}, os.path.join(args.save_dir, f'D_epoch_{epoch}.pth'))\n",
    "            save_checkpoint({'epoch': epoch, 'state_dict': G.state_dict()}, os.path.join(args.save_dir, f'G_epoch_{epoch}.pth'))\n",
    "            torch.save(G.state_dict(), os.path.join(args.save_dir, 'gen_model.pt'))\n",
    "\n",
    "        # Log gradient norms for generator and discriminator\n",
    "        g_norm, g_max = grad_info(G.parameters())\n",
    "        d_norm, d_max = grad_info(D.parameters())\n",
    "        print(f\"G grad l2-norm: {g_norm:.6f}, max value: {g_max:.6f}\")\n",
    "        print(f\"D grad l2-norm: {d_norm:.6f}, max value: {d_max:.6f}\")\n",
    "\n",
    "        # Gradient clipping (optional but can stabilize training)\n",
    "        nn.utils.clip_grad_norm_(G.parameters(), max_norm=100)\n",
    "        nn.utils.clip_grad_norm_(D.parameters(), max_norm=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17f15ae2-c288-431a-8189-cc508af49eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Cross-validation split for time series data --\n",
    "def time_series_cv_split(data, window_size=20, train_size=0.65, val_window=100, step=50):\n",
    "    \"\"\"\n",
    "    Returns a list of (train, validation) pairs from a single time series,\n",
    "    using rolling window split strategy.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    split_point = int(n * train_size)\n",
    "    splits = []\n",
    "\n",
    "    for start in range(0, split_point - window_size - val_window + 1, step):\n",
    "        train_end = start + window_size\n",
    "        val_end = train_end + val_window\n",
    "        if val_end > n:\n",
    "            break\n",
    "        train_data = data[start:train_end]\n",
    "        val_data = data[train_end:val_end]\n",
    "        splits.append((train_data.copy(), val_data.copy()))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97daa576-7687-4254-af21-fa4e60c667b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- SGHMC noise injection --\n",
    "def noise_loss(model, noise_sampler, alpha):\n",
    "    \"\"\"Applies SGHMC noise to model parameters for regularization\"\"\"\n",
    "    loss = 0\n",
    "    for p, n in zip(model.parameters(), noise_sampler):\n",
    "        n.normal_(mean=0, std=alpha)\n",
    "        loss += torch.sum(p * n)\n",
    "    return loss\n",
    "\n",
    "def get_sghmc_noise(model):\n",
    "    \"\"\"Creates zero-initialized noise buffers for SGHMC\"\"\"\n",
    "    return [to_tensor(torch.zeros(p.size())) for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d05dcc2-ff2a-4959-b457-330c3a79d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Utility for tracking averages over time --\n",
    "class AverageMeter:\n",
    "    \"\"\"Tracks average and current value of a quantity\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96c0b2e1-31da-46aa-a750-6549653541d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gradient statistics logging --\n",
    "def grad_info(parameters):\n",
    "    total_norm = 0\n",
    "    total_abs_max = 0\n",
    "    for p in parameters:\n",
    "        if p.requires_grad:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "            vmax = p.grad.data.abs().max().item()\n",
    "            if vmax > total_abs_max:\n",
    "                total_abs_max = vmax\n",
    "    total_norm = total_norm ** 0.5\n",
    "    return total_norm, total_abs_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b3c7b26-aa47-4149-82a7-d7f365fa18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gradient penalty calculation (WGAN-GP) --\n",
    "def calc_gradient_penalty(netD, real_data, fake_data, gp_lambda=10):\n",
    "    \"\"\"Compute WGAN-GP gradient penalty\"\"\"\n",
    "    alpha = torch.rand(len(real_data), 1, 1, 1).to(device)\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "    interpolates = Variable(interpolates, requires_grad=True)\n",
    "    disc_interpolates = netD(interpolates)\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean() * gp_lambda\n",
    "\n",
    "# -- Optional variant for multi-GAN architectures --\n",
    "def calc_gradient_penalty_mgan(netD, real_data, fake_data, gp_lambda=10):\n",
    "    alpha = torch.rand(len(real_data), 1, 1, 1).to(device)\n",
    "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "    interpolates = Variable(interpolates, requires_grad=True)\n",
    "    disc_interpolates, _ = netD(interpolates)\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean() * gp_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ccfa912-e432-47f7-a657-f16fe3453992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Rolling Window CV Split --\n",
    "def rolling_window_splits(data, window_size=20, test_size=100, step=10):\n",
    "    \"\"\"Generate rolling window splits for univariate time series.\"\"\"\n",
    "    splits = []\n",
    "    for start in range(0, len(data) - window_size - test_size, step):\n",
    "        train = data[start:start+window_size]\n",
    "        test = data[start+window_size:start+window_size+test_size]\n",
    "        splits.append((train, test))\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db5c074b-3968-49e4-b4ac-2dabccc79785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Plot Training Loss Curves --\n",
    "def plot_loss_my(d_loss, g_loss, g_loss_hist, num_epoch, epoches, save_dir):\n",
    "    \"\"\"Plot loss curves for discriminator, generator, and generator (hist).\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, epoches + 1)\n",
    "    ax.set_ylim(min(np.min(g_loss_hist), min(np.min(g_loss), np.min(d_loss))) - 0.1,\n",
    "                max(np.max(g_loss), np.max(d_loss)) * 1.1)\n",
    "    plt.xlabel(f'Epoch {num_epoch}')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.plot(range(1, num_epoch + 1), d_loss, label='Discriminator', color='red', linewidth=3)\n",
    "    plt.plot(range(1, num_epoch + 1), g_loss, label='Generator', color='mediumblue', linewidth=3, alpha=0.5)\n",
    "    plt.plot(range(1, num_epoch + 1), g_loss_hist, label='Generator - (hist)', color='green', linewidth=3, alpha=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, f'DCGAN_loss_epoch_{num_epoch}.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ede1fd74-c944-494a-ac40-b8858ef137ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Visualize Generated Samples (time series) --\n",
    "def plot_result(G, fixed_noise, image_size, num_epoch, save_dir, is_gray=False, n_series=None):\n",
    "    \"\"\"Plot a single sample from the generator's output across all series.\"\"\"\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = G(fixed_noise).cpu().numpy()  # shape: [1, timesteps, features]\n",
    "\n",
    "    if n_series is None:\n",
    "        n_series = generated.shape[2]\n",
    "\n",
    "    fig, axes = plt.subplots(n_series, 1, figsize=(12, 2 * n_series), sharex=True)\n",
    "    if n_series == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(n_series):\n",
    "        series = generated[0, :, i]\n",
    "        axes[i].plot(series)\n",
    "        axes[i].set_ylabel(f'Series {i+1}')\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Timestep\")\n",
    "    fig.suptitle(f\"Generated Time Series Sample - Epoch {num_epoch}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"time_series_epoch_{num_epoch}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cd7a67b-35a4-4932-99f5-b4a41663f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Print Epoch Summary Log --\n",
    "def print_log_2(epoch, epoches, iteration, iters, learning_rate,\n",
    "                display, batch_time, data_time, D_losses, G_losses, G_n_losses):\n",
    "    print('epoch: [{}/{}] iteration: [{}/{}]\\tLearning rate: {}'.format(\n",
    "        epoch, epoches, iteration, iters, learning_rate))\n",
    "    print('Time {batch_time.sum:.3f}s / {0} iters, ({batch_time.avg:.3f})\\t'\n",
    "          'Data load {data_time.sum:.3f}s / {0} iters, ({data_time.avg:3f})\\n'\n",
    "          'Loss_D = {loss_D.val:.8f} (ave = {loss_D.avg:.8f})\\n'\n",
    "          'Loss_G = {loss_G.val:.8f} (ave = {loss_G.avg:.8f})\\n'\n",
    "          'Loss_GN = {loss_GN.val:.8f} (ave = {loss_GN.avg:.8f})\\n'.format(\n",
    "        display, batch_time=batch_time, data_time=data_time,\n",
    "        loss_D=D_losses, loss_G=G_losses, loss_GN=G_n_losses))\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S\\n' + '-' * 120 + '\\n', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e59eb5a-7e0a-4549-94c6-f025173d78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Generate Synthetic Forecast from Generator --\n",
    "def generate_synthetic_forecast(G, forecast_horizon=300, n_samples=1, steps_per_pass=20):\n",
    "    \"\"\"Generate synthetic price forecasts from trained generator.\"\"\"\n",
    "    n_passes = forecast_horizon // steps_per_pass\n",
    "    all_returns = []\n",
    "\n",
    "    if scaler is None:\n",
    "        raise ValueError(\"Scaler must be provided to inverse transform returns.\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_passes):\n",
    "            z = torch.randn(n_samples, 100).to(device)\n",
    "            returns_block = G(z).cpu().numpy()\n",
    "            all_returns.append(returns_block)\n",
    "\n",
    "    returns = np.concatenate(all_returns, axis=1)  # shape: (1, horizon, features)\n",
    "\n",
    "    # Inverse scale and compute price paths\n",
    "    returns_flat = returns.reshape(-1, returns.shape[2])\n",
    "    returns_unscaled = scaler.inverse_transform(returns_flat)\n",
    "    returns = returns_unscaled.reshape(returns.shape)\n",
    "\n",
    "    prices = []\n",
    "    for i in range(returns.shape[2]):\n",
    "        series = returns[0, :, i]\n",
    "        series_prices = [LAST_KNOWN_PRICES[i]]\n",
    "        for r in series:\n",
    "            series_prices.append(series_prices[-1] * (1 + r))\n",
    "        prices.append(series_prices[1:])\n",
    "\n",
    "    df_synthetic = pd.DataFrame(np.array(prices).T, columns=raw_df.columns)\n",
    "    df_synthetic.to_csv(\"synthetic_prices.csv\", index=False)\n",
    "    return df_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd710e5b-589e-4095-8891-390f3e761f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Compare Real vs Synthetic Returns with Stylized Metrics --\n",
    "def evaluate_synthetic_vs_real(real_returns, synthetic_returns):\n",
    "    \"\"\"Compute statistical comparisons between real and synthetic return series.\"\"\"\n",
    "    results = {\n",
    "        \"Mean_Real\": np.mean(real_returns),\n",
    "        \"Mean_Synthetic\": np.mean(synthetic_returns),\n",
    "        \"Std_Real\": np.std(real_returns),\n",
    "        \"Std_Synthetic\": np.std(synthetic_returns),\n",
    "        \"Skew_Real\": skew(real_returns),\n",
    "        \"Skew_Synthetic\": skew(synthetic_returns),\n",
    "        \"Kurt_Real\": kurtosis(real_returns),\n",
    "        \"Kurt_Synthetic\": kurtosis(synthetic_returns),\n",
    "        \"KS_Distance\": ks_2samp(real_returns, synthetic_returns).statistic,\n",
    "        \"Jarque_Bera_Real\": jarque_bera(real_returns)[0],\n",
    "        \"Jarque_Bera_Synthetic\": jarque_bera(synthetic_returns)[0],\n",
    "    }\n",
    "    return pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c26fdb0b-e113-4192-afcf-333d4cfe2b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fxeq_returns_scaler.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- CONFIGURATION SETUP --\n",
    "config = EasyDict()\n",
    "config.num_gens = 10\n",
    "config.num_discs = 4\n",
    "config.z_size = 100\n",
    "config.channel_size = 1\n",
    "config.ngf = 128\n",
    "config.ndf = 128\n",
    "config.batch_size = 64\n",
    "config.g_batch_size = 128\n",
    "config.base_lr = 0.0001\n",
    "config.beta1 = 0.5\n",
    "config.epoches = 200\n",
    "config.dump_ep = 10\n",
    "config.image_size = 1\n",
    "config.get_dataset = lambda: FXEQDataset(\"raw (FX + EQ).csv\", window_size=20, scaler=scaler)\n",
    "config.display = 800\n",
    "config.workers = 0\n",
    "\n",
    "# -- ARGUMENTS CLASS --\n",
    "class Args:\n",
    "    sghmc_alpha = 0.01\n",
    "    g_noise_loss_lambda = 3e-2\n",
    "    d_noise_loss_lambda = 3e-2\n",
    "    d_hist_loss_lambda = 1.0\n",
    "    gan_obj = \"NS\"\n",
    "    dataset = \"fxeq\"\n",
    "    save_dir = \"fxeq_probgan_output\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Save the scaler for later use\n",
    "joblib.dump(scaler, \"fxeq_returns_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4027c2ff-ec67-49cc-a1f9-b890a5f96e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- LOAD DATA --\n",
    "raw_df = pd.read_csv(\"raw (FX + EQ).csv\").dropna()\n",
    "raw_returns_all_assets = raw_df.pct_change().dropna().values\n",
    "NUM_ASSETS = 12\n",
    "all_metrics = []  # Stores evaluation results for each asset/fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26354451-e473-41bc-a89e-bc9a92fbd452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ TSCV for Asset 0\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.37107742 (ave = 1.37413762)\n",
      "Loss_G = 0.65652001 (ave = 0.65724317)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975907, max value: 0.025689\n",
      "D grad l2-norm: 0.682603, max value: 0.481343\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.36014509 (ave = 1.36029146)\n",
      "Loss_G = 0.65453088 (ave = 0.65540142)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970680, max value: 0.023311\n",
      "D grad l2-norm: 0.685305, max value: 0.480309\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 1.33459938 (ave = 1.34530854)\n",
      "Loss_G = 0.65284157 (ave = 0.65370294)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969007, max value: 0.026495\n",
      "D grad l2-norm: 0.686602, max value: 0.479429\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 1.32240808 (ave = 1.33257167)\n",
      "Loss_G = 0.65209204 (ave = 0.65241915)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965309, max value: 0.029730\n",
      "D grad l2-norm: 0.692083, max value: 0.479040\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 1.31245947 (ave = 1.32076540)\n",
      "Loss_G = 0.65209168 (ave = 0.65232093)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974998, max value: 0.029616\n",
      "D grad l2-norm: 0.695450, max value: 0.479038\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.30581760 (ave = 1.30988810)\n",
      "Loss_G = 0.65129769 (ave = 0.65140145)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968576, max value: 0.031261\n",
      "D grad l2-norm: 0.697838, max value: 0.478625\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 1.28389239 (ave = 1.29683051)\n",
      "Loss_G = 0.65246737 (ave = 0.65164777)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971990, max value: 0.029197\n",
      "D grad l2-norm: 0.703324, max value: 0.479236\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001193)\n",
      "Loss_D = 1.27958441 (ave = 1.28606639)\n",
      "Loss_G = 0.65179533 (ave = 0.65202190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964562, max value: 0.030225\n",
      "D grad l2-norm: 0.710996, max value: 0.478885\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 1.28597927 (ave = 1.27697079)\n",
      "Loss_G = 0.65368319 (ave = 0.65325941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970016, max value: 0.025906\n",
      "D grad l2-norm: 0.713326, max value: 0.479867\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002716)\n",
      "Loss_D = 1.25909090 (ave = 1.26349483)\n",
      "Loss_G = 0.65465307 (ave = 0.65451393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972598, max value: 0.024865\n",
      "D grad l2-norm: 0.721266, max value: 0.480370\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 1.26030922 (ave = 1.25403950)\n",
      "Loss_G = 0.65679628 (ave = 0.65627699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967534, max value: 0.028271\n",
      "D grad l2-norm: 0.726508, max value: 0.481481\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001195)\n",
      "Loss_D = 1.24039066 (ave = 1.24129772)\n",
      "Loss_G = 0.65803993 (ave = 0.65791332)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971095, max value: 0.028099\n",
      "D grad l2-norm: 0.733078, max value: 0.482127\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.22969937 (ave = 1.22940571)\n",
      "Loss_G = 0.66154516 (ave = 0.66052107)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969801, max value: 0.028676\n",
      "D grad l2-norm: 0.740314, max value: 0.483939\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 1.21388030 (ave = 1.21794736)\n",
      "Loss_G = 0.66306823 (ave = 0.66270210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973207, max value: 0.031110\n",
      "D grad l2-norm: 0.748962, max value: 0.484722\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.23318148 (ave = 1.21080692)\n",
      "Loss_G = 0.66641951 (ave = 0.66520275)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973729, max value: 0.035197\n",
      "D grad l2-norm: 0.753383, max value: 0.486447\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001152)\n",
      "Loss_D = 1.18370116 (ave = 1.19493761)\n",
      "Loss_G = 0.66779667 (ave = 0.66732529)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968693, max value: 0.032133\n",
      "D grad l2-norm: 0.762901, max value: 0.487149\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 1.18013740 (ave = 1.18478422)\n",
      "Loss_G = 0.67104280 (ave = 0.66993678)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969950, max value: 0.034423\n",
      "D grad l2-norm: 0.771282, max value: 0.488812\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 1.17286205 (ave = 1.17451985)\n",
      "Loss_G = 0.67396390 (ave = 0.67321136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971020, max value: 0.042269\n",
      "D grad l2-norm: 0.776590, max value: 0.490305\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.17370200 (ave = 1.16378558)\n",
      "Loss_G = 0.67760754 (ave = 0.67653079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.982261, max value: 0.036951\n",
      "D grad l2-norm: 0.787916, max value: 0.492157\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001237)\n",
      "Loss_D = 1.13315356 (ave = 1.14963081)\n",
      "Loss_G = 0.68289787 (ave = 0.67958424)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979183, max value: 0.047646\n",
      "D grad l2-norm: 0.794384, max value: 0.494834\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.12534606 (ave = 1.13918607)\n",
      "Loss_G = 0.68606931 (ave = 0.68410552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979817, max value: 0.047092\n",
      "D grad l2-norm: 0.810049, max value: 0.496435\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.13194799 (ave = 1.13007758)\n",
      "Loss_G = 0.68944126 (ave = 0.68782606)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985471, max value: 0.059255\n",
      "D grad l2-norm: 0.821353, max value: 0.498128\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 1.10210049 (ave = 1.11630375)\n",
      "Loss_G = 0.69423598 (ave = 0.69162017)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986145, max value: 0.060189\n",
      "D grad l2-norm: 0.828443, max value: 0.500529\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 1.08827615 (ave = 1.10486884)\n",
      "Loss_G = 0.69689155 (ave = 0.69622190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985657, max value: 0.055499\n",
      "D grad l2-norm: 0.848569, max value: 0.501845\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.09927261 (ave = 1.09632728)\n",
      "Loss_G = 0.70124960 (ave = 0.69979310)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.989919, max value: 0.072814\n",
      "D grad l2-norm: 0.856923, max value: 0.504017\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.07856488 (ave = 1.08421741)\n",
      "Loss_G = 0.70631099 (ave = 0.70480585)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.990414, max value: 0.061196\n",
      "D grad l2-norm: 0.867411, max value: 0.506520\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.05785775 (ave = 1.07189090)\n",
      "Loss_G = 0.71060741 (ave = 0.70902691)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992329, max value: 0.062372\n",
      "D grad l2-norm: 0.879258, max value: 0.508630\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 1.06615055 (ave = 1.06353645)\n",
      "Loss_G = 0.71662623 (ave = 0.71436152)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986671, max value: 0.058550\n",
      "D grad l2-norm: 0.899315, max value: 0.511582\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.03871536 (ave = 1.05030577)\n",
      "Loss_G = 0.72316289 (ave = 0.72023853)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.994783, max value: 0.057416\n",
      "D grad l2-norm: 0.910119, max value: 0.514767\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 1.02176702 (ave = 1.03767121)\n",
      "Loss_G = 0.72801530 (ave = 0.72642871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.999292, max value: 0.059169\n",
      "D grad l2-norm: 0.925862, max value: 0.517112\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002740)\n",
      "Loss_D = 1.00645471 (ave = 1.02511735)\n",
      "Loss_G = 0.73370051 (ave = 0.73161025)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.010456, max value: 0.065043\n",
      "D grad l2-norm: 0.942403, max value: 0.519847\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001155)\n",
      "Loss_D = 0.99293435 (ave = 1.01424448)\n",
      "Loss_G = 0.73906118 (ave = 0.73737384)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.013119, max value: 0.054313\n",
      "D grad l2-norm: 0.959648, max value: 0.522411\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001005)\n",
      "Loss_D = 1.02402496 (ave = 1.00810575)\n",
      "Loss_G = 0.74554580 (ave = 0.74440150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.020639, max value: 0.055695\n",
      "D grad l2-norm: 0.986042, max value: 0.525501\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.009s / 800 iters, (0.001708)\n",
      "Loss_D = 1.02270877 (ave = 0.99765921)\n",
      "Loss_G = 0.75182194 (ave = 0.74890302)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.033197, max value: 0.060503\n",
      "D grad l2-norm: 0.994597, max value: 0.528473\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.98320985 (ave = 0.98322985)\n",
      "Loss_G = 0.75570709 (ave = 0.75516628)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.044736, max value: 0.062535\n",
      "D grad l2-norm: 1.008689, max value: 0.530284\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.95665503 (ave = 0.97159241)\n",
      "Loss_G = 0.76177007 (ave = 0.75990885)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.052808, max value: 0.062833\n",
      "D grad l2-norm: 1.027503, max value: 0.533121\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 1.00725031 (ave = 0.96937084)\n",
      "Loss_G = 0.76610136 (ave = 0.76401031)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.072979, max value: 0.068344\n",
      "D grad l2-norm: 1.050101, max value: 0.535149\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.93974936 (ave = 0.95578444)\n",
      "Loss_G = 0.76793092 (ave = 0.76661029)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.093859, max value: 0.069051\n",
      "D grad l2-norm: 1.061317, max value: 0.535986\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.96148491 (ave = 0.95252895)\n",
      "Loss_G = 0.77095342 (ave = 0.76799599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.113282, max value: 0.085658\n",
      "D grad l2-norm: 1.084976, max value: 0.537376\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.94174159 (ave = 0.94653817)\n",
      "Loss_G = 0.76978827 (ave = 0.76929530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.130741, max value: 0.098741\n",
      "D grad l2-norm: 1.096327, max value: 0.536820\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.92111731 (ave = 0.94159836)\n",
      "Loss_G = 0.76802951 (ave = 0.76774861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.155481, max value: 0.110017\n",
      "D grad l2-norm: 1.117471, max value: 0.536000\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.93731797 (ave = 0.94008738)\n",
      "Loss_G = 0.76680100 (ave = 0.76840618)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.185726, max value: 0.117980\n",
      "D grad l2-norm: 1.148477, max value: 0.535402\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001019)\n",
      "Loss_D = 0.89837325 (ave = 0.93022946)\n",
      "Loss_G = 0.77099681 (ave = 0.76877704)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.188502, max value: 0.130676\n",
      "D grad l2-norm: 1.164314, max value: 0.537346\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001216)\n",
      "Loss_D = 0.91663492 (ave = 0.92854037)\n",
      "Loss_G = 0.77255034 (ave = 0.77197856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.201510, max value: 0.137140\n",
      "D grad l2-norm: 1.197254, max value: 0.538048\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.007s / 800 iters, (0.001458)\n",
      "Loss_D = 0.91455156 (ave = 0.92249279)\n",
      "Loss_G = 0.77923185 (ave = 0.77529671)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.207818, max value: 0.129387\n",
      "D grad l2-norm: 1.213039, max value: 0.541133\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.90215331 (ave = 0.91329966)\n",
      "Loss_G = 0.78797358 (ave = 0.78514360)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.219295, max value: 0.131528\n",
      "D grad l2-norm: 1.250098, max value: 0.545138\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001758)\n",
      "Loss_D = 0.91007364 (ave = 0.90491577)\n",
      "Loss_G = 0.79885131 (ave = 0.79400215)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.225597, max value: 0.126114\n",
      "D grad l2-norm: 1.278182, max value: 0.550057\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.89655769 (ave = 0.89177173)\n",
      "Loss_G = 0.80829525 (ave = 0.80498320)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.242262, max value: 0.135477\n",
      "D grad l2-norm: 1.304165, max value: 0.554250\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.89491701 (ave = 0.88322306)\n",
      "Loss_G = 0.81972563 (ave = 0.81539379)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.257588, max value: 0.131755\n",
      "D grad l2-norm: 1.331442, max value: 0.559334\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.87155807 (ave = 0.87131704)\n",
      "Loss_G = 0.82538360 (ave = 0.82317238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.309202, max value: 0.125728\n",
      "D grad l2-norm: 1.366341, max value: 0.561784\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.008s / 800 iters, (0.001678)\n",
      "Loss_D = 0.86749184 (ave = 0.86342609)\n",
      "Loss_G = 0.82876289 (ave = 0.82769191)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.354305, max value: 0.134439\n",
      "D grad l2-norm: 1.408527, max value: 0.563231\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002732)\n",
      "Loss_D = 0.86072195 (ave = 0.85770226)\n",
      "Loss_G = 0.83427614 (ave = 0.83503751)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.394363, max value: 0.131843\n",
      "D grad l2-norm: 1.439848, max value: 0.565653\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.012s / 800 iters, (0.002361)\n",
      "Loss_D = 0.87011302 (ave = 0.85498170)\n",
      "Loss_G = 0.84154809 (ave = 0.83631650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.436758, max value: 0.139241\n",
      "D grad l2-norm: 1.492065, max value: 0.568770\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000967)\n",
      "Loss_D = 0.91412628 (ave = 0.85694132)\n",
      "Loss_G = 0.84189260 (ave = 0.83865989)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.486683, max value: 0.147355\n",
      "D grad l2-norm: 1.526981, max value: 0.568890\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.000999)\n",
      "Loss_D = 0.87508631 (ave = 0.84888006)\n",
      "Loss_G = 0.83839989 (ave = 0.84072738)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.532958, max value: 0.140245\n",
      "D grad l2-norm: 1.572684, max value: 0.567259\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.85013437 (ave = 0.84153556)\n",
      "Loss_G = 0.84050214 (ave = 0.84335384)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.589721, max value: 0.141924\n",
      "D grad l2-norm: 1.637312, max value: 0.568204\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001003)\n",
      "Loss_D = 0.84587562 (ave = 0.83866951)\n",
      "Loss_G = 0.85332310 (ave = 0.84779848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.602488, max value: 0.147054\n",
      "D grad l2-norm: 1.683949, max value: 0.573723\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 0.85976708 (ave = 0.83577348)\n",
      "Loss_G = 0.86190522 (ave = 0.85603905)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.624980, max value: 0.148464\n",
      "D grad l2-norm: 1.751897, max value: 0.577314\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.81710684 (ave = 0.82272323)\n",
      "Loss_G = 0.88023221 (ave = 0.87173276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.651786, max value: 0.154170\n",
      "D grad l2-norm: 1.820998, max value: 0.585010\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.81110108 (ave = 0.81217958)\n",
      "Loss_G = 0.88563955 (ave = 0.88271098)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.725923, max value: 0.151217\n",
      "D grad l2-norm: 1.907444, max value: 0.587234\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001030)\n",
      "Loss_D = 0.83558536 (ave = 0.80787253)\n",
      "Loss_G = 0.90201867 (ave = 0.88974630)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.765919, max value: 0.159709\n",
      "D grad l2-norm: 1.976671, max value: 0.593956\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.83322048 (ave = 0.79955943)\n",
      "Loss_G = 0.90982336 (ave = 0.90441204)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.901540, max value: 0.186583\n",
      "D grad l2-norm: 2.124726, max value: 0.597099\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001022)\n",
      "Loss_D = 0.72981310 (ave = 0.77988958)\n",
      "Loss_G = 0.93063706 (ave = 0.92106657)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.946206, max value: 0.214768\n",
      "D grad l2-norm: 2.177536, max value: 0.605314\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 0.87560034 (ave = 0.79304456)\n",
      "Loss_G = 0.94427639 (ave = 0.93560954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.031359, max value: 0.228544\n",
      "D grad l2-norm: 2.274535, max value: 0.610621\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.018s / 800 iters, (0.003543)\n",
      "Loss_D = 0.78147066 (ave = 0.77654681)\n",
      "Loss_G = 0.94763595 (ave = 0.94527446)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.169675, max value: 0.247496\n",
      "D grad l2-norm: 2.377896, max value: 0.611859\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.75846142 (ave = 0.76805429)\n",
      "Loss_G = 0.95961040 (ave = 0.95144736)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.286916, max value: 0.253934\n",
      "D grad l2-norm: 2.458971, max value: 0.616308\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001002)\n",
      "Loss_D = 0.78836983 (ave = 0.78041565)\n",
      "Loss_G = 0.94509912 (ave = 0.94837263)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.484326, max value: 0.272098\n",
      "D grad l2-norm: 2.555249, max value: 0.610765\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001001)\n",
      "Loss_D = 0.73892415 (ave = 0.77934701)\n",
      "Loss_G = 0.93851995 (ave = 0.94708800)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.435676, max value: 0.255473\n",
      "D grad l2-norm: 2.584155, max value: 0.608066\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 0.76352161 (ave = 0.78712429)\n",
      "Loss_G = 0.95263606 (ave = 0.94852993)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.480482, max value: 0.260253\n",
      "D grad l2-norm: 2.718270, max value: 0.613638\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001005)\n",
      "Loss_D = 0.84463197 (ave = 0.79329792)\n",
      "Loss_G = 0.97128564 (ave = 0.96891534)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.531452, max value: 0.269506\n",
      "D grad l2-norm: 2.841739, max value: 0.620725\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 0.89583945 (ave = 0.79389431)\n",
      "Loss_G = 0.99661160 (ave = 0.98702879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.548553, max value: 0.290662\n",
      "D grad l2-norm: 2.936112, max value: 0.630203\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001155)\n",
      "Loss_D = 0.70998347 (ave = 0.75976610)\n",
      "Loss_G = 1.03606129 (ave = 1.01951864)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.533880, max value: 0.284485\n",
      "D grad l2-norm: 3.022233, max value: 0.644544\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.75739825 (ave = 0.75334785)\n",
      "Loss_G = 1.05634975 (ave = 1.04645641)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.713139, max value: 0.295879\n",
      "D grad l2-norm: 3.178616, max value: 0.651620\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000990)\n",
      "Loss_D = 0.66110152 (ave = 0.73886116)\n",
      "Loss_G = 1.07959414 (ave = 1.06932552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.888333, max value: 0.301149\n",
      "D grad l2-norm: 3.297414, max value: 0.659483\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.013s / 800 iters, (0.002650)\n",
      "Loss_D = 0.73773277 (ave = 0.75335033)\n",
      "Loss_G = 1.08253026 (ave = 1.08001318)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.007579, max value: 0.330571\n",
      "D grad l2-norm: 3.328591, max value: 0.660267\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000968)\n",
      "Loss_D = 0.71994549 (ave = 0.76007012)\n",
      "Loss_G = 1.07422268 (ave = 1.07242305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.254298, max value: 0.369183\n",
      "D grad l2-norm: 3.422939, max value: 0.657426\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.016s / 800 iters, (0.003144)\n",
      "Loss_D = 0.74948359 (ave = 0.78127337)\n",
      "Loss_G = 1.05229759 (ave = 1.05745976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.423910, max value: 0.391564\n",
      "D grad l2-norm: 3.467593, max value: 0.649902\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.85885769 (ave = 0.81101395)\n",
      "Loss_G = 1.03813112 (ave = 1.04297023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.520283, max value: 0.389705\n",
      "D grad l2-norm: 3.566325, max value: 0.644761\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000982)\n",
      "Loss_D = 0.87907362 (ave = 0.84089116)\n",
      "Loss_G = 1.00845468 (ave = 1.02036827)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.778322, max value: 0.349017\n",
      "D grad l2-norm: 3.626205, max value: 0.633501\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.008s / 800 iters, (0.001689)\n",
      "Loss_D = 0.95256758 (ave = 0.87349200)\n",
      "Loss_G = 1.00472224 (ave = 1.00289016)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.821526, max value: 0.324280\n",
      "D grad l2-norm: 3.758606, max value: 0.632025\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.85120237 (ave = 0.86752975)\n",
      "Loss_G = 1.00794721 (ave = 1.00699791)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.955650, max value: 0.311735\n",
      "D grad l2-norm: 3.918353, max value: 0.632985\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.95755237 (ave = 0.89241892)\n",
      "Loss_G = 1.02705169 (ave = 1.01689770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.180465, max value: 0.341608\n",
      "D grad l2-norm: 4.107110, max value: 0.639277\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.90136611 (ave = 0.89322512)\n",
      "Loss_G = 1.00354230 (ave = 1.01604486)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.280775, max value: 0.372058\n",
      "D grad l2-norm: 4.229478, max value: 0.631192\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.07269669 (ave = 0.92442818)\n",
      "Loss_G = 1.04530859 (ave = 1.02985280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.392020, max value: 0.374226\n",
      "D grad l2-norm: 4.492655, max value: 0.645874\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.91645575 (ave = 0.90005035)\n",
      "Loss_G = 1.06685603 (ave = 1.04305868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.377086, max value: 0.368824\n",
      "D grad l2-norm: 4.647512, max value: 0.653363\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001039)\n",
      "Loss_D = 0.83294141 (ave = 0.88213700)\n",
      "Loss_G = 1.11577702 (ave = 1.09239693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.481532, max value: 0.369668\n",
      "D grad l2-norm: 4.957739, max value: 0.670218\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.93336153 (ave = 0.88870467)\n",
      "Loss_G = 1.16444361 (ave = 1.14737017)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.568025, max value: 0.368418\n",
      "D grad l2-norm: 5.237695, max value: 0.685424\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.000993)\n",
      "Loss_D = 0.90550178 (ave = 0.85504717)\n",
      "Loss_G = 1.21065092 (ave = 1.20690844)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.653313, max value: 0.420455\n",
      "D grad l2-norm: 5.588921, max value: 0.699207\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.81762636 (ave = 0.82785680)\n",
      "Loss_G = 1.27161157 (ave = 1.24942806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.672552, max value: 0.435115\n",
      "D grad l2-norm: 5.853226, max value: 0.716668\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.65819120 (ave = 0.78410462)\n",
      "Loss_G = 1.33074474 (ave = 1.32015216)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:58:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.847452, max value: 0.449709\n",
      "D grad l2-norm: 6.333378, max value: 0.733641\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.022s / 800 iters, (0.004347)\n",
      "Loss_D = 0.80981898 (ave = 0.77716341)\n",
      "Loss_G = 1.40089822 (ave = 1.39477479)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.928094, max value: 0.484119\n",
      "D grad l2-norm: 6.503023, max value: 0.751937\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002754)\n",
      "Loss_D = 0.78566849 (ave = 0.76390234)\n",
      "Loss_G = 1.45980763 (ave = 1.43360453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.189853, max value: 0.499525\n",
      "D grad l2-norm: 6.684230, max value: 0.765675\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 800 iters, (0.027)\tData load 0.007s / 800 iters, (0.001413)\n",
      "Loss_D = 0.73568296 (ave = 0.74414088)\n",
      "Loss_G = 1.46262848 (ave = 1.46331475)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.397470, max value: 0.513109\n",
      "D grad l2-norm: 6.880406, max value: 0.766393\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.74043059 (ave = 0.73933693)\n",
      "Loss_G = 1.47435093 (ave = 1.48215156)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.508831, max value: 0.517584\n",
      "D grad l2-norm: 6.876159, max value: 0.769338\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.64269376 (ave = 0.72818668)\n",
      "Loss_G = 1.48678339 (ave = 1.49311013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.689522, max value: 0.507693\n",
      "D grad l2-norm: 7.077349, max value: 0.772142\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.81738412 (ave = 0.75070657)\n",
      "Loss_G = 1.50898445 (ave = 1.49739118)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.792985, max value: 0.480402\n",
      "D grad l2-norm: 7.128175, max value: 0.777146\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.76037490 (ave = 0.73842421)\n",
      "Loss_G = 1.49385953 (ave = 1.49316270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.913247, max value: 0.465223\n",
      "D grad l2-norm: 7.096278, max value: 0.773744\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 0.87374443 (ave = 0.75646619)\n",
      "Loss_G = 1.50036967 (ave = 1.48187761)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.728353, max value: 0.458863\n",
      "D grad l2-norm: 6.791178, max value: 0.775186\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.80845004 (ave = 0.74945881)\n",
      "Loss_G = 1.49339092 (ave = 1.48910153)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.816637, max value: 0.454066\n",
      "D grad l2-norm: 6.855133, max value: 0.773561\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.78134155 (ave = 0.74321388)\n",
      "Loss_G = 1.47862816 (ave = 1.47257550)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.876781, max value: 0.498154\n",
      "D grad l2-norm: 6.813414, max value: 0.770584\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001019)\n",
      "Loss_D = 0.84135354 (ave = 0.74970613)\n",
      "Loss_G = 1.47244954 (ave = 1.47995334)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.265975, max value: 0.540103\n",
      "D grad l2-norm: 6.820131, max value: 0.767858\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.80909646 (ave = 0.75479993)\n",
      "Loss_G = 1.39822340 (ave = 1.44025338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.372005, max value: 0.580871\n",
      "D grad l2-norm: 6.612168, max value: 0.750227\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001014)\n",
      "Loss_D = 0.95940244 (ave = 0.78877316)\n",
      "Loss_G = 1.38200486 (ave = 1.41158304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.589543, max value: 0.607037\n",
      "D grad l2-norm: 6.533052, max value: 0.745810\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001030)\n",
      "Loss_D = 0.82553023 (ave = 0.78931020)\n",
      "Loss_G = 1.29713476 (ave = 1.33100190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.687920, max value: 0.592011\n",
      "D grad l2-norm: 6.458510, max value: 0.723020\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000996)\n",
      "Loss_D = 0.80876267 (ave = 0.80984991)\n",
      "Loss_G = 1.28254271 (ave = 1.30150719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.405120, max value: 0.580356\n",
      "D grad l2-norm: 6.164434, max value: 0.719840\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001020)\n",
      "Loss_D = 0.86701119 (ave = 0.83414706)\n",
      "Loss_G = 1.26889932 (ave = 1.27539811)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.296706, max value: 0.557902\n",
      "D grad l2-norm: 6.108171, max value: 0.715129\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.000999)\n",
      "Loss_D = 0.97053486 (ave = 0.85683981)\n",
      "Loss_G = 1.23751044 (ave = 1.24584436)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.494892, max value: 0.545195\n",
      "D grad l2-norm: 6.257916, max value: 0.706464\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.93586302 (ave = 0.86102707)\n",
      "Loss_G = 1.23398089 (ave = 1.23918543)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.445487, max value: 0.539317\n",
      "D grad l2-norm: 5.986116, max value: 0.704179\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001034)\n",
      "Loss_D = 0.75228524 (ave = 0.85077630)\n",
      "Loss_G = 1.18504977 (ave = 1.20247130)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.668483, max value: 0.515240\n",
      "D grad l2-norm: 6.098107, max value: 0.689161\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 0.93906760 (ave = 0.88699645)\n",
      "Loss_G = 1.18707228 (ave = 1.19402187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.331851, max value: 0.484074\n",
      "D grad l2-norm: 5.993522, max value: 0.689305\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.009s / 800 iters, (0.001866)\n",
      "Loss_D = 0.92834806 (ave = 0.88464029)\n",
      "Loss_G = 1.19856477 (ave = 1.20006759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.460719, max value: 0.456426\n",
      "D grad l2-norm: 6.194667, max value: 0.693470\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.82045627 (ave = 0.86269754)\n",
      "Loss_G = 1.24876297 (ave = 1.22842641)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.401770, max value: 0.427605\n",
      "D grad l2-norm: 6.471617, max value: 0.709502\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.89360678 (ave = 0.85069861)\n",
      "Loss_G = 1.30371952 (ave = 1.27301135)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.474526, max value: 0.404121\n",
      "D grad l2-norm: 6.779950, max value: 0.724366\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.77033561 (ave = 0.81273723)\n",
      "Loss_G = 1.34119976 (ave = 1.32301302)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.570039, max value: 0.417061\n",
      "D grad l2-norm: 7.020728, max value: 0.734097\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.84591824 (ave = 0.80823356)\n",
      "Loss_G = 1.40237641 (ave = 1.36688910)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.772250, max value: 0.443577\n",
      "D grad l2-norm: 7.500445, max value: 0.750611\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.66527551 (ave = 0.76300187)\n",
      "Loss_G = 1.47622681 (ave = 1.42246549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.077229, max value: 0.495921\n",
      "D grad l2-norm: 7.925480, max value: 0.768443\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.67103732 (ave = 0.74557621)\n",
      "Loss_G = 1.53497338 (ave = 1.49516630)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.140004, max value: 0.533278\n",
      "D grad l2-norm: 8.015040, max value: 0.782022\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 0.70974177 (ave = 0.73485180)\n",
      "Loss_G = 1.52710605 (ave = 1.51173608)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.607474, max value: 0.565597\n",
      "D grad l2-norm: 8.509297, max value: 0.779165\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.71142042 (ave = 0.72182392)\n",
      "Loss_G = 1.57360387 (ave = 1.55613821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.434651, max value: 0.593642\n",
      "D grad l2-norm: 8.630536, max value: 0.789592\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.69133669 (ave = 0.69810913)\n",
      "Loss_G = 1.63037550 (ave = 1.60526326)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.267573, max value: 0.611437\n",
      "D grad l2-norm: 8.919443, max value: 0.801411\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.50270844 (ave = 0.64892188)\n",
      "Loss_G = 1.72242367 (ave = 1.69261615)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.934772, max value: 0.591271\n",
      "D grad l2-norm: 8.948028, max value: 0.819038\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.58200240 (ave = 0.63283433)\n",
      "Loss_G = 1.76862633 (ave = 1.75947113)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.227926, max value: 0.656261\n",
      "D grad l2-norm: 9.469104, max value: 0.861817\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001199)\n",
      "Loss_D = 0.62320590 (ave = 0.62398283)\n",
      "Loss_G = 1.77906656 (ave = 1.78464997)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.906413, max value: 0.572847\n",
      "D grad l2-norm: 9.081519, max value: 0.834944\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 0.53103906 (ave = 0.59700224)\n",
      "Loss_G = 1.80045128 (ave = 1.80717571)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.344513, max value: 0.595368\n",
      "D grad l2-norm: 9.468447, max value: 0.869035\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001166)\n",
      "Loss_D = 0.55453849 (ave = 0.59508243)\n",
      "Loss_G = 1.81506419 (ave = 1.80772195)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.434890, max value: 0.582910\n",
      "D grad l2-norm: 9.390074, max value: 0.861175\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.61060297 (ave = 0.59981148)\n",
      "Loss_G = 1.75551689 (ave = 1.80488415)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.430080, max value: 0.588543\n",
      "D grad l2-norm: 9.220119, max value: 0.824969\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.71167243 (ave = 0.61725347)\n",
      "Loss_G = 1.71937943 (ave = 1.75598800)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.628772, max value: 0.591185\n",
      "D grad l2-norm: 9.226570, max value: 0.839186\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.55465651 (ave = 0.60221825)\n",
      "Loss_G = 1.68339920 (ave = 1.71239119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.826111, max value: 0.593365\n",
      "D grad l2-norm: 9.128144, max value: 0.855193\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 0.66410553 (ave = 0.62978077)\n",
      "Loss_G = 1.61231124 (ave = 1.64864380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.780911, max value: 0.552287\n",
      "D grad l2-norm: 8.846174, max value: 0.853876\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001240)\n",
      "Loss_D = 0.51109010 (ave = 0.62467757)\n",
      "Loss_G = 1.62543631 (ave = 1.62032921)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.759456, max value: 0.552643\n",
      "D grad l2-norm: 8.674292, max value: 0.861379\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 0.60591757 (ave = 0.65133448)\n",
      "Loss_G = 1.56229675 (ave = 1.58826594)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.083987, max value: 0.557676\n",
      "D grad l2-norm: 8.494084, max value: 0.836805\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 0.81472468 (ave = 0.70783553)\n",
      "Loss_G = 1.53398299 (ave = 1.54101875)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.684721, max value: 0.532613\n",
      "D grad l2-norm: 8.506829, max value: 0.827042\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 0.72809529 (ave = 0.73206042)\n",
      "Loss_G = 1.46508563 (ave = 1.46663105)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.723223, max value: 0.536797\n",
      "D grad l2-norm: 8.349203, max value: 0.772959\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.88498747 (ave = 0.77058806)\n",
      "Loss_G = 1.42334783 (ave = 1.42803433)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.359896, max value: 0.551180\n",
      "D grad l2-norm: 8.200635, max value: 0.753042\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.68220705 (ave = 0.74510731)\n",
      "Loss_G = 1.44773901 (ave = 1.44216337)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.418223, max value: 0.562176\n",
      "D grad l2-norm: 8.555557, max value: 0.759109\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.58956838 (ave = 0.72630557)\n",
      "Loss_G = 1.52063012 (ave = 1.47135682)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.532216, max value: 0.568845\n",
      "D grad l2-norm: 8.792449, max value: 0.776483\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002753)\n",
      "Loss_D = 0.73444450 (ave = 0.74114499)\n",
      "Loss_G = 1.52518940 (ave = 1.50956538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.388443, max value: 0.585240\n",
      "D grad l2-norm: 8.734812, max value: 0.778332\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.80451435 (ave = 0.74449284)\n",
      "Loss_G = 1.52830863 (ave = 1.52455032)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.619823, max value: 0.612844\n",
      "D grad l2-norm: 8.995375, max value: 0.809969\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002782)\n",
      "Loss_D = 0.64363873 (ave = 0.71522089)\n",
      "Loss_G = 1.53111660 (ave = 1.51542192)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.904639, max value: 0.635968\n",
      "D grad l2-norm: 9.212372, max value: 0.833174\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.58783597 (ave = 0.70547904)\n",
      "Loss_G = 1.59992254 (ave = 1.55993814)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.617594, max value: 0.637216\n",
      "D grad l2-norm: 9.273508, max value: 0.836397\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.73623812 (ave = 0.70668643)\n",
      "Loss_G = 1.59331870 (ave = 1.56544333)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.771842, max value: 0.603856\n",
      "D grad l2-norm: 9.512904, max value: 0.859992\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.79803628 (ave = 0.70816852)\n",
      "Loss_G = 1.59592783 (ave = 1.58157482)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.900541, max value: 0.627310\n",
      "D grad l2-norm: 9.666055, max value: 0.865456\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.73074734 (ave = 0.68935611)\n",
      "Loss_G = 1.63864803 (ave = 1.59930084)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.921000, max value: 0.623208\n",
      "D grad l2-norm: 9.644494, max value: 0.842034\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.010s / 800 iters, (0.002078)\n",
      "Loss_D = 0.74046779 (ave = 0.68319144)\n",
      "Loss_G = 1.61912513 (ave = 1.61310122)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.300297, max value: 0.673358\n",
      "D grad l2-norm: 9.660761, max value: 0.808511\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.72108883 (ave = 0.69367560)\n",
      "Loss_G = 1.55643797 (ave = 1.57811608)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.065645, max value: 0.727991\n",
      "D grad l2-norm: 9.761841, max value: 0.791224\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.71058494 (ave = 0.71030329)\n",
      "Loss_G = 1.49153709 (ave = 1.52600551)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.409263, max value: 0.774650\n",
      "D grad l2-norm: 9.703005, max value: 0.768528\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.71260941 (ave = 0.73579142)\n",
      "Loss_G = 1.45372248 (ave = 1.46048880)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.446847, max value: 0.801311\n",
      "D grad l2-norm: 9.546633, max value: 0.758329\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.73243320 (ave = 0.75472205)\n",
      "Loss_G = 1.42963398 (ave = 1.44347177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.438471, max value: 0.754817\n",
      "D grad l2-norm: 9.435659, max value: 0.755844\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 0.51918554 (ave = 0.74777884)\n",
      "Loss_G = 1.38980556 (ave = 1.38833280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.199598, max value: 0.763909\n",
      "D grad l2-norm: 9.107754, max value: 0.740178\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.93903828 (ave = 0.81538136)\n",
      "Loss_G = 1.39961672 (ave = 1.37437389)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.933474, max value: 0.708177\n",
      "D grad l2-norm: 8.918653, max value: 0.745000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.81374031 (ave = 0.81071519)\n",
      "Loss_G = 1.35639989 (ave = 1.36009238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.550987, max value: 0.652730\n",
      "D grad l2-norm: 8.688243, max value: 0.733903\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 0.90678346 (ave = 0.81160884)\n",
      "Loss_G = 1.36931658 (ave = 1.37431014)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.698433, max value: 0.643975\n",
      "D grad l2-norm: 8.955788, max value: 0.738979\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.75712192 (ave = 0.80816536)\n",
      "Loss_G = 1.38880718 (ave = 1.37364666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.221011, max value: 0.644183\n",
      "D grad l2-norm: 8.536558, max value: 0.742144\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.95257467 (ave = 0.81572804)\n",
      "Loss_G = 1.36605990 (ave = 1.36825695)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.984852, max value: 0.579127\n",
      "D grad l2-norm: 8.370214, max value: 0.736598\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.017s / 800 iters, (0.003488)\n",
      "Loss_D = 0.78273195 (ave = 0.79073861)\n",
      "Loss_G = 1.42430925 (ave = 1.41569870)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.308524, max value: 0.637583\n",
      "D grad l2-norm: 8.867299, max value: 0.750004\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 0.76208502 (ave = 0.77847476)\n",
      "Loss_G = 1.39856613 (ave = 1.42675109)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.396814, max value: 0.740469\n",
      "D grad l2-norm: 8.785434, max value: 0.746142\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002782)\n",
      "Loss_D = 0.79346895 (ave = 0.78578781)\n",
      "Loss_G = 1.40686870 (ave = 1.41527135)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.595678, max value: 0.830805\n",
      "D grad l2-norm: 8.903998, max value: 0.777504\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 0.70168078 (ave = 0.78886020)\n",
      "Loss_G = 1.40377665 (ave = 1.40591726)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.758380, max value: 0.873285\n",
      "D grad l2-norm: 8.949438, max value: 0.805688\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.89642787 (ave = 0.81254196)\n",
      "Loss_G = 1.38049507 (ave = 1.38324270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.857303, max value: 0.867150\n",
      "D grad l2-norm: 9.218655, max value: 0.845736\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.75360858 (ave = 0.79246602)\n",
      "Loss_G = 1.44296253 (ave = 1.42552030)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.063240, max value: 0.881239\n",
      "D grad l2-norm: 9.494742, max value: 0.892250\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.59317803 (ave = 0.76568468)\n",
      "Loss_G = 1.45764732 (ave = 1.46238520)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.027673, max value: 0.874749\n",
      "D grad l2-norm: 9.488656, max value: 0.895035\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001001)\n",
      "Loss_D = 0.95792365 (ave = 0.80289081)\n",
      "Loss_G = 1.47595704 (ave = 1.46187196)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.202617, max value: 0.868575\n",
      "D grad l2-norm: 9.916784, max value: 0.943222\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.010s / 800 iters, (0.001974)\n",
      "Loss_D = 0.98194319 (ave = 0.78865565)\n",
      "Loss_G = 1.50528932 (ave = 1.48882585)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.039179, max value: 0.795138\n",
      "D grad l2-norm: 9.975501, max value: 0.953328\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.87462181 (ave = 0.76594702)\n",
      "Loss_G = 1.50467360 (ave = 1.52689233)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.320669, max value: 0.825473\n",
      "D grad l2-norm: 10.147941, max value: 0.938215\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 0.75485384 (ave = 0.74590907)\n",
      "Loss_G = 1.59974122 (ave = 1.58788855)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.812414, max value: 0.877650\n",
      "D grad l2-norm: 10.564650, max value: 0.962636\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.71581602 (ave = 0.73595244)\n",
      "Loss_G = 1.61103177 (ave = 1.59457564)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.594774, max value: 0.908219\n",
      "D grad l2-norm: 11.242212, max value: 0.982459\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.78489983 (ave = 0.75969762)\n",
      "Loss_G = 1.61049104 (ave = 1.60554106)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.980839, max value: 0.887775\n",
      "D grad l2-norm: 11.534729, max value: 1.038521\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.80530107 (ave = 0.76343515)\n",
      "Loss_G = 1.58673954 (ave = 1.60455346)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.067702, max value: 0.916442\n",
      "D grad l2-norm: 11.484859, max value: 1.039444\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.011s / 800 iters, (0.002201)\n",
      "Loss_D = 0.73651677 (ave = 0.76251950)\n",
      "Loss_G = 1.58868337 (ave = 1.57992072)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.922523, max value: 0.919955\n",
      "D grad l2-norm: 12.216222, max value: 1.114575\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.85951257 (ave = 0.79355491)\n",
      "Loss_G = 1.54133916 (ave = 1.56277997)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.963056, max value: 0.836039\n",
      "D grad l2-norm: 12.140640, max value: 1.104224\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.94992685 (ave = 0.82318683)\n",
      "Loss_G = 1.56749249 (ave = 1.57794437)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.782447, max value: 0.884571\n",
      "D grad l2-norm: 11.985085, max value: 1.081423\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.94708902 (ave = 0.82616857)\n",
      "Loss_G = 1.58431530 (ave = 1.60314243)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.956187, max value: 0.926642\n",
      "D grad l2-norm: 12.452618, max value: 1.101132\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.83126444 (ave = 0.81190028)\n",
      "Loss_G = 1.56442773 (ave = 1.58151302)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.993254, max value: 0.963579\n",
      "D grad l2-norm: 12.807129, max value: 1.078797\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 0.89875650 (ave = 0.82663649)\n",
      "Loss_G = 1.68352354 (ave = 1.64596093)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.882223, max value: 1.009425\n",
      "D grad l2-norm: 12.910006, max value: 1.092590\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.82771575 (ave = 0.80653121)\n",
      "Loss_G = 1.69410682 (ave = 1.67990513)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 13.154290, max value: 1.122971\n",
      "D grad l2-norm: 12.905125, max value: 1.120440\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.79938042 (ave = 0.82761142)\n",
      "Loss_G = 1.65124404 (ave = 1.64946718)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 14.155318, max value: 1.259168\n",
      "D grad l2-norm: 13.366907, max value: 1.144301\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.66729498 (ave = 0.83690594)\n",
      "Loss_G = 1.69357920 (ave = 1.66010067)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 13.723511, max value: 1.271243\n",
      "D grad l2-norm: 13.348913, max value: 1.146987\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.68155831 (ave = 0.84541585)\n",
      "Loss_G = 1.69298255 (ave = 1.67613847)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 13.629388, max value: 1.303418\n",
      "D grad l2-norm: 13.632103, max value: 1.149924\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002753)\n",
      "Loss_D = 1.02549946 (ave = 0.89644283)\n",
      "Loss_G = 1.70373571 (ave = 1.68987577)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 13.200219, max value: 1.184047\n",
      "D grad l2-norm: 13.424988, max value: 1.130003\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.90749657 (ave = 0.88764237)\n",
      "Loss_G = 1.66049898 (ave = 1.67515390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.911869, max value: 1.158193\n",
      "D grad l2-norm: 13.329935, max value: 1.113918\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.96756303 (ave = 0.90949149)\n",
      "Loss_G = 1.70663047 (ave = 1.71314549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.878991, max value: 1.115231\n",
      "D grad l2-norm: 13.213186, max value: 1.078322\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.90975225 (ave = 0.90000392)\n",
      "Loss_G = 1.69125593 (ave = 1.68424058)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.784252, max value: 1.049084\n",
      "D grad l2-norm: 13.293783, max value: 1.068792\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.81746340 (ave = 0.89808595)\n",
      "Loss_G = 1.68762481 (ave = 1.65995374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.959036, max value: 0.883081\n",
      "D grad l2-norm: 12.861179, max value: 1.004774\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.89000857 (ave = 0.90076274)\n",
      "Loss_G = 1.65434408 (ave = 1.68773808)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.315095, max value: 0.811660\n",
      "D grad l2-norm: 12.211148, max value: 0.990895\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.58637261 (ave = 0.85781504)\n",
      "Loss_G = 1.66148460 (ave = 1.66709297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.001424, max value: 0.757803\n",
      "D grad l2-norm: 12.234558, max value: 1.076315\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.68908185 (ave = 0.85996624)\n",
      "Loss_G = 1.68134868 (ave = 1.69278584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.383757, max value: 0.665054\n",
      "D grad l2-norm: 12.091742, max value: 1.136346\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 1.05468023 (ave = 0.88895382)\n",
      "Loss_G = 1.72840345 (ave = 1.71865466)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.974219, max value: 0.636057\n",
      "D grad l2-norm: 12.098007, max value: 1.200560\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.81572670 (ave = 0.83848829)\n",
      "Loss_G = 1.73612773 (ave = 1.73233728)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.320209, max value: 0.551683\n",
      "D grad l2-norm: 11.670736, max value: 1.204523\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.63154590 (ave = 0.78935740)\n",
      "Loss_G = 1.78391230 (ave = 1.75747287)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.983635, max value: 0.499024\n",
      "D grad l2-norm: 11.543634, max value: 1.231912\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.70119989 (ave = 0.76987566)\n",
      "Loss_G = 1.82778907 (ave = 1.79440997)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.926023, max value: 0.449731\n",
      "D grad l2-norm: 11.701474, max value: 1.284104\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.76792991 (ave = 0.75358256)\n",
      "Loss_G = 1.81550574 (ave = 1.81862338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.671117, max value: 0.435469\n",
      "D grad l2-norm: 11.389327, max value: 1.269107\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.67859900 (ave = 0.71609173)\n",
      "Loss_G = 1.81284535 (ave = 1.81282172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.587803, max value: 0.456448\n",
      "D grad l2-norm: 11.278375, max value: 1.262788\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.57098722 (ave = 0.67672161)\n",
      "Loss_G = 1.82138395 (ave = 1.82826653)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.842764, max value: 0.519484\n",
      "D grad l2-norm: 11.171629, max value: 1.253554\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.86230433 (ave = 0.69205427)\n",
      "Loss_G = 1.80870891 (ave = 1.80220096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.958590, max value: 0.573332\n",
      "D grad l2-norm: 11.057810, max value: 1.224954\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.61221433 (ave = 0.64873850)\n",
      "Loss_G = 1.76591742 (ave = 1.78494256)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.017469, max value: 0.602833\n",
      "D grad l2-norm: 10.897270, max value: 1.176515\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.012s / 800 iters, (0.002372)\n",
      "Loss_D = 0.53853267 (ave = 0.62437168)\n",
      "Loss_G = 1.74694872 (ave = 1.76148498)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.092897, max value: 0.643397\n",
      "D grad l2-norm: 10.668806, max value: 1.119588\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.51156318 (ave = 0.61177298)\n",
      "Loss_G = 1.71456182 (ave = 1.74531498)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.389193, max value: 0.668997\n",
      "D grad l2-norm: 10.425005, max value: 1.050133\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.58537179 (ave = 0.61602799)\n",
      "Loss_G = 1.68182027 (ave = 1.70633743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.826783, max value: 0.679873\n",
      "D grad l2-norm: 10.457005, max value: 1.013083\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.009s / 800 iters, (0.001724)\n",
      "Loss_D = 0.56649756 (ave = 0.61826274)\n",
      "Loss_G = 1.67936575 (ave = 1.66277552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.957869, max value: 0.652834\n",
      "D grad l2-norm: 10.470802, max value: 1.020284\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 0.62545025 (ave = 0.62355136)\n",
      "Loss_G = 1.62189031 (ave = 1.63694642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.658211, max value: 0.642151\n",
      "D grad l2-norm: 10.101780, max value: 0.959368\n",
      "üîÅ TSCV for Asset 1\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.39038420 (ave = 1.39934056)\n",
      "Loss_G = 0.69919246 (ave = 0.70075157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.959920, max value: 0.028195\n",
      "D grad l2-norm: 0.679569, max value: 0.503012\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.36530614 (ave = 1.38278482)\n",
      "Loss_G = 0.69531357 (ave = 0.69669557)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961079, max value: 0.021186\n",
      "D grad l2-norm: 0.676614, max value: 0.501080\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 1.36769295 (ave = 1.36943638)\n",
      "Loss_G = 0.69211584 (ave = 0.69305849)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969049, max value: 0.019296\n",
      "D grad l2-norm: 0.676303, max value: 0.499482\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.35442042 (ave = 1.35495076)\n",
      "Loss_G = 0.68943018 (ave = 0.69041224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968118, max value: 0.026838\n",
      "D grad l2-norm: 0.676008, max value: 0.498136\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 1.33973658 (ave = 1.34049919)\n",
      "Loss_G = 0.68670779 (ave = 0.68776798)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964715, max value: 0.021928\n",
      "D grad l2-norm: 0.676673, max value: 0.496768\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.33115661 (ave = 1.32749510)\n",
      "Loss_G = 0.68428779 (ave = 0.68544072)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965022, max value: 0.022039\n",
      "D grad l2-norm: 0.679140, max value: 0.495547\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001009)\n",
      "Loss_D = 1.29567790 (ave = 1.31163528)\n",
      "Loss_G = 0.68232006 (ave = 0.68346126)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967584, max value: 0.026824\n",
      "D grad l2-norm: 0.683152, max value: 0.494554\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.007s / 800 iters, (0.001497)\n",
      "Loss_D = 1.29319382 (ave = 1.29995837)\n",
      "Loss_G = 0.68124121 (ave = 0.68157637)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969366, max value: 0.020028\n",
      "D grad l2-norm: 0.684549, max value: 0.494009\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 1.29172730 (ave = 1.28863873)\n",
      "Loss_G = 0.67963046 (ave = 0.68014547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964004, max value: 0.020080\n",
      "D grad l2-norm: 0.688293, max value: 0.493191\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.26441646 (ave = 1.27461278)\n",
      "Loss_G = 0.67839450 (ave = 0.67879679)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968684, max value: 0.021169\n",
      "D grad l2-norm: 0.693399, max value: 0.492565\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000952)\n",
      "Loss_D = 1.26409745 (ave = 1.26409791)\n",
      "Loss_G = 0.67774564 (ave = 0.67770814)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967036, max value: 0.021518\n",
      "D grad l2-norm: 0.698258, max value: 0.492236\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001766)\n",
      "Loss_D = 1.25056291 (ave = 1.25186880)\n",
      "Loss_G = 0.67663890 (ave = 0.67715652)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971898, max value: 0.023211\n",
      "D grad l2-norm: 0.703210, max value: 0.491672\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.24807858 (ave = 1.24105949)\n",
      "Loss_G = 0.67675889 (ave = 0.67674344)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964369, max value: 0.024632\n",
      "D grad l2-norm: 0.708677, max value: 0.491733\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.22068572 (ave = 1.22794967)\n",
      "Loss_G = 0.67596316 (ave = 0.67636713)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971755, max value: 0.020069\n",
      "D grad l2-norm: 0.714952, max value: 0.491327\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 1.20668352 (ave = 1.21611502)\n",
      "Loss_G = 0.67684042 (ave = 0.67615298)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967686, max value: 0.026992\n",
      "D grad l2-norm: 0.721721, max value: 0.491772\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.19842696 (ave = 1.20585887)\n",
      "Loss_G = 0.67664063 (ave = 0.67671207)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970877, max value: 0.028908\n",
      "D grad l2-norm: 0.728646, max value: 0.491670\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 1.17976534 (ave = 1.19358270)\n",
      "Loss_G = 0.67756641 (ave = 0.67739164)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967227, max value: 0.019731\n",
      "D grad l2-norm: 0.736262, max value: 0.492142\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 1.17039680 (ave = 1.18258901)\n",
      "Loss_G = 0.67950845 (ave = 0.67856448)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966602, max value: 0.028183\n",
      "D grad l2-norm: 0.744932, max value: 0.493126\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 1.16358614 (ave = 1.17214856)\n",
      "Loss_G = 0.68040121 (ave = 0.67968516)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969065, max value: 0.023421\n",
      "D grad l2-norm: 0.752672, max value: 0.493576\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.155s / 800 iters, (0.031)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 1.16816616 (ave = 1.16320150)\n",
      "Loss_G = 0.68199670 (ave = 0.68162124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974315, max value: 0.032549\n",
      "D grad l2-norm: 0.761373, max value: 0.494376\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002713)\n",
      "Loss_D = 1.14639056 (ave = 1.15125339)\n",
      "Loss_G = 0.68454266 (ave = 0.68327563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975793, max value: 0.031419\n",
      "D grad l2-norm: 0.769677, max value: 0.495668\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001031)\n",
      "Loss_D = 1.12523210 (ave = 1.13930960)\n",
      "Loss_G = 0.68560684 (ave = 0.68585403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977656, max value: 0.036451\n",
      "D grad l2-norm: 0.783900, max value: 0.496201\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.000999)\n",
      "Loss_D = 1.14111292 (ave = 1.13217959)\n",
      "Loss_G = 0.68996716 (ave = 0.68872150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971602, max value: 0.035940\n",
      "D grad l2-norm: 0.793104, max value: 0.498394\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.12234712 (ave = 1.12004333)\n",
      "Loss_G = 0.69368982 (ave = 0.69124691)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977600, max value: 0.041065\n",
      "D grad l2-norm: 0.806539, max value: 0.500255\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 1.08919573 (ave = 1.10680363)\n",
      "Loss_G = 0.69696188 (ave = 0.69476825)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.978183, max value: 0.045446\n",
      "D grad l2-norm: 0.817513, max value: 0.501887\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.08945954 (ave = 1.09754329)\n",
      "Loss_G = 0.70048547 (ave = 0.69832810)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979234, max value: 0.034710\n",
      "D grad l2-norm: 0.834077, max value: 0.503638\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 1.05662441 (ave = 1.08395269)\n",
      "Loss_G = 0.70477688 (ave = 0.70324380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.981752, max value: 0.042117\n",
      "D grad l2-norm: 0.849267, max value: 0.505763\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.06153584 (ave = 1.07448993)\n",
      "Loss_G = 0.70968950 (ave = 0.70804602)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.982575, max value: 0.045845\n",
      "D grad l2-norm: 0.868311, max value: 0.508179\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 1.07400787 (ave = 1.06628921)\n",
      "Loss_G = 0.71546173 (ave = 0.71368089)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984849, max value: 0.041791\n",
      "D grad l2-norm: 0.884365, max value: 0.511011\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000994)\n",
      "Loss_D = 1.03518081 (ave = 1.05175364)\n",
      "Loss_G = 0.72036898 (ave = 0.71824112)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.987225, max value: 0.046557\n",
      "D grad l2-norm: 0.905809, max value: 0.513402\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 1.01850522 (ave = 1.03970432)\n",
      "Loss_G = 0.72763634 (ave = 0.72499139)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.989571, max value: 0.042482\n",
      "D grad l2-norm: 0.917118, max value: 0.516934\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 1.03270388 (ave = 1.03152828)\n",
      "Loss_G = 0.73432654 (ave = 0.73244427)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984816, max value: 0.036737\n",
      "D grad l2-norm: 0.937964, max value: 0.520145\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001227)\n",
      "Loss_D = 1.02683794 (ave = 1.02028499)\n",
      "Loss_G = 0.74142766 (ave = 0.73962123)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991635, max value: 0.035104\n",
      "D grad l2-norm: 0.960354, max value: 0.523539\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.000989)\n",
      "Loss_D = 1.00870037 (ave = 1.00762720)\n",
      "Loss_G = 0.75129330 (ave = 0.74789528)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991387, max value: 0.036958\n",
      "D grad l2-norm: 0.977807, max value: 0.528214\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 0.94676197 (ave = 0.98907782)\n",
      "Loss_G = 0.75896925 (ave = 0.75553102)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.994219, max value: 0.042322\n",
      "D grad l2-norm: 1.001191, max value: 0.531829\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.98019099 (ave = 0.98386997)\n",
      "Loss_G = 0.76651329 (ave = 0.76379414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.001273, max value: 0.049178\n",
      "D grad l2-norm: 1.026956, max value: 0.535336\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.96758354 (ave = 0.97064768)\n",
      "Loss_G = 0.77704209 (ave = 0.77256833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.999488, max value: 0.039560\n",
      "D grad l2-norm: 1.038094, max value: 0.540200\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.96463764 (ave = 0.96053900)\n",
      "Loss_G = 0.78393167 (ave = 0.78096793)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.012017, max value: 0.059559\n",
      "D grad l2-norm: 1.062929, max value: 0.543356\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.93691599 (ave = 0.94770353)\n",
      "Loss_G = 0.79008728 (ave = 0.78830161)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.018882, max value: 0.059835\n",
      "D grad l2-norm: 1.100083, max value: 0.546151\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 0.92371297 (ave = 0.93626726)\n",
      "Loss_G = 0.80168039 (ave = 0.79708109)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.023511, max value: 0.066153\n",
      "D grad l2-norm: 1.114739, max value: 0.551380\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.015s / 800 iters, (0.003083)\n",
      "Loss_D = 0.94992763 (ave = 0.92934514)\n",
      "Loss_G = 0.80891776 (ave = 0.80562563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.035519, max value: 0.078916\n",
      "D grad l2-norm: 1.142428, max value: 0.554613\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.92629302 (ave = 0.91606510)\n",
      "Loss_G = 0.81865561 (ave = 0.81448197)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.041833, max value: 0.089721\n",
      "D grad l2-norm: 1.169581, max value: 0.558923\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000977)\n",
      "Loss_D = 0.89023578 (ave = 0.90287631)\n",
      "Loss_G = 0.82122779 (ave = 0.82243845)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.065344, max value: 0.089618\n",
      "D grad l2-norm: 1.215927, max value: 0.560027\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.92292929 (ave = 0.89716969)\n",
      "Loss_G = 0.83469462 (ave = 0.83133970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.064359, max value: 0.093581\n",
      "D grad l2-norm: 1.235177, max value: 0.565923\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 0.88736773 (ave = 0.88509040)\n",
      "Loss_G = 0.84124482 (ave = 0.84001194)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.090670, max value: 0.100501\n",
      "D grad l2-norm: 1.271596, max value: 0.568750\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.011s / 800 iters, (0.002249)\n",
      "Loss_D = 0.87464917 (ave = 0.87573211)\n",
      "Loss_G = 0.85212934 (ave = 0.84837228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.096191, max value: 0.106952\n",
      "D grad l2-norm: 1.291361, max value: 0.573420\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 0.86468273 (ave = 0.86600792)\n",
      "Loss_G = 0.86241043 (ave = 0.85759542)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.113174, max value: 0.112581\n",
      "D grad l2-norm: 1.328069, max value: 0.577781\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 0.82514656 (ave = 0.85260514)\n",
      "Loss_G = 0.86986637 (ave = 0.86375725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.138889, max value: 0.110427\n",
      "D grad l2-norm: 1.357671, max value: 0.580913\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.009s / 800 iters, (0.001872)\n",
      "Loss_D = 0.82971847 (ave = 0.84749068)\n",
      "Loss_G = 0.87961704 (ave = 0.87381774)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.156076, max value: 0.106878\n",
      "D grad l2-norm: 1.384963, max value: 0.584984\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.86030602 (ave = 0.84359407)\n",
      "Loss_G = 0.88713211 (ave = 0.88366206)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.188051, max value: 0.120315\n",
      "D grad l2-norm: 1.436590, max value: 0.588043\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.84806287 (ave = 0.83537967)\n",
      "Loss_G = 0.89655447 (ave = 0.88947769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.209536, max value: 0.121969\n",
      "D grad l2-norm: 1.462932, max value: 0.591927\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000989)\n",
      "Loss_D = 0.81029820 (ave = 0.82526278)\n",
      "Loss_G = 0.89779019 (ave = 0.89633130)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.250866, max value: 0.140527\n",
      "D grad l2-norm: 1.512001, max value: 0.592434\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.82595706 (ave = 0.82229686)\n",
      "Loss_G = 0.90224344 (ave = 0.90308893)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.291356, max value: 0.148163\n",
      "D grad l2-norm: 1.529568, max value: 0.594195\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.77576101 (ave = 0.81323692)\n",
      "Loss_G = 0.91075218 (ave = 0.90635477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.293501, max value: 0.129774\n",
      "D grad l2-norm: 1.519251, max value: 0.597594\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.87649477 (ave = 0.82641258)\n",
      "Loss_G = 0.90278941 (ave = 0.90759625)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.355292, max value: 0.136894\n",
      "D grad l2-norm: 1.567533, max value: 0.594373\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.83602756 (ave = 0.82265288)\n",
      "Loss_G = 0.90448564 (ave = 0.90338541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.367141, max value: 0.133679\n",
      "D grad l2-norm: 1.560188, max value: 0.595059\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.84780443 (ave = 0.82545112)\n",
      "Loss_G = 0.90220976 (ave = 0.89972951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.412957, max value: 0.148609\n",
      "D grad l2-norm: 1.579693, max value: 0.594107\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.77827477 (ave = 0.82009094)\n",
      "Loss_G = 0.88237542 (ave = 0.89166759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.498025, max value: 0.185767\n",
      "D grad l2-norm: 1.594367, max value: 0.585890\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.90132684 (ave = 0.84164971)\n",
      "Loss_G = 0.88221669 (ave = 0.88225914)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.533196, max value: 0.210113\n",
      "D grad l2-norm: 1.617953, max value: 0.585789\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.83641601 (ave = 0.84068255)\n",
      "Loss_G = 0.86811709 (ave = 0.87437601)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.594690, max value: 0.228999\n",
      "D grad l2-norm: 1.630888, max value: 0.579913\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001239)\n",
      "Loss_D = 0.82726979 (ave = 0.84412220)\n",
      "Loss_G = 0.86682075 (ave = 0.86407112)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.616755, max value: 0.241346\n",
      "D grad l2-norm: 1.692339, max value: 0.579425\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.013s / 800 iters, (0.002670)\n",
      "Loss_D = 0.88504267 (ave = 0.85541463)\n",
      "Loss_G = 0.87179667 (ave = 0.86521834)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.616860, max value: 0.252266\n",
      "D grad l2-norm: 1.731897, max value: 0.581217\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 0.86341095 (ave = 0.84365236)\n",
      "Loss_G = 0.87541425 (ave = 0.87347816)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.653940, max value: 0.241193\n",
      "D grad l2-norm: 1.790275, max value: 0.582766\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.77937186 (ave = 0.82275350)\n",
      "Loss_G = 0.90253401 (ave = 0.89079640)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.660679, max value: 0.246281\n",
      "D grad l2-norm: 1.890976, max value: 0.593948\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.83654380 (ave = 0.81048607)\n",
      "Loss_G = 0.92772537 (ave = 0.91657650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.681683, max value: 0.259177\n",
      "D grad l2-norm: 1.937708, max value: 0.604162\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.011s / 800 iters, (0.002247)\n",
      "Loss_D = 0.81665659 (ave = 0.79625893)\n",
      "Loss_G = 0.94523597 (ave = 0.93282319)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.775495, max value: 0.255839\n",
      "D grad l2-norm: 2.053659, max value: 0.610976\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.76002556 (ave = 0.77289186)\n",
      "Loss_G = 0.96319592 (ave = 0.95189784)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.852615, max value: 0.265801\n",
      "D grad l2-norm: 2.109277, max value: 0.617691\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.76014948 (ave = 0.76712959)\n",
      "Loss_G = 0.97178602 (ave = 0.97199572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.985575, max value: 0.279778\n",
      "D grad l2-norm: 2.195259, max value: 0.620824\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.76420474 (ave = 0.76231436)\n",
      "Loss_G = 0.98197103 (ave = 0.98034807)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.065855, max value: 0.271969\n",
      "D grad l2-norm: 2.274240, max value: 0.624690\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.73532152 (ave = 0.75508981)\n",
      "Loss_G = 0.98702425 (ave = 0.98844688)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.164991, max value: 0.268601\n",
      "D grad l2-norm: 2.412982, max value: 0.626569\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 0.72345024 (ave = 0.74381392)\n",
      "Loss_G = 1.00510263 (ave = 1.00194117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.121312, max value: 0.245129\n",
      "D grad l2-norm: 2.460791, max value: 0.633102\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001224)\n",
      "Loss_D = 0.72958124 (ave = 0.73527771)\n",
      "Loss_G = 1.03282547 (ave = 1.02053599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.171569, max value: 0.243502\n",
      "D grad l2-norm: 2.565571, max value: 0.643390\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.72039175 (ave = 0.72895852)\n",
      "Loss_G = 1.04457319 (ave = 1.03928370)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.300135, max value: 0.239641\n",
      "D grad l2-norm: 2.686931, max value: 0.647202\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.71435416 (ave = 0.72070862)\n",
      "Loss_G = 1.04047620 (ave = 1.04432755)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.380658, max value: 0.247290\n",
      "D grad l2-norm: 2.738407, max value: 0.645587\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001213)\n",
      "Loss_D = 0.70672673 (ave = 0.71651510)\n",
      "Loss_G = 1.05271637 (ave = 1.05565004)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.477103, max value: 0.261607\n",
      "D grad l2-norm: 2.878916, max value: 0.649880\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.007s / 800 iters, (0.001308)\n",
      "Loss_D = 0.73085320 (ave = 0.72152495)\n",
      "Loss_G = 1.05920696 (ave = 1.05567362)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.544515, max value: 0.283520\n",
      "D grad l2-norm: 2.884813, max value: 0.651998\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.011s / 800 iters, (0.002163)\n",
      "Loss_D = 0.70331478 (ave = 0.72291834)\n",
      "Loss_G = 1.04012287 (ave = 1.05541141)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.812187, max value: 0.305233\n",
      "D grad l2-norm: 3.006430, max value: 0.644930\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.70046246 (ave = 0.73801212)\n",
      "Loss_G = 1.03778875 (ave = 1.04526913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.985984, max value: 0.327175\n",
      "D grad l2-norm: 3.042966, max value: 0.643977\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.78113079 (ave = 0.77128035)\n",
      "Loss_G = 0.99665970 (ave = 1.00435989)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.106269, max value: 0.313378\n",
      "D grad l2-norm: 3.141898, max value: 0.628759\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.69862562 (ave = 0.78325063)\n",
      "Loss_G = 0.98666227 (ave = 0.98847935)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.997206, max value: 0.299608\n",
      "D grad l2-norm: 3.128971, max value: 0.624269\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.78787428 (ave = 0.80145763)\n",
      "Loss_G = 1.01074159 (ave = 0.99634064)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.018914, max value: 0.298699\n",
      "D grad l2-norm: 3.196832, max value: 0.634030\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.79850364 (ave = 0.80592453)\n",
      "Loss_G = 1.00125408 (ave = 1.00031774)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.252619, max value: 0.306970\n",
      "D grad l2-norm: 3.350661, max value: 0.630355\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.93190324 (ave = 0.83713728)\n",
      "Loss_G = 0.99210590 (ave = 1.00148467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.385585, max value: 0.311065\n",
      "D grad l2-norm: 3.396155, max value: 0.626831\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002758)\n",
      "Loss_D = 0.92998755 (ave = 0.84686487)\n",
      "Loss_G = 0.98440015 (ave = 0.98514841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.480569, max value: 0.319885\n",
      "D grad l2-norm: 3.494067, max value: 0.623788\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.77732980 (ave = 0.84318887)\n",
      "Loss_G = 0.97862273 (ave = 0.98108852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.432403, max value: 0.328174\n",
      "D grad l2-norm: 3.476780, max value: 0.621973\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.016s / 800 iters, (0.003238)\n",
      "Loss_D = 0.91503417 (ave = 0.85957190)\n",
      "Loss_G = 0.98788381 (ave = 0.99068377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.490383, max value: 0.351590\n",
      "D grad l2-norm: 3.509811, max value: 0.625677\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.75866616 (ave = 0.84700532)\n",
      "Loss_G = 0.99931127 (ave = 0.98696240)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.632848, max value: 0.349281\n",
      "D grad l2-norm: 3.547738, max value: 0.629849\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000975)\n",
      "Loss_D = 0.79770923 (ave = 0.86055361)\n",
      "Loss_G = 0.97509241 (ave = 0.97530893)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.904235, max value: 0.348337\n",
      "D grad l2-norm: 3.659533, max value: 0.620938\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.023s / 800 iters, (0.004641)\n",
      "Loss_D = 0.81164420 (ave = 0.87614799)\n",
      "Loss_G = 0.96369541 (ave = 0.95800089)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.045020, max value: 0.340506\n",
      "D grad l2-norm: 3.748264, max value: 0.616504\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.01085269 (ave = 0.91133827)\n",
      "Loss_G = 0.97793841 (ave = 0.96700802)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.187975, max value: 0.370872\n",
      "D grad l2-norm: 3.896353, max value: 0.622019\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001175)\n",
      "Loss_D = 0.87844658 (ave = 0.89891342)\n",
      "Loss_G = 1.00698447 (ave = 0.98682059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.175444, max value: 0.400330\n",
      "D grad l2-norm: 4.068405, max value: 0.632793\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.86868113 (ave = 0.87270845)\n",
      "Loss_G = 1.06034565 (ave = 1.03005292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.167844, max value: 0.401559\n",
      "D grad l2-norm: 4.329557, max value: 0.651705\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.79759598 (ave = 0.83421042)\n",
      "Loss_G = 1.11915004 (ave = 1.08351150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.116777, max value: 0.408604\n",
      "D grad l2-norm: 4.531405, max value: 0.672070\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.67095679 (ave = 0.78288684)\n",
      "Loss_G = 1.20393801 (ave = 1.16580026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.103991, max value: 0.407173\n",
      "D grad l2-norm: 4.864031, max value: 0.698694\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.81782669 (ave = 0.76087487)\n",
      "Loss_G = 1.28324604 (ave = 1.25048330)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.083427, max value: 0.399013\n",
      "D grad l2-norm: 5.174926, max value: 0.721769\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001285)\n",
      "Loss_D = 0.70293701 (ave = 0.71252159)\n",
      "Loss_G = 1.35364437 (ave = 1.32028329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.138663, max value: 0.398301\n",
      "D grad l2-norm: 5.459710, max value: 0.740773\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.72942108 (ave = 0.69295757)\n",
      "Loss_G = 1.42589879 (ave = 1.39525263)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.422876, max value: 0.417757\n",
      "D grad l2-norm: 5.817063, max value: 0.758288\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.59061998 (ave = 0.65584170)\n",
      "Loss_G = 1.41974902 (ave = 1.43194735)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.807566, max value: 0.443860\n",
      "D grad l2-norm: 6.097482, max value: 0.756240\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.016s / 800 iters, (0.003106)\n",
      "Loss_D = 0.65859532 (ave = 0.65840948)\n",
      "Loss_G = 1.42856956 (ave = 1.43787766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.020941, max value: 0.477332\n",
      "D grad l2-norm: 6.297320, max value: 0.758494\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.60909671 (ave = 0.65832232)\n",
      "Loss_G = 1.45771611 (ave = 1.44028273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.241406, max value: 0.484345\n",
      "D grad l2-norm: 6.551272, max value: 0.765204\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.70699650 (ave = 0.67403779)\n",
      "Loss_G = 1.46316338 (ave = 1.46218467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.593753, max value: 0.487585\n",
      "D grad l2-norm: 6.729415, max value: 0.765097\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002772)\n",
      "Loss_D = 0.62629163 (ave = 0.67655982)\n",
      "Loss_G = 1.42505670 (ave = 1.42746503)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.677866, max value: 0.479009\n",
      "D grad l2-norm: 6.759960, max value: 0.756143\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 0.69327962 (ave = 0.69946992)\n",
      "Loss_G = 1.42847967 (ave = 1.43109291)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.782625, max value: 0.464417\n",
      "D grad l2-norm: 7.038828, max value: 0.757243\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.74981570 (ave = 0.70678227)\n",
      "Loss_G = 1.43851948 (ave = 1.42814693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.002042, max value: 0.464757\n",
      "D grad l2-norm: 7.340865, max value: 0.758828\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.67819589 (ave = 0.70005039)\n",
      "Loss_G = 1.50302613 (ave = 1.49442363)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.021164, max value: 0.474366\n",
      "D grad l2-norm: 7.495094, max value: 0.774362\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.70539463 (ave = 0.69681761)\n",
      "Loss_G = 1.50226831 (ave = 1.51999073)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.209894, max value: 0.519385\n",
      "D grad l2-norm: 7.542009, max value: 0.774052\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.77435470 (ave = 0.71760592)\n",
      "Loss_G = 1.51366687 (ave = 1.50777903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.002492, max value: 0.560848\n",
      "D grad l2-norm: 8.114060, max value: 0.774891\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002783)\n",
      "Loss_D = 0.79369140 (ave = 0.74068235)\n",
      "Loss_G = 1.48165715 (ave = 1.48570900)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.152732, max value: 0.603248\n",
      "D grad l2-norm: 8.031936, max value: 0.768470\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.65124035 (ave = 0.74963753)\n",
      "Loss_G = 1.46154320 (ave = 1.44852257)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.417331, max value: 0.633930\n",
      "D grad l2-norm: 8.006914, max value: 0.763322\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.94290090 (ave = 0.82182035)\n",
      "Loss_G = 1.38990819 (ave = 1.41004937)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.846324, max value: 0.673771\n",
      "D grad l2-norm: 8.009588, max value: 0.743977\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 0.91016948 (ave = 0.84568830)\n",
      "Loss_G = 1.34794366 (ave = 1.39464018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.256986, max value: 0.686310\n",
      "D grad l2-norm: 7.940561, max value: 0.732746\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.93599832 (ave = 0.89551065)\n",
      "Loss_G = 1.24523282 (ave = 1.31926143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.545936, max value: 0.690154\n",
      "D grad l2-norm: 7.764204, max value: 0.702442\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.93779874 (ave = 0.96383920)\n",
      "Loss_G = 1.24852598 (ave = 1.25030103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.226951, max value: 0.613535\n",
      "D grad l2-norm: 7.627143, max value: 0.703685\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 1.10761523 (ave = 1.00983737)\n",
      "Loss_G = 1.22820866 (ave = 1.24080496)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.227556, max value: 0.588937\n",
      "D grad l2-norm: 7.892725, max value: 0.697598\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 1.13783538 (ave = 1.03102181)\n",
      "Loss_G = 1.28722477 (ave = 1.28856392)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.179447, max value: 0.572512\n",
      "D grad l2-norm: 7.956444, max value: 0.717078\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 1.01438487 (ave = 1.00635182)\n",
      "Loss_G = 1.26737726 (ave = 1.29337237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.818402, max value: 0.472623\n",
      "D grad l2-norm: 8.139579, max value: 0.746532\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 1.11455941 (ave = 1.00374647)\n",
      "Loss_G = 1.35659957 (ave = 1.35183125)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.734122, max value: 0.516040\n",
      "D grad l2-norm: 8.580958, max value: 0.815126\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 1.07483697 (ave = 0.97553421)\n",
      "Loss_G = 1.48804474 (ave = 1.41792607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.698363, max value: 0.542473\n",
      "D grad l2-norm: 8.912268, max value: 0.863203\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.89345181 (ave = 0.92525976)\n",
      "Loss_G = 1.51958752 (ave = 1.47417383)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.845623, max value: 0.574627\n",
      "D grad l2-norm: 9.426635, max value: 0.894282\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 800 iters, (0.020)\tData load 0.011s / 800 iters, (0.002128)\n",
      "Loss_D = 0.86666507 (ave = 0.90112234)\n",
      "Loss_G = 1.59506130 (ave = 1.57526522)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.127986, max value: 0.618607\n",
      "D grad l2-norm: 9.798311, max value: 0.936494\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.90766960 (ave = 0.88471364)\n",
      "Loss_G = 1.63617289 (ave = 1.63151076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.580527, max value: 0.637962\n",
      "D grad l2-norm: 10.335112, max value: 1.014396\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001004)\n",
      "Loss_D = 0.83614898 (ave = 0.86516993)\n",
      "Loss_G = 1.64087737 (ave = 1.64248502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.616015, max value: 0.673692\n",
      "D grad l2-norm: 10.284222, max value: 1.029883\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.009s / 800 iters, (0.001763)\n",
      "Loss_D = 0.81689304 (ave = 0.85106325)\n",
      "Loss_G = 1.66349506 (ave = 1.65876563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.862764, max value: 0.659715\n",
      "D grad l2-norm: 10.696037, max value: 1.115677\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.92670876 (ave = 0.85303649)\n",
      "Loss_G = 1.72034693 (ave = 1.70335941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.939017, max value: 0.641425\n",
      "D grad l2-norm: 10.886948, max value: 1.198165\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.79313803 (ave = 0.82303809)\n",
      "Loss_G = 1.70288444 (ave = 1.72201381)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.593755, max value: 0.685287\n",
      "D grad l2-norm: 11.351207, max value: 1.273134\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001169)\n",
      "Loss_D = 0.95622158 (ave = 0.84155871)\n",
      "Loss_G = 1.71096313 (ave = 1.72080467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.714889, max value: 0.728388\n",
      "D grad l2-norm: 11.351388, max value: 1.304393\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001264)\n",
      "Loss_D = 0.82104516 (ave = 0.82833858)\n",
      "Loss_G = 1.69893312 (ave = 1.72182558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.650138, max value: 0.718181\n",
      "D grad l2-norm: 11.250144, max value: 1.315745\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 1.30541968 (ave = 0.88582163)\n",
      "Loss_G = 1.73652256 (ave = 1.72920489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.820758, max value: 0.747566\n",
      "D grad l2-norm: 11.491449, max value: 1.367656\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.61627924 (ave = 0.79853119)\n",
      "Loss_G = 1.70122373 (ave = 1.69585710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.654680, max value: 0.632744\n",
      "D grad l2-norm: 11.377655, max value: 1.358491\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.92504394 (ave = 0.82674993)\n",
      "Loss_G = 1.66541386 (ave = 1.71086762)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.837159, max value: 0.613921\n",
      "D grad l2-norm: 11.350217, max value: 1.332428\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.77016652 (ave = 0.81353815)\n",
      "Loss_G = 1.69447637 (ave = 1.69100523)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.083238, max value: 0.627292\n",
      "D grad l2-norm: 11.520778, max value: 1.341028\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.79433417 (ave = 0.81552536)\n",
      "Loss_G = 1.70497262 (ave = 1.69326882)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.894562, max value: 0.646711\n",
      "D grad l2-norm: 11.089678, max value: 1.286422\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.80959678 (ave = 0.82042129)\n",
      "Loss_G = 1.70361412 (ave = 1.72244763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.597286, max value: 0.662196\n",
      "D grad l2-norm: 11.131317, max value: 1.274671\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.76477730 (ave = 0.79855304)\n",
      "Loss_G = 1.70537758 (ave = 1.70938051)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.405778, max value: 0.656403\n",
      "D grad l2-norm: 11.137103, max value: 1.247906\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 0.69422758 (ave = 0.77522873)\n",
      "Loss_G = 1.76001203 (ave = 1.75430112)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.480206, max value: 0.658847\n",
      "D grad l2-norm: 11.129934, max value: 1.226710\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.89691770 (ave = 0.78720907)\n",
      "Loss_G = 1.74031663 (ave = 1.75832665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.326700, max value: 0.646153\n",
      "D grad l2-norm: 10.881078, max value: 1.156718\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.64750075 (ave = 0.75489246)\n",
      "Loss_G = 1.73993993 (ave = 1.74402654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.236275, max value: 0.633905\n",
      "D grad l2-norm: 10.737249, max value: 1.093054\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.75989670 (ave = 0.76056483)\n",
      "Loss_G = 1.73978329 (ave = 1.73072062)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.455268, max value: 0.653494\n",
      "D grad l2-norm: 10.833618, max value: 1.026033\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.89451456 (ave = 0.76623799)\n",
      "Loss_G = 1.65579104 (ave = 1.69904883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.417711, max value: 0.656709\n",
      "D grad l2-norm: 10.435846, max value: 0.942672\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001171)\n",
      "Loss_D = 0.73410571 (ave = 0.74969077)\n",
      "Loss_G = 1.70261312 (ave = 1.68577292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.350724, max value: 0.640376\n",
      "D grad l2-norm: 10.225538, max value: 0.937769\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.64996052 (ave = 0.74422851)\n",
      "Loss_G = 1.64876735 (ave = 1.65325387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.092777, max value: 0.609421\n",
      "D grad l2-norm: 9.961697, max value: 0.897240\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.60238445 (ave = 0.73224950)\n",
      "Loss_G = 1.67410207 (ave = 1.63934023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.111464, max value: 0.589154\n",
      "D grad l2-norm: 10.160536, max value: 0.893752\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 0.72922385 (ave = 0.74151179)\n",
      "Loss_G = 1.67574894 (ave = 1.65368550)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.474698, max value: 0.593920\n",
      "D grad l2-norm: 10.349522, max value: 0.863417\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.62298030 (ave = 0.73292638)\n",
      "Loss_G = 1.70412278 (ave = 1.64586184)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.676495, max value: 0.635502\n",
      "D grad l2-norm: 10.223635, max value: 0.831107\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.007s / 800 iters, (0.001425)\n",
      "Loss_D = 0.84336746 (ave = 0.76528698)\n",
      "Loss_G = 1.57689679 (ave = 1.61026845)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.963388, max value: 0.703021\n",
      "D grad l2-norm: 10.104815, max value: 0.786385\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.74676144 (ave = 0.76898751)\n",
      "Loss_G = 1.54951477 (ave = 1.56339352)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.691791, max value: 0.702636\n",
      "D grad l2-norm: 10.019268, max value: 0.782734\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002761)\n",
      "Loss_D = 0.73491055 (ave = 0.75655951)\n",
      "Loss_G = 1.55005407 (ave = 1.57603714)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.334800, max value: 0.726144\n",
      "D grad l2-norm: 9.813578, max value: 0.782916\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.72826457 (ave = 0.74906442)\n",
      "Loss_G = 1.55013978 (ave = 1.56251497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.664219, max value: 0.722894\n",
      "D grad l2-norm: 9.961234, max value: 0.782312\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.91121769 (ave = 0.78560238)\n",
      "Loss_G = 1.53397095 (ave = 1.54167650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.538798, max value: 0.792570\n",
      "D grad l2-norm: 9.873889, max value: 0.779558\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.81626964 (ave = 0.76876434)\n",
      "Loss_G = 1.54895139 (ave = 1.53813772)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.702843, max value: 0.821137\n",
      "D grad l2-norm: 10.020349, max value: 0.795925\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.68823147 (ave = 0.75332741)\n",
      "Loss_G = 1.54405844 (ave = 1.55078456)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.847874, max value: 0.843264\n",
      "D grad l2-norm: 10.138168, max value: 0.827817\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 0.76858115 (ave = 0.75890157)\n",
      "Loss_G = 1.57972205 (ave = 1.55508158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.702898, max value: 0.819585\n",
      "D grad l2-norm: 10.102788, max value: 0.890157\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.70349389 (ave = 0.74265596)\n",
      "Loss_G = 1.59792113 (ave = 1.57444253)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.260618, max value: 0.788342\n",
      "D grad l2-norm: 9.986870, max value: 0.932488\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 0.78989625 (ave = 0.73622081)\n",
      "Loss_G = 1.64390969 (ave = 1.61847029)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.237282, max value: 0.803006\n",
      "D grad l2-norm: 10.143208, max value: 0.989473\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001009)\n",
      "Loss_D = 0.73562241 (ave = 0.71184583)\n",
      "Loss_G = 1.62225688 (ave = 1.62934868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.053793, max value: 0.770687\n",
      "D grad l2-norm: 10.021772, max value: 0.990012\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.012s / 800 iters, (0.002308)\n",
      "Loss_D = 0.52299255 (ave = 0.67242507)\n",
      "Loss_G = 1.65889657 (ave = 1.65305297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.434699, max value: 0.769355\n",
      "D grad l2-norm: 10.244328, max value: 1.016172\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.68424571 (ave = 0.68927277)\n",
      "Loss_G = 1.67581415 (ave = 1.65399859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.465399, max value: 0.718913\n",
      "D grad l2-norm: 10.096437, max value: 1.003485\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.74019957 (ave = 0.69189661)\n",
      "Loss_G = 1.67149663 (ave = 1.66882775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.516556, max value: 0.700538\n",
      "D grad l2-norm: 9.957894, max value: 0.982776\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 0.70896125 (ave = 0.69136695)\n",
      "Loss_G = 1.63069582 (ave = 1.62083857)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.612847, max value: 0.694582\n",
      "D grad l2-norm: 9.670779, max value: 0.938099\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.82354194 (ave = 0.71311468)\n",
      "Loss_G = 1.58189380 (ave = 1.59848387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.150673, max value: 0.784977\n",
      "D grad l2-norm: 9.859152, max value: 0.906532\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001195)\n",
      "Loss_D = 0.66856551 (ave = 0.70980363)\n",
      "Loss_G = 1.55969703 (ave = 1.55582933)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.645716, max value: 0.784656\n",
      "D grad l2-norm: 9.256154, max value: 0.844992\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.67886364 (ave = 0.71716686)\n",
      "Loss_G = 1.50147104 (ave = 1.52768600)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.810356, max value: 0.760918\n",
      "D grad l2-norm: 9.236936, max value: 0.807916\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.74695873 (ave = 0.74120694)\n",
      "Loss_G = 1.49133933 (ave = 1.51388745)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.148404, max value: 0.826635\n",
      "D grad l2-norm: 9.294775, max value: 0.777782\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.85021532 (ave = 0.77107124)\n",
      "Loss_G = 1.44806731 (ave = 1.48019192)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.397069, max value: 0.817933\n",
      "D grad l2-norm: 9.212387, max value: 0.759889\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.71907282 (ave = 0.77265233)\n",
      "Loss_G = 1.43051195 (ave = 1.44645369)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.398738, max value: 0.793648\n",
      "D grad l2-norm: 9.144518, max value: 0.756676\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 0.72047460 (ave = 0.78138957)\n",
      "Loss_G = 1.43035138 (ave = 1.42889264)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.996347, max value: 0.766055\n",
      "D grad l2-norm: 9.029088, max value: 0.756727\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.93058944 (ave = 0.81161106)\n",
      "Loss_G = 1.45352638 (ave = 1.44115419)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.068634, max value: 0.803643\n",
      "D grad l2-norm: 9.400002, max value: 0.784478\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001170)\n",
      "Loss_D = 0.77870697 (ave = 0.78722925)\n",
      "Loss_G = 1.48540449 (ave = 1.45886827)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.139619, max value: 0.835224\n",
      "D grad l2-norm: 9.420383, max value: 0.783174\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.67336297 (ave = 0.77504537)\n",
      "Loss_G = 1.43005717 (ave = 1.46281688)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.399599, max value: 0.924842\n",
      "D grad l2-norm: 9.573952, max value: 0.770905\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.59670734 (ave = 0.77050359)\n",
      "Loss_G = 1.44894278 (ave = 1.45995860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.038533, max value: 0.919997\n",
      "D grad l2-norm: 9.547627, max value: 0.760059\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.67204690 (ave = 0.77326753)\n",
      "Loss_G = 1.51629543 (ave = 1.49706683)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.226696, max value: 0.993760\n",
      "D grad l2-norm: 9.980300, max value: 0.798112\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.70152682 (ave = 0.76004353)\n",
      "Loss_G = 1.55130911 (ave = 1.54550157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.400689, max value: 1.017378\n",
      "D grad l2-norm: 10.208550, max value: 0.824975\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.84097677 (ave = 0.78090633)\n",
      "Loss_G = 1.53694892 (ave = 1.56521912)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.375817, max value: 1.041559\n",
      "D grad l2-norm: 10.156780, max value: 0.837046\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 0.70168638 (ave = 0.76143397)\n",
      "Loss_G = 1.57784069 (ave = 1.57420926)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.491679, max value: 1.019421\n",
      "D grad l2-norm: 10.269652, max value: 0.842210\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.70097047 (ave = 0.75701593)\n",
      "Loss_G = 1.63947153 (ave = 1.59390855)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.788814, max value: 1.022990\n",
      "D grad l2-norm: 10.489018, max value: 0.843724\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 0.68397868 (ave = 0.74773448)\n",
      "Loss_G = 1.63651276 (ave = 1.61185303)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.671947, max value: 1.007579\n",
      "D grad l2-norm: 10.505006, max value: 0.827158\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001197)\n",
      "Loss_D = 0.74288678 (ave = 0.74838346)\n",
      "Loss_G = 1.66515708 (ave = 1.64537802)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.170735, max value: 1.029484\n",
      "D grad l2-norm: 11.057148, max value: 0.878216\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.69402599 (ave = 0.74234456)\n",
      "Loss_G = 1.67854047 (ave = 1.65665758)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.157510, max value: 0.969152\n",
      "D grad l2-norm: 10.916794, max value: 0.878691\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.76531595 (ave = 0.75014415)\n",
      "Loss_G = 1.69069982 (ave = 1.65723295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.509051, max value: 0.920404\n",
      "D grad l2-norm: 11.083167, max value: 0.898765\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.76435339 (ave = 0.74759300)\n",
      "Loss_G = 1.63749468 (ave = 1.61764407)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.467650, max value: 0.895272\n",
      "D grad l2-norm: 11.092660, max value: 0.963488\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.70512551 (ave = 0.75397193)\n",
      "Loss_G = 1.60293746 (ave = 1.62038469)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.566093, max value: 0.928591\n",
      "D grad l2-norm: 11.112867, max value: 1.020655\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.64264435 (ave = 0.75645490)\n",
      "Loss_G = 1.55487072 (ave = 1.59627457)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.728810, max value: 0.928892\n",
      "D grad l2-norm: 10.935198, max value: 1.037505\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 0.87218165 (ave = 0.80745991)\n",
      "Loss_G = 1.50890172 (ave = 1.54991338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.639568, max value: 0.886038\n",
      "D grad l2-norm: 10.846021, max value: 1.069213\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.82987857 (ave = 0.81903354)\n",
      "Loss_G = 1.52507925 (ave = 1.52540069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.744402, max value: 0.858547\n",
      "D grad l2-norm: 10.948979, max value: 1.122762\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.94114113 (ave = 0.85388063)\n",
      "Loss_G = 1.42391849 (ave = 1.48942580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.005718, max value: 0.798762\n",
      "D grad l2-norm: 10.261211, max value: 1.078559\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.80926669 (ave = 0.85232798)\n",
      "Loss_G = 1.43829119 (ave = 1.48785639)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.321564, max value: 0.785785\n",
      "D grad l2-norm: 10.548049, max value: 1.134616\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.007s / 800 iters, (0.001342)\n",
      "Loss_D = 0.86527920 (ave = 0.87461206)\n",
      "Loss_G = 1.47065306 (ave = 1.48064690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.417206, max value: 0.745194\n",
      "D grad l2-norm: 10.611273, max value: 1.156148\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.008s / 800 iters, (0.001566)\n",
      "Loss_D = 0.72974122 (ave = 0.86607776)\n",
      "Loss_G = 1.46859801 (ave = 1.46078148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.275082, max value: 0.652176\n",
      "D grad l2-norm: 10.579864, max value: 1.153199\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 0.92390430 (ave = 0.90198953)\n",
      "Loss_G = 1.46427202 (ave = 1.46834688)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.288712, max value: 0.671438\n",
      "D grad l2-norm: 10.627066, max value: 1.129412\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.76523703 (ave = 0.88951676)\n",
      "Loss_G = 1.45504117 (ave = 1.46329694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.399170, max value: 0.690907\n",
      "D grad l2-norm: 10.671762, max value: 1.111024\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.87925947 (ave = 0.91693593)\n",
      "Loss_G = 1.42103004 (ave = 1.43616476)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.644452, max value: 0.744661\n",
      "D grad l2-norm: 10.702298, max value: 1.074097\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000995)\n",
      "Loss_D = 1.01037705 (ave = 0.95151595)\n",
      "Loss_G = 1.36402583 (ave = 1.41248500)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.472548, max value: 0.768465\n",
      "D grad l2-norm: 10.362691, max value: 0.993403\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.008s / 800 iters, (0.001584)\n",
      "Loss_D = 0.81985199 (ave = 0.94386966)\n",
      "Loss_G = 1.42131400 (ave = 1.41156297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.182281, max value: 0.887884\n",
      "D grad l2-norm: 10.895249, max value: 1.008255\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001007)\n",
      "Loss_D = 0.88738614 (ave = 0.96941446)\n",
      "Loss_G = 1.40746486 (ave = 1.40976145)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.544570, max value: 0.856698\n",
      "D grad l2-norm: 10.611234, max value: 0.976825\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001022)\n",
      "Loss_D = 1.11032987 (ave = 0.99303119)\n",
      "Loss_G = 1.46139431 (ave = 1.45233951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.584210, max value: 0.912601\n",
      "D grad l2-norm: 10.949305, max value: 1.013062\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.86627150 (ave = 0.95195545)\n",
      "Loss_G = 1.47412694 (ave = 1.45115016)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.086101, max value: 0.881780\n",
      "D grad l2-norm: 10.656601, max value: 1.071506\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 1.06086111 (ave = 0.96818941)\n",
      "Loss_G = 1.53025830 (ave = 1.50158877)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.261120, max value: 0.871963\n",
      "D grad l2-norm: 10.985379, max value: 1.182633\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.92960453 (ave = 0.93527535)\n",
      "Loss_G = 1.53893387 (ave = 1.52305703)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.294880, max value: 0.897059\n",
      "D grad l2-norm: 10.938274, max value: 1.231894\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.73967028 (ave = 0.90816067)\n",
      "Loss_G = 1.54092383 (ave = 1.51191831)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.389142, max value: 0.901998\n",
      "D grad l2-norm: 10.904855, max value: 1.266289\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.95233226 (ave = 0.92883891)\n",
      "Loss_G = 1.49196267 (ave = 1.51231523)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.760378, max value: 0.780199\n",
      "D grad l2-norm: 10.375015, max value: 1.225985\n",
      "üîÅ TSCV for Asset 2\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 1.38297057 (ave = 1.39077146)\n",
      "Loss_G = 0.66442108 (ave = 0.66514224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964496, max value: 0.022861\n",
      "D grad l2-norm: 0.663758, max value: 0.485426\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.35957074 (ave = 1.37474587)\n",
      "Loss_G = 0.66185671 (ave = 0.66300011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972092, max value: 0.020475\n",
      "D grad l2-norm: 0.661903, max value: 0.484105\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 1.37341404 (ave = 1.36378107)\n",
      "Loss_G = 0.65997553 (ave = 0.66078815)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966053, max value: 0.030271\n",
      "D grad l2-norm: 0.663556, max value: 0.483133\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.34168410 (ave = 1.34782717)\n",
      "Loss_G = 0.65813255 (ave = 0.65903031)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968295, max value: 0.026411\n",
      "D grad l2-norm: 0.665892, max value: 0.482180\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 1.33370829 (ave = 1.33497686)\n",
      "Loss_G = 0.65708578 (ave = 0.65764143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967311, max value: 0.028238\n",
      "D grad l2-norm: 0.667339, max value: 0.481637\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.31637239 (ave = 1.32103403)\n",
      "Loss_G = 0.65630329 (ave = 0.65678787)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964615, max value: 0.020034\n",
      "D grad l2-norm: 0.671381, max value: 0.481231\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.29231882 (ave = 1.30695732)\n",
      "Loss_G = 0.65559846 (ave = 0.65582796)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962389, max value: 0.020328\n",
      "D grad l2-norm: 0.674920, max value: 0.480867\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.29335260 (ave = 1.29566956)\n",
      "Loss_G = 0.65498412 (ave = 0.65561473)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966314, max value: 0.023948\n",
      "D grad l2-norm: 0.678536, max value: 0.480547\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 1.28129911 (ave = 1.28350303)\n",
      "Loss_G = 0.65561843 (ave = 0.65549458)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969643, max value: 0.019420\n",
      "D grad l2-norm: 0.683144, max value: 0.480876\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 1.27424955 (ave = 1.27139478)\n",
      "Loss_G = 0.65607387 (ave = 0.65542839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965291, max value: 0.024492\n",
      "D grad l2-norm: 0.686344, max value: 0.481113\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 1.23718798 (ave = 1.25593781)\n",
      "Loss_G = 0.65581012 (ave = 0.65560329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970788, max value: 0.018372\n",
      "D grad l2-norm: 0.690963, max value: 0.480974\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.23132730 (ave = 1.24488142)\n",
      "Loss_G = 0.65668172 (ave = 0.65609096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967276, max value: 0.023916\n",
      "D grad l2-norm: 0.698142, max value: 0.481427\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.000932)\n",
      "Loss_D = 1.23062706 (ave = 1.23427227)\n",
      "Loss_G = 0.65777755 (ave = 0.65723516)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974274, max value: 0.018957\n",
      "D grad l2-norm: 0.703416, max value: 0.481995\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.19731522 (ave = 1.22018800)\n",
      "Loss_G = 0.65850210 (ave = 0.65795465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970109, max value: 0.024843\n",
      "D grad l2-norm: 0.709654, max value: 0.482369\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 1.19476604 (ave = 1.20980713)\n",
      "Loss_G = 0.65996063 (ave = 0.65895584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977245, max value: 0.021744\n",
      "D grad l2-norm: 0.717449, max value: 0.483122\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.19586110 (ave = 1.20034928)\n",
      "Loss_G = 0.66039389 (ave = 0.66025980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973705, max value: 0.025980\n",
      "D grad l2-norm: 0.725852, max value: 0.483346\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 1.18470633 (ave = 1.18958020)\n",
      "Loss_G = 0.66267139 (ave = 0.66171530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974073, max value: 0.026549\n",
      "D grad l2-norm: 0.733583, max value: 0.484521\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.17387354 (ave = 1.17935236)\n",
      "Loss_G = 0.66378140 (ave = 0.66274774)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.987528, max value: 0.025442\n",
      "D grad l2-norm: 0.742010, max value: 0.485091\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001214)\n",
      "Loss_D = 1.17241931 (ave = 1.17034318)\n",
      "Loss_G = 0.66605014 (ave = 0.66452025)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984636, max value: 0.032181\n",
      "D grad l2-norm: 0.751201, max value: 0.486260\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 1.15741682 (ave = 1.15924122)\n",
      "Loss_G = 0.66749328 (ave = 0.66644635)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979003, max value: 0.039045\n",
      "D grad l2-norm: 0.760679, max value: 0.486996\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 1.14828980 (ave = 1.14962378)\n",
      "Loss_G = 0.66883945 (ave = 0.66862385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.987029, max value: 0.041738\n",
      "D grad l2-norm: 0.772111, max value: 0.487685\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 1.13717866 (ave = 1.13965187)\n",
      "Loss_G = 0.67181206 (ave = 0.67110835)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985751, max value: 0.041435\n",
      "D grad l2-norm: 0.783925, max value: 0.489202\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.12719142 (ave = 1.12898867)\n",
      "Loss_G = 0.67610574 (ave = 0.67391593)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.990698, max value: 0.049964\n",
      "D grad l2-norm: 0.796105, max value: 0.491391\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 1.09609199 (ave = 1.11577206)\n",
      "Loss_G = 0.68138975 (ave = 0.67821914)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.989338, max value: 0.040421\n",
      "D grad l2-norm: 0.812197, max value: 0.494072\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001261)\n",
      "Loss_D = 1.08955753 (ave = 1.10493891)\n",
      "Loss_G = 0.68399304 (ave = 0.68357497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.996698, max value: 0.043916\n",
      "D grad l2-norm: 0.826250, max value: 0.495385\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.07478237 (ave = 1.09222710)\n",
      "Loss_G = 0.68972176 (ave = 0.68764541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992659, max value: 0.054457\n",
      "D grad l2-norm: 0.841719, max value: 0.498266\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001763)\n",
      "Loss_D = 1.08587146 (ave = 1.08358471)\n",
      "Loss_G = 0.69691437 (ave = 0.69371387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.994975, max value: 0.056385\n",
      "D grad l2-norm: 0.856174, max value: 0.501859\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 1.05285871 (ave = 1.06891525)\n",
      "Loss_G = 0.70368028 (ave = 0.70023071)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.996495, max value: 0.050571\n",
      "D grad l2-norm: 0.879198, max value: 0.505218\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.06889558 (ave = 1.05917859)\n",
      "Loss_G = 0.71180040 (ave = 0.70784028)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993829, max value: 0.049857\n",
      "D grad l2-norm: 0.895433, max value: 0.509216\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.04275084 (ave = 1.04413950)\n",
      "Loss_G = 0.71847999 (ave = 0.71532232)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.000322, max value: 0.054822\n",
      "D grad l2-norm: 0.920511, max value: 0.512487\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001173)\n",
      "Loss_D = 1.01438630 (ave = 1.02812324)\n",
      "Loss_G = 0.72796041 (ave = 0.72505081)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.995648, max value: 0.051836\n",
      "D grad l2-norm: 0.938977, max value: 0.517085\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001158)\n",
      "Loss_D = 1.00725937 (ave = 1.01432490)\n",
      "Loss_G = 0.73717934 (ave = 0.73418763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004331, max value: 0.051936\n",
      "D grad l2-norm: 0.962345, max value: 0.521516\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 0.98507524 (ave = 0.99871459)\n",
      "Loss_G = 0.74664843 (ave = 0.74285042)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.010826, max value: 0.045042\n",
      "D grad l2-norm: 0.987938, max value: 0.526021\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000987)\n",
      "Loss_D = 0.99073541 (ave = 0.98743302)\n",
      "Loss_G = 0.75624311 (ave = 0.75273465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.014755, max value: 0.050131\n",
      "D grad l2-norm: 1.015627, max value: 0.530549\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 0.98347819 (ave = 0.97495068)\n",
      "Loss_G = 0.76547980 (ave = 0.76143628)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.024499, max value: 0.049780\n",
      "D grad l2-norm: 1.029813, max value: 0.534868\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.94709647 (ave = 0.95940297)\n",
      "Loss_G = 0.77377224 (ave = 0.76954453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.027821, max value: 0.055191\n",
      "D grad l2-norm: 1.050483, max value: 0.538707\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.95129323 (ave = 0.94941893)\n",
      "Loss_G = 0.78212321 (ave = 0.77759196)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.038778, max value: 0.057862\n",
      "D grad l2-norm: 1.067433, max value: 0.542534\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.88513076 (ave = 0.93279210)\n",
      "Loss_G = 0.78399694 (ave = 0.78230937)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.061782, max value: 0.071228\n",
      "D grad l2-norm: 1.097854, max value: 0.543389\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001753)\n",
      "Loss_D = 0.89473879 (ave = 0.92587694)\n",
      "Loss_G = 0.78802311 (ave = 0.78751107)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.077698, max value: 0.072140\n",
      "D grad l2-norm: 1.108442, max value: 0.545207\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 0.89054441 (ave = 0.91980466)\n",
      "Loss_G = 0.79444784 (ave = 0.79052505)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.090591, max value: 0.091524\n",
      "D grad l2-norm: 1.122061, max value: 0.548115\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.92690295 (ave = 0.91893734)\n",
      "Loss_G = 0.79303688 (ave = 0.79332038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.122372, max value: 0.098931\n",
      "D grad l2-norm: 1.152777, max value: 0.547487\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001041)\n",
      "Loss_D = 0.90185225 (ave = 0.91235157)\n",
      "Loss_G = 0.79802448 (ave = 0.79545041)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.131347, max value: 0.101938\n",
      "D grad l2-norm: 1.163199, max value: 0.549715\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.93997991 (ave = 0.91346445)\n",
      "Loss_G = 0.79297131 (ave = 0.79452586)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.156472, max value: 0.105339\n",
      "D grad l2-norm: 1.192386, max value: 0.547418\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 0.90533328 (ave = 0.90612015)\n",
      "Loss_G = 0.79745120 (ave = 0.79608009)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.174548, max value: 0.110468\n",
      "D grad l2-norm: 1.208790, max value: 0.549455\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.90470994 (ave = 0.90283048)\n",
      "Loss_G = 0.79386675 (ave = 0.79566040)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.203160, max value: 0.113536\n",
      "D grad l2-norm: 1.241038, max value: 0.547778\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.90187001 (ave = 0.89932911)\n",
      "Loss_G = 0.80311191 (ave = 0.79773813)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.204090, max value: 0.111514\n",
      "D grad l2-norm: 1.255865, max value: 0.551938\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000980)\n",
      "Loss_D = 0.90305853 (ave = 0.89656460)\n",
      "Loss_G = 0.79624289 (ave = 0.79827304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.253922, max value: 0.114324\n",
      "D grad l2-norm: 1.304335, max value: 0.548823\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.020s / 800 iters, (0.004002)\n",
      "Loss_D = 0.84919715 (ave = 0.88616427)\n",
      "Loss_G = 0.80856144 (ave = 0.80308541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.248492, max value: 0.101754\n",
      "D grad l2-norm: 1.332978, max value: 0.554376\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.84848678 (ave = 0.88144588)\n",
      "Loss_G = 0.81344724 (ave = 0.80937508)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.279575, max value: 0.114705\n",
      "D grad l2-norm: 1.394930, max value: 0.556497\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 0.82560658 (ave = 0.86984278)\n",
      "Loss_G = 0.82320964 (ave = 0.81862422)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.294650, max value: 0.108785\n",
      "D grad l2-norm: 1.453587, max value: 0.560809\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.86264992 (ave = 0.86355544)\n",
      "Loss_G = 0.83832943 (ave = 0.83187125)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.327356, max value: 0.119766\n",
      "D grad l2-norm: 1.518688, max value: 0.567438\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.84317458 (ave = 0.85125811)\n",
      "Loss_G = 0.84938651 (ave = 0.84741898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.357062, max value: 0.129563\n",
      "D grad l2-norm: 1.576265, max value: 0.572158\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002761)\n",
      "Loss_D = 0.83793974 (ave = 0.83942302)\n",
      "Loss_G = 0.87223184 (ave = 0.86167133)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.385404, max value: 0.144756\n",
      "D grad l2-norm: 1.628333, max value: 0.581807\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.82323980 (ave = 0.82582355)\n",
      "Loss_G = 0.88292485 (ave = 0.87636904)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.446113, max value: 0.156376\n",
      "D grad l2-norm: 1.679354, max value: 0.586230\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.81843102 (ave = 0.81900661)\n",
      "Loss_G = 0.90153188 (ave = 0.89109915)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.495928, max value: 0.169630\n",
      "D grad l2-norm: 1.723967, max value: 0.593859\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.81985259 (ave = 0.81088542)\n",
      "Loss_G = 0.89119256 (ave = 0.89451550)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.610356, max value: 0.174534\n",
      "D grad l2-norm: 1.798563, max value: 0.589472\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.013s / 800 iters, (0.002694)\n",
      "Loss_D = 0.75550556 (ave = 0.80171820)\n",
      "Loss_G = 0.90185219 (ave = 0.89755802)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.646985, max value: 0.194044\n",
      "D grad l2-norm: 1.816299, max value: 0.593880\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.78707349 (ave = 0.80605487)\n",
      "Loss_G = 0.89606726 (ave = 0.89588892)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.733245, max value: 0.207831\n",
      "D grad l2-norm: 1.872099, max value: 0.591476\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.81471705 (ave = 0.81366547)\n",
      "Loss_G = 0.89654720 (ave = 0.89730809)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.777196, max value: 0.213631\n",
      "D grad l2-norm: 1.896831, max value: 0.591555\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001013)\n",
      "Loss_D = 0.81529987 (ave = 0.81493045)\n",
      "Loss_G = 0.89844835 (ave = 0.89707031)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.825573, max value: 0.225421\n",
      "D grad l2-norm: 1.939262, max value: 0.592355\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.87517786 (ave = 0.82685387)\n",
      "Loss_G = 0.88955927 (ave = 0.88694665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.867655, max value: 0.231186\n",
      "D grad l2-norm: 1.938455, max value: 0.588583\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.80050915 (ave = 0.82532402)\n",
      "Loss_G = 0.88180274 (ave = 0.88361968)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.945623, max value: 0.225703\n",
      "D grad l2-norm: 1.972083, max value: 0.585262\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.81754184 (ave = 0.83368607)\n",
      "Loss_G = 0.86971569 (ave = 0.87541780)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.032404, max value: 0.207618\n",
      "D grad l2-norm: 2.038847, max value: 0.580228\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.000983)\n",
      "Loss_D = 0.80551517 (ave = 0.83698151)\n",
      "Loss_G = 0.87495255 (ave = 0.87272228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.004101, max value: 0.206104\n",
      "D grad l2-norm: 2.036221, max value: 0.582384\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.84588015 (ave = 0.84547119)\n",
      "Loss_G = 0.86405039 (ave = 0.86823908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.069209, max value: 0.193598\n",
      "D grad l2-norm: 2.100408, max value: 0.577613\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.88454711 (ave = 0.85115027)\n",
      "Loss_G = 0.87226897 (ave = 0.87230216)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.059877, max value: 0.183574\n",
      "D grad l2-norm: 2.105650, max value: 0.581169\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.83111930 (ave = 0.84399931)\n",
      "Loss_G = 0.87192047 (ave = 0.87720431)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.132011, max value: 0.180362\n",
      "D grad l2-norm: 2.186026, max value: 0.581124\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 0.77772135 (ave = 0.83154546)\n",
      "Loss_G = 0.90105152 (ave = 0.88861018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.116289, max value: 0.195048\n",
      "D grad l2-norm: 2.211735, max value: 0.593033\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.82705688 (ave = 0.83211528)\n",
      "Loss_G = 0.90289718 (ave = 0.90051841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.166262, max value: 0.213583\n",
      "D grad l2-norm: 2.273408, max value: 0.593778\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 0.76572430 (ave = 0.81994689)\n",
      "Loss_G = 0.92425203 (ave = 0.91271101)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.233666, max value: 0.240856\n",
      "D grad l2-norm: 2.305377, max value: 0.602640\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000989)\n",
      "Loss_D = 0.79570019 (ave = 0.81513577)\n",
      "Loss_G = 0.92461759 (ave = 0.91945238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.354569, max value: 0.249101\n",
      "D grad l2-norm: 2.381690, max value: 0.602485\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.047s / 800 iters, (0.009)\tData load 0.005s / 800 iters, (0.000953)\n",
      "Loss_D = 0.80258405 (ave = 0.81056664)\n",
      "Loss_G = 0.94454545 (ave = 0.93061254)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.349624, max value: 0.249052\n",
      "D grad l2-norm: 2.421585, max value: 0.610419\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001007)\n",
      "Loss_D = 0.76649022 (ave = 0.80469583)\n",
      "Loss_G = 0.94012815 (ave = 0.93284255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.419749, max value: 0.240334\n",
      "D grad l2-norm: 2.524846, max value: 0.608893\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000993)\n",
      "Loss_D = 0.74878603 (ave = 0.79153955)\n",
      "Loss_G = 0.96034408 (ave = 0.95738921)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.544305, max value: 0.245085\n",
      "D grad l2-norm: 2.682110, max value: 0.616562\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001014)\n",
      "Loss_D = 0.73569000 (ave = 0.77216054)\n",
      "Loss_G = 0.98694521 (ave = 0.97721044)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.555328, max value: 0.235060\n",
      "D grad l2-norm: 2.736485, max value: 0.626547\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000984)\n",
      "Loss_D = 0.82730854 (ave = 0.77622467)\n",
      "Loss_G = 1.00742400 (ave = 0.99967841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.590747, max value: 0.237496\n",
      "D grad l2-norm: 2.789902, max value: 0.634173\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000946)\n",
      "Loss_D = 0.68770218 (ave = 0.74783133)\n",
      "Loss_G = 1.02440214 (ave = 1.01359158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.685527, max value: 0.248718\n",
      "D grad l2-norm: 2.893363, max value: 0.640151\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.011s / 800 iters, (0.002117)\n",
      "Loss_D = 0.82871962 (ave = 0.75585345)\n",
      "Loss_G = 1.04114568 (ave = 1.03406568)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.745961, max value: 0.261502\n",
      "D grad l2-norm: 3.011424, max value: 0.646268\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001020)\n",
      "Loss_D = 0.65592796 (ave = 0.72536629)\n",
      "Loss_G = 1.06545866 (ave = 1.05561538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.826313, max value: 0.255397\n",
      "D grad l2-norm: 3.175390, max value: 0.654697\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.64143795 (ave = 0.71090918)\n",
      "Loss_G = 1.08533370 (ave = 1.08246281)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.861069, max value: 0.264979\n",
      "D grad l2-norm: 3.249163, max value: 0.661286\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.66679072 (ave = 0.70269712)\n",
      "Loss_G = 1.11768484 (ave = 1.10379410)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.985763, max value: 0.272151\n",
      "D grad l2-norm: 3.366639, max value: 0.672114\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.68918860 (ave = 0.70245931)\n",
      "Loss_G = 1.12720823 (ave = 1.11797047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.235987, max value: 0.300968\n",
      "D grad l2-norm: 3.588764, max value: 0.675008\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.73389769 (ave = 0.70865709)\n",
      "Loss_G = 1.14667630 (ave = 1.13451779)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.397400, max value: 0.317221\n",
      "D grad l2-norm: 3.735246, max value: 0.681008\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.76932800 (ave = 0.71201153)\n",
      "Loss_G = 1.15418100 (ave = 1.14482827)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.618844, max value: 0.316864\n",
      "D grad l2-norm: 3.951062, max value: 0.683227\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.76555514 (ave = 0.71440145)\n",
      "Loss_G = 1.14962268 (ave = 1.14732316)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.690043, max value: 0.315901\n",
      "D grad l2-norm: 4.050268, max value: 0.681645\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.82605863 (ave = 0.73194748)\n",
      "Loss_G = 1.15662575 (ave = 1.14462345)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.971391, max value: 0.328010\n",
      "D grad l2-norm: 4.242178, max value: 0.683790\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001015)\n",
      "Loss_D = 0.71738398 (ave = 0.72636040)\n",
      "Loss_G = 1.16769791 (ave = 1.16024902)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.288979, max value: 0.368150\n",
      "D grad l2-norm: 4.308722, max value: 0.686850\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001005)\n",
      "Loss_D = 0.69432962 (ave = 0.74134270)\n",
      "Loss_G = 1.10581434 (ave = 1.11983070)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.819192, max value: 0.423303\n",
      "D grad l2-norm: 4.478899, max value: 0.666270\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.008s / 800 iters, (0.001683)\n",
      "Loss_D = 0.76951879 (ave = 0.79100763)\n",
      "Loss_G = 1.08735144 (ave = 1.07975364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.954580, max value: 0.432779\n",
      "D grad l2-norm: 4.449324, max value: 0.659473\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.88253617 (ave = 0.84307348)\n",
      "Loss_G = 1.04404950 (ave = 1.04706903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.118568, max value: 0.427362\n",
      "D grad l2-norm: 4.675855, max value: 0.644504\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.78758764 (ave = 0.84372319)\n",
      "Loss_G = 1.06429827 (ave = 1.04705439)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.201316, max value: 0.421087\n",
      "D grad l2-norm: 4.795233, max value: 0.651091\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.92346418 (ave = 0.87067900)\n",
      "Loss_G = 1.06478560 (ave = 1.06168540)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.599603, max value: 0.425453\n",
      "D grad l2-norm: 5.081583, max value: 0.651102\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 0.89798617 (ave = 0.87690089)\n",
      "Loss_G = 1.08706367 (ave = 1.08027763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.545996, max value: 0.404532\n",
      "D grad l2-norm: 5.259872, max value: 0.657912\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.95853734 (ave = 0.88290825)\n",
      "Loss_G = 1.13736606 (ave = 1.10940096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.787828, max value: 0.430129\n",
      "D grad l2-norm: 5.607503, max value: 0.676220\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 0.88725722 (ave = 0.87258122)\n",
      "Loss_G = 1.13849843 (ave = 1.14286988)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.801088, max value: 0.429802\n",
      "D grad l2-norm: 5.713352, max value: 0.676129\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.90726566 (ave = 0.88084860)\n",
      "Loss_G = 1.18092561 (ave = 1.16825187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.125241, max value: 0.474178\n",
      "D grad l2-norm: 6.083039, max value: 0.688845\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.76782256 (ave = 0.87168636)\n",
      "Loss_G = 1.18112803 (ave = 1.19305480)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.349268, max value: 0.514664\n",
      "D grad l2-norm: 6.301326, max value: 0.688475\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001032)\n",
      "Loss_D = 0.92931938 (ave = 0.89781818)\n",
      "Loss_G = 1.18469465 (ave = 1.20176389)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.896087, max value: 0.551018\n",
      "D grad l2-norm: 6.814726, max value: 0.689736\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.00346386 (ave = 0.93900386)\n",
      "Loss_G = 1.20703161 (ave = 1.21609190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.934607, max value: 0.603314\n",
      "D grad l2-norm: 6.758588, max value: 0.696481\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.010s / 800 iters, (0.002065)\n",
      "Loss_D = 1.06990588 (ave = 0.95738319)\n",
      "Loss_G = 1.20351672 (ave = 1.21684408)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.076754, max value: 0.641994\n",
      "D grad l2-norm: 6.900806, max value: 0.695156\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 800 iters, (0.027)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.18145323 (ave = 0.97942665)\n",
      "Loss_G = 1.25286341 (ave = 1.22892978)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.854195, max value: 0.640953\n",
      "D grad l2-norm: 7.337725, max value: 0.781995\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.81997132 (ave = 0.92440712)\n",
      "Loss_G = 1.32436013 (ave = 1.30377009)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.945814, max value: 0.686893\n",
      "D grad l2-norm: 7.607901, max value: 0.875305\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001019)\n",
      "Loss_D = 0.80572754 (ave = 0.90692589)\n",
      "Loss_G = 1.36590195 (ave = 1.35202742)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.634341, max value: 0.672115\n",
      "D grad l2-norm: 7.706906, max value: 0.945666\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000974)\n",
      "Loss_D = 0.88525689 (ave = 0.90179090)\n",
      "Loss_G = 1.44626939 (ave = 1.40306230)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.821304, max value: 0.677010\n",
      "D grad l2-norm: 8.118090, max value: 1.039154\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.99440211 (ave = 0.90688411)\n",
      "Loss_G = 1.44679022 (ave = 1.44440804)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.814788, max value: 0.682193\n",
      "D grad l2-norm: 8.299121, max value: 1.104629\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.96375191 (ave = 0.89292510)\n",
      "Loss_G = 1.49674070 (ave = 1.48387399)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.716303, max value: 0.600808\n",
      "D grad l2-norm: 8.312020, max value: 1.129198\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.89320403 (ave = 0.87369589)\n",
      "Loss_G = 1.51552844 (ave = 1.51662745)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.301223, max value: 0.588436\n",
      "D grad l2-norm: 8.796149, max value: 1.209799\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.84155208 (ave = 0.87270906)\n",
      "Loss_G = 1.50826192 (ave = 1.50534322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.335459, max value: 0.548491\n",
      "D grad l2-norm: 8.515088, max value: 1.176540\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001150)\n",
      "Loss_D = 0.78062403 (ave = 0.87614177)\n",
      "Loss_G = 1.48863137 (ave = 1.49180884)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.488956, max value: 0.509372\n",
      "D grad l2-norm: 8.665102, max value: 1.198678\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 0.84628719 (ave = 0.88456498)\n",
      "Loss_G = 1.48946762 (ave = 1.49868903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.460936, max value: 0.520603\n",
      "D grad l2-norm: 8.646422, max value: 1.186844\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 1.03377414 (ave = 0.91384687)\n",
      "Loss_G = 1.47754979 (ave = 1.49089439)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.895578, max value: 0.606471\n",
      "D grad l2-norm: 8.881120, max value: 1.200692\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.94609672 (ave = 0.91191262)\n",
      "Loss_G = 1.45090163 (ave = 1.46709599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.964636, max value: 0.620014\n",
      "D grad l2-norm: 8.745879, max value: 1.148960\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.010s / 800 iters, (0.001948)\n",
      "Loss_D = 0.74448341 (ave = 0.88404793)\n",
      "Loss_G = 1.51184583 (ave = 1.48414497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.936619, max value: 0.637109\n",
      "D grad l2-norm: 8.800618, max value: 1.131650\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 1.10687935 (ave = 0.92962810)\n",
      "Loss_G = 1.47012722 (ave = 1.47863228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.414825, max value: 0.707824\n",
      "D grad l2-norm: 9.006112, max value: 1.113238\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.86164540 (ave = 0.90331445)\n",
      "Loss_G = 1.43998277 (ave = 1.43401880)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.563477, max value: 0.680500\n",
      "D grad l2-norm: 8.663919, max value: 1.034420\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 1.07126904 (ave = 0.94372562)\n",
      "Loss_G = 1.38390839 (ave = 1.42278056)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.739294, max value: 0.682858\n",
      "D grad l2-norm: 8.734298, max value: 1.000605\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.87604648 (ave = 0.93589225)\n",
      "Loss_G = 1.39473331 (ave = 1.38623879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.799735, max value: 0.641511\n",
      "D grad l2-norm: 8.765026, max value: 0.955759\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.00250685 (ave = 0.95766792)\n",
      "Loss_G = 1.37387156 (ave = 1.36617377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.857310, max value: 0.600885\n",
      "D grad l2-norm: 8.758128, max value: 0.895783\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.86335254 (ave = 0.94390820)\n",
      "Loss_G = 1.36620224 (ave = 1.36687100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.979462, max value: 0.546180\n",
      "D grad l2-norm: 8.748869, max value: 0.817401\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001039)\n",
      "Loss_D = 0.85625190 (ave = 0.94933053)\n",
      "Loss_G = 1.37678754 (ave = 1.35379033)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.477093, max value: 0.484852\n",
      "D grad l2-norm: 8.645011, max value: 0.774285\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.007s / 800 iters, (0.001422)\n",
      "Loss_D = 1.06961954 (ave = 0.96031536)\n",
      "Loss_G = 1.42490578 (ave = 1.40276935)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.890807, max value: 0.485045\n",
      "D grad l2-norm: 9.093080, max value: 0.827367\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.014s / 800 iters, (0.002732)\n",
      "Loss_D = 0.87802362 (ave = 0.93116947)\n",
      "Loss_G = 1.38965940 (ave = 1.39109297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.471596, max value: 0.552679\n",
      "D grad l2-norm: 9.023001, max value: 0.824306\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001163)\n",
      "Loss_D = 0.85910487 (ave = 0.90133240)\n",
      "Loss_G = 1.47823000 (ave = 1.45180500)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.774416, max value: 0.594929\n",
      "D grad l2-norm: 9.120711, max value: 0.858682\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000990)\n",
      "Loss_D = 0.81943440 (ave = 0.85050282)\n",
      "Loss_G = 1.59885502 (ave = 1.55548425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.175829, max value: 0.621724\n",
      "D grad l2-norm: 9.426525, max value: 0.907412\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.009s / 800 iters, (0.001813)\n",
      "Loss_D = 0.68394113 (ave = 0.78590032)\n",
      "Loss_G = 1.72792602 (ave = 1.68888054)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.240439, max value: 0.636398\n",
      "D grad l2-norm: 9.886688, max value: 0.977512\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.89097089 (ave = 0.77277848)\n",
      "Loss_G = 1.78327537 (ave = 1.77168314)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.446078, max value: 0.695780\n",
      "D grad l2-norm: 10.226298, max value: 1.016604\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.80986768 (ave = 0.73678131)\n",
      "Loss_G = 1.79907477 (ave = 1.79045854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.333447, max value: 0.677788\n",
      "D grad l2-norm: 10.019531, max value: 1.001345\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.58500206 (ave = 0.68861283)\n",
      "Loss_G = 1.82087088 (ave = 1.81472330)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.383242, max value: 0.733512\n",
      "D grad l2-norm: 10.299745, max value: 1.027710\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.54243755 (ave = 0.65360631)\n",
      "Loss_G = 1.87792563 (ave = 1.87073851)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.720760, max value: 0.748419\n",
      "D grad l2-norm: 10.709780, max value: 1.071305\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.62581474 (ave = 0.64984307)\n",
      "Loss_G = 1.89436734 (ave = 1.89158616)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.876385, max value: 0.749695\n",
      "D grad l2-norm: 10.552669, max value: 1.046392\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.63217109 (ave = 0.64017476)\n",
      "Loss_G = 1.89851081 (ave = 1.90266654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.412368, max value: 0.833360\n",
      "D grad l2-norm: 10.908680, max value: 1.076067\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.69700044 (ave = 0.64003421)\n",
      "Loss_G = 1.83593106 (ave = 1.86846945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.344358, max value: 0.798291\n",
      "D grad l2-norm: 10.542624, max value: 1.021736\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 0.50727737 (ave = 0.60746944)\n",
      "Loss_G = 1.89550757 (ave = 1.85879004)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.178202, max value: 0.768659\n",
      "D grad l2-norm: 10.363546, max value: 1.016557\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.44215035 (ave = 0.58623211)\n",
      "Loss_G = 1.87537968 (ave = 1.86958661)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.475020, max value: 0.772692\n",
      "D grad l2-norm: 10.536103, max value: 1.050059\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.76436496 (ave = 0.62997135)\n",
      "Loss_G = 1.82218552 (ave = 1.85529969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.693441, max value: 0.820066\n",
      "D grad l2-norm: 10.340482, max value: 1.044204\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.019s / 800 iters, (0.003872)\n",
      "Loss_D = 0.72395575 (ave = 0.62653103)\n",
      "Loss_G = 1.78330123 (ave = 1.79732018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.856030, max value: 0.820209\n",
      "D grad l2-norm: 10.286771, max value: 1.055632\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.009s / 800 iters, (0.001722)\n",
      "Loss_D = 0.54344273 (ave = 0.60816238)\n",
      "Loss_G = 1.77644157 (ave = 1.78318565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.007962, max value: 0.838708\n",
      "D grad l2-norm: 10.222014, max value: 1.069222\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.62801999 (ave = 0.62396729)\n",
      "Loss_G = 1.69162428 (ave = 1.72500558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.095927, max value: 0.805280\n",
      "D grad l2-norm: 10.013711, max value: 1.032739\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.57780164 (ave = 0.63388869)\n",
      "Loss_G = 1.67394209 (ave = 1.66584342)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.054136, max value: 0.809467\n",
      "D grad l2-norm: 9.716731, max value: 1.000459\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.85704589 (ave = 0.68010929)\n",
      "Loss_G = 1.61838555 (ave = 1.63015010)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.848237, max value: 0.725453\n",
      "D grad l2-norm: 9.171297, max value: 0.931123\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.67891550 (ave = 0.67695223)\n",
      "Loss_G = 1.54970706 (ave = 1.56780450)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.034961, max value: 0.728629\n",
      "D grad l2-norm: 8.870577, max value: 0.870077\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 0.72971332 (ave = 0.70954168)\n",
      "Loss_G = 1.44469070 (ave = 1.49521141)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.670497, max value: 0.674271\n",
      "D grad l2-norm: 8.382203, max value: 0.833693\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.007s / 800 iters, (0.001339)\n",
      "Loss_D = 0.77896976 (ave = 0.73444843)\n",
      "Loss_G = 1.42243290 (ave = 1.44676106)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.744635, max value: 0.654182\n",
      "D grad l2-norm: 8.276289, max value: 0.833104\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002757)\n",
      "Loss_D = 0.74738997 (ave = 0.75404683)\n",
      "Loss_G = 1.35989833 (ave = 1.39612906)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.280605, max value: 0.608253\n",
      "D grad l2-norm: 7.846222, max value: 0.797925\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.68471611 (ave = 0.76291020)\n",
      "Loss_G = 1.36843824 (ave = 1.36197124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.019178, max value: 0.585815\n",
      "D grad l2-norm: 7.700968, max value: 0.788660\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.93157947 (ave = 0.79567647)\n",
      "Loss_G = 1.35071170 (ave = 1.36119180)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.745014, max value: 0.605608\n",
      "D grad l2-norm: 7.575106, max value: 0.757542\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001214)\n",
      "Loss_D = 0.64865971 (ave = 0.76015190)\n",
      "Loss_G = 1.36722755 (ave = 1.34812615)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.670169, max value: 0.609258\n",
      "D grad l2-norm: 7.396429, max value: 0.740400\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000952)\n",
      "Loss_D = 0.62537551 (ave = 0.76725717)\n",
      "Loss_G = 1.32582998 (ave = 1.35673900)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.820693, max value: 0.599373\n",
      "D grad l2-norm: 7.476746, max value: 0.729590\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.78456676 (ave = 0.79579673)\n",
      "Loss_G = 1.32013917 (ave = 1.32066717)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.928925, max value: 0.596393\n",
      "D grad l2-norm: 7.842177, max value: 0.727744\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.74761236 (ave = 0.79278630)\n",
      "Loss_G = 1.35038042 (ave = 1.35274746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.662865, max value: 0.529809\n",
      "D grad l2-norm: 7.784659, max value: 0.735652\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002864)\n",
      "Loss_D = 0.72117102 (ave = 0.76671017)\n",
      "Loss_G = 1.38140082 (ave = 1.39397359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.950404, max value: 0.515625\n",
      "D grad l2-norm: 8.205665, max value: 0.771270\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.60584974 (ave = 0.74983311)\n",
      "Loss_G = 1.38458514 (ave = 1.39097667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.047869, max value: 0.485628\n",
      "D grad l2-norm: 8.272041, max value: 0.758540\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.72941363 (ave = 0.75004199)\n",
      "Loss_G = 1.43581581 (ave = 1.42523851)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.125706, max value: 0.478697\n",
      "D grad l2-norm: 8.696098, max value: 0.773684\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.62136459 (ave = 0.73479608)\n",
      "Loss_G = 1.46780014 (ave = 1.44624782)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.879297, max value: 0.547215\n",
      "D grad l2-norm: 9.286317, max value: 0.867358\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.06168032 (ave = 0.78913578)\n",
      "Loss_G = 1.47272420 (ave = 1.48463955)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.219561, max value: 0.564253\n",
      "D grad l2-norm: 9.472060, max value: 0.886265\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.72044528 (ave = 0.74594491)\n",
      "Loss_G = 1.47824740 (ave = 1.48104360)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.713110, max value: 0.663132\n",
      "D grad l2-norm: 10.005528, max value: 0.885464\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 0.82691085 (ave = 0.76867796)\n",
      "Loss_G = 1.53230429 (ave = 1.50595331)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.300003, max value: 0.792219\n",
      "D grad l2-norm: 10.689091, max value: 0.971443\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.008s / 800 iters, (0.001658)\n",
      "Loss_D = 0.73151523 (ave = 0.73825104)\n",
      "Loss_G = 1.57047820 (ave = 1.55035062)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.243388, max value: 0.787295\n",
      "D grad l2-norm: 10.971682, max value: 0.990088\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001013)\n",
      "Loss_D = 0.79403180 (ave = 0.72710525)\n",
      "Loss_G = 1.64781451 (ave = 1.60261431)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.503615, max value: 0.829971\n",
      "D grad l2-norm: 11.694668, max value: 0.996376\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.69035256 (ave = 0.70310307)\n",
      "Loss_G = 1.67435229 (ave = 1.67326221)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.420696, max value: 0.818528\n",
      "D grad l2-norm: 11.679106, max value: 0.952973\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.008s / 800 iters, (0.001693)\n",
      "Loss_D = 0.55199820 (ave = 0.66872035)\n",
      "Loss_G = 1.75032508 (ave = 1.71733165)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.937255, max value: 0.859718\n",
      "D grad l2-norm: 12.287995, max value: 1.070776\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002728)\n",
      "Loss_D = 0.55752856 (ave = 0.66144760)\n",
      "Loss_G = 1.78051615 (ave = 1.77839146)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.676091, max value: 0.858396\n",
      "D grad l2-norm: 12.300238, max value: 1.147016\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002749)\n",
      "Loss_D = 0.78384256 (ave = 0.66903358)\n",
      "Loss_G = 1.86164296 (ave = 1.83648241)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.481834, max value: 0.835248\n",
      "D grad l2-norm: 12.411383, max value: 1.221222\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.68112552 (ave = 0.64325860)\n",
      "Loss_G = 1.87986362 (ave = 1.86127710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.819185, max value: 0.850093\n",
      "D grad l2-norm: 12.898771, max value: 1.304928\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.70111120 (ave = 0.63580161)\n",
      "Loss_G = 1.89688241 (ave = 1.90220978)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.646772, max value: 0.849378\n",
      "D grad l2-norm: 12.690252, max value: 1.307086\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.67737669 (ave = 0.62401863)\n",
      "Loss_G = 1.88114798 (ave = 1.89990177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.889648, max value: 0.871817\n",
      "D grad l2-norm: 12.782903, max value: 1.309228\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.53270710 (ave = 0.59875929)\n",
      "Loss_G = 1.89148998 (ave = 1.87968905)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.190856, max value: 0.839925\n",
      "D grad l2-norm: 13.140831, max value: 1.346178\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.68329501 (ave = 0.62067862)\n",
      "Loss_G = 1.86148190 (ave = 1.90094442)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.662406, max value: 0.805031\n",
      "D grad l2-norm: 12.586398, max value: 1.279555\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.55960047 (ave = 0.59528563)\n",
      "Loss_G = 1.91158903 (ave = 1.89551902)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.515396, max value: 0.857652\n",
      "D grad l2-norm: 12.448406, max value: 1.261947\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001198)\n",
      "Loss_D = 0.56712496 (ave = 0.59833668)\n",
      "Loss_G = 1.90862250 (ave = 1.87679393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.569837, max value: 0.864333\n",
      "D grad l2-norm: 12.398106, max value: 1.221025\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.012s / 800 iters, (0.002448)\n",
      "Loss_D = 0.54636037 (ave = 0.59460672)\n",
      "Loss_G = 1.88123798 (ave = 1.86090233)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.636320, max value: 0.856446\n",
      "D grad l2-norm: 12.153840, max value: 1.144372\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001200)\n",
      "Loss_D = 0.64326179 (ave = 0.60969464)\n",
      "Loss_G = 1.79435182 (ave = 1.83886452)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.638859, max value: 0.834039\n",
      "D grad l2-norm: 11.895741, max value: 1.118998\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.61644137 (ave = 0.62205657)\n",
      "Loss_G = 1.79927862 (ave = 1.78863578)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.725058, max value: 0.826760\n",
      "D grad l2-norm: 11.900210, max value: 1.178766\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.56184185 (ave = 0.61951346)\n",
      "Loss_G = 1.77213311 (ave = 1.76922069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.716069, max value: 0.800672\n",
      "D grad l2-norm: 11.575709, max value: 1.183986\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001205)\n",
      "Loss_D = 0.73826510 (ave = 0.65200595)\n",
      "Loss_G = 1.67910683 (ave = 1.72463689)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.660045, max value: 0.798506\n",
      "D grad l2-norm: 11.099885, max value: 1.142170\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.65703559 (ave = 0.66489947)\n",
      "Loss_G = 1.68602526 (ave = 1.69363115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.350030, max value: 0.769931\n",
      "D grad l2-norm: 11.357071, max value: 1.169017\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001014)\n",
      "Loss_D = 0.69768786 (ave = 0.68880348)\n",
      "Loss_G = 1.57306111 (ave = 1.62718902)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.160096, max value: 0.826438\n",
      "D grad l2-norm: 10.734058, max value: 1.110824\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.76066875 (ave = 0.72043355)\n",
      "Loss_G = 1.49324453 (ave = 1.57665305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.704477, max value: 0.885171\n",
      "D grad l2-norm: 10.957404, max value: 1.122345\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 0.90650481 (ave = 0.78353772)\n",
      "Loss_G = 1.49933517 (ave = 1.51999485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.049513, max value: 0.932298\n",
      "D grad l2-norm: 10.694743, max value: 1.097279\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.85296541 (ave = 0.81475941)\n",
      "Loss_G = 1.38533401 (ave = 1.43634584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.569340, max value: 0.865356\n",
      "D grad l2-norm: 10.076205, max value: 1.022583\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001205)\n",
      "Loss_D = 1.01905882 (ave = 0.87149124)\n",
      "Loss_G = 1.37270534 (ave = 1.39014125)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.275857, max value: 0.802894\n",
      "D grad l2-norm: 10.001588, max value: 1.019142\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001243)\n",
      "Loss_D = 0.86694670 (ave = 0.86541479)\n",
      "Loss_G = 1.36811638 (ave = 1.36894970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.151725, max value: 0.768036\n",
      "D grad l2-norm: 9.868997, max value: 0.999031\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.96890378 (ave = 0.89675666)\n",
      "Loss_G = 1.35870361 (ave = 1.38056266)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.827258, max value: 0.676030\n",
      "D grad l2-norm: 9.750338, max value: 0.990001\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.014s / 800 iters, (0.002723)\n",
      "Loss_D = 0.85260499 (ave = 0.89464736)\n",
      "Loss_G = 1.41397715 (ave = 1.39991059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.016208, max value: 0.705997\n",
      "D grad l2-norm: 9.942933, max value: 1.029598\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002761)\n",
      "Loss_D = 1.05308175 (ave = 0.92039427)\n",
      "Loss_G = 1.40763426 (ave = 1.39222522)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.186073, max value: 0.665154\n",
      "D grad l2-norm: 9.942089, max value: 1.024254\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.98188055 (ave = 0.92173535)\n",
      "Loss_G = 1.38026202 (ave = 1.38491755)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.087452, max value: 0.637662\n",
      "D grad l2-norm: 9.845084, max value: 1.002776\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001141)\n",
      "Loss_D = 0.94099522 (ave = 0.91460284)\n",
      "Loss_G = 1.41693783 (ave = 1.42714231)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.335076, max value: 0.647036\n",
      "D grad l2-norm: 9.597773, max value: 0.965194\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001783)\n",
      "Loss_D = 0.79952002 (ave = 0.87687672)\n",
      "Loss_G = 1.45064163 (ave = 1.45063426)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.625445, max value: 0.655169\n",
      "D grad l2-norm: 9.926583, max value: 0.961872\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.96788555 (ave = 0.89172653)\n",
      "Loss_G = 1.44592202 (ave = 1.46749341)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.303024, max value: 0.691659\n",
      "D grad l2-norm: 9.539090, max value: 0.895584\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001199)\n",
      "Loss_D = 0.64512944 (ave = 0.85196134)\n",
      "Loss_G = 1.43581057 (ave = 1.45046489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.538321, max value: 0.727566\n",
      "D grad l2-norm: 9.487748, max value: 0.844884\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.88508445 (ave = 0.89011295)\n",
      "Loss_G = 1.40589130 (ave = 1.43861113)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.612050, max value: 0.784626\n",
      "D grad l2-norm: 9.327493, max value: 0.790150\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 1.07493949 (ave = 0.91853048)\n",
      "Loss_G = 1.37990928 (ave = 1.41203105)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.400756, max value: 0.773762\n",
      "D grad l2-norm: 9.488997, max value: 0.780533\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.94947124 (ave = 0.89481097)\n",
      "Loss_G = 1.39390576 (ave = 1.40775936)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.068845, max value: 0.732632\n",
      "D grad l2-norm: 9.467879, max value: 0.754732\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.92573774 (ave = 0.88332129)\n",
      "Loss_G = 1.46277308 (ave = 1.46046965)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.194912, max value: 0.683601\n",
      "D grad l2-norm: 9.088929, max value: 0.763146\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.71498907 (ave = 0.82866193)\n",
      "Loss_G = 1.51908934 (ave = 1.50220757)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.115837, max value: 0.693727\n",
      "D grad l2-norm: 9.400293, max value: 0.776567\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001250)\n",
      "Loss_D = 0.81698632 (ave = 0.82086061)\n",
      "Loss_G = 1.56346822 (ave = 1.53113089)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.424503, max value: 0.660705\n",
      "D grad l2-norm: 9.340026, max value: 0.786747\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 0.89203078 (ave = 0.80166322)\n",
      "Loss_G = 1.58985889 (ave = 1.57950976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.892246, max value: 0.620195\n",
      "D grad l2-norm: 9.289235, max value: 0.793083\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001041)\n",
      "Loss_D = 0.55096942 (ave = 0.72883450)\n",
      "Loss_G = 1.67014885 (ave = 1.61787407)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.828945, max value: 0.585950\n",
      "D grad l2-norm: 9.409044, max value: 0.808946\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.013s / 800 iters, (0.002588)\n",
      "Loss_D = 0.63236600 (ave = 0.72046231)\n",
      "Loss_G = 1.67638659 (ave = 1.67048116)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.022747, max value: 0.565223\n",
      "D grad l2-norm: 9.433535, max value: 0.811917\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.012s / 800 iters, (0.002375)\n",
      "Loss_D = 0.65254533 (ave = 0.70749949)\n",
      "Loss_G = 1.64217329 (ave = 1.65875852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.055291, max value: 0.522018\n",
      "D grad l2-norm: 9.179132, max value: 0.807653\n",
      "üîÅ TSCV for Asset 3\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.40227008 (ave = 1.40547512)\n",
      "Loss_G = 0.65858376 (ave = 0.65907143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965897, max value: 0.024832\n",
      "D grad l2-norm: 0.632818, max value: 0.482414\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001189)\n",
      "Loss_D = 1.40484667 (ave = 1.39801960)\n",
      "Loss_G = 0.65648097 (ave = 0.65735744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966368, max value: 0.021722\n",
      "D grad l2-norm: 0.630600, max value: 0.481325\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.009s / 800 iters, (0.001796)\n",
      "Loss_D = 1.39602017 (ave = 1.38949144)\n",
      "Loss_G = 0.65472841 (ave = 0.65556891)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968108, max value: 0.024162\n",
      "D grad l2-norm: 0.629958, max value: 0.480414\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.013s / 800 iters, (0.002687)\n",
      "Loss_D = 1.37049401 (ave = 1.37941763)\n",
      "Loss_G = 0.65279204 (ave = 0.65372508)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968620, max value: 0.021366\n",
      "D grad l2-norm: 0.630061, max value: 0.479406\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 1.36611044 (ave = 1.37166052)\n",
      "Loss_G = 0.65206122 (ave = 0.65252073)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966548, max value: 0.029349\n",
      "D grad l2-norm: 0.632746, max value: 0.479026\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002747)\n",
      "Loss_D = 1.36619282 (ave = 1.36544969)\n",
      "Loss_G = 0.64973366 (ave = 0.65075705)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966173, max value: 0.032265\n",
      "D grad l2-norm: 0.632617, max value: 0.477813\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001296)\n",
      "Loss_D = 1.34330750 (ave = 1.35589130)\n",
      "Loss_G = 0.64929783 (ave = 0.64941764)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965473, max value: 0.027348\n",
      "D grad l2-norm: 0.633558, max value: 0.477585\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 1.35889184 (ave = 1.35168095)\n",
      "Loss_G = 0.64748979 (ave = 0.64817635)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971012, max value: 0.023473\n",
      "D grad l2-norm: 0.636187, max value: 0.476639\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001012)\n",
      "Loss_D = 1.33280885 (ave = 1.34196162)\n",
      "Loss_G = 0.64652193 (ave = 0.64696120)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968773, max value: 0.040422\n",
      "D grad l2-norm: 0.638473, max value: 0.476133\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.33103716 (ave = 1.33559988)\n",
      "Loss_G = 0.64511001 (ave = 0.64583178)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968977, max value: 0.026096\n",
      "D grad l2-norm: 0.640614, max value: 0.475391\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001181)\n",
      "Loss_D = 1.31573558 (ave = 1.32789454)\n",
      "Loss_G = 0.64495021 (ave = 0.64524138)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967409, max value: 0.031917\n",
      "D grad l2-norm: 0.644017, max value: 0.475307\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 1.32193565 (ave = 1.32229545)\n",
      "Loss_G = 0.64465117 (ave = 0.64468555)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968575, max value: 0.031049\n",
      "D grad l2-norm: 0.647601, max value: 0.475149\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 1.32251143 (ave = 1.31626418)\n",
      "Loss_G = 0.64443541 (ave = 0.64424754)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970434, max value: 0.028881\n",
      "D grad l2-norm: 0.650688, max value: 0.475037\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 1.30732512 (ave = 1.30841765)\n",
      "Loss_G = 0.64332533 (ave = 0.64377875)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970929, max value: 0.029049\n",
      "D grad l2-norm: 0.656978, max value: 0.474452\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.28550124 (ave = 1.30000274)\n",
      "Loss_G = 0.64395511 (ave = 0.64370898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979833, max value: 0.034856\n",
      "D grad l2-norm: 0.661353, max value: 0.474782\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.28601408 (ave = 1.29441340)\n",
      "Loss_G = 0.64437252 (ave = 0.64401821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973335, max value: 0.031276\n",
      "D grad l2-norm: 0.665961, max value: 0.475001\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.27360809 (ave = 1.28684413)\n",
      "Loss_G = 0.64471453 (ave = 0.64447877)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975017, max value: 0.032492\n",
      "D grad l2-norm: 0.671902, max value: 0.475181\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 1.27835631 (ave = 1.28115966)\n",
      "Loss_G = 0.64570087 (ave = 0.64519418)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970299, max value: 0.030449\n",
      "D grad l2-norm: 0.678614, max value: 0.475694\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 1.27684247 (ave = 1.27480114)\n",
      "Loss_G = 0.64575458 (ave = 0.64591868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974092, max value: 0.029227\n",
      "D grad l2-norm: 0.687859, max value: 0.475724\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.25255954 (ave = 1.26503675)\n",
      "Loss_G = 0.64834398 (ave = 0.64748737)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:59:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969331, max value: 0.032023\n",
      "D grad l2-norm: 0.692566, max value: 0.477081\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001012)\n",
      "Loss_D = 1.26318920 (ave = 1.26034904)\n",
      "Loss_G = 0.64828402 (ave = 0.64810572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970043, max value: 0.025668\n",
      "D grad l2-norm: 0.704049, max value: 0.477046\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 1.24047494 (ave = 1.25100453)\n",
      "Loss_G = 0.65147090 (ave = 0.65019439)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977615, max value: 0.030932\n",
      "D grad l2-norm: 0.713035, max value: 0.478711\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.24000633 (ave = 1.24373333)\n",
      "Loss_G = 0.65492195 (ave = 0.65338119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970270, max value: 0.031524\n",
      "D grad l2-norm: 0.716749, max value: 0.480506\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001226)\n",
      "Loss_D = 1.22854972 (ave = 1.23413575)\n",
      "Loss_G = 0.65804148 (ave = 0.65626451)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962637, max value: 0.033560\n",
      "D grad l2-norm: 0.727963, max value: 0.482123\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.21631157 (ave = 1.22489786)\n",
      "Loss_G = 0.66152632 (ave = 0.65988511)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970593, max value: 0.025202\n",
      "D grad l2-norm: 0.735619, max value: 0.483924\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.21814430 (ave = 1.21677403)\n",
      "Loss_G = 0.66310018 (ave = 0.66263096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971118, max value: 0.028107\n",
      "D grad l2-norm: 0.754701, max value: 0.484733\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 1.22311974 (ave = 1.20891056)\n",
      "Loss_G = 0.66974491 (ave = 0.66713485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970210, max value: 0.027481\n",
      "D grad l2-norm: 0.760140, max value: 0.488146\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001158)\n",
      "Loss_D = 1.18953478 (ave = 1.19573989)\n",
      "Loss_G = 0.67534322 (ave = 0.67248112)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971485, max value: 0.021276\n",
      "D grad l2-norm: 0.773839, max value: 0.491007\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 1.18168402 (ave = 1.18464587)\n",
      "Loss_G = 0.68107861 (ave = 0.67796836)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969441, max value: 0.023083\n",
      "D grad l2-norm: 0.782985, max value: 0.493919\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 1.18834162 (ave = 1.17599819)\n",
      "Loss_G = 0.68659735 (ave = 0.68370227)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968443, max value: 0.021894\n",
      "D grad l2-norm: 0.795636, max value: 0.496702\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001152)\n",
      "Loss_D = 1.15170467 (ave = 1.16111374)\n",
      "Loss_G = 0.69185865 (ave = 0.68966804)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970277, max value: 0.021360\n",
      "D grad l2-norm: 0.811896, max value: 0.499343\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 1.14969862 (ave = 1.15084317)\n",
      "Loss_G = 0.69947278 (ave = 0.69624292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977861, max value: 0.021063\n",
      "D grad l2-norm: 0.822737, max value: 0.503143\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001198)\n",
      "Loss_D = 1.11153400 (ave = 1.13503499)\n",
      "Loss_G = 0.70591980 (ave = 0.70272564)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973133, max value: 0.028302\n",
      "D grad l2-norm: 0.839879, max value: 0.506336\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001162)\n",
      "Loss_D = 1.11120164 (ave = 1.12409129)\n",
      "Loss_G = 0.71276623 (ave = 0.71015605)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972314, max value: 0.032563\n",
      "D grad l2-norm: 0.856405, max value: 0.509700\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001168)\n",
      "Loss_D = 1.10312283 (ave = 1.11174219)\n",
      "Loss_G = 0.71991897 (ave = 0.71708149)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974954, max value: 0.035505\n",
      "D grad l2-norm: 0.868881, max value: 0.513198\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001209)\n",
      "Loss_D = 1.07695651 (ave = 1.09798198)\n",
      "Loss_G = 0.72582656 (ave = 0.72427177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.990061, max value: 0.035286\n",
      "D grad l2-norm: 0.890975, max value: 0.516062\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001206)\n",
      "Loss_D = 1.09902048 (ave = 1.08992021)\n",
      "Loss_G = 0.73389089 (ave = 0.73141255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979943, max value: 0.030743\n",
      "D grad l2-norm: 0.913570, max value: 0.519949\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001188)\n",
      "Loss_D = 1.07448077 (ave = 1.07646351)\n",
      "Loss_G = 0.74106252 (ave = 0.73788135)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986592, max value: 0.042218\n",
      "D grad l2-norm: 0.923007, max value: 0.523374\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001166)\n",
      "Loss_D = 1.07373428 (ave = 1.06628308)\n",
      "Loss_G = 0.74692732 (ave = 0.74494277)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992651, max value: 0.042806\n",
      "D grad l2-norm: 0.940747, max value: 0.526166\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001263)\n",
      "Loss_D = 1.02933908 (ave = 1.05095031)\n",
      "Loss_G = 0.75081724 (ave = 0.75037527)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.009270, max value: 0.044827\n",
      "D grad l2-norm: 0.955385, max value: 0.527999\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 1.03372562 (ave = 1.04249334)\n",
      "Loss_G = 0.75954026 (ave = 0.75666136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.012436, max value: 0.052785\n",
      "D grad l2-norm: 0.972333, max value: 0.532094\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001184)\n",
      "Loss_D = 1.04591966 (ave = 1.03600848)\n",
      "Loss_G = 0.76241291 (ave = 0.76061566)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.028595, max value: 0.054258\n",
      "D grad l2-norm: 0.982023, max value: 0.533432\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001164)\n",
      "Loss_D = 1.04524064 (ave = 1.02982519)\n",
      "Loss_G = 0.76383102 (ave = 0.76239731)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.040380, max value: 0.055073\n",
      "D grad l2-norm: 0.999210, max value: 0.534091\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.007s / 800 iters, (0.001319)\n",
      "Loss_D = 1.00749242 (ave = 1.01899018)\n",
      "Loss_G = 0.76569957 (ave = 0.76477485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.062525, max value: 0.069796\n",
      "D grad l2-norm: 1.017783, max value: 0.534960\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001230)\n",
      "Loss_D = 0.99914557 (ave = 1.01293234)\n",
      "Loss_G = 0.76123869 (ave = 0.76295094)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.071872, max value: 0.066491\n",
      "D grad l2-norm: 1.035552, max value: 0.532857\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002846)\n",
      "Loss_D = 1.01867950 (ave = 1.01407630)\n",
      "Loss_G = 0.76333088 (ave = 0.76341499)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.088626, max value: 0.070359\n",
      "D grad l2-norm: 1.051369, max value: 0.533835\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.138s / 800 iters, (0.028)\tData load 0.014s / 800 iters, (0.002874)\n",
      "Loss_D = 1.02225173 (ave = 1.01197772)\n",
      "Loss_G = 0.76443470 (ave = 0.76280123)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.101325, max value: 0.075058\n",
      "D grad l2-norm: 1.074645, max value: 0.534346\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 800 iters, (0.026)\tData load 0.006s / 800 iters, (0.001197)\n",
      "Loss_D = 0.99096686 (ave = 1.00511352)\n",
      "Loss_G = 0.76403826 (ave = 0.76366874)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.115557, max value: 0.073559\n",
      "D grad l2-norm: 1.098909, max value: 0.534144\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001165)\n",
      "Loss_D = 0.99820840 (ave = 1.00087179)\n",
      "Loss_G = 0.76632339 (ave = 0.76510433)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.122916, max value: 0.086300\n",
      "D grad l2-norm: 1.129767, max value: 0.535205\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001184)\n",
      "Loss_D = 0.97121215 (ave = 0.99408031)\n",
      "Loss_G = 0.76970804 (ave = 0.76796113)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.146932, max value: 0.088589\n",
      "D grad l2-norm: 1.166347, max value: 0.536763\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.99501610 (ave = 0.99494827)\n",
      "Loss_G = 0.77313185 (ave = 0.77277961)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.151746, max value: 0.099618\n",
      "D grad l2-norm: 1.185971, max value: 0.538310\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001146)\n",
      "Loss_D = 0.98242009 (ave = 0.98771852)\n",
      "Loss_G = 0.77850819 (ave = 0.77597028)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.168807, max value: 0.102010\n",
      "D grad l2-norm: 1.216879, max value: 0.540787\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 0.99008369 (ave = 0.98532172)\n",
      "Loss_G = 0.78014433 (ave = 0.77784696)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.205369, max value: 0.118496\n",
      "D grad l2-norm: 1.254754, max value: 0.541521\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.96227896 (ave = 0.97945609)\n",
      "Loss_G = 0.78529227 (ave = 0.78180896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.234081, max value: 0.131714\n",
      "D grad l2-norm: 1.291464, max value: 0.543839\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 0.97708786 (ave = 0.97831769)\n",
      "Loss_G = 0.78104782 (ave = 0.78191974)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.276415, max value: 0.141312\n",
      "D grad l2-norm: 1.325578, max value: 0.541853\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 0.99534905 (ave = 0.97918036)\n",
      "Loss_G = 0.78704429 (ave = 0.78740883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.289861, max value: 0.150465\n",
      "D grad l2-norm: 1.364886, max value: 0.544600\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 1.00971627 (ave = 0.97671227)\n",
      "Loss_G = 0.79221517 (ave = 0.79325238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.314482, max value: 0.154107\n",
      "D grad l2-norm: 1.394233, max value: 0.546910\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 0.97222066 (ave = 0.96725022)\n",
      "Loss_G = 0.80300987 (ave = 0.79921472)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.315277, max value: 0.154704\n",
      "D grad l2-norm: 1.429170, max value: 0.551834\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 0.93343842 (ave = 0.95513973)\n",
      "Loss_G = 0.81283927 (ave = 0.80927351)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.335306, max value: 0.140758\n",
      "D grad l2-norm: 1.464440, max value: 0.556118\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.88998258 (ave = 0.94149585)\n",
      "Loss_G = 0.82521832 (ave = 0.81789527)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.332309, max value: 0.151205\n",
      "D grad l2-norm: 1.489045, max value: 0.561681\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001174)\n",
      "Loss_D = 0.97124308 (ave = 0.94175929)\n",
      "Loss_G = 0.83867025 (ave = 0.83039058)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.326581, max value: 0.140397\n",
      "D grad l2-norm: 1.496197, max value: 0.567480\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.92490935 (ave = 0.92635913)\n",
      "Loss_G = 0.84506005 (ave = 0.84082620)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.358955, max value: 0.144341\n",
      "D grad l2-norm: 1.542370, max value: 0.570199\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001179)\n",
      "Loss_D = 0.84871972 (ave = 0.90345998)\n",
      "Loss_G = 0.86225432 (ave = 0.85512339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.356769, max value: 0.144023\n",
      "D grad l2-norm: 1.551041, max value: 0.577615\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.90855908 (ave = 0.89736402)\n",
      "Loss_G = 0.86795372 (ave = 0.86647851)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.411190, max value: 0.139705\n",
      "D grad l2-norm: 1.576816, max value: 0.579953\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 0.88636786 (ave = 0.88572125)\n",
      "Loss_G = 0.87730074 (ave = 0.87415303)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.433310, max value: 0.142842\n",
      "D grad l2-norm: 1.578892, max value: 0.583840\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.84459960 (ave = 0.87193000)\n",
      "Loss_G = 0.88376611 (ave = 0.88069403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.449336, max value: 0.131901\n",
      "D grad l2-norm: 1.603794, max value: 0.586558\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001196)\n",
      "Loss_D = 0.85967612 (ave = 0.86616378)\n",
      "Loss_G = 0.88475186 (ave = 0.88309853)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.477489, max value: 0.147144\n",
      "D grad l2-norm: 1.602915, max value: 0.586914\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.83422112 (ave = 0.85831546)\n",
      "Loss_G = 0.89212114 (ave = 0.88963937)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.510226, max value: 0.134417\n",
      "D grad l2-norm: 1.601028, max value: 0.590008\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 800 iters, (0.026)\tData load 0.018s / 800 iters, (0.003698)\n",
      "Loss_D = 0.84922349 (ave = 0.85511701)\n",
      "Loss_G = 0.88489854 (ave = 0.88737658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.567436, max value: 0.140048\n",
      "D grad l2-norm: 1.622829, max value: 0.586952\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.79535973 (ave = 0.84782889)\n",
      "Loss_G = 0.88545346 (ave = 0.88473197)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.616197, max value: 0.143977\n",
      "D grad l2-norm: 1.644068, max value: 0.587259\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.88625008 (ave = 0.86047001)\n",
      "Loss_G = 0.88042665 (ave = 0.87892485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.679870, max value: 0.156557\n",
      "D grad l2-norm: 1.665235, max value: 0.585123\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.91644657 (ave = 0.87159592)\n",
      "Loss_G = 0.85756993 (ave = 0.86261871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.828989, max value: 0.176750\n",
      "D grad l2-norm: 1.710209, max value: 0.575372\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.95582283 (ave = 0.88843874)\n",
      "Loss_G = 0.83669007 (ave = 0.84607588)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.971531, max value: 0.206587\n",
      "D grad l2-norm: 1.766172, max value: 0.566373\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.89586639 (ave = 0.89471133)\n",
      "Loss_G = 0.82069445 (ave = 0.83001647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.009774, max value: 0.210902\n",
      "D grad l2-norm: 1.802854, max value: 0.559128\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.91827744 (ave = 0.91328806)\n",
      "Loss_G = 0.80955827 (ave = 0.81382583)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.092236, max value: 0.220847\n",
      "D grad l2-norm: 1.875596, max value: 0.554210\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.92326152 (ave = 0.91785631)\n",
      "Loss_G = 0.81083971 (ave = 0.80691257)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.103379, max value: 0.221821\n",
      "D grad l2-norm: 1.931169, max value: 0.554772\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001146)\n",
      "Loss_D = 0.84345275 (ave = 0.90852611)\n",
      "Loss_G = 0.82056665 (ave = 0.81726511)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.140294, max value: 0.215710\n",
      "D grad l2-norm: 2.040702, max value: 0.559094\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.89435863 (ave = 0.91279148)\n",
      "Loss_G = 0.83898324 (ave = 0.82760624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.240027, max value: 0.210889\n",
      "D grad l2-norm: 2.178475, max value: 0.567084\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.88311982 (ave = 0.90162294)\n",
      "Loss_G = 0.84233892 (ave = 0.84695259)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.319402, max value: 0.214964\n",
      "D grad l2-norm: 2.303433, max value: 0.568304\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001178)\n",
      "Loss_D = 0.89283621 (ave = 0.89694635)\n",
      "Loss_G = 0.88144892 (ave = 0.86999856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.398334, max value: 0.235406\n",
      "D grad l2-norm: 2.404820, max value: 0.584938\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.84603816 (ave = 0.88214470)\n",
      "Loss_G = 0.88598770 (ave = 0.88296448)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.668188, max value: 0.251924\n",
      "D grad l2-norm: 2.605445, max value: 0.586609\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 0.83265114 (ave = 0.88490723)\n",
      "Loss_G = 0.89955533 (ave = 0.89407495)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.762636, max value: 0.271353\n",
      "D grad l2-norm: 2.656989, max value: 0.591952\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.94324934 (ave = 0.90599525)\n",
      "Loss_G = 0.88523114 (ave = 0.89174138)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.951659, max value: 0.283108\n",
      "D grad l2-norm: 2.835730, max value: 0.585986\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.99123502 (ave = 0.92359264)\n",
      "Loss_G = 0.90377200 (ave = 0.89875265)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.991459, max value: 0.287879\n",
      "D grad l2-norm: 2.917692, max value: 0.593157\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.86435318 (ave = 0.90895586)\n",
      "Loss_G = 0.93531764 (ave = 0.92242007)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.136937, max value: 0.296640\n",
      "D grad l2-norm: 3.148448, max value: 0.605614\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.94688845 (ave = 0.91009481)\n",
      "Loss_G = 0.96682298 (ave = 0.95472953)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.240566, max value: 0.317265\n",
      "D grad l2-norm: 3.299101, max value: 0.617988\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001251)\n",
      "Loss_D = 0.96623659 (ave = 0.90645663)\n",
      "Loss_G = 0.97166675 (ave = 0.97304093)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.325070, max value: 0.344912\n",
      "D grad l2-norm: 3.444675, max value: 0.620063\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.87718618 (ave = 0.89538549)\n",
      "Loss_G = 0.99994481 (ave = 0.99029458)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.513793, max value: 0.371925\n",
      "D grad l2-norm: 3.646805, max value: 0.629776\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.014s / 800 iters, (0.002748)\n",
      "Loss_D = 0.84305930 (ave = 0.88661741)\n",
      "Loss_G = 1.03941369 (ave = 1.02553716)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.620481, max value: 0.366446\n",
      "D grad l2-norm: 3.880501, max value: 0.644274\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002756)\n",
      "Loss_D = 0.86591780 (ave = 0.88333759)\n",
      "Loss_G = 1.05722380 (ave = 1.05274811)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.769961, max value: 0.364021\n",
      "D grad l2-norm: 4.099636, max value: 0.650546\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001154)\n",
      "Loss_D = 0.89403552 (ave = 0.89184830)\n",
      "Loss_G = 1.09444070 (ave = 1.07816477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.835506, max value: 0.355753\n",
      "D grad l2-norm: 4.190028, max value: 0.662843\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.81972605 (ave = 0.87873381)\n",
      "Loss_G = 1.09784174 (ave = 1.09425113)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.981310, max value: 0.348884\n",
      "D grad l2-norm: 4.376734, max value: 0.664195\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.90842998 (ave = 0.89946195)\n",
      "Loss_G = 1.09070611 (ave = 1.09467862)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.296044, max value: 0.356179\n",
      "D grad l2-norm: 4.554210, max value: 0.660317\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.93508995 (ave = 0.92527428)\n",
      "Loss_G = 1.06264448 (ave = 1.08452942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.582823, max value: 0.393354\n",
      "D grad l2-norm: 4.796194, max value: 0.650398\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.99464369 (ave = 0.95662999)\n",
      "Loss_G = 1.11305737 (ave = 1.09941890)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.637528, max value: 0.445207\n",
      "D grad l2-norm: 4.927540, max value: 0.667380\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.94716990 (ave = 0.95940316)\n",
      "Loss_G = 1.11045623 (ave = 1.10644772)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.818322, max value: 0.458483\n",
      "D grad l2-norm: 5.219316, max value: 0.667302\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.97371882 (ave = 0.96740373)\n",
      "Loss_G = 1.14216161 (ave = 1.13578434)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.727140, max value: 0.468846\n",
      "D grad l2-norm: 5.349900, max value: 0.677212\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.94371033 (ave = 0.95104367)\n",
      "Loss_G = 1.21494842 (ave = 1.18504248)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.901074, max value: 0.437578\n",
      "D grad l2-norm: 5.837932, max value: 0.705013\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.02405524 (ave = 0.95421244)\n",
      "Loss_G = 1.23667526 (ave = 1.22626295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.079880, max value: 0.413165\n",
      "D grad l2-norm: 6.093774, max value: 0.729811\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.86712623 (ave = 0.93437043)\n",
      "Loss_G = 1.29172039 (ave = 1.27513885)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.255038, max value: 0.420320\n",
      "D grad l2-norm: 6.470090, max value: 0.779271\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.017s / 800 iters, (0.003434)\n",
      "Loss_D = 0.91694450 (ave = 0.92982063)\n",
      "Loss_G = 1.35085940 (ave = 1.34053032)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.313121, max value: 0.446251\n",
      "D grad l2-norm: 6.640679, max value: 0.808369\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001162)\n",
      "Loss_D = 0.95875633 (ave = 0.92890095)\n",
      "Loss_G = 1.40801263 (ave = 1.39468234)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.423333, max value: 0.457759\n",
      "D grad l2-norm: 6.854601, max value: 0.841261\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.98486853 (ave = 0.92811807)\n",
      "Loss_G = 1.38693154 (ave = 1.39757617)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.501138, max value: 0.478904\n",
      "D grad l2-norm: 6.899604, max value: 0.834628\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.99434733 (ave = 0.93929950)\n",
      "Loss_G = 1.41568232 (ave = 1.41514027)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.482964, max value: 0.478882\n",
      "D grad l2-norm: 6.804966, max value: 0.830414\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.98108613 (ave = 0.94360386)\n",
      "Loss_G = 1.39549446 (ave = 1.41645188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.789721, max value: 0.462466\n",
      "D grad l2-norm: 6.942277, max value: 0.832825\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 1.01712215 (ave = 0.97246644)\n",
      "Loss_G = 1.33357811 (ave = 1.37388513)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.533838, max value: 0.454243\n",
      "D grad l2-norm: 6.959793, max value: 0.791186\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.24099767 (ave = 1.04632611)\n",
      "Loss_G = 1.29899287 (ave = 1.30824418)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.775110, max value: 0.441926\n",
      "D grad l2-norm: 6.877697, max value: 0.742768\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.91209841 (ave = 1.05382887)\n",
      "Loss_G = 1.18210840 (ave = 1.22214441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.953234, max value: 0.497531\n",
      "D grad l2-norm: 6.859795, max value: 0.688357\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 1.11455333 (ave = 1.11204758)\n",
      "Loss_G = 1.18416262 (ave = 1.20027401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.997337, max value: 0.525791\n",
      "D grad l2-norm: 6.998681, max value: 0.715347\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001173)\n",
      "Loss_D = 1.24643636 (ave = 1.13841000)\n",
      "Loss_G = 1.22641015 (ave = 1.20279245)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.888428, max value: 0.554227\n",
      "D grad l2-norm: 6.907305, max value: 0.710016\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 1.17387390 (ave = 1.13524714)\n",
      "Loss_G = 1.24301505 (ave = 1.23550360)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.373849, max value: 0.606572\n",
      "D grad l2-norm: 7.194615, max value: 0.732051\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.000966)\n",
      "Loss_D = 1.26549911 (ave = 1.15112238)\n",
      "Loss_G = 1.17546964 (ave = 1.21237261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.616361, max value: 0.634251\n",
      "D grad l2-norm: 7.203799, max value: 0.707234\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001165)\n",
      "Loss_D = 1.05960977 (ave = 1.14841876)\n",
      "Loss_G = 1.18907070 (ave = 1.19578292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.608881, max value: 0.635437\n",
      "D grad l2-norm: 7.216727, max value: 0.692088\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.12990189 (ave = 1.15437014)\n",
      "Loss_G = 1.17659688 (ave = 1.19848595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.577617, max value: 0.628929\n",
      "D grad l2-norm: 7.166812, max value: 0.683836\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.99020720 (ave = 1.13306777)\n",
      "Loss_G = 1.20597899 (ave = 1.21643670)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.798960, max value: 0.640940\n",
      "D grad l2-norm: 7.284106, max value: 0.695356\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.19321775 (ave = 1.15625122)\n",
      "Loss_G = 1.20808995 (ave = 1.21297996)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.524648, max value: 0.602240\n",
      "D grad l2-norm: 7.128181, max value: 0.695961\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 1.17784381 (ave = 1.13214922)\n",
      "Loss_G = 1.26078570 (ave = 1.23349814)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.444241, max value: 0.569881\n",
      "D grad l2-norm: 7.348116, max value: 0.712199\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.08148599 (ave = 1.09690403)\n",
      "Loss_G = 1.28865933 (ave = 1.28259814)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.112491, max value: 0.541061\n",
      "D grad l2-norm: 7.151131, max value: 0.719479\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.05616009 (ave = 1.05846772)\n",
      "Loss_G = 1.34569311 (ave = 1.31751549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.095204, max value: 0.576408\n",
      "D grad l2-norm: 7.437767, max value: 0.759079\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 1.01103389 (ave = 1.02106925)\n",
      "Loss_G = 1.38736844 (ave = 1.37631233)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.150682, max value: 0.622723\n",
      "D grad l2-norm: 7.698476, max value: 0.792224\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.87338156 (ave = 0.97440419)\n",
      "Loss_G = 1.38271809 (ave = 1.40350382)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.947900, max value: 0.633670\n",
      "D grad l2-norm: 7.661603, max value: 0.777039\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.83259517 (ave = 0.94432424)\n",
      "Loss_G = 1.43437302 (ave = 1.43120947)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.136600, max value: 0.665208\n",
      "D grad l2-norm: 7.706422, max value: 0.788432\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 1.05316997 (ave = 0.95452574)\n",
      "Loss_G = 1.42369258 (ave = 1.43677385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.193976, max value: 0.691289\n",
      "D grad l2-norm: 7.445037, max value: 0.754284\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.84164041 (ave = 0.92493865)\n",
      "Loss_G = 1.38228941 (ave = 1.40864456)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.705377, max value: 0.721852\n",
      "D grad l2-norm: 7.635407, max value: 0.753728\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.91255271 (ave = 0.94855859)\n",
      "Loss_G = 1.37034678 (ave = 1.36425607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.362195, max value: 0.668915\n",
      "D grad l2-norm: 7.377961, max value: 0.742133\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.011s / 800 iters, (0.002281)\n",
      "Loss_D = 0.86966693 (ave = 0.93422046)\n",
      "Loss_G = 1.32986140 (ave = 1.35090387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.062303, max value: 0.620504\n",
      "D grad l2-norm: 6.989228, max value: 0.731729\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.99489439 (ave = 0.94339105)\n",
      "Loss_G = 1.36573315 (ave = 1.35090842)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.291614, max value: 0.669136\n",
      "D grad l2-norm: 7.205355, max value: 0.739268\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.97875524 (ave = 0.94378121)\n",
      "Loss_G = 1.33480215 (ave = 1.32732179)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.186018, max value: 0.682107\n",
      "D grad l2-norm: 7.007466, max value: 0.732262\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.05818021 (ave = 0.95209683)\n",
      "Loss_G = 1.33027339 (ave = 1.32148013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.287208, max value: 0.730671\n",
      "D grad l2-norm: 7.043878, max value: 0.730307\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.84788322 (ave = 0.92545756)\n",
      "Loss_G = 1.28843367 (ave = 1.30332208)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.930151, max value: 0.725403\n",
      "D grad l2-norm: 6.756314, max value: 0.719629\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.91766846 (ave = 0.91944056)\n",
      "Loss_G = 1.33221602 (ave = 1.30713181)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.726744, max value: 0.684554\n",
      "D grad l2-norm: 6.798625, max value: 0.732507\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.93323642 (ave = 0.90703100)\n",
      "Loss_G = 1.33641851 (ave = 1.33686919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.602208, max value: 0.699069\n",
      "D grad l2-norm: 6.723358, max value: 0.733215\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.82786202 (ave = 0.88042766)\n",
      "Loss_G = 1.35069048 (ave = 1.35381253)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.014848, max value: 0.739909\n",
      "D grad l2-norm: 6.948383, max value: 0.735837\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.83163548 (ave = 0.88156830)\n",
      "Loss_G = 1.35352325 (ave = 1.36184599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.039222, max value: 0.695678\n",
      "D grad l2-norm: 6.872028, max value: 0.737202\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.94875908 (ave = 0.89375536)\n",
      "Loss_G = 1.36044014 (ave = 1.35517220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.524783, max value: 0.725104\n",
      "D grad l2-norm: 7.198690, max value: 0.739192\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.84695381 (ave = 0.87502171)\n",
      "Loss_G = 1.34660637 (ave = 1.35480325)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.837874, max value: 0.724416\n",
      "D grad l2-norm: 7.419886, max value: 0.735281\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.008s / 800 iters, (0.001510)\n",
      "Loss_D = 0.94638038 (ave = 0.89087642)\n",
      "Loss_G = 1.37944984 (ave = 1.36248739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.938727, max value: 0.739350\n",
      "D grad l2-norm: 7.575149, max value: 0.744455\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.88157606 (ave = 0.86845422)\n",
      "Loss_G = 1.39135849 (ave = 1.39210911)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.135510, max value: 0.734837\n",
      "D grad l2-norm: 7.820383, max value: 0.747480\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.80586129 (ave = 0.84750643)\n",
      "Loss_G = 1.38695216 (ave = 1.39134316)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.135688, max value: 0.738894\n",
      "D grad l2-norm: 8.004655, max value: 0.746991\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.74469614 (ave = 0.83381277)\n",
      "Loss_G = 1.43740213 (ave = 1.43762813)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.640709, max value: 0.786525\n",
      "D grad l2-norm: 8.256582, max value: 0.769163\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.70742726 (ave = 0.82857029)\n",
      "Loss_G = 1.44051576 (ave = 1.44323020)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.590290, max value: 0.836119\n",
      "D grad l2-norm: 8.225641, max value: 0.758198\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.90038860 (ave = 0.85000491)\n",
      "Loss_G = 1.43844187 (ave = 1.45699930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.577342, max value: 0.782011\n",
      "D grad l2-norm: 8.183545, max value: 0.758979\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.78221035 (ave = 0.83267995)\n",
      "Loss_G = 1.46237779 (ave = 1.45828915)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.305465, max value: 0.769425\n",
      "D grad l2-norm: 7.973132, max value: 0.764248\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.69495243 (ave = 0.82811053)\n",
      "Loss_G = 1.43583012 (ave = 1.43229389)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.432395, max value: 0.827718\n",
      "D grad l2-norm: 7.996654, max value: 0.758448\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.88616163 (ave = 0.85112313)\n",
      "Loss_G = 1.43081892 (ave = 1.43688188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.479356, max value: 0.856803\n",
      "D grad l2-norm: 7.997749, max value: 0.755972\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 1.01718092 (ave = 0.87629851)\n",
      "Loss_G = 1.36924064 (ave = 1.38922403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.793995, max value: 0.840564\n",
      "D grad l2-norm: 7.992273, max value: 0.740995\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001018)\n",
      "Loss_D = 0.91758287 (ave = 0.89435984)\n",
      "Loss_G = 1.34423542 (ave = 1.34987590)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.832380, max value: 0.783934\n",
      "D grad l2-norm: 8.064470, max value: 0.780071\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001205)\n",
      "Loss_D = 0.96004921 (ave = 0.91009988)\n",
      "Loss_G = 1.33686543 (ave = 1.32973175)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.472670, max value: 0.708166\n",
      "D grad l2-norm: 7.856517, max value: 0.792423\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.93442565 (ave = 0.91068859)\n",
      "Loss_G = 1.31834459 (ave = 1.33731296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.465743, max value: 0.656776\n",
      "D grad l2-norm: 7.775808, max value: 0.797463\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 1.08648276 (ave = 0.95217744)\n",
      "Loss_G = 1.28917885 (ave = 1.28931577)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.543433, max value: 0.625545\n",
      "D grad l2-norm: 7.752042, max value: 0.801082\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.92566574 (ave = 0.94188262)\n",
      "Loss_G = 1.27929699 (ave = 1.29144924)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.975477, max value: 0.660804\n",
      "D grad l2-norm: 8.102734, max value: 0.841736\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 0.85437918 (ave = 0.95021693)\n",
      "Loss_G = 1.33493078 (ave = 1.29425380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.674720, max value: 0.679918\n",
      "D grad l2-norm: 7.947817, max value: 0.828860\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001020)\n",
      "Loss_D = 0.93113130 (ave = 0.96665384)\n",
      "Loss_G = 1.31358933 (ave = 1.31658010)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.865378, max value: 0.742008\n",
      "D grad l2-norm: 8.060843, max value: 0.809256\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 0.91516858 (ave = 0.97640626)\n",
      "Loss_G = 1.28292608 (ave = 1.31030211)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.923028, max value: 0.720564\n",
      "D grad l2-norm: 8.174340, max value: 0.788642\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 1.02955425 (ave = 0.99181994)\n",
      "Loss_G = 1.34882808 (ave = 1.33347626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.112514, max value: 0.737123\n",
      "D grad l2-norm: 8.318782, max value: 0.790585\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 1.04684329 (ave = 1.00609330)\n",
      "Loss_G = 1.32618332 (ave = 1.31937971)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.773542, max value: 0.708894\n",
      "D grad l2-norm: 8.156707, max value: 0.742516\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 1.01725721 (ave = 0.99982538)\n",
      "Loss_G = 1.35862792 (ave = 1.36956596)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.817047, max value: 0.732662\n",
      "D grad l2-norm: 8.476274, max value: 0.739000\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.86425018 (ave = 0.96967576)\n",
      "Loss_G = 1.41152787 (ave = 1.39634781)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.847199, max value: 0.740538\n",
      "D grad l2-norm: 8.707466, max value: 0.751827\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 0.96819532 (ave = 0.97506163)\n",
      "Loss_G = 1.43665016 (ave = 1.43251376)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.008052, max value: 0.734280\n",
      "D grad l2-norm: 8.853575, max value: 0.756955\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 1.05987740 (ave = 0.98981255)\n",
      "Loss_G = 1.44866145 (ave = 1.43668602)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.864666, max value: 0.698974\n",
      "D grad l2-norm: 8.699535, max value: 0.761003\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 1.06799459 (ave = 0.98760060)\n",
      "Loss_G = 1.44113362 (ave = 1.44030013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.838599, max value: 0.721410\n",
      "D grad l2-norm: 8.731383, max value: 0.758494\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.007s / 800 iters, (0.001313)\n",
      "Loss_D = 0.86967504 (ave = 0.95923781)\n",
      "Loss_G = 1.47852278 (ave = 1.45544925)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.493392, max value: 0.794722\n",
      "D grad l2-norm: 8.657201, max value: 0.767062\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.14742732 (ave = 0.97762933)\n",
      "Loss_G = 1.51595163 (ave = 1.49534962)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.615602, max value: 0.862490\n",
      "D grad l2-norm: 9.065387, max value: 0.776561\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.02975237 (ave = 0.95027145)\n",
      "Loss_G = 1.54593110 (ave = 1.52789819)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.513162, max value: 0.886195\n",
      "D grad l2-norm: 8.940840, max value: 0.783161\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 0.94204742 (ave = 0.92751389)\n",
      "Loss_G = 1.52652562 (ave = 1.54591436)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.668119, max value: 0.938173\n",
      "D grad l2-norm: 8.753860, max value: 0.776311\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.82787156 (ave = 0.91064873)\n",
      "Loss_G = 1.51544642 (ave = 1.52022352)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.145047, max value: 0.981459\n",
      "D grad l2-norm: 8.824067, max value: 0.774980\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.81119955 (ave = 0.91923950)\n",
      "Loss_G = 1.46220541 (ave = 1.46741986)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.482947, max value: 0.948860\n",
      "D grad l2-norm: 8.907724, max value: 0.774822\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 0.90838325 (ave = 0.94832852)\n",
      "Loss_G = 1.40747261 (ave = 1.42708697)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.501992, max value: 0.887646\n",
      "D grad l2-norm: 8.730831, max value: 0.759443\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001041)\n",
      "Loss_D = 0.93580323 (ave = 0.96308107)\n",
      "Loss_G = 1.38639832 (ave = 1.41180553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.229636, max value: 0.790334\n",
      "D grad l2-norm: 8.385974, max value: 0.742462\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001022)\n",
      "Loss_D = 1.14726233 (ave = 1.00166049)\n",
      "Loss_G = 1.33040500 (ave = 1.34417646)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.182770, max value: 0.743420\n",
      "D grad l2-norm: 8.297883, max value: 0.728286\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.93764704 (ave = 1.00229172)\n",
      "Loss_G = 1.29904509 (ave = 1.30619152)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.203152, max value: 0.718095\n",
      "D grad l2-norm: 8.343088, max value: 0.720727\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001281)\n",
      "Loss_D = 1.00861979 (ave = 1.01248857)\n",
      "Loss_G = 1.29575896 (ave = 1.29611065)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.662995, max value: 0.634930\n",
      "D grad l2-norm: 7.905234, max value: 0.718804\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000964)\n",
      "Loss_D = 1.00297081 (ave = 1.01930377)\n",
      "Loss_G = 1.27427149 (ave = 1.26857350)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.376878, max value: 0.550062\n",
      "D grad l2-norm: 7.692489, max value: 0.714063\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001001)\n",
      "Loss_D = 0.99466038 (ave = 1.01418787)\n",
      "Loss_G = 1.22128820 (ave = 1.25533988)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.987720, max value: 0.510982\n",
      "D grad l2-norm: 7.569817, max value: 0.699838\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 1.01489723 (ave = 1.01344211)\n",
      "Loss_G = 1.29638052 (ave = 1.26105883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.984829, max value: 0.622640\n",
      "D grad l2-norm: 7.583442, max value: 0.720888\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001030)\n",
      "Loss_D = 0.92825693 (ave = 0.99358134)\n",
      "Loss_G = 1.22542429 (ave = 1.24865541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.798326, max value: 0.690671\n",
      "D grad l2-norm: 7.148771, max value: 0.701734\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 1.14154732 (ave = 1.02868050)\n",
      "Loss_G = 1.23010004 (ave = 1.22635055)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.151860, max value: 0.801704\n",
      "D grad l2-norm: 7.172716, max value: 0.701408\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 1.17513061 (ave = 1.05522227)\n",
      "Loss_G = 1.17319584 (ave = 1.17696896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.334503, max value: 0.867181\n",
      "D grad l2-norm: 7.158774, max value: 0.684811\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.92163563 (ave = 1.04818814)\n",
      "Loss_G = 1.14441466 (ave = 1.13846457)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.733889, max value: 0.879092\n",
      "D grad l2-norm: 6.663256, max value: 0.674886\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.011s / 800 iters, (0.002250)\n",
      "Loss_D = 1.14964437 (ave = 1.06669613)\n",
      "Loss_G = 1.16286492 (ave = 1.15150979)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.709834, max value: 0.906442\n",
      "D grad l2-norm: 6.785497, max value: 0.681880\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 1.06716418 (ave = 1.04652364)\n",
      "Loss_G = 1.18172514 (ave = 1.16842256)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.408153, max value: 0.879617\n",
      "D grad l2-norm: 6.643445, max value: 0.688834\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 0.99225104 (ave = 1.02729211)\n",
      "Loss_G = 1.17616272 (ave = 1.16770642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.463628, max value: 0.879975\n",
      "D grad l2-norm: 6.689504, max value: 0.687453\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.84614134 (ave = 1.00096737)\n",
      "Loss_G = 1.17733800 (ave = 1.16934834)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.380699, max value: 0.910801\n",
      "D grad l2-norm: 6.596896, max value: 0.688456\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001228)\n",
      "Loss_D = 1.15825975 (ave = 1.03431603)\n",
      "Loss_G = 1.18143988 (ave = 1.19637489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.401934, max value: 0.915283\n",
      "D grad l2-norm: 6.566877, max value: 0.688316\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.026s / 800 iters, (0.005135)\n",
      "Loss_D = 1.05115652 (ave = 1.02638116)\n",
      "Loss_G = 1.16796422 (ave = 1.16865375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.037504, max value: 0.845293\n",
      "D grad l2-norm: 6.310079, max value: 0.684475\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.92452621 (ave = 0.99661164)\n",
      "Loss_G = 1.21294188 (ave = 1.20578544)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.841664, max value: 0.779134\n",
      "D grad l2-norm: 6.464895, max value: 0.698561\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.02040124 (ave = 0.98849823)\n",
      "Loss_G = 1.23990643 (ave = 1.21300604)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.120902, max value: 0.719411\n",
      "D grad l2-norm: 6.330143, max value: 0.707475\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 0.85426104 (ave = 0.93198853)\n",
      "Loss_G = 1.28033817 (ave = 1.27005942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.064875, max value: 0.696552\n",
      "D grad l2-norm: 6.422015, max value: 0.718959\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.89785165 (ave = 0.90845017)\n",
      "Loss_G = 1.35274887 (ave = 1.31915689)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.003525, max value: 0.676240\n",
      "D grad l2-norm: 6.442043, max value: 0.737802\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.011s / 800 iters, (0.002229)\n",
      "Loss_D = 0.92375243 (ave = 0.89823520)\n",
      "Loss_G = 1.34320199 (ave = 1.34837081)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.932851, max value: 0.615720\n",
      "D grad l2-norm: 6.370876, max value: 0.735854\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002712)\n",
      "Loss_D = 0.86860681 (ave = 0.87710621)\n",
      "Loss_G = 1.34256983 (ave = 1.32957940)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.981272, max value: 0.554515\n",
      "D grad l2-norm: 6.395994, max value: 0.734978\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002756)\n",
      "Loss_D = 0.90271580 (ave = 0.87537225)\n",
      "Loss_G = 1.31438839 (ave = 1.32602241)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.043911, max value: 0.525981\n",
      "D grad l2-norm: 6.362106, max value: 0.727117\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.88079250 (ave = 0.86402472)\n",
      "Loss_G = 1.29102516 (ave = 1.31481247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.890483, max value: 0.450995\n",
      "D grad l2-norm: 6.104116, max value: 0.720674\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001150)\n",
      "Loss_D = 0.76643574 (ave = 0.85380391)\n",
      "Loss_G = 1.30296922 (ave = 1.29434001)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.903034, max value: 0.467070\n",
      "D grad l2-norm: 6.045775, max value: 0.724575\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.018s / 800 iters, (0.003675)\n",
      "Loss_D = 0.75723475 (ave = 0.84554932)\n",
      "Loss_G = 1.27404165 (ave = 1.28409584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.529817, max value: 0.468979\n",
      "D grad l2-norm: 5.726738, max value: 0.716152\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 0.81100297 (ave = 0.84361364)\n",
      "Loss_G = 1.29830575 (ave = 1.28813667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.283342, max value: 0.450736\n",
      "D grad l2-norm: 5.700337, max value: 0.723098\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.73994482 (ave = 0.83348600)\n",
      "Loss_G = 1.29907882 (ave = 1.28968413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.202202, max value: 0.451508\n",
      "D grad l2-norm: 5.663092, max value: 0.723698\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 0.67771167 (ave = 0.80439646)\n",
      "Loss_G = 1.30410957 (ave = 1.30380559)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.305665, max value: 0.460845\n",
      "D grad l2-norm: 5.525866, max value: 0.724110\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001150)\n",
      "Loss_D = 1.00524116 (ave = 0.84319798)\n",
      "Loss_G = 1.28746521 (ave = 1.30980921)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.641717, max value: 0.497102\n",
      "D grad l2-norm: 5.479819, max value: 0.720193\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.93794739 (ave = 0.83158801)\n",
      "Loss_G = 1.24873519 (ave = 1.28036366)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.104132, max value: 0.495686\n",
      "D grad l2-norm: 5.443716, max value: 0.708675\n",
      "üîÅ TSCV for Asset 4\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 1.38251114 (ave = 1.38953133)\n",
      "Loss_G = 0.69584554 (ave = 0.69720030)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961852, max value: 0.020199\n",
      "D grad l2-norm: 0.683126, max value: 0.501346\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 1.37053967 (ave = 1.37717426)\n",
      "Loss_G = 0.69298303 (ave = 0.69422610)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.958127, max value: 0.028870\n",
      "D grad l2-norm: 0.681735, max value: 0.499917\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.36722374 (ave = 1.36657839)\n",
      "Loss_G = 0.69091213 (ave = 0.69170913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963739, max value: 0.017517\n",
      "D grad l2-norm: 0.679539, max value: 0.498880\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.009s / 800 iters, (0.001739)\n",
      "Loss_D = 1.34942675 (ave = 1.35458016)\n",
      "Loss_G = 0.68874961 (ave = 0.68961917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967316, max value: 0.020326\n",
      "D grad l2-norm: 0.678943, max value: 0.497794\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001259)\n",
      "Loss_D = 1.34003079 (ave = 1.34393446)\n",
      "Loss_G = 0.68629980 (ave = 0.68735067)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969436, max value: 0.020277\n",
      "D grad l2-norm: 0.679156, max value: 0.496562\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001030)\n",
      "Loss_D = 1.31997824 (ave = 1.33252673)\n",
      "Loss_G = 0.68480736 (ave = 0.68537166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965590, max value: 0.027205\n",
      "D grad l2-norm: 0.677836, max value: 0.495810\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.32153082 (ave = 1.32411413)\n",
      "Loss_G = 0.68316603 (ave = 0.68361638)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967265, max value: 0.022889\n",
      "D grad l2-norm: 0.679371, max value: 0.494982\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.30107737 (ave = 1.31330724)\n",
      "Loss_G = 0.68123370 (ave = 0.68180093)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968098, max value: 0.027579\n",
      "D grad l2-norm: 0.683242, max value: 0.494004\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 1.29731131 (ave = 1.30472765)\n",
      "Loss_G = 0.67953306 (ave = 0.68003161)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969348, max value: 0.022802\n",
      "D grad l2-norm: 0.685732, max value: 0.493142\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 1.28105593 (ave = 1.29504969)\n",
      "Loss_G = 0.67782748 (ave = 0.67847304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962568, max value: 0.030367\n",
      "D grad l2-norm: 0.688338, max value: 0.492276\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 800 iters, (0.025)\tData load 0.018s / 800 iters, (0.003654)\n",
      "Loss_D = 1.27411902 (ave = 1.28652081)\n",
      "Loss_G = 0.67636293 (ave = 0.67703127)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965757, max value: 0.022996\n",
      "D grad l2-norm: 0.694103, max value: 0.491533\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.26876652 (ave = 1.27864232)\n",
      "Loss_G = 0.67462498 (ave = 0.67556930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964240, max value: 0.028282\n",
      "D grad l2-norm: 0.696900, max value: 0.490646\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001167)\n",
      "Loss_D = 1.26767015 (ave = 1.27154822)\n",
      "Loss_G = 0.67319000 (ave = 0.67412347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973134, max value: 0.024667\n",
      "D grad l2-norm: 0.700890, max value: 0.489912\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.006s / 800 iters, (0.001157)\n",
      "Loss_D = 1.24417543 (ave = 1.26198204)\n",
      "Loss_G = 0.67270684 (ave = 0.67321069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971870, max value: 0.031908\n",
      "D grad l2-norm: 0.705321, max value: 0.489666\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 1.24878669 (ave = 1.25566173)\n",
      "Loss_G = 0.67180687 (ave = 0.67222769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967740, max value: 0.032588\n",
      "D grad l2-norm: 0.711385, max value: 0.489208\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.24204516 (ave = 1.24855871)\n",
      "Loss_G = 0.67132342 (ave = 0.67190162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976088, max value: 0.040767\n",
      "D grad l2-norm: 0.720181, max value: 0.488961\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001241)\n",
      "Loss_D = 1.24282479 (ave = 1.24239421)\n",
      "Loss_G = 0.67134786 (ave = 0.67097178)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976034, max value: 0.039703\n",
      "D grad l2-norm: 0.721968, max value: 0.488971\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.24187851 (ave = 1.23589029)\n",
      "Loss_G = 0.67140770 (ave = 0.67117385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976879, max value: 0.035965\n",
      "D grad l2-norm: 0.730045, max value: 0.489000\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 1.22814250 (ave = 1.22812483)\n",
      "Loss_G = 0.67146164 (ave = 0.67126968)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972040, max value: 0.033562\n",
      "D grad l2-norm: 0.739653, max value: 0.489028\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.22186399 (ave = 1.22066944)\n",
      "Loss_G = 0.67316324 (ave = 0.67206085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968333, max value: 0.034083\n",
      "D grad l2-norm: 0.747377, max value: 0.489898\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.20371485 (ave = 1.21167216)\n",
      "Loss_G = 0.67524105 (ave = 0.67349645)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974440, max value: 0.029553\n",
      "D grad l2-norm: 0.755632, max value: 0.490956\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 1.22122407 (ave = 1.20734975)\n",
      "Loss_G = 0.67776835 (ave = 0.67511610)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977268, max value: 0.033068\n",
      "D grad l2-norm: 0.765052, max value: 0.492242\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001146)\n",
      "Loss_D = 1.19684899 (ave = 1.19769764)\n",
      "Loss_G = 0.67854869 (ave = 0.67725328)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976800, max value: 0.033476\n",
      "D grad l2-norm: 0.778991, max value: 0.492635\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 1.17887998 (ave = 1.18840623)\n",
      "Loss_G = 0.68174547 (ave = 0.68050454)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.978486, max value: 0.035379\n",
      "D grad l2-norm: 0.790461, max value: 0.494253\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.18672550 (ave = 1.18183827)\n",
      "Loss_G = 0.68419909 (ave = 0.68340771)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980900, max value: 0.034005\n",
      "D grad l2-norm: 0.805502, max value: 0.495491\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001263)\n",
      "Loss_D = 1.15450501 (ave = 1.17012691)\n",
      "Loss_G = 0.68885463 (ave = 0.68742231)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971016, max value: 0.029729\n",
      "D grad l2-norm: 0.815947, max value: 0.497836\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.017s / 800 iters, (0.003443)\n",
      "Loss_D = 1.15052378 (ave = 1.16189814)\n",
      "Loss_G = 0.69103992 (ave = 0.69076368)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974961, max value: 0.030870\n",
      "D grad l2-norm: 0.834285, max value: 0.498928\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.14415789 (ave = 1.15360463)\n",
      "Loss_G = 0.69852644 (ave = 0.69535987)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.981002, max value: 0.031282\n",
      "D grad l2-norm: 0.837198, max value: 0.502670\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.15727794 (ave = 1.14735398)\n",
      "Loss_G = 0.70067459 (ave = 0.69904575)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.981990, max value: 0.034951\n",
      "D grad l2-norm: 0.854873, max value: 0.503727\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 1.12155783 (ave = 1.13542585)\n",
      "Loss_G = 0.70464051 (ave = 0.70329323)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985226, max value: 0.049947\n",
      "D grad l2-norm: 0.870250, max value: 0.505691\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.12709677 (ave = 1.12885771)\n",
      "Loss_G = 0.71146411 (ave = 0.70818604)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984157, max value: 0.041771\n",
      "D grad l2-norm: 0.879887, max value: 0.509054\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002769)\n",
      "Loss_D = 1.12973595 (ave = 1.12005906)\n",
      "Loss_G = 0.71394771 (ave = 0.71255472)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.987753, max value: 0.048756\n",
      "D grad l2-norm: 0.900058, max value: 0.510275\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002759)\n",
      "Loss_D = 1.12053931 (ave = 1.11169817)\n",
      "Loss_G = 0.71870685 (ave = 0.71724998)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993757, max value: 0.048369\n",
      "D grad l2-norm: 0.915423, max value: 0.512599\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001202)\n",
      "Loss_D = 1.09185755 (ave = 1.10037715)\n",
      "Loss_G = 0.72357595 (ave = 0.72204070)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.999775, max value: 0.062774\n",
      "D grad l2-norm: 0.927124, max value: 0.514962\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002773)\n",
      "Loss_D = 1.09178972 (ave = 1.09331870)\n",
      "Loss_G = 0.72892076 (ave = 0.72677127)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.995005, max value: 0.060401\n",
      "D grad l2-norm: 0.941114, max value: 0.517538\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001016)\n",
      "Loss_D = 1.08776653 (ave = 1.08519092)\n",
      "Loss_G = 0.73470652 (ave = 0.73296484)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004162, max value: 0.058923\n",
      "D grad l2-norm: 0.957699, max value: 0.520327\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.07003307 (ave = 1.07497356)\n",
      "Loss_G = 0.74128467 (ave = 0.73715014)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.003602, max value: 0.066964\n",
      "D grad l2-norm: 0.973175, max value: 0.523468\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 1.08057415 (ave = 1.06864226)\n",
      "Loss_G = 0.74329007 (ave = 0.74133335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.012051, max value: 0.078755\n",
      "D grad l2-norm: 0.994144, max value: 0.524415\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 1.07034123 (ave = 1.05934844)\n",
      "Loss_G = 0.74834418 (ave = 0.74721875)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.021798, max value: 0.072932\n",
      "D grad l2-norm: 1.004791, max value: 0.526810\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.07646573 (ave = 1.05150476)\n",
      "Loss_G = 0.75339490 (ave = 0.75332196)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.021080, max value: 0.068105\n",
      "D grad l2-norm: 1.015231, max value: 0.529195\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.03177154 (ave = 1.03745492)\n",
      "Loss_G = 0.75918388 (ave = 0.75782349)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.027783, max value: 0.067947\n",
      "D grad l2-norm: 1.035690, max value: 0.531904\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.01675487 (ave = 1.02771528)\n",
      "Loss_G = 0.76640457 (ave = 0.76362337)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.033489, max value: 0.075328\n",
      "D grad l2-norm: 1.056647, max value: 0.535265\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001017)\n",
      "Loss_D = 1.00623620 (ave = 1.01779003)\n",
      "Loss_G = 0.77137065 (ave = 0.76995049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.040619, max value: 0.082118\n",
      "D grad l2-norm: 1.071524, max value: 0.537545\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 1.03983033 (ave = 1.01302252)\n",
      "Loss_G = 0.77887845 (ave = 0.77433753)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.046214, max value: 0.078171\n",
      "D grad l2-norm: 1.086714, max value: 0.541027\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001011)\n",
      "Loss_D = 0.99451500 (ave = 0.99901586)\n",
      "Loss_G = 0.78272021 (ave = 0.78072056)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.059991, max value: 0.078430\n",
      "D grad l2-norm: 1.109766, max value: 0.542768\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.98803329 (ave = 0.98974642)\n",
      "Loss_G = 0.78993827 (ave = 0.78711913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.065693, max value: 0.084078\n",
      "D grad l2-norm: 1.120566, max value: 0.546048\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.95672750 (ave = 0.97758684)\n",
      "Loss_G = 0.79617375 (ave = 0.79223919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.076434, max value: 0.089263\n",
      "D grad l2-norm: 1.147835, max value: 0.548883\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.93243635 (ave = 0.96529510)\n",
      "Loss_G = 0.79901600 (ave = 0.79704769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.092389, max value: 0.098133\n",
      "D grad l2-norm: 1.180429, max value: 0.550144\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.93870699 (ave = 0.95686722)\n",
      "Loss_G = 0.80986583 (ave = 0.80673586)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.086309, max value: 0.096944\n",
      "D grad l2-norm: 1.188178, max value: 0.555024\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000977)\n",
      "Loss_D = 0.93338454 (ave = 0.94755442)\n",
      "Loss_G = 0.81337321 (ave = 0.81189308)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.108432, max value: 0.096767\n",
      "D grad l2-norm: 1.214382, max value: 0.556559\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000994)\n",
      "Loss_D = 0.91465831 (ave = 0.93396268)\n",
      "Loss_G = 0.82327008 (ave = 0.82004726)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.109887, max value: 0.105726\n",
      "D grad l2-norm: 1.237978, max value: 0.560907\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001022)\n",
      "Loss_D = 0.90816098 (ave = 0.92360803)\n",
      "Loss_G = 0.83416629 (ave = 0.83073323)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.112539, max value: 0.097916\n",
      "D grad l2-norm: 1.255968, max value: 0.565660\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001000)\n",
      "Loss_D = 0.84479249 (ave = 0.90601597)\n",
      "Loss_G = 0.83794534 (ave = 0.83681922)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.138283, max value: 0.099578\n",
      "D grad l2-norm: 1.300549, max value: 0.567299\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000952)\n",
      "Loss_D = 0.90637398 (ave = 0.90481536)\n",
      "Loss_G = 0.84906465 (ave = 0.84712328)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.155114, max value: 0.107879\n",
      "D grad l2-norm: 1.316441, max value: 0.572102\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 0.87324035 (ave = 0.89079655)\n",
      "Loss_G = 0.85720575 (ave = 0.85517656)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.170326, max value: 0.108667\n",
      "D grad l2-norm: 1.345355, max value: 0.575551\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000988)\n",
      "Loss_D = 0.83541226 (ave = 0.87550769)\n",
      "Loss_G = 0.86468703 (ave = 0.86286292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.176363, max value: 0.108686\n",
      "D grad l2-norm: 1.367862, max value: 0.578734\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 0.86887658 (ave = 0.87001767)\n",
      "Loss_G = 0.88354540 (ave = 0.87601496)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.182364, max value: 0.112016\n",
      "D grad l2-norm: 1.374827, max value: 0.586592\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.87492120 (ave = 0.86140023)\n",
      "Loss_G = 0.88673753 (ave = 0.88223890)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.209451, max value: 0.116916\n",
      "D grad l2-norm: 1.397581, max value: 0.587907\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.80023515 (ave = 0.84297967)\n",
      "Loss_G = 0.89033377 (ave = 0.88800454)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.267139, max value: 0.138161\n",
      "D grad l2-norm: 1.420628, max value: 0.589365\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.82364845 (ave = 0.84043733)\n",
      "Loss_G = 0.89512205 (ave = 0.89374750)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.305215, max value: 0.141630\n",
      "D grad l2-norm: 1.415462, max value: 0.591303\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.85812271 (ave = 0.84186301)\n",
      "Loss_G = 0.89004791 (ave = 0.89553407)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.376682, max value: 0.155855\n",
      "D grad l2-norm: 1.424727, max value: 0.589226\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.83551192 (ave = 0.84043927)\n",
      "Loss_G = 0.88141334 (ave = 0.88274776)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.437893, max value: 0.180722\n",
      "D grad l2-norm: 1.433364, max value: 0.585611\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002726)\n",
      "Loss_D = 0.84427387 (ave = 0.84577395)\n",
      "Loss_G = 0.86386353 (ave = 0.87085418)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.530241, max value: 0.189001\n",
      "D grad l2-norm: 1.446678, max value: 0.578197\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.88428533 (ave = 0.86431892)\n",
      "Loss_G = 0.84516943 (ave = 0.85102708)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.570476, max value: 0.190949\n",
      "D grad l2-norm: 1.454297, max value: 0.570122\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.141s / 800 iters, (0.028)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.88593197 (ave = 0.87790264)\n",
      "Loss_G = 0.82372135 (ave = 0.82992654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.647038, max value: 0.195085\n",
      "D grad l2-norm: 1.461003, max value: 0.560839\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.91017032 (ave = 0.89395896)\n",
      "Loss_G = 0.79932559 (ave = 0.81195014)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.677708, max value: 0.219555\n",
      "D grad l2-norm: 1.466534, max value: 0.549839\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.016s / 800 iters, (0.003234)\n",
      "Loss_D = 0.95822775 (ave = 0.91693527)\n",
      "Loss_G = 0.78379691 (ave = 0.79271339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.735708, max value: 0.234209\n",
      "D grad l2-norm: 1.483167, max value: 0.542836\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.03872132 (ave = 0.94539679)\n",
      "Loss_G = 0.76903379 (ave = 0.77358412)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.786780, max value: 0.257763\n",
      "D grad l2-norm: 1.506456, max value: 0.535764\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 1.02325523 (ave = 0.95733019)\n",
      "Loss_G = 0.75638443 (ave = 0.75754023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.825712, max value: 0.268478\n",
      "D grad l2-norm: 1.560494, max value: 0.529899\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.97346890 (ave = 0.96219549)\n",
      "Loss_G = 0.74311596 (ave = 0.74387037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.863842, max value: 0.279858\n",
      "D grad l2-norm: 1.618442, max value: 0.523467\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.97926068 (ave = 0.97442944)\n",
      "Loss_G = 0.73827851 (ave = 0.73947648)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.889429, max value: 0.277407\n",
      "D grad l2-norm: 1.688156, max value: 0.520835\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.00459468 (ave = 0.98138089)\n",
      "Loss_G = 0.75899613 (ave = 0.74824574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.888066, max value: 0.278426\n",
      "D grad l2-norm: 1.782651, max value: 0.530705\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.95342189 (ave = 0.95732656)\n",
      "Loss_G = 0.78780854 (ave = 0.77114656)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.919389, max value: 0.286911\n",
      "D grad l2-norm: 1.891174, max value: 0.544232\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.009s / 800 iters, (0.001714)\n",
      "Loss_D = 0.86901116 (ave = 0.93565474)\n",
      "Loss_G = 0.80508727 (ave = 0.79489065)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.980520, max value: 0.276116\n",
      "D grad l2-norm: 2.048390, max value: 0.551921\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.89715660 (ave = 0.91880544)\n",
      "Loss_G = 0.85234320 (ave = 0.83840284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.991357, max value: 0.269539\n",
      "D grad l2-norm: 2.182649, max value: 0.572892\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001228)\n",
      "Loss_D = 0.84982288 (ave = 0.88882291)\n",
      "Loss_G = 0.88792896 (ave = 0.87075171)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.087965, max value: 0.272531\n",
      "D grad l2-norm: 2.342821, max value: 0.587819\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001020)\n",
      "Loss_D = 0.86921370 (ave = 0.87697788)\n",
      "Loss_G = 0.91723210 (ave = 0.90681415)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.193741, max value: 0.273239\n",
      "D grad l2-norm: 2.507474, max value: 0.599732\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.88432515 (ave = 0.86642711)\n",
      "Loss_G = 0.95563954 (ave = 0.94011738)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.292087, max value: 0.275946\n",
      "D grad l2-norm: 2.662364, max value: 0.614434\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.79520440 (ave = 0.84432746)\n",
      "Loss_G = 0.97506016 (ave = 0.96293948)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.462715, max value: 0.280182\n",
      "D grad l2-norm: 2.873815, max value: 0.622192\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 0.78414822 (ave = 0.83408610)\n",
      "Loss_G = 0.98071343 (ave = 0.98623680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.628680, max value: 0.279147\n",
      "D grad l2-norm: 3.042037, max value: 0.623886\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.90460873 (ave = 0.84979978)\n",
      "Loss_G = 1.01144266 (ave = 1.01337967)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.797586, max value: 0.298408\n",
      "D grad l2-norm: 3.244996, max value: 0.635356\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 0.87203765 (ave = 0.84430408)\n",
      "Loss_G = 1.04332244 (ave = 1.03054335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.946665, max value: 0.327473\n",
      "D grad l2-norm: 3.358153, max value: 0.646705\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.85261977 (ave = 0.85266342)\n",
      "Loss_G = 1.04119349 (ave = 1.02700529)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.167165, max value: 0.344941\n",
      "D grad l2-norm: 3.511881, max value: 0.645761\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.85862839 (ave = 0.86799159)\n",
      "Loss_G = 1.03244793 (ave = 1.02550824)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.330211, max value: 0.346449\n",
      "D grad l2-norm: 3.674622, max value: 0.642663\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001168)\n",
      "Loss_D = 0.91660130 (ave = 0.89197394)\n",
      "Loss_G = 1.02404380 (ave = 1.02158077)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.354559, max value: 0.328242\n",
      "D grad l2-norm: 3.744818, max value: 0.639111\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 0.85080171 (ave = 0.88948866)\n",
      "Loss_G = 1.04649854 (ave = 1.03527699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.378211, max value: 0.315390\n",
      "D grad l2-norm: 3.855663, max value: 0.647221\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.83921111 (ave = 0.89270535)\n",
      "Loss_G = 1.04337621 (ave = 1.04339414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.499903, max value: 0.325351\n",
      "D grad l2-norm: 3.922553, max value: 0.646431\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001171)\n",
      "Loss_D = 0.88095772 (ave = 0.90743235)\n",
      "Loss_G = 1.03408837 (ave = 1.04468100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.816920, max value: 0.355871\n",
      "D grad l2-norm: 4.049321, max value: 0.642332\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.007s / 800 iters, (0.001372)\n",
      "Loss_D = 0.91709781 (ave = 0.93673064)\n",
      "Loss_G = 1.03337419 (ave = 1.03503261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.953404, max value: 0.382515\n",
      "D grad l2-norm: 4.180214, max value: 0.642026\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.92075121 (ave = 0.95423892)\n",
      "Loss_G = 1.03690195 (ave = 1.03610237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.004474, max value: 0.386970\n",
      "D grad l2-norm: 4.232630, max value: 0.643333\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.02237320 (ave = 0.97046242)\n",
      "Loss_G = 1.07272005 (ave = 1.05184817)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.074955, max value: 0.394045\n",
      "D grad l2-norm: 4.417765, max value: 0.656203\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001170)\n",
      "Loss_D = 0.91594529 (ave = 0.95006146)\n",
      "Loss_G = 1.11504245 (ave = 1.08904023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.019860, max value: 0.372920\n",
      "D grad l2-norm: 4.481914, max value: 0.670687\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.99275583 (ave = 0.94508913)\n",
      "Loss_G = 1.13108504 (ave = 1.11609998)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.059036, max value: 0.372855\n",
      "D grad l2-norm: 4.616910, max value: 0.675474\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.82962584 (ave = 0.90637976)\n",
      "Loss_G = 1.17933655 (ave = 1.16253262)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.155419, max value: 0.406096\n",
      "D grad l2-norm: 4.833911, max value: 0.690731\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.99210405 (ave = 0.90907304)\n",
      "Loss_G = 1.21610963 (ave = 1.21280117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.303826, max value: 0.434398\n",
      "D grad l2-norm: 4.944459, max value: 0.701602\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001018)\n",
      "Loss_D = 0.88804191 (ave = 0.88667773)\n",
      "Loss_G = 1.22379124 (ave = 1.21843352)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.549805, max value: 0.461260\n",
      "D grad l2-norm: 5.003463, max value: 0.703395\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.90890658 (ave = 0.89206035)\n",
      "Loss_G = 1.22015202 (ave = 1.21823187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.796953, max value: 0.497148\n",
      "D grad l2-norm: 5.004102, max value: 0.702830\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.83120108 (ave = 0.89005518)\n",
      "Loss_G = 1.18363190 (ave = 1.19206419)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.001045, max value: 0.512615\n",
      "D grad l2-norm: 4.956355, max value: 0.691293\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.016s / 800 iters, (0.003181)\n",
      "Loss_D = 1.10965669 (ave = 0.95082922)\n",
      "Loss_G = 1.14766192 (ave = 1.16407089)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.111935, max value: 0.547947\n",
      "D grad l2-norm: 4.877519, max value: 0.679368\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.91076398 (ave = 0.94473034)\n",
      "Loss_G = 1.14363134 (ave = 1.14106405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.312304, max value: 0.545688\n",
      "D grad l2-norm: 5.031528, max value: 0.677643\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.00137281 (ave = 0.97440450)\n",
      "Loss_G = 1.10999870 (ave = 1.11009064)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.262651, max value: 0.547597\n",
      "D grad l2-norm: 4.872210, max value: 0.665272\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 0.92183602 (ave = 0.98434806)\n",
      "Loss_G = 1.07163620 (ave = 1.08160379)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.206115, max value: 0.545603\n",
      "D grad l2-norm: 4.728230, max value: 0.653944\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001016)\n",
      "Loss_D = 1.00575721 (ave = 1.01287159)\n",
      "Loss_G = 1.02689278 (ave = 1.06289098)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.221336, max value: 0.528344\n",
      "D grad l2-norm: 4.698402, max value: 0.636265\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 800 iters, (0.020)\tData load 0.014s / 800 iters, (0.002823)\n",
      "Loss_D = 0.89585996 (ave = 1.00805942)\n",
      "Loss_G = 1.03925943 (ave = 1.05460398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.266197, max value: 0.526111\n",
      "D grad l2-norm: 4.685506, max value: 0.642077\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.95476305 (ave = 1.02749665)\n",
      "Loss_G = 1.01911378 (ave = 1.03436856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.535876, max value: 0.515555\n",
      "D grad l2-norm: 4.788709, max value: 0.634463\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002775)\n",
      "Loss_D = 0.85058379 (ave = 1.03686721)\n",
      "Loss_G = 0.99550879 (ave = 1.00198237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.439526, max value: 0.484008\n",
      "D grad l2-norm: 4.714523, max value: 0.624555\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.14022517 (ave = 1.08306105)\n",
      "Loss_G = 1.01527143 (ave = 1.00502437)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.329552, max value: 0.455585\n",
      "D grad l2-norm: 4.800692, max value: 0.633375\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.013s / 800 iters, (0.002695)\n",
      "Loss_D = 1.07212651 (ave = 1.07203467)\n",
      "Loss_G = 1.04500806 (ave = 1.02557194)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.326946, max value: 0.408943\n",
      "D grad l2-norm: 4.938254, max value: 0.644300\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.021s / 800 iters, (0.004192)\n",
      "Loss_D = 0.98124969 (ave = 1.04681251)\n",
      "Loss_G = 1.08690548 (ave = 1.05797853)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.174039, max value: 0.404109\n",
      "D grad l2-norm: 4.993857, max value: 0.660217\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.008s / 800 iters, (0.001536)\n",
      "Loss_D = 1.06028843 (ave = 1.03533378)\n",
      "Loss_G = 1.10967708 (ave = 1.08335447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.133563, max value: 0.400911\n",
      "D grad l2-norm: 5.113441, max value: 0.665979\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.96389151 (ave = 0.99896224)\n",
      "Loss_G = 1.17754841 (ave = 1.14279284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.320785, max value: 0.448602\n",
      "D grad l2-norm: 5.423022, max value: 0.688614\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.83711678 (ave = 0.95372808)\n",
      "Loss_G = 1.18141496 (ave = 1.16518793)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.420572, max value: 0.468179\n",
      "D grad l2-norm: 5.532647, max value: 0.689958\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.86262399 (ave = 0.94427084)\n",
      "Loss_G = 1.18324840 (ave = 1.19218969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.348096, max value: 0.465083\n",
      "D grad l2-norm: 5.542035, max value: 0.690347\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001211)\n",
      "Loss_D = 0.88829613 (ave = 0.92787557)\n",
      "Loss_G = 1.22992015 (ave = 1.21755245)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.648944, max value: 0.478299\n",
      "D grad l2-norm: 5.926369, max value: 0.704391\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.77936554 (ave = 0.89779848)\n",
      "Loss_G = 1.23647809 (ave = 1.23046980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.847851, max value: 0.528696\n",
      "D grad l2-norm: 5.905413, max value: 0.706049\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.87679040 (ave = 0.90503893)\n",
      "Loss_G = 1.24628997 (ave = 1.23181922)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.073326, max value: 0.581514\n",
      "D grad l2-norm: 6.038370, max value: 0.709460\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000993)\n",
      "Loss_D = 0.81832302 (ave = 0.88946861)\n",
      "Loss_G = 1.24519551 (ave = 1.23578463)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.120058, max value: 0.581835\n",
      "D grad l2-norm: 6.190978, max value: 0.730299\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001005)\n",
      "Loss_D = 1.01282156 (ave = 0.90530632)\n",
      "Loss_G = 1.26668835 (ave = 1.25810680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.188844, max value: 0.619353\n",
      "D grad l2-norm: 6.247767, max value: 0.768991\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001262)\n",
      "Loss_D = 0.76479304 (ave = 0.85933516)\n",
      "Loss_G = 1.30845010 (ave = 1.27805254)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.194762, max value: 0.620003\n",
      "D grad l2-norm: 6.185474, max value: 0.790403\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.93727517 (ave = 0.86871456)\n",
      "Loss_G = 1.29895782 (ave = 1.29366376)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.559837, max value: 0.685012\n",
      "D grad l2-norm: 6.330186, max value: 0.823997\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.73859406 (ave = 0.83592404)\n",
      "Loss_G = 1.27061045 (ave = 1.30384707)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.152408, max value: 0.777245\n",
      "D grad l2-norm: 6.424883, max value: 0.830482\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001032)\n",
      "Loss_D = 0.81090796 (ave = 0.85342120)\n",
      "Loss_G = 1.27021194 (ave = 1.28471849)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.594778, max value: 0.834108\n",
      "D grad l2-norm: 6.463729, max value: 0.832843\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.76483488 (ave = 0.86681737)\n",
      "Loss_G = 1.26749110 (ave = 1.24693007)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.654141, max value: 0.781256\n",
      "D grad l2-norm: 6.477017, max value: 0.831176\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.81364125 (ave = 0.88744247)\n",
      "Loss_G = 1.15764523 (ave = 1.19344177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.812576, max value: 0.750904\n",
      "D grad l2-norm: 6.383127, max value: 0.784750\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001168)\n",
      "Loss_D = 0.93385094 (ave = 0.93147031)\n",
      "Loss_G = 1.14209163 (ave = 1.15638044)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.724692, max value: 0.687297\n",
      "D grad l2-norm: 6.245274, max value: 0.753339\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.00865209 (ave = 0.96226308)\n",
      "Loss_G = 1.14776683 (ave = 1.14061866)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.770055, max value: 0.603621\n",
      "D grad l2-norm: 6.263800, max value: 0.742455\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002785)\n",
      "Loss_D = 0.92588872 (ave = 0.97166535)\n",
      "Loss_G = 1.08844781 (ave = 1.10294600)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.541568, max value: 0.566496\n",
      "D grad l2-norm: 6.187435, max value: 0.732005\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.88788354 (ave = 0.98027601)\n",
      "Loss_G = 1.06825018 (ave = 1.07594404)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.669397, max value: 0.579345\n",
      "D grad l2-norm: 6.289782, max value: 0.744000\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.90630639 (ave = 1.01276097)\n",
      "Loss_G = 1.09601688 (ave = 1.07916811)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.447901, max value: 0.575304\n",
      "D grad l2-norm: 6.248848, max value: 0.744659\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002817)\n",
      "Loss_D = 1.11949849 (ave = 1.05224457)\n",
      "Loss_G = 1.10706830 (ave = 1.10786557)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.474024, max value: 0.553435\n",
      "D grad l2-norm: 6.435606, max value: 0.758135\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.96917737 (ave = 1.03874872)\n",
      "Loss_G = 1.13464892 (ave = 1.10751879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.246424, max value: 0.568006\n",
      "D grad l2-norm: 6.529952, max value: 0.748275\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.87449622 (ave = 0.99658306)\n",
      "Loss_G = 1.18805230 (ave = 1.15128157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.350776, max value: 0.559776\n",
      "D grad l2-norm: 6.841128, max value: 0.800311\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.04334486 (ave = 1.00113429)\n",
      "Loss_G = 1.21155322 (ave = 1.20386155)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.625336, max value: 0.536903\n",
      "D grad l2-norm: 7.401678, max value: 0.875684\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.99377549 (ave = 0.97765932)\n",
      "Loss_G = 1.29470587 (ave = 1.26572752)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.676806, max value: 0.535787\n",
      "D grad l2-norm: 7.771336, max value: 0.912352\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.86578012 (ave = 0.93835758)\n",
      "Loss_G = 1.33805561 (ave = 1.32218571)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.782704, max value: 0.505444\n",
      "D grad l2-norm: 8.080255, max value: 0.944584\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 1.02855635 (ave = 0.94223152)\n",
      "Loss_G = 1.43514252 (ave = 1.38500404)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.686881, max value: 0.476865\n",
      "D grad l2-norm: 8.216604, max value: 0.954782\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 1.03116250 (ave = 0.92927140)\n",
      "Loss_G = 1.47539091 (ave = 1.43103144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.539650, max value: 0.517033\n",
      "D grad l2-norm: 8.501823, max value: 0.981158\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.96132493 (ave = 0.89999003)\n",
      "Loss_G = 1.49401379 (ave = 1.49364228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.540270, max value: 0.536028\n",
      "D grad l2-norm: 8.837788, max value: 1.005991\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001017)\n",
      "Loss_D = 0.97796381 (ave = 0.88835560)\n",
      "Loss_G = 1.55397034 (ave = 1.52871804)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.934273, max value: 0.540295\n",
      "D grad l2-norm: 9.398891, max value: 1.052788\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.88053328 (ave = 0.87117712)\n",
      "Loss_G = 1.56911588 (ave = 1.56091387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.075470, max value: 0.523338\n",
      "D grad l2-norm: 9.328410, max value: 1.024988\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 0.74433964 (ave = 0.86013901)\n",
      "Loss_G = 1.55283749 (ave = 1.56006076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.444068, max value: 0.582740\n",
      "D grad l2-norm: 9.462572, max value: 1.017595\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 0.79276162 (ave = 0.88257594)\n",
      "Loss_G = 1.51053214 (ave = 1.51185741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.979363, max value: 0.665370\n",
      "D grad l2-norm: 9.679750, max value: 1.016928\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.98693699 (ave = 0.93444487)\n",
      "Loss_G = 1.42195547 (ave = 1.46703179)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.515454, max value: 0.698503\n",
      "D grad l2-norm: 9.535616, max value: 0.966299\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.14337790 (ave = 0.99706336)\n",
      "Loss_G = 1.42804933 (ave = 1.45325136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.563204, max value: 0.721194\n",
      "D grad l2-norm: 9.374597, max value: 0.935878\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 1.05281484 (ave = 1.01328466)\n",
      "Loss_G = 1.39770460 (ave = 1.40265882)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.457880, max value: 0.712201\n",
      "D grad l2-norm: 9.494365, max value: 1.012637\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001193)\n",
      "Loss_D = 0.94947624 (ave = 1.00709980)\n",
      "Loss_G = 1.43184817 (ave = 1.40540566)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.886138, max value: 0.699543\n",
      "D grad l2-norm: 9.288961, max value: 1.063432\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001199)\n",
      "Loss_D = 0.80323994 (ave = 0.99229045)\n",
      "Loss_G = 1.47209644 (ave = 1.45043099)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.904802, max value: 0.665065\n",
      "D grad l2-norm: 9.317018, max value: 1.115364\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.10463893 (ave = 1.04357250)\n",
      "Loss_G = 1.44031906 (ave = 1.44690688)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.206989, max value: 0.654875\n",
      "D grad l2-norm: 9.401528, max value: 1.138811\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.010s / 800 iters, (0.001970)\n",
      "Loss_D = 0.96931171 (ave = 1.05680768)\n",
      "Loss_G = 1.37989521 (ave = 1.38803587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.611802, max value: 0.654602\n",
      "D grad l2-norm: 9.388905, max value: 1.131587\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.84976363 (ave = 1.07443180)\n",
      "Loss_G = 1.34471595 (ave = 1.36200666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.348960, max value: 0.642539\n",
      "D grad l2-norm: 9.017362, max value: 1.089278\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.38464022 (ave = 1.16281099)\n",
      "Loss_G = 1.35556817 (ave = 1.35300047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.132185, max value: 0.618672\n",
      "D grad l2-norm: 8.825411, max value: 1.058387\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 1.36983943 (ave = 1.18104901)\n",
      "Loss_G = 1.31528628 (ave = 1.31452930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.962068, max value: 0.584926\n",
      "D grad l2-norm: 8.562387, max value: 0.996730\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 1.24251294 (ave = 1.17771199)\n",
      "Loss_G = 1.25685954 (ave = 1.31897969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.022163, max value: 0.556942\n",
      "D grad l2-norm: 8.460445, max value: 0.943545\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001007)\n",
      "Loss_D = 1.13964260 (ave = 1.17841291)\n",
      "Loss_G = 1.28470278 (ave = 1.30224872)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.824500, max value: 0.539412\n",
      "D grad l2-norm: 8.423408, max value: 0.942642\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.11936653 (ave = 1.17545636)\n",
      "Loss_G = 1.30258048 (ave = 1.27286696)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.586441, max value: 0.526153\n",
      "D grad l2-norm: 8.275247, max value: 0.912087\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.15270042 (ave = 1.19861627)\n",
      "Loss_G = 1.29720747 (ave = 1.28637540)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.525182, max value: 0.495149\n",
      "D grad l2-norm: 8.352714, max value: 0.882840\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.14026892 (ave = 1.17353108)\n",
      "Loss_G = 1.31644261 (ave = 1.33003838)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.272367, max value: 0.475688\n",
      "D grad l2-norm: 8.386554, max value: 0.854601\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.20837021 (ave = 1.16508007)\n",
      "Loss_G = 1.38610601 (ave = 1.35405505)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.654585, max value: 0.447096\n",
      "D grad l2-norm: 8.136753, max value: 0.814966\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 1.04451478 (ave = 1.12141244)\n",
      "Loss_G = 1.37170577 (ave = 1.35491700)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.251636, max value: 0.408030\n",
      "D grad l2-norm: 8.022485, max value: 0.757067\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 1.21964157 (ave = 1.12024648)\n",
      "Loss_G = 1.44002175 (ave = 1.40456305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.338012, max value: 0.430016\n",
      "D grad l2-norm: 8.386066, max value: 0.835393\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001257)\n",
      "Loss_D = 1.04732680 (ave = 1.07053659)\n",
      "Loss_G = 1.44381380 (ave = 1.42842035)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.130850, max value: 0.470664\n",
      "D grad l2-norm: 8.334781, max value: 0.883987\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.98574573 (ave = 1.03076816)\n",
      "Loss_G = 1.51344502 (ave = 1.47247798)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.217272, max value: 0.512174\n",
      "D grad l2-norm: 8.507184, max value: 0.953078\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.01168835 (ave = 1.01039469)\n",
      "Loss_G = 1.50198686 (ave = 1.49359605)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.304635, max value: 0.530500\n",
      "D grad l2-norm: 8.568198, max value: 0.993915\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.96799380 (ave = 0.97768255)\n",
      "Loss_G = 1.53333592 (ave = 1.50820303)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.012986, max value: 0.523483\n",
      "D grad l2-norm: 8.284929, max value: 0.989668\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 0.90335274 (ave = 0.93408873)\n",
      "Loss_G = 1.57510149 (ave = 1.54998899)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.408454, max value: 0.585648\n",
      "D grad l2-norm: 8.832412, max value: 1.074644\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.82561928 (ave = 0.90745058)\n",
      "Loss_G = 1.57591951 (ave = 1.56503327)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.199227, max value: 0.628088\n",
      "D grad l2-norm: 8.602555, max value: 1.059428\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001190)\n",
      "Loss_D = 0.84511411 (ave = 0.88026690)\n",
      "Loss_G = 1.62812138 (ave = 1.59015691)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.937245, max value: 0.646527\n",
      "D grad l2-norm: 8.546675, max value: 1.080055\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001154)\n",
      "Loss_D = 1.00693738 (ave = 0.87552298)\n",
      "Loss_G = 1.61672914 (ave = 1.61488900)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.885943, max value: 0.650097\n",
      "D grad l2-norm: 8.467736, max value: 1.069925\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.79250908 (ave = 0.82297450)\n",
      "Loss_G = 1.57402682 (ave = 1.61919477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.754958, max value: 0.648087\n",
      "D grad l2-norm: 8.078273, max value: 1.006086\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.010s / 800 iters, (0.001954)\n",
      "Loss_D = 0.68048084 (ave = 0.78192173)\n",
      "Loss_G = 1.63730145 (ave = 1.64658761)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.251164, max value: 0.653136\n",
      "D grad l2-norm: 8.457356, max value: 1.054691\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.79795611 (ave = 0.78452507)\n",
      "Loss_G = 1.62728882 (ave = 1.63470478)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.406868, max value: 0.643147\n",
      "D grad l2-norm: 8.341494, max value: 1.028689\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.98350322 (ave = 0.79671446)\n",
      "Loss_G = 1.55598903 (ave = 1.56889846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.484979, max value: 0.669387\n",
      "D grad l2-norm: 8.219141, max value: 0.994508\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.75200772 (ave = 0.76409247)\n",
      "Loss_G = 1.52964771 (ave = 1.55562403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.386002, max value: 0.705979\n",
      "D grad l2-norm: 8.022506, max value: 0.982266\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.65487760 (ave = 0.74192631)\n",
      "Loss_G = 1.54210758 (ave = 1.54752634)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.368724, max value: 0.752724\n",
      "D grad l2-norm: 7.817892, max value: 0.990091\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.68562633 (ave = 0.73359519)\n",
      "Loss_G = 1.55540061 (ave = 1.56338708)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.449049, max value: 0.766463\n",
      "D grad l2-norm: 7.839885, max value: 1.011868\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001174)\n",
      "Loss_D = 0.73641604 (ave = 0.72816840)\n",
      "Loss_G = 1.51795101 (ave = 1.53814118)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.117198, max value: 0.729495\n",
      "D grad l2-norm: 7.365215, max value: 0.965555\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.71105194 (ave = 0.72278640)\n",
      "Loss_G = 1.52010620 (ave = 1.49659643)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.101040, max value: 0.772237\n",
      "D grad l2-norm: 7.214083, max value: 0.962093\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.75423741 (ave = 0.72680118)\n",
      "Loss_G = 1.43639827 (ave = 1.46805372)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.040842, max value: 0.791711\n",
      "D grad l2-norm: 6.885266, max value: 0.893652\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.71991420 (ave = 0.72841603)\n",
      "Loss_G = 1.42574716 (ave = 1.42543306)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.960824, max value: 0.812883\n",
      "D grad l2-norm: 6.652153, max value: 0.871994\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.012s / 800 iters, (0.002439)\n",
      "Loss_D = 0.71226776 (ave = 0.72235831)\n",
      "Loss_G = 1.38687766 (ave = 1.38370237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.823485, max value: 0.779253\n",
      "D grad l2-norm: 6.385964, max value: 0.822320\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 0.72121108 (ave = 0.73456284)\n",
      "Loss_G = 1.35527384 (ave = 1.37075930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.686205, max value: 0.752785\n",
      "D grad l2-norm: 6.071134, max value: 0.767619\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 0.73093164 (ave = 0.73775386)\n",
      "Loss_G = 1.28569365 (ave = 1.31355200)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.568868, max value: 0.705600\n",
      "D grad l2-norm: 5.811347, max value: 0.718370\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.015s / 800 iters, (0.003074)\n",
      "Loss_D = 0.73239231 (ave = 0.74831653)\n",
      "Loss_G = 1.28006434 (ave = 1.29116530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.597475, max value: 0.665220\n",
      "D grad l2-norm: 5.629092, max value: 0.716588\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.81535834 (ave = 0.77709144)\n",
      "Loss_G = 1.19780779 (ave = 1.22571766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.422365, max value: 0.605311\n",
      "D grad l2-norm: 5.348905, max value: 0.691366\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.85326517 (ave = 0.79907156)\n",
      "Loss_G = 1.16514921 (ave = 1.17545269)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.281626, max value: 0.567442\n",
      "D grad l2-norm: 5.066716, max value: 0.682015\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.013s / 800 iters, (0.002682)\n",
      "Loss_D = 0.78046811 (ave = 0.80791475)\n",
      "Loss_G = 1.12072003 (ave = 1.13328815)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.205024, max value: 0.543696\n",
      "D grad l2-norm: 4.923590, max value: 0.667656\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 1.01261544 (ave = 0.85560175)\n",
      "Loss_G = 1.07771385 (ave = 1.08599925)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.184792, max value: 0.505664\n",
      "D grad l2-norm: 4.797911, max value: 0.653373\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.81570077 (ave = 0.84921898)\n",
      "Loss_G = 1.05714202 (ave = 1.05403972)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.196348, max value: 0.468444\n",
      "D grad l2-norm: 4.740993, max value: 0.645606\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002757)\n",
      "Loss_D = 0.85643113 (ave = 0.87316558)\n",
      "Loss_G = 1.00979269 (ave = 1.01946828)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.928939, max value: 0.439419\n",
      "D grad l2-norm: 4.527762, max value: 0.628975\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 1.11195564 (ave = 0.91149721)\n",
      "Loss_G = 1.01299977 (ave = 1.01567690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.968365, max value: 0.428190\n",
      "D grad l2-norm: 4.638521, max value: 0.629181\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.77486026 (ave = 0.86883204)\n",
      "Loss_G = 1.01429152 (ave = 1.02063732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.794076, max value: 0.420199\n",
      "D grad l2-norm: 4.605047, max value: 0.630708\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001022)\n",
      "Loss_D = 0.95587051 (ave = 0.90030760)\n",
      "Loss_G = 1.02834094 (ave = 1.03426197)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.740007, max value: 0.411000\n",
      "D grad l2-norm: 4.669531, max value: 0.636298\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001039)\n",
      "Loss_D = 1.07642806 (ave = 0.90424455)\n",
      "Loss_G = 1.03953254 (ave = 1.03533099)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.536603, max value: 0.392047\n",
      "D grad l2-norm: 4.636896, max value: 0.640086\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.79494882 (ave = 0.86650159)\n",
      "Loss_G = 1.08843386 (ave = 1.06460721)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.678969, max value: 0.440793\n",
      "D grad l2-norm: 4.860136, max value: 0.658110\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 0.85280013 (ave = 0.85747780)\n",
      "Loss_G = 1.08333838 (ave = 1.09489946)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.585517, max value: 0.447103\n",
      "D grad l2-norm: 4.876868, max value: 0.656445\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.88379133 (ave = 0.85966182)\n",
      "Loss_G = 1.12777460 (ave = 1.10871272)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.495527, max value: 0.423404\n",
      "D grad l2-norm: 4.978764, max value: 0.671328\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.73527890 (ave = 0.83161107)\n",
      "Loss_G = 1.13758028 (ave = 1.12935944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.219396, max value: 0.416704\n",
      "D grad l2-norm: 4.955342, max value: 0.673747\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.82530332 (ave = 0.82376169)\n",
      "Loss_G = 1.20441544 (ave = 1.17242806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.081158, max value: 0.408774\n",
      "D grad l2-norm: 5.065160, max value: 0.695051\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.80963117 (ave = 0.80494412)\n",
      "Loss_G = 1.20790863 (ave = 1.19924407)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.021204, max value: 0.400728\n",
      "D grad l2-norm: 5.084096, max value: 0.697337\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001164)\n",
      "Loss_D = 0.72609043 (ave = 0.77933838)\n",
      "Loss_G = 1.21435308 (ave = 1.23397386)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.200872, max value: 0.408374\n",
      "D grad l2-norm: 5.130830, max value: 0.699409\n",
      "üîÅ TSCV for Asset 5\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.37524104 (ave = 1.38027499)\n",
      "Loss_G = 0.71945369 (ave = 0.72042096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964606, max value: 0.025700\n",
      "D grad l2-norm: 0.761817, max value: 0.512980\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.36377382 (ave = 1.36964970)\n",
      "Loss_G = 0.71848553 (ave = 0.71864744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964894, max value: 0.018739\n",
      "D grad l2-norm: 0.758900, max value: 0.512509\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 1.34552491 (ave = 1.35803409)\n",
      "Loss_G = 0.71689516 (ave = 0.71720198)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964142, max value: 0.021193\n",
      "D grad l2-norm: 0.756948, max value: 0.511732\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.35262585 (ave = 1.35003314)\n",
      "Loss_G = 0.71601391 (ave = 0.71634052)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961192, max value: 0.024863\n",
      "D grad l2-norm: 0.755988, max value: 0.511302\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 1.33349633 (ave = 1.33842754)\n",
      "Loss_G = 0.71545148 (ave = 0.71548402)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.957015, max value: 0.019675\n",
      "D grad l2-norm: 0.760022, max value: 0.511027\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.018s / 800 iters, (0.003547)\n",
      "Loss_D = 1.32837462 (ave = 1.32888680)\n",
      "Loss_G = 0.71478409 (ave = 0.71471430)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963075, max value: 0.020983\n",
      "D grad l2-norm: 0.760599, max value: 0.510701\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 1.30673110 (ave = 1.31703002)\n",
      "Loss_G = 0.71489704 (ave = 0.71475309)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965771, max value: 0.019879\n",
      "D grad l2-norm: 0.762322, max value: 0.510756\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 1.29795170 (ave = 1.30723007)\n",
      "Loss_G = 0.71494758 (ave = 0.71496782)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963977, max value: 0.020124\n",
      "D grad l2-norm: 0.768162, max value: 0.510779\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002787)\n",
      "Loss_D = 1.29573429 (ave = 1.29807835)\n",
      "Loss_G = 0.71514052 (ave = 0.71536727)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961954, max value: 0.022783\n",
      "D grad l2-norm: 0.773612, max value: 0.510875\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.27858353 (ave = 1.28730593)\n",
      "Loss_G = 0.71492976 (ave = 0.71550274)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965737, max value: 0.018993\n",
      "D grad l2-norm: 0.780865, max value: 0.510770\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 1.27910316 (ave = 1.27907763)\n",
      "Loss_G = 0.71596438 (ave = 0.71622024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964254, max value: 0.018355\n",
      "D grad l2-norm: 0.786128, max value: 0.511276\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 1.26493669 (ave = 1.26870525)\n",
      "Loss_G = 0.71737015 (ave = 0.71699674)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.959468, max value: 0.021102\n",
      "D grad l2-norm: 0.791062, max value: 0.511962\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 1.24161243 (ave = 1.25760243)\n",
      "Loss_G = 0.71899688 (ave = 0.71813327)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970798, max value: 0.029912\n",
      "D grad l2-norm: 0.798982, max value: 0.512755\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001174)\n",
      "Loss_D = 1.24204421 (ave = 1.24942980)\n",
      "Loss_G = 0.71971399 (ave = 0.71914619)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969958, max value: 0.029513\n",
      "D grad l2-norm: 0.810596, max value: 0.513104\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001190)\n",
      "Loss_D = 1.24254107 (ave = 1.24177787)\n",
      "Loss_G = 0.72038835 (ave = 0.72035933)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963823, max value: 0.027291\n",
      "D grad l2-norm: 0.820149, max value: 0.513431\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 1.23025966 (ave = 1.23221214)\n",
      "Loss_G = 0.72194356 (ave = 0.72156222)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969465, max value: 0.034779\n",
      "D grad l2-norm: 0.829523, max value: 0.514187\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.22399545 (ave = 1.22349648)\n",
      "Loss_G = 0.72311974 (ave = 0.72275598)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972595, max value: 0.035443\n",
      "D grad l2-norm: 0.840672, max value: 0.514758\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001237)\n",
      "Loss_D = 1.18763781 (ave = 1.21165915)\n",
      "Loss_G = 0.72492445 (ave = 0.72427746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973105, max value: 0.034334\n",
      "D grad l2-norm: 0.847267, max value: 0.515629\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.015s / 800 iters, (0.002914)\n",
      "Loss_D = 1.20025098 (ave = 1.20534163)\n",
      "Loss_G = 0.72669363 (ave = 0.72621140)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980629, max value: 0.039759\n",
      "D grad l2-norm: 0.862192, max value: 0.516485\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.18952227 (ave = 1.19698770)\n",
      "Loss_G = 0.72953475 (ave = 0.72804217)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979419, max value: 0.037622\n",
      "D grad l2-norm: 0.875527, max value: 0.517851\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001164)\n",
      "Loss_D = 1.18915319 (ave = 1.18947983)\n",
      "Loss_G = 0.73110867 (ave = 0.73035785)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.987437, max value: 0.038383\n",
      "D grad l2-norm: 0.889374, max value: 0.518610\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 1.15960383 (ave = 1.17931304)\n",
      "Loss_G = 0.73231953 (ave = 0.73202450)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992168, max value: 0.041690\n",
      "D grad l2-norm: 0.907437, max value: 0.519188\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.19300556 (ave = 1.17606421)\n",
      "Loss_G = 0.73477721 (ave = 0.73405524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.995730, max value: 0.049694\n",
      "D grad l2-norm: 0.925532, max value: 0.520355\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 1.16034377 (ave = 1.16526906)\n",
      "Loss_G = 0.73634076 (ave = 0.73701526)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.002113, max value: 0.047736\n",
      "D grad l2-norm: 0.943326, max value: 0.521104\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 1.13375378 (ave = 1.15552745)\n",
      "Loss_G = 0.74242842 (ave = 0.73951365)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.003268, max value: 0.050201\n",
      "D grad l2-norm: 0.951496, max value: 0.524009\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 1.15967059 (ave = 1.15186095)\n",
      "Loss_G = 0.74605960 (ave = 0.74293760)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.000263, max value: 0.051225\n",
      "D grad l2-norm: 0.973635, max value: 0.525737\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 1.13733768 (ave = 1.14174216)\n",
      "Loss_G = 0.74793816 (ave = 0.74572785)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.012572, max value: 0.054274\n",
      "D grad l2-norm: 1.003154, max value: 0.526621\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 1.12580907 (ave = 1.13257973)\n",
      "Loss_G = 0.75317860 (ave = 0.75138246)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.009349, max value: 0.052573\n",
      "D grad l2-norm: 1.019713, max value: 0.529088\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.14154434 (ave = 1.12601225)\n",
      "Loss_G = 0.75973070 (ave = 0.75629896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.008494, max value: 0.044782\n",
      "D grad l2-norm: 1.034654, max value: 0.532159\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.007s / 800 iters, (0.001400)\n",
      "Loss_D = 1.11755860 (ave = 1.11439128)\n",
      "Loss_G = 0.76399386 (ave = 0.76329942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.018040, max value: 0.049294\n",
      "D grad l2-norm: 1.072390, max value: 0.534158\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 1.08142722 (ave = 1.10092793)\n",
      "Loss_G = 0.77283603 (ave = 0.77036843)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.015172, max value: 0.045545\n",
      "D grad l2-norm: 1.099976, max value: 0.538251\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001177)\n",
      "Loss_D = 1.07785463 (ave = 1.09030771)\n",
      "Loss_G = 0.78075737 (ave = 0.77943529)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.019867, max value: 0.053007\n",
      "D grad l2-norm: 1.120670, max value: 0.541882\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 1.09706068 (ave = 1.08097932)\n",
      "Loss_G = 0.79146457 (ave = 0.78874216)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.019392, max value: 0.057853\n",
      "D grad l2-norm: 1.144685, max value: 0.546777\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001157)\n",
      "Loss_D = 1.06857955 (ave = 1.06565461)\n",
      "Loss_G = 0.80471605 (ave = 0.79954849)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.014909, max value: 0.065195\n",
      "D grad l2-norm: 1.172397, max value: 0.552754\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 1.04131663 (ave = 1.04962714)\n",
      "Loss_G = 0.81589317 (ave = 0.81081017)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.020609, max value: 0.065930\n",
      "D grad l2-norm: 1.199705, max value: 0.557727\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001198)\n",
      "Loss_D = 1.02667880 (ave = 1.03554120)\n",
      "Loss_G = 0.82762516 (ave = 0.82263966)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.026159, max value: 0.069681\n",
      "D grad l2-norm: 1.217254, max value: 0.562879\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.01643205 (ave = 1.02194691)\n",
      "Loss_G = 0.83974665 (ave = 0.83503046)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.037196, max value: 0.067827\n",
      "D grad l2-norm: 1.241701, max value: 0.568143\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.01635826 (ave = 1.00968314)\n",
      "Loss_G = 0.84742600 (ave = 0.84464214)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.074866, max value: 0.082174\n",
      "D grad l2-norm: 1.263505, max value: 0.571437\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.96570551 (ave = 0.99439911)\n",
      "Loss_G = 0.85274297 (ave = 0.84910470)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.113498, max value: 0.092351\n",
      "D grad l2-norm: 1.276509, max value: 0.573695\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.96632636 (ave = 0.98901213)\n",
      "Loss_G = 0.85042524 (ave = 0.85063881)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.157210, max value: 0.102389\n",
      "D grad l2-norm: 1.273719, max value: 0.572670\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.95982444 (ave = 0.98455713)\n",
      "Loss_G = 0.84817386 (ave = 0.84812187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.222640, max value: 0.122495\n",
      "D grad l2-norm: 1.281868, max value: 0.571672\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 1.03217268 (ave = 0.99495023)\n",
      "Loss_G = 0.83515453 (ave = 0.83908398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.267102, max value: 0.121015\n",
      "D grad l2-norm: 1.272342, max value: 0.566052\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.01000214 (ave = 0.99649415)\n",
      "Loss_G = 0.81814975 (ave = 0.82347161)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.308608, max value: 0.126090\n",
      "D grad l2-norm: 1.265734, max value: 0.558592\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 1.02769649 (ave = 1.00763667)\n",
      "Loss_G = 0.79890776 (ave = 0.80476013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.351726, max value: 0.117365\n",
      "D grad l2-norm: 1.253908, max value: 0.549934\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.06601644 (ave = 1.02373983)\n",
      "Loss_G = 0.78512132 (ave = 0.78908672)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.392356, max value: 0.135341\n",
      "D grad l2-norm: 1.255850, max value: 0.543689\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001255)\n",
      "Loss_D = 1.04434419 (ave = 1.03161755)\n",
      "Loss_G = 0.76319653 (ave = 0.77023692)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.417354, max value: 0.133032\n",
      "D grad l2-norm: 1.251216, max value: 0.533512\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.01345265 (ave = 1.04109151)\n",
      "Loss_G = 0.74288452 (ave = 0.75117599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.438654, max value: 0.142722\n",
      "D grad l2-norm: 1.259478, max value: 0.523891\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.013s / 800 iters, (0.002610)\n",
      "Loss_D = 1.06799543 (ave = 1.05443013)\n",
      "Loss_G = 0.72809231 (ave = 0.73634043)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.443820, max value: 0.138803\n",
      "D grad l2-norm: 1.290890, max value: 0.516740\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.03753102 (ave = 1.05945737)\n",
      "Loss_G = 0.72999102 (ave = 0.73368548)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.418524, max value: 0.134225\n",
      "D grad l2-norm: 1.319267, max value: 0.517695\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.01024318 (ave = 1.04880714)\n",
      "Loss_G = 0.73306757 (ave = 0.73454329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.397959, max value: 0.124904\n",
      "D grad l2-norm: 1.369892, max value: 0.519228\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.03376806 (ave = 1.03976350)\n",
      "Loss_G = 0.75616646 (ave = 0.74759908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.365323, max value: 0.124177\n",
      "D grad l2-norm: 1.411204, max value: 0.530226\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002781)\n",
      "Loss_D = 1.00824225 (ave = 1.01734731)\n",
      "Loss_G = 0.77613813 (ave = 0.76869993)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.357526, max value: 0.127086\n",
      "D grad l2-norm: 1.480009, max value: 0.539498\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.98883677 (ave = 0.99621385)\n",
      "Loss_G = 0.81001747 (ave = 0.79674566)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.330329, max value: 0.128356\n",
      "D grad l2-norm: 1.518766, max value: 0.554955\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 800 iters, (0.027)\tData load 0.015s / 800 iters, (0.003008)\n",
      "Loss_D = 0.97572291 (ave = 0.96981803)\n",
      "Loss_G = 0.84085619 (ave = 0.82449058)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.326407, max value: 0.133061\n",
      "D grad l2-norm: 1.604815, max value: 0.568509\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002740)\n",
      "Loss_D = 0.94212866 (ave = 0.93811476)\n",
      "Loss_G = 0.87163436 (ave = 0.85649529)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.345386, max value: 0.128946\n",
      "D grad l2-norm: 1.676611, max value: 0.581582\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.87164259 (ave = 0.90288415)\n",
      "Loss_G = 0.90100694 (ave = 0.89060833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.368390, max value: 0.137011\n",
      "D grad l2-norm: 1.753382, max value: 0.593682\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.85332096 (ave = 0.87689880)\n",
      "Loss_G = 0.93304843 (ave = 0.92035327)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.403046, max value: 0.142267\n",
      "D grad l2-norm: 1.843856, max value: 0.606494\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.88538396 (ave = 0.85941190)\n",
      "Loss_G = 0.95663828 (ave = 0.94812270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.453792, max value: 0.141119\n",
      "D grad l2-norm: 1.898214, max value: 0.615664\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.83654666 (ave = 0.83425084)\n",
      "Loss_G = 0.98625630 (ave = 0.97551641)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.515799, max value: 0.176440\n",
      "D grad l2-norm: 1.981003, max value: 0.626828\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 0.78889954 (ave = 0.81494807)\n",
      "Loss_G = 1.00106144 (ave = 0.99274071)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.610515, max value: 0.194421\n",
      "D grad l2-norm: 2.064783, max value: 0.632285\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.80832863 (ave = 0.80764583)\n",
      "Loss_G = 1.01074243 (ave = 1.01055546)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.725765, max value: 0.227236\n",
      "D grad l2-norm: 2.142229, max value: 0.635722\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.81086910 (ave = 0.80179349)\n",
      "Loss_G = 1.01651049 (ave = 1.01867421)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.824158, max value: 0.254177\n",
      "D grad l2-norm: 2.193445, max value: 0.637845\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.84720147 (ave = 0.80515869)\n",
      "Loss_G = 1.02493882 (ave = 1.02275143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.938145, max value: 0.262024\n",
      "D grad l2-norm: 2.287067, max value: 0.640842\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 0.80960733 (ave = 0.80024763)\n",
      "Loss_G = 1.01955903 (ave = 1.02182577)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.973798, max value: 0.283153\n",
      "D grad l2-norm: 2.284939, max value: 0.638859\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.75842607 (ave = 0.79796717)\n",
      "Loss_G = 1.01721954 (ave = 1.01757295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.046856, max value: 0.290869\n",
      "D grad l2-norm: 2.324427, max value: 0.638043\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.80898547 (ave = 0.81103969)\n",
      "Loss_G = 1.01200998 (ave = 1.01500542)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.127493, max value: 0.297441\n",
      "D grad l2-norm: 2.336453, max value: 0.636084\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001022)\n",
      "Loss_D = 0.77375782 (ave = 0.81335742)\n",
      "Loss_G = 1.00135946 (ave = 1.00279655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.223829, max value: 0.308101\n",
      "D grad l2-norm: 2.369465, max value: 0.631991\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.92181492 (ave = 0.84489324)\n",
      "Loss_G = 0.98050410 (ave = 0.98205467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.289907, max value: 0.308934\n",
      "D grad l2-norm: 2.368005, max value: 0.624289\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.89719260 (ave = 0.85960774)\n",
      "Loss_G = 0.94904423 (ave = 0.95787839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.333757, max value: 0.310180\n",
      "D grad l2-norm: 2.348239, max value: 0.612015\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001176)\n",
      "Loss_D = 0.82934058 (ave = 0.86980107)\n",
      "Loss_G = 0.93189394 (ave = 0.93535488)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.354452, max value: 0.299286\n",
      "D grad l2-norm: 2.331470, max value: 0.605416\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001248)\n",
      "Loss_D = 0.91424811 (ave = 0.89666432)\n",
      "Loss_G = 0.91741139 (ave = 0.91849664)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.502952, max value: 0.298519\n",
      "D grad l2-norm: 2.365090, max value: 0.599473\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001167)\n",
      "Loss_D = 0.83511573 (ave = 0.91425059)\n",
      "Loss_G = 0.87604660 (ave = 0.89467980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.660435, max value: 0.303200\n",
      "D grad l2-norm: 2.365111, max value: 0.582054\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 0.94107091 (ave = 0.95879320)\n",
      "Loss_G = 0.84174448 (ave = 0.85827680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.884813, max value: 0.305584\n",
      "D grad l2-norm: 2.409785, max value: 0.567417\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 800 iters, (0.027)\tData load 0.014s / 800 iters, (0.002818)\n",
      "Loss_D = 1.00528717 (ave = 1.01374141)\n",
      "Loss_G = 0.79936439 (ave = 0.80771903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.874767, max value: 0.299558\n",
      "D grad l2-norm: 2.376686, max value: 0.548550\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001162)\n",
      "Loss_D = 1.04398775 (ave = 1.05927186)\n",
      "Loss_G = 0.76330864 (ave = 0.77132412)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.928514, max value: 0.296312\n",
      "D grad l2-norm: 2.415556, max value: 0.532015\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001171)\n",
      "Loss_D = 1.19455481 (ave = 1.10846136)\n",
      "Loss_G = 0.75674003 (ave = 0.75304552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.861633, max value: 0.286561\n",
      "D grad l2-norm: 2.465272, max value: 0.528690\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002796)\n",
      "Loss_D = 1.17155802 (ave = 1.11170249)\n",
      "Loss_G = 0.75215852 (ave = 0.75849156)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.886308, max value: 0.291201\n",
      "D grad l2-norm: 2.537194, max value: 0.526406\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.007s / 800 iters, (0.001317)\n",
      "Loss_D = 1.03375053 (ave = 1.10186849)\n",
      "Loss_G = 0.78936476 (ave = 0.76879088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.959678, max value: 0.289764\n",
      "D grad l2-norm: 2.661851, max value: 0.543552\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001157)\n",
      "Loss_D = 1.08832490 (ave = 1.09824274)\n",
      "Loss_G = 0.80598378 (ave = 0.78552316)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.126814, max value: 0.298562\n",
      "D grad l2-norm: 2.800072, max value: 0.551033\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.21691716 (ave = 1.12075360)\n",
      "Loss_G = 0.81147063 (ave = 0.80339664)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.295499, max value: 0.318254\n",
      "D grad l2-norm: 3.000727, max value: 0.553205\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.010s / 800 iters, (0.001922)\n",
      "Loss_D = 1.18845963 (ave = 1.12035363)\n",
      "Loss_G = 0.83765006 (ave = 0.82559690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.373711, max value: 0.336617\n",
      "D grad l2-norm: 3.158004, max value: 0.565148\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.06908047 (ave = 1.09490879)\n",
      "Loss_G = 0.86007750 (ave = 0.84693770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.565576, max value: 0.366937\n",
      "D grad l2-norm: 3.496035, max value: 0.574357\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 1.06691897 (ave = 1.06563587)\n",
      "Loss_G = 0.93805164 (ave = 0.91216824)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.578167, max value: 0.383960\n",
      "D grad l2-norm: 3.755612, max value: 0.606555\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.98921573 (ave = 1.01982670)\n",
      "Loss_G = 0.99312812 (ave = 0.96988245)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.726939, max value: 0.392458\n",
      "D grad l2-norm: 4.134826, max value: 0.627751\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.92927992 (ave = 0.97429022)\n",
      "Loss_G = 1.06648135 (ave = 1.04127920)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.761055, max value: 0.389853\n",
      "D grad l2-norm: 4.396672, max value: 0.654371\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001189)\n",
      "Loss_D = 0.91713947 (ave = 0.94845666)\n",
      "Loss_G = 1.13378787 (ave = 1.10778244)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.955644, max value: 0.400865\n",
      "D grad l2-norm: 4.732583, max value: 0.676952\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001176)\n",
      "Loss_D = 0.90354943 (ave = 0.92252867)\n",
      "Loss_G = 1.17521107 (ave = 1.16334512)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.275536, max value: 0.409183\n",
      "D grad l2-norm: 5.024869, max value: 0.689647\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 0.88755035 (ave = 0.91084242)\n",
      "Loss_G = 1.19979644 (ave = 1.18813608)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.436348, max value: 0.391785\n",
      "D grad l2-norm: 5.184696, max value: 0.697042\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 0.79776597 (ave = 0.89799381)\n",
      "Loss_G = 1.19959903 (ave = 1.20890300)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.794268, max value: 0.401190\n",
      "D grad l2-norm: 5.486891, max value: 0.696690\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.91009831 (ave = 0.91961629)\n",
      "Loss_G = 1.20785940 (ave = 1.20970531)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.732285, max value: 0.417993\n",
      "D grad l2-norm: 5.396680, max value: 0.699073\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.79712343 (ave = 0.91079984)\n",
      "Loss_G = 1.22425127 (ave = 1.21557510)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.890353, max value: 0.435103\n",
      "D grad l2-norm: 5.612617, max value: 0.703672\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001187)\n",
      "Loss_D = 0.93203622 (ave = 0.93002588)\n",
      "Loss_G = 1.20967913 (ave = 1.21734252)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.922370, max value: 0.452481\n",
      "D grad l2-norm: 5.580971, max value: 0.699432\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.98944694 (ave = 0.94412484)\n",
      "Loss_G = 1.20937002 (ave = 1.21282694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.121104, max value: 0.465796\n",
      "D grad l2-norm: 5.781263, max value: 0.699026\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002776)\n",
      "Loss_D = 0.87972981 (ave = 0.94241018)\n",
      "Loss_G = 1.21802557 (ave = 1.21104076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.043004, max value: 0.452887\n",
      "D grad l2-norm: 5.748968, max value: 0.701282\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 0.95895225 (ave = 0.95301906)\n",
      "Loss_G = 1.21450734 (ave = 1.22536137)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.020007, max value: 0.457741\n",
      "D grad l2-norm: 5.760962, max value: 0.700503\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002807)\n",
      "Loss_D = 1.04252660 (ave = 0.96334851)\n",
      "Loss_G = 1.23293221 (ave = 1.22507839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.235343, max value: 0.440550\n",
      "D grad l2-norm: 6.073847, max value: 0.706333\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.99103296 (ave = 0.96290940)\n",
      "Loss_G = 1.25397038 (ave = 1.24860084)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.320988, max value: 0.431462\n",
      "D grad l2-norm: 6.105051, max value: 0.712454\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.15195727 (ave = 0.98015581)\n",
      "Loss_G = 1.26194394 (ave = 1.26504893)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.457710, max value: 0.460549\n",
      "D grad l2-norm: 6.130592, max value: 0.714456\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.89360821 (ave = 0.95159030)\n",
      "Loss_G = 1.27814627 (ave = 1.26450021)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.491978, max value: 0.481445\n",
      "D grad l2-norm: 6.062142, max value: 0.719242\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 0.97084212 (ave = 0.96833261)\n",
      "Loss_G = 1.27794802 (ave = 1.26837819)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.734396, max value: 0.502797\n",
      "D grad l2-norm: 6.126441, max value: 0.718458\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001232)\n",
      "Loss_D = 0.92761183 (ave = 0.96849649)\n",
      "Loss_G = 1.27390385 (ave = 1.25668957)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.896589, max value: 0.561002\n",
      "D grad l2-norm: 6.133405, max value: 0.717343\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.77908695 (ave = 0.95909781)\n",
      "Loss_G = 1.21249402 (ave = 1.23446653)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.105318, max value: 0.613921\n",
      "D grad l2-norm: 5.994376, max value: 0.699410\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.94222027 (ave = 1.00068997)\n",
      "Loss_G = 1.20620406 (ave = 1.21499305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.259980, max value: 0.636031\n",
      "D grad l2-norm: 5.856493, max value: 0.697137\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001091)\n",
      "Loss_D = 1.17878616 (ave = 1.05305572)\n",
      "Loss_G = 1.16083920 (ave = 1.18069990)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.599303, max value: 0.617401\n",
      "D grad l2-norm: 6.102544, max value: 0.682930\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.95113909 (ave = 1.04067295)\n",
      "Loss_G = 1.13706458 (ave = 1.16078095)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.493445, max value: 0.568673\n",
      "D grad l2-norm: 5.984703, max value: 0.675266\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.10012436 (ave = 1.06346357)\n",
      "Loss_G = 1.13873792 (ave = 1.14748693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.158340, max value: 0.535203\n",
      "D grad l2-norm: 5.756835, max value: 0.675812\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.99645418 (ave = 1.04495391)\n",
      "Loss_G = 1.12840414 (ave = 1.14428768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.151161, max value: 0.479560\n",
      "D grad l2-norm: 5.737374, max value: 0.672351\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.29245794 (ave = 1.09543352)\n",
      "Loss_G = 1.12871528 (ave = 1.13174655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.957358, max value: 0.427640\n",
      "D grad l2-norm: 5.618413, max value: 0.673502\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.007s / 800 iters, (0.001410)\n",
      "Loss_D = 1.04994810 (ave = 1.06601210)\n",
      "Loss_G = 1.12270188 (ave = 1.12084684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.079107, max value: 0.409292\n",
      "D grad l2-norm: 5.787959, max value: 0.671600\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.016s / 800 iters, (0.003162)\n",
      "Loss_D = 1.18462276 (ave = 1.07173510)\n",
      "Loss_G = 1.12267327 (ave = 1.12596812)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.998366, max value: 0.417583\n",
      "D grad l2-norm: 5.812751, max value: 0.671323\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001041)\n",
      "Loss_D = 1.06315863 (ave = 1.05102525)\n",
      "Loss_G = 1.14229953 (ave = 1.13350136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.958443, max value: 0.405119\n",
      "D grad l2-norm: 5.840892, max value: 0.677771\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001166)\n",
      "Loss_D = 0.94457209 (ave = 1.02694788)\n",
      "Loss_G = 1.15410054 (ave = 1.14335430)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.162833, max value: 0.412602\n",
      "D grad l2-norm: 5.935844, max value: 0.681134\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 1.17923474 (ave = 1.05132549)\n",
      "Loss_G = 1.16811192 (ave = 1.16434920)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.339150, max value: 0.426693\n",
      "D grad l2-norm: 6.075115, max value: 0.685343\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.32308269 (ave = 1.06500059)\n",
      "Loss_G = 1.16659033 (ave = 1.16063976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.163088, max value: 0.421454\n",
      "D grad l2-norm: 6.201036, max value: 0.685155\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.99355853 (ave = 0.99802126)\n",
      "Loss_G = 1.24552405 (ave = 1.22454703)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.715688, max value: 0.421572\n",
      "D grad l2-norm: 6.083251, max value: 0.709969\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.04193640 (ave = 0.97264178)\n",
      "Loss_G = 1.32412636 (ave = 1.27810919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.646950, max value: 0.412502\n",
      "D grad l2-norm: 6.307890, max value: 0.731413\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.007s / 800 iters, (0.001365)\n",
      "Loss_D = 0.92322052 (ave = 0.92204731)\n",
      "Loss_G = 1.36426675 (ave = 1.33003335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.697039, max value: 0.395733\n",
      "D grad l2-norm: 6.533287, max value: 0.742271\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.91493893 (ave = 0.90103219)\n",
      "Loss_G = 1.40601039 (ave = 1.36853838)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.892819, max value: 0.397977\n",
      "D grad l2-norm: 6.745962, max value: 0.752211\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.84609163 (ave = 0.87369168)\n",
      "Loss_G = 1.41979682 (ave = 1.40497403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.957450, max value: 0.432062\n",
      "D grad l2-norm: 6.674673, max value: 0.756155\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.79221773 (ave = 0.85066720)\n",
      "Loss_G = 1.44624090 (ave = 1.42539825)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.412228, max value: 0.442396\n",
      "D grad l2-norm: 7.205835, max value: 0.767436\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.85805178 (ave = 0.84186612)\n",
      "Loss_G = 1.46924484 (ave = 1.45396440)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.200369, max value: 0.441973\n",
      "D grad l2-norm: 7.156891, max value: 0.767877\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001000)\n",
      "Loss_D = 0.95419705 (ave = 0.84009278)\n",
      "Loss_G = 1.45699000 (ave = 1.47830584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.572831, max value: 0.472470\n",
      "D grad l2-norm: 7.423354, max value: 0.764762\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.64792150 (ave = 0.79688648)\n",
      "Loss_G = 1.50323033 (ave = 1.49809856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.577566, max value: 0.474918\n",
      "D grad l2-norm: 7.359531, max value: 0.775203\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.76439452 (ave = 0.80424060)\n",
      "Loss_G = 1.51636720 (ave = 1.50727112)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.976537, max value: 0.503001\n",
      "D grad l2-norm: 7.500859, max value: 0.777650\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.87522709 (ave = 0.82263190)\n",
      "Loss_G = 1.51005840 (ave = 1.50918465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.252053, max value: 0.518689\n",
      "D grad l2-norm: 7.704179, max value: 0.775984\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.89633697 (ave = 0.82261549)\n",
      "Loss_G = 1.46485722 (ave = 1.48322725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.519352, max value: 0.548766\n",
      "D grad l2-norm: 7.776786, max value: 0.765777\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.04931712 (ave = 0.84785217)\n",
      "Loss_G = 1.47285604 (ave = 1.47826564)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.286652, max value: 0.570069\n",
      "D grad l2-norm: 7.648163, max value: 0.767732\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.88289535 (ave = 0.82556584)\n",
      "Loss_G = 1.47846484 (ave = 1.48877289)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.444044, max value: 0.611371\n",
      "D grad l2-norm: 7.748378, max value: 0.768361\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.84368402 (ave = 0.83239583)\n",
      "Loss_G = 1.39897668 (ave = 1.43436992)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.482922, max value: 0.630288\n",
      "D grad l2-norm: 7.467947, max value: 0.748701\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 0.93315232 (ave = 0.85879606)\n",
      "Loss_G = 1.43218613 (ave = 1.43579133)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.605169, max value: 0.623062\n",
      "D grad l2-norm: 7.421286, max value: 0.756585\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.75195682 (ave = 0.85646312)\n",
      "Loss_G = 1.35108411 (ave = 1.37166712)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.466342, max value: 0.587378\n",
      "D grad l2-norm: 7.186622, max value: 0.736646\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001291)\n",
      "Loss_D = 1.00687110 (ave = 0.91172341)\n",
      "Loss_G = 1.28782868 (ave = 1.32872090)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.148199, max value: 0.575504\n",
      "D grad l2-norm: 6.804610, max value: 0.719211\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.82367146 (ave = 0.91546999)\n",
      "Loss_G = 1.31019664 (ave = 1.29229198)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.547133, max value: 0.610094\n",
      "D grad l2-norm: 6.976469, max value: 0.724514\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.96468067 (ave = 0.94457543)\n",
      "Loss_G = 1.24891305 (ave = 1.25999420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.407744, max value: 0.623508\n",
      "D grad l2-norm: 6.743378, max value: 0.707296\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.88149154 (ave = 0.95500844)\n",
      "Loss_G = 1.19871926 (ave = 1.23640702)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.250005, max value: 0.646471\n",
      "D grad l2-norm: 6.642560, max value: 0.693126\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.93150347 (ave = 0.97709583)\n",
      "Loss_G = 1.20711195 (ave = 1.21068411)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.758763, max value: 0.621449\n",
      "D grad l2-norm: 6.495681, max value: 0.695837\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.014s / 800 iters, (0.002778)\n",
      "Loss_D = 0.92217529 (ave = 0.96978147)\n",
      "Loss_G = 1.24914694 (ave = 1.23087020)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.861539, max value: 0.624794\n",
      "D grad l2-norm: 6.670448, max value: 0.708525\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.97818601 (ave = 0.97185469)\n",
      "Loss_G = 1.26819956 (ave = 1.25237687)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:00:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.041849, max value: 0.632215\n",
      "D grad l2-norm: 6.776746, max value: 0.714290\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.88365889 (ave = 0.96170324)\n",
      "Loss_G = 1.24428129 (ave = 1.25529642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.040380, max value: 0.613975\n",
      "D grad l2-norm: 6.840012, max value: 0.706940\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001166)\n",
      "Loss_D = 1.00578260 (ave = 0.98163816)\n",
      "Loss_G = 1.27456760 (ave = 1.27652965)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.777847, max value: 0.579642\n",
      "D grad l2-norm: 6.817221, max value: 0.716251\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.03329170 (ave = 0.97397922)\n",
      "Loss_G = 1.29278243 (ave = 1.29578674)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.674054, max value: 0.536959\n",
      "D grad l2-norm: 7.018309, max value: 0.722175\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.82946134 (ave = 0.93380115)\n",
      "Loss_G = 1.34996116 (ave = 1.31222432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.891801, max value: 0.504211\n",
      "D grad l2-norm: 7.263101, max value: 0.737382\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.01660299 (ave = 0.95043287)\n",
      "Loss_G = 1.37485111 (ave = 1.34814799)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.954653, max value: 0.493969\n",
      "D grad l2-norm: 7.182252, max value: 0.743704\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001154)\n",
      "Loss_D = 1.23667312 (ave = 0.97647010)\n",
      "Loss_G = 1.31020677 (ave = 1.33275692)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.106633, max value: 0.512604\n",
      "D grad l2-norm: 7.204010, max value: 0.726402\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 1.02152026 (ave = 0.95630960)\n",
      "Loss_G = 1.31702065 (ave = 1.32745690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.372486, max value: 0.539979\n",
      "D grad l2-norm: 7.325553, max value: 0.727933\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.011s / 800 iters, (0.002296)\n",
      "Loss_D = 1.12093210 (ave = 0.98024926)\n",
      "Loss_G = 1.28798759 (ave = 1.29735663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.351619, max value: 0.598023\n",
      "D grad l2-norm: 7.120657, max value: 0.720285\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.13197970 (ave = 0.99466240)\n",
      "Loss_G = 1.27527428 (ave = 1.30156250)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.469670, max value: 0.600339\n",
      "D grad l2-norm: 7.303739, max value: 0.716347\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.04286671 (ave = 0.99156090)\n",
      "Loss_G = 1.28870749 (ave = 1.27645903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.394298, max value: 0.590675\n",
      "D grad l2-norm: 7.475596, max value: 0.721498\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.008s / 800 iters, (0.001544)\n",
      "Loss_D = 1.02436137 (ave = 0.99085255)\n",
      "Loss_G = 1.27809775 (ave = 1.29574540)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.505518, max value: 0.569809\n",
      "D grad l2-norm: 7.484075, max value: 0.717459\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000994)\n",
      "Loss_D = 1.08437204 (ave = 1.00470872)\n",
      "Loss_G = 1.30264926 (ave = 1.29024997)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.497429, max value: 0.606694\n",
      "D grad l2-norm: 7.399841, max value: 0.724216\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.87342072 (ave = 0.98577634)\n",
      "Loss_G = 1.26011813 (ave = 1.28185892)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.590188, max value: 0.626555\n",
      "D grad l2-norm: 7.494045, max value: 0.712354\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.95539153 (ave = 1.00384965)\n",
      "Loss_G = 1.28339517 (ave = 1.28007665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.179639, max value: 0.629373\n",
      "D grad l2-norm: 7.294042, max value: 0.719165\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.02587771 (ave = 1.00579000)\n",
      "Loss_G = 1.31836116 (ave = 1.30199692)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.026859, max value: 0.651189\n",
      "D grad l2-norm: 7.338201, max value: 0.743432\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 1.17609286 (ave = 1.02231803)\n",
      "Loss_G = 1.30137956 (ave = 1.29401157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.945058, max value: 0.646688\n",
      "D grad l2-norm: 7.368029, max value: 0.759950\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001199)\n",
      "Loss_D = 0.97327489 (ave = 0.99426748)\n",
      "Loss_G = 1.31722522 (ave = 1.31874654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.707293, max value: 0.652695\n",
      "D grad l2-norm: 7.225303, max value: 0.757212\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.09337151 (ave = 1.00207652)\n",
      "Loss_G = 1.29782867 (ave = 1.32235091)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.517610, max value: 0.647246\n",
      "D grad l2-norm: 6.922712, max value: 0.723884\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.93186998 (ave = 0.98019605)\n",
      "Loss_G = 1.32461953 (ave = 1.32524853)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.883166, max value: 0.642772\n",
      "D grad l2-norm: 7.365975, max value: 0.771373\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 0.96112221 (ave = 0.97594272)\n",
      "Loss_G = 1.32541454 (ave = 1.32599573)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.570044, max value: 0.605155\n",
      "D grad l2-norm: 7.022000, max value: 0.731146\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002778)\n",
      "Loss_D = 0.74529827 (ave = 0.94977758)\n",
      "Loss_G = 1.31961668 (ave = 1.32129714)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.311876, max value: 0.555136\n",
      "D grad l2-norm: 6.898359, max value: 0.730043\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001166)\n",
      "Loss_D = 1.05753136 (ave = 0.96530526)\n",
      "Loss_G = 1.37986147 (ave = 1.35604105)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.602258, max value: 0.538358\n",
      "D grad l2-norm: 7.285208, max value: 0.746185\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 1.01982296 (ave = 0.95075169)\n",
      "Loss_G = 1.37629914 (ave = 1.36713557)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.573420, max value: 0.517130\n",
      "D grad l2-norm: 7.170425, max value: 0.744300\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001168)\n",
      "Loss_D = 0.98631024 (ave = 0.93616632)\n",
      "Loss_G = 1.38001013 (ave = 1.36520312)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.709190, max value: 0.535965\n",
      "D grad l2-norm: 7.147839, max value: 0.745614\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 1.01868808 (ave = 0.93589281)\n",
      "Loss_G = 1.35300803 (ave = 1.35799103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.681057, max value: 0.546008\n",
      "D grad l2-norm: 7.121306, max value: 0.738942\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.86098862 (ave = 0.90634191)\n",
      "Loss_G = 1.37076163 (ave = 1.35460927)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.488378, max value: 0.559214\n",
      "D grad l2-norm: 6.867552, max value: 0.743235\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.89612705 (ave = 0.89734960)\n",
      "Loss_G = 1.35002422 (ave = 1.35400772)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.540772, max value: 0.556879\n",
      "D grad l2-norm: 6.896021, max value: 0.737921\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.84620559 (ave = 0.88727591)\n",
      "Loss_G = 1.36445642 (ave = 1.35253789)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.567865, max value: 0.563703\n",
      "D grad l2-norm: 6.806843, max value: 0.741620\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 1.05505729 (ave = 0.91032976)\n",
      "Loss_G = 1.32348228 (ave = 1.34531078)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.409969, max value: 0.572375\n",
      "D grad l2-norm: 6.582107, max value: 0.730978\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.015s / 800 iters, (0.003008)\n",
      "Loss_D = 0.91014582 (ave = 0.89046992)\n",
      "Loss_G = 1.31781042 (ave = 1.32321217)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.588259, max value: 0.575169\n",
      "D grad l2-norm: 6.648653, max value: 0.729354\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.78112990 (ave = 0.87319098)\n",
      "Loss_G = 1.27769637 (ave = 1.29749725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.693964, max value: 0.573564\n",
      "D grad l2-norm: 6.486279, max value: 0.717822\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.78347158 (ave = 0.88311608)\n",
      "Loss_G = 1.27403140 (ave = 1.28246610)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.667516, max value: 0.569789\n",
      "D grad l2-norm: 6.409610, max value: 0.717795\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001191)\n",
      "Loss_D = 0.95478737 (ave = 0.91282136)\n",
      "Loss_G = 1.24722767 (ave = 1.25238693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.597961, max value: 0.574533\n",
      "D grad l2-norm: 6.333423, max value: 0.709346\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001172)\n",
      "Loss_D = 0.80010056 (ave = 0.89267462)\n",
      "Loss_G = 1.24628997 (ave = 1.23093779)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.594953, max value: 0.589622\n",
      "D grad l2-norm: 6.235581, max value: 0.709345\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.95246053 (ave = 0.91882167)\n",
      "Loss_G = 1.23045588 (ave = 1.23262310)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.847705, max value: 0.590192\n",
      "D grad l2-norm: 6.309546, max value: 0.704870\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.90050757 (ave = 0.92438107)\n",
      "Loss_G = 1.18282747 (ave = 1.20245447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.837624, max value: 0.601788\n",
      "D grad l2-norm: 6.145275, max value: 0.689743\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001178)\n",
      "Loss_D = 0.94685000 (ave = 0.93772937)\n",
      "Loss_G = 1.17591012 (ave = 1.17397640)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.664213, max value: 0.595848\n",
      "D grad l2-norm: 5.864758, max value: 0.688416\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001157)\n",
      "Loss_D = 1.02560472 (ave = 0.96098483)\n",
      "Loss_G = 1.13352275 (ave = 1.14746733)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.882077, max value: 0.572823\n",
      "D grad l2-norm: 5.823905, max value: 0.674178\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.98275816 (ave = 0.96970609)\n",
      "Loss_G = 1.10690928 (ave = 1.11237347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.834011, max value: 0.552573\n",
      "D grad l2-norm: 5.715378, max value: 0.665472\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 1.04052830 (ave = 0.99812152)\n",
      "Loss_G = 1.07658672 (ave = 1.06797929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.621700, max value: 0.537469\n",
      "D grad l2-norm: 5.571033, max value: 0.655060\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 1.05102158 (ave = 0.99535379)\n",
      "Loss_G = 1.06515384 (ave = 1.06757607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.422995, max value: 0.520095\n",
      "D grad l2-norm: 5.478660, max value: 0.651208\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002876)\n",
      "Loss_D = 1.11100507 (ave = 1.00675811)\n",
      "Loss_G = 1.09943533 (ave = 1.08165455)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.088510, max value: 0.503659\n",
      "D grad l2-norm: 5.432334, max value: 0.664139\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 800 iters, (0.027)\tData load 0.014s / 800 iters, (0.002834)\n",
      "Loss_D = 0.85348809 (ave = 0.95995816)\n",
      "Loss_G = 1.10865402 (ave = 1.08331373)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.943027, max value: 0.488456\n",
      "D grad l2-norm: 5.432554, max value: 0.667182\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.92129242 (ave = 0.96212106)\n",
      "Loss_G = 1.12952042 (ave = 1.10487883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.908013, max value: 0.506102\n",
      "D grad l2-norm: 5.414473, max value: 0.673910\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.007s / 800 iters, (0.001320)\n",
      "Loss_D = 0.97288048 (ave = 0.97054375)\n",
      "Loss_G = 1.10208774 (ave = 1.11158755)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.995958, max value: 0.514204\n",
      "D grad l2-norm: 5.467769, max value: 0.664245\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.93465388 (ave = 0.95560987)\n",
      "Loss_G = 1.12908447 (ave = 1.11785047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.773812, max value: 0.465841\n",
      "D grad l2-norm: 5.424013, max value: 0.674029\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001186)\n",
      "Loss_D = 1.08218932 (ave = 0.96660217)\n",
      "Loss_G = 1.13764858 (ave = 1.12505808)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.864790, max value: 0.489018\n",
      "D grad l2-norm: 5.601588, max value: 0.677224\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.97653198 (ave = 0.94051044)\n",
      "Loss_G = 1.15064454 (ave = 1.13417931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.817317, max value: 0.511639\n",
      "D grad l2-norm: 5.635465, max value: 0.680649\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.81082845 (ave = 0.90920546)\n",
      "Loss_G = 1.18987584 (ave = 1.15643806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.757145, max value: 0.535348\n",
      "D grad l2-norm: 5.603811, max value: 0.693466\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.92158228 (ave = 0.90969760)\n",
      "Loss_G = 1.15856409 (ave = 1.16466374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.817583, max value: 0.566732\n",
      "D grad l2-norm: 5.632981, max value: 0.683577\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001184)\n",
      "Loss_D = 1.01545787 (ave = 0.90911717)\n",
      "Loss_G = 1.17933893 (ave = 1.18665390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.070848, max value: 0.599452\n",
      "D grad l2-norm: 5.829972, max value: 0.689994\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 1.00932574 (ave = 0.89982949)\n",
      "Loss_G = 1.19635987 (ave = 1.20715587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.197332, max value: 0.591492\n",
      "D grad l2-norm: 5.937628, max value: 0.694987\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 0.85288191 (ave = 0.87135412)\n",
      "Loss_G = 1.21534789 (ave = 1.20620134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.319709, max value: 0.593559\n",
      "D grad l2-norm: 6.047725, max value: 0.700888\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.82207334 (ave = 0.86362841)\n",
      "Loss_G = 1.24239755 (ave = 1.22126732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.332188, max value: 0.566294\n",
      "D grad l2-norm: 6.198239, max value: 0.708600\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.89953166 (ave = 0.86460171)\n",
      "Loss_G = 1.24096274 (ave = 1.23886595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.089149, max value: 0.522329\n",
      "D grad l2-norm: 6.018135, max value: 0.708244\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 0.78224397 (ave = 0.83728369)\n",
      "Loss_G = 1.26053452 (ave = 1.25302603)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.239913, max value: 0.509062\n",
      "D grad l2-norm: 6.077437, max value: 0.714324\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.007s / 800 iters, (0.001392)\n",
      "Loss_D = 0.77899861 (ave = 0.82910253)\n",
      "Loss_G = 1.22866940 (ave = 1.25439162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.169139, max value: 0.492730\n",
      "D grad l2-norm: 5.986902, max value: 0.704351\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.79079586 (ave = 0.82697572)\n",
      "Loss_G = 1.25548649 (ave = 1.26029699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.304396, max value: 0.477765\n",
      "D grad l2-norm: 6.071087, max value: 0.712424\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 0.87968671 (ave = 0.83815583)\n",
      "Loss_G = 1.25319827 (ave = 1.25294137)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.123718, max value: 0.447039\n",
      "D grad l2-norm: 5.896268, max value: 0.711916\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.86963469 (ave = 0.82962384)\n",
      "Loss_G = 1.27035999 (ave = 1.26451569)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.227881, max value: 0.455088\n",
      "D grad l2-norm: 5.966078, max value: 0.716095\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.68106198 (ave = 0.80332166)\n",
      "Loss_G = 1.24276745 (ave = 1.24425611)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.943641, max value: 0.474236\n",
      "D grad l2-norm: 5.640195, max value: 0.708743\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.81878132 (ave = 0.82183342)\n",
      "Loss_G = 1.21191669 (ave = 1.23593936)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.981686, max value: 0.498745\n",
      "D grad l2-norm: 5.553262, max value: 0.699768\n",
      "üîÅ TSCV for Asset 6\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.143s / 800 iters, (0.029)\tData load 0.006s / 800 iters, (0.001204)\n",
      "Loss_D = 1.32889891 (ave = 1.33484180)\n",
      "Loss_G = 0.70489526 (ave = 0.70548782)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.955951, max value: 0.018555\n",
      "D grad l2-norm: 0.670459, max value: 0.505838\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 1.31845319 (ave = 1.32299254)\n",
      "Loss_G = 0.70347625 (ave = 0.70406798)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961135, max value: 0.020040\n",
      "D grad l2-norm: 0.670478, max value: 0.505136\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 1.31750643 (ave = 1.31265593)\n",
      "Loss_G = 0.70200217 (ave = 0.70267193)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968360, max value: 0.022497\n",
      "D grad l2-norm: 0.671470, max value: 0.504406\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002795)\n",
      "Loss_D = 1.30467534 (ave = 1.30095968)\n",
      "Loss_G = 0.70130861 (ave = 0.70153799)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968267, max value: 0.018731\n",
      "D grad l2-norm: 0.674832, max value: 0.504062\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 1.28967929 (ave = 1.28909454)\n",
      "Loss_G = 0.70070332 (ave = 0.70068871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.960862, max value: 0.019066\n",
      "D grad l2-norm: 0.678653, max value: 0.503761\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 1.27969670 (ave = 1.27818887)\n",
      "Loss_G = 0.69899058 (ave = 0.69948930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962778, max value: 0.021903\n",
      "D grad l2-norm: 0.684534, max value: 0.502909\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.25980163 (ave = 1.26619341)\n",
      "Loss_G = 0.69824725 (ave = 0.69903040)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968560, max value: 0.024310\n",
      "D grad l2-norm: 0.688491, max value: 0.502538\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.25154674 (ave = 1.25609732)\n",
      "Loss_G = 0.69751251 (ave = 0.69775683)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965264, max value: 0.025964\n",
      "D grad l2-norm: 0.695210, max value: 0.502172\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001833)\n",
      "Loss_D = 1.24947810 (ave = 1.24720476)\n",
      "Loss_G = 0.69729751 (ave = 0.69714155)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969117, max value: 0.035842\n",
      "D grad l2-norm: 0.700656, max value: 0.502064\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001189)\n",
      "Loss_D = 1.24493337 (ave = 1.23837028)\n",
      "Loss_G = 0.69580132 (ave = 0.69632944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968690, max value: 0.033154\n",
      "D grad l2-norm: 0.711228, max value: 0.501318\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 1.23505425 (ave = 1.22864063)\n",
      "Loss_G = 0.69498956 (ave = 0.69561204)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975617, max value: 0.031940\n",
      "D grad l2-norm: 0.716941, max value: 0.500910\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.21438992 (ave = 1.21816382)\n",
      "Loss_G = 0.69527763 (ave = 0.69510263)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970341, max value: 0.032474\n",
      "D grad l2-norm: 0.723180, max value: 0.501053\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.19929886 (ave = 1.20852084)\n",
      "Loss_G = 0.69519150 (ave = 0.69465383)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970150, max value: 0.033985\n",
      "D grad l2-norm: 0.732896, max value: 0.501010\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.140s / 800 iters, (0.028)\tData load 0.006s / 800 iters, (0.001271)\n",
      "Loss_D = 1.20150208 (ave = 1.20163732)\n",
      "Loss_G = 0.69409037 (ave = 0.69431959)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974821, max value: 0.037898\n",
      "D grad l2-norm: 0.739156, max value: 0.500455\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 1.20287299 (ave = 1.19440389)\n",
      "Loss_G = 0.69442987 (ave = 0.69349767)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980610, max value: 0.033911\n",
      "D grad l2-norm: 0.749697, max value: 0.500625\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.18976784 (ave = 1.18663538)\n",
      "Loss_G = 0.69288182 (ave = 0.69343529)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.982835, max value: 0.035790\n",
      "D grad l2-norm: 0.755028, max value: 0.499847\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.19814110 (ave = 1.18082011)\n",
      "Loss_G = 0.69478244 (ave = 0.69380103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.988117, max value: 0.038354\n",
      "D grad l2-norm: 0.764346, max value: 0.500800\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 1.16719854 (ave = 1.17063818)\n",
      "Loss_G = 0.69505137 (ave = 0.69333131)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.983795, max value: 0.048405\n",
      "D grad l2-norm: 0.774519, max value: 0.500929\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 1.14750624 (ave = 1.16166816)\n",
      "Loss_G = 0.69443405 (ave = 0.69435824)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.989648, max value: 0.038554\n",
      "D grad l2-norm: 0.789595, max value: 0.500620\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 1.15326226 (ave = 1.15619807)\n",
      "Loss_G = 0.69663894 (ave = 0.69553090)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985024, max value: 0.044873\n",
      "D grad l2-norm: 0.798945, max value: 0.501718\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001152)\n",
      "Loss_D = 1.14916682 (ave = 1.14855001)\n",
      "Loss_G = 0.69717509 (ave = 0.69622917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991413, max value: 0.047142\n",
      "D grad l2-norm: 0.806989, max value: 0.501980\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 1.11994207 (ave = 1.13852837)\n",
      "Loss_G = 0.69825137 (ave = 0.69762635)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991281, max value: 0.052535\n",
      "D grad l2-norm: 0.820983, max value: 0.502512\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 1.15502226 (ave = 1.13614023)\n",
      "Loss_G = 0.70217907 (ave = 0.70011270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.998442, max value: 0.058306\n",
      "D grad l2-norm: 0.833782, max value: 0.504467\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001091)\n",
      "Loss_D = 1.13236034 (ave = 1.12573533)\n",
      "Loss_G = 0.70492029 (ave = 0.70345994)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993640, max value: 0.055994\n",
      "D grad l2-norm: 0.844030, max value: 0.505817\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 1.11106670 (ave = 1.11509018)\n",
      "Loss_G = 0.70873940 (ave = 0.70699826)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.002781, max value: 0.055428\n",
      "D grad l2-norm: 0.858477, max value: 0.507708\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000960)\n",
      "Loss_D = 1.09299326 (ave = 1.10453556)\n",
      "Loss_G = 0.71493542 (ave = 0.71116315)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.994207, max value: 0.057090\n",
      "D grad l2-norm: 0.867721, max value: 0.510742\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.06587982 (ave = 1.09275584)\n",
      "Loss_G = 0.71641934 (ave = 0.71576403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.998431, max value: 0.063547\n",
      "D grad l2-norm: 0.883108, max value: 0.511463\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 1.07274210 (ave = 1.08510215)\n",
      "Loss_G = 0.72212714 (ave = 0.72025713)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.994101, max value: 0.067210\n",
      "D grad l2-norm: 0.899124, max value: 0.514249\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 1.06298900 (ave = 1.07398708)\n",
      "Loss_G = 0.72843844 (ave = 0.72504226)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.001410, max value: 0.062233\n",
      "D grad l2-norm: 0.907625, max value: 0.517300\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 1.04178715 (ave = 1.06183772)\n",
      "Loss_G = 0.73512101 (ave = 0.73153579)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.999597, max value: 0.058556\n",
      "D grad l2-norm: 0.924769, max value: 0.520527\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 1.06407249 (ave = 1.05415826)\n",
      "Loss_G = 0.74321842 (ave = 0.73959852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.005451, max value: 0.068587\n",
      "D grad l2-norm: 0.934226, max value: 0.524395\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 1.02783108 (ave = 1.03958864)\n",
      "Loss_G = 0.74833494 (ave = 0.74504119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004181, max value: 0.057275\n",
      "D grad l2-norm: 0.947720, max value: 0.526814\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001150)\n",
      "Loss_D = 1.02816677 (ave = 1.02880845)\n",
      "Loss_G = 0.75629205 (ave = 0.75213505)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.012748, max value: 0.062429\n",
      "D grad l2-norm: 0.953047, max value: 0.530564\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 1.02675200 (ave = 1.01777449)\n",
      "Loss_G = 0.76450002 (ave = 0.75939962)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.013592, max value: 0.061795\n",
      "D grad l2-norm: 0.965477, max value: 0.534404\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 1.00003088 (ave = 1.00562477)\n",
      "Loss_G = 0.76805472 (ave = 0.76561859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.021189, max value: 0.060602\n",
      "D grad l2-norm: 0.993937, max value: 0.536051\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.99290073 (ave = 0.99508864)\n",
      "Loss_G = 0.77228987 (ave = 0.76998770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.035363, max value: 0.062470\n",
      "D grad l2-norm: 1.000937, max value: 0.537999\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.009s / 800 iters, (0.001729)\n",
      "Loss_D = 0.99181354 (ave = 0.98672121)\n",
      "Loss_G = 0.77686429 (ave = 0.77636003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.043115, max value: 0.057521\n",
      "D grad l2-norm: 1.012213, max value: 0.540097\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.018s / 800 iters, (0.003637)\n",
      "Loss_D = 0.95602942 (ave = 0.97275472)\n",
      "Loss_G = 0.78041917 (ave = 0.78052597)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.053199, max value: 0.062042\n",
      "D grad l2-norm: 1.035036, max value: 0.541722\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001164)\n",
      "Loss_D = 0.97829211 (ave = 0.96923842)\n",
      "Loss_G = 0.78337169 (ave = 0.78321153)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.065851, max value: 0.079300\n",
      "D grad l2-norm: 1.041552, max value: 0.543073\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001157)\n",
      "Loss_D = 0.91847223 (ave = 0.95248407)\n",
      "Loss_G = 0.79132122 (ave = 0.78829339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.071162, max value: 0.068250\n",
      "D grad l2-norm: 1.051082, max value: 0.546692\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.91066778 (ave = 0.94332386)\n",
      "Loss_G = 0.79717290 (ave = 0.79452403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.071659, max value: 0.068982\n",
      "D grad l2-norm: 1.070901, max value: 0.549334\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002768)\n",
      "Loss_D = 0.90179753 (ave = 0.93431840)\n",
      "Loss_G = 0.80048645 (ave = 0.79953144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.079118, max value: 0.074405\n",
      "D grad l2-norm: 1.082937, max value: 0.550823\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001155)\n",
      "Loss_D = 0.93130076 (ave = 0.92930938)\n",
      "Loss_G = 0.80961132 (ave = 0.80649753)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.083733, max value: 0.074086\n",
      "D grad l2-norm: 1.098063, max value: 0.554904\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002787)\n",
      "Loss_D = 0.95795381 (ave = 0.92318897)\n",
      "Loss_G = 0.81469530 (ave = 0.81253575)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.105825, max value: 0.089154\n",
      "D grad l2-norm: 1.123407, max value: 0.557136\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002875)\n",
      "Loss_D = 0.88926983 (ave = 0.90741582)\n",
      "Loss_G = 0.82046592 (ave = 0.81833781)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.122409, max value: 0.094013\n",
      "D grad l2-norm: 1.134131, max value: 0.559638\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.91217935 (ave = 0.90194837)\n",
      "Loss_G = 0.82727098 (ave = 0.82465553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.140328, max value: 0.100655\n",
      "D grad l2-norm: 1.152747, max value: 0.562643\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001199)\n",
      "Loss_D = 0.87833917 (ave = 0.89164895)\n",
      "Loss_G = 0.83050609 (ave = 0.82746748)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.179947, max value: 0.107092\n",
      "D grad l2-norm: 1.183410, max value: 0.564044\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001003)\n",
      "Loss_D = 0.87387544 (ave = 0.88516371)\n",
      "Loss_G = 0.83251083 (ave = 0.83061951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.190702, max value: 0.121255\n",
      "D grad l2-norm: 1.190822, max value: 0.564901\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001186)\n",
      "Loss_D = 0.84251916 (ave = 0.87601056)\n",
      "Loss_G = 0.82977611 (ave = 0.83110069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.243206, max value: 0.120000\n",
      "D grad l2-norm: 1.243705, max value: 0.563681\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.91006273 (ave = 0.88152868)\n",
      "Loss_G = 0.83634037 (ave = 0.83378872)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.246818, max value: 0.126249\n",
      "D grad l2-norm: 1.252616, max value: 0.566515\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.84164864 (ave = 0.86787256)\n",
      "Loss_G = 0.84018087 (ave = 0.83909848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.270384, max value: 0.134522\n",
      "D grad l2-norm: 1.267820, max value: 0.568182\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.82876444 (ave = 0.85822303)\n",
      "Loss_G = 0.84300685 (ave = 0.84185524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.287401, max value: 0.139141\n",
      "D grad l2-norm: 1.294309, max value: 0.569351\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001177)\n",
      "Loss_D = 0.85798585 (ave = 0.86023312)\n",
      "Loss_G = 0.84811223 (ave = 0.84346954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.309847, max value: 0.139948\n",
      "D grad l2-norm: 1.333812, max value: 0.571525\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001152)\n",
      "Loss_D = 0.87275589 (ave = 0.85683761)\n",
      "Loss_G = 0.84655130 (ave = 0.84685392)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.354435, max value: 0.151870\n",
      "D grad l2-norm: 1.367345, max value: 0.570866\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 0.84525180 (ave = 0.84989910)\n",
      "Loss_G = 0.85084397 (ave = 0.84745939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.383738, max value: 0.154390\n",
      "D grad l2-norm: 1.384422, max value: 0.572686\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.85841990 (ave = 0.84819151)\n",
      "Loss_G = 0.84675759 (ave = 0.84943861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.450662, max value: 0.159410\n",
      "D grad l2-norm: 1.447112, max value: 0.570910\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.87669146 (ave = 0.84769394)\n",
      "Loss_G = 0.85210389 (ave = 0.84865773)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.507784, max value: 0.171097\n",
      "D grad l2-norm: 1.474843, max value: 0.573146\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001212)\n",
      "Loss_D = 0.89640641 (ave = 0.85312368)\n",
      "Loss_G = 0.85307103 (ave = 0.85066507)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.588454, max value: 0.189011\n",
      "D grad l2-norm: 1.524185, max value: 0.573477\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.030s / 800 iters, (0.005908)\n",
      "Loss_D = 0.84819007 (ave = 0.85021678)\n",
      "Loss_G = 0.84138501 (ave = 0.84034647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.662565, max value: 0.200588\n",
      "D grad l2-norm: 1.581943, max value: 0.568394\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001152)\n",
      "Loss_D = 0.86211622 (ave = 0.85563753)\n",
      "Loss_G = 0.83907825 (ave = 0.83806634)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.720793, max value: 0.195515\n",
      "D grad l2-norm: 1.632420, max value: 0.567332\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001198)\n",
      "Loss_D = 0.80265951 (ave = 0.85228263)\n",
      "Loss_G = 0.83607179 (ave = 0.83592268)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.800657, max value: 0.199065\n",
      "D grad l2-norm: 1.712374, max value: 0.565978\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001198)\n",
      "Loss_D = 0.82691163 (ave = 0.86214050)\n",
      "Loss_G = 0.83410501 (ave = 0.83109553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.851416, max value: 0.216238\n",
      "D grad l2-norm: 1.767124, max value: 0.565093\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.84987283 (ave = 0.86268415)\n",
      "Loss_G = 0.83834970 (ave = 0.83597275)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.894506, max value: 0.230805\n",
      "D grad l2-norm: 1.848383, max value: 0.566975\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002796)\n",
      "Loss_D = 0.89762467 (ave = 0.87100868)\n",
      "Loss_G = 0.84307617 (ave = 0.83706739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.965629, max value: 0.244240\n",
      "D grad l2-norm: 1.943902, max value: 0.569016\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.007s / 800 iters, (0.001365)\n",
      "Loss_D = 0.89560258 (ave = 0.86993222)\n",
      "Loss_G = 0.84784579 (ave = 0.84663644)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.010773, max value: 0.241436\n",
      "D grad l2-norm: 2.002116, max value: 0.571035\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.86780643 (ave = 0.86361372)\n",
      "Loss_G = 0.86044705 (ave = 0.85603158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.009360, max value: 0.233680\n",
      "D grad l2-norm: 2.043256, max value: 0.576323\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.83343923 (ave = 0.85239118)\n",
      "Loss_G = 0.86657000 (ave = 0.86767390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.108179, max value: 0.248657\n",
      "D grad l2-norm: 2.151366, max value: 0.578683\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.84422362 (ave = 0.85232568)\n",
      "Loss_G = 0.88291132 (ave = 0.88182323)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.118686, max value: 0.231169\n",
      "D grad l2-norm: 2.172934, max value: 0.585590\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.86688125 (ave = 0.84970094)\n",
      "Loss_G = 0.89485395 (ave = 0.88891685)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.138230, max value: 0.224005\n",
      "D grad l2-norm: 2.250886, max value: 0.590658\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.78630894 (ave = 0.83178487)\n",
      "Loss_G = 0.90647095 (ave = 0.90414934)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.207846, max value: 0.250775\n",
      "D grad l2-norm: 2.353846, max value: 0.595227\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.81939280 (ave = 0.82857779)\n",
      "Loss_G = 0.92359245 (ave = 0.91938832)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.284633, max value: 0.266286\n",
      "D grad l2-norm: 2.444129, max value: 0.602060\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001013)\n",
      "Loss_D = 0.76835418 (ave = 0.81874968)\n",
      "Loss_G = 0.93446875 (ave = 0.92988669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.374520, max value: 0.290618\n",
      "D grad l2-norm: 2.473645, max value: 0.606453\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.82217360 (ave = 0.82467446)\n",
      "Loss_G = 0.93178052 (ave = 0.93580909)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.554866, max value: 0.319032\n",
      "D grad l2-norm: 2.563277, max value: 0.605190\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.92148817 (ave = 0.84803560)\n",
      "Loss_G = 0.91306406 (ave = 0.92554393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.769408, max value: 0.336220\n",
      "D grad l2-norm: 2.623317, max value: 0.597386\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001034)\n",
      "Loss_D = 0.80974805 (ave = 0.85320730)\n",
      "Loss_G = 0.88236099 (ave = 0.90756658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.031840, max value: 0.343200\n",
      "D grad l2-norm: 2.725007, max value: 0.584327\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.94396996 (ave = 0.89705834)\n",
      "Loss_G = 0.87786555 (ave = 0.88290726)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.111946, max value: 0.349313\n",
      "D grad l2-norm: 2.785206, max value: 0.582538\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.96044898 (ave = 0.92724212)\n",
      "Loss_G = 0.86601424 (ave = 0.86987720)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.084552, max value: 0.343565\n",
      "D grad l2-norm: 2.792418, max value: 0.577056\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.84681755 (ave = 0.91239551)\n",
      "Loss_G = 0.87970710 (ave = 0.87112477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.207376, max value: 0.339897\n",
      "D grad l2-norm: 2.962663, max value: 0.583540\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001165)\n",
      "Loss_D = 0.90551233 (ave = 0.92131661)\n",
      "Loss_G = 0.88536352 (ave = 0.87563881)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.135435, max value: 0.335744\n",
      "D grad l2-norm: 2.983946, max value: 0.585317\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.009s / 800 iters, (0.001758)\n",
      "Loss_D = 0.89494324 (ave = 0.91487254)\n",
      "Loss_G = 0.92307568 (ave = 0.90923177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.168708, max value: 0.344680\n",
      "D grad l2-norm: 3.171622, max value: 0.600818\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.95046198 (ave = 0.90603231)\n",
      "Loss_G = 0.96823901 (ave = 0.94319656)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.124623, max value: 0.354404\n",
      "D grad l2-norm: 3.290674, max value: 0.618437\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 0.84779572 (ave = 0.87925140)\n",
      "Loss_G = 0.99930799 (ave = 0.98263627)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.117631, max value: 0.343489\n",
      "D grad l2-norm: 3.393388, max value: 0.630434\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002729)\n",
      "Loss_D = 0.81195486 (ave = 0.85622978)\n",
      "Loss_G = 1.03052139 (ave = 1.02280872)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.182558, max value: 0.338478\n",
      "D grad l2-norm: 3.492018, max value: 0.640975\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.88234210 (ave = 0.86370468)\n",
      "Loss_G = 1.04518318 (ave = 1.03593385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.233498, max value: 0.338138\n",
      "D grad l2-norm: 3.593739, max value: 0.646582\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002878)\n",
      "Loss_D = 0.94411182 (ave = 0.86807621)\n",
      "Loss_G = 1.05544293 (ave = 1.04949994)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.265168, max value: 0.321328\n",
      "D grad l2-norm: 3.710432, max value: 0.650163\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002778)\n",
      "Loss_D = 0.84661114 (ave = 0.85762073)\n",
      "Loss_G = 1.06828797 (ave = 1.06663227)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.299476, max value: 0.299225\n",
      "D grad l2-norm: 3.769659, max value: 0.654351\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.78553200 (ave = 0.85169145)\n",
      "Loss_G = 1.09659016 (ave = 1.08750906)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.333297, max value: 0.314023\n",
      "D grad l2-norm: 3.817060, max value: 0.664189\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.85898483 (ave = 0.86361541)\n",
      "Loss_G = 1.09194160 (ave = 1.08760645)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.567057, max value: 0.344407\n",
      "D grad l2-norm: 4.014585, max value: 0.662934\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.88912868 (ave = 0.87176925)\n",
      "Loss_G = 1.09104526 (ave = 1.09739001)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.824760, max value: 0.388323\n",
      "D grad l2-norm: 4.168586, max value: 0.662040\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.89458120 (ave = 0.88864111)\n",
      "Loss_G = 1.06970847 (ave = 1.07914448)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.990755, max value: 0.423460\n",
      "D grad l2-norm: 4.226172, max value: 0.654793\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 0.89106596 (ave = 0.91747112)\n",
      "Loss_G = 1.07016921 (ave = 1.05824172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.924518, max value: 0.416520\n",
      "D grad l2-norm: 4.248292, max value: 0.654564\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 0.91528201 (ave = 0.92424279)\n",
      "Loss_G = 1.08602464 (ave = 1.06955438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.999809, max value: 0.406259\n",
      "D grad l2-norm: 4.402599, max value: 0.659668\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.87619948 (ave = 0.92117605)\n",
      "Loss_G = 1.09179139 (ave = 1.08063703)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.102013, max value: 0.435403\n",
      "D grad l2-norm: 4.485764, max value: 0.661687\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.98389179 (ave = 0.94579482)\n",
      "Loss_G = 1.08220077 (ave = 1.09925957)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.497970, max value: 0.470029\n",
      "D grad l2-norm: 4.660337, max value: 0.658393\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.00967121 (ave = 0.96677705)\n",
      "Loss_G = 1.08866525 (ave = 1.10013621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.763023, max value: 0.474464\n",
      "D grad l2-norm: 4.726284, max value: 0.659530\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.94374824 (ave = 0.98113889)\n",
      "Loss_G = 1.06585860 (ave = 1.06666119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.929832, max value: 0.442041\n",
      "D grad l2-norm: 4.800285, max value: 0.651918\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.98663765 (ave = 1.01548967)\n",
      "Loss_G = 1.06636608 (ave = 1.04531138)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.239405, max value: 0.410548\n",
      "D grad l2-norm: 4.918261, max value: 0.651858\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.009s / 800 iters, (0.001826)\n",
      "Loss_D = 1.03916633 (ave = 1.04699802)\n",
      "Loss_G = 1.04200065 (ave = 1.03191936)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.346150, max value: 0.380454\n",
      "D grad l2-norm: 4.936593, max value: 0.643001\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001216)\n",
      "Loss_D = 1.12784791 (ave = 1.08379343)\n",
      "Loss_G = 1.04728425 (ave = 1.01686127)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.462437, max value: 0.382927\n",
      "D grad l2-norm: 5.118573, max value: 0.645598\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000935)\n",
      "Loss_D = 1.06696129 (ave = 1.07874482)\n",
      "Loss_G = 1.08463860 (ave = 1.05546322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.362753, max value: 0.399979\n",
      "D grad l2-norm: 5.413949, max value: 0.658447\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 1.01984429 (ave = 1.03992827)\n",
      "Loss_G = 1.15559077 (ave = 1.12125347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.338790, max value: 0.420535\n",
      "D grad l2-norm: 5.735429, max value: 0.683467\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001000)\n",
      "Loss_D = 1.05524802 (ave = 1.00557113)\n",
      "Loss_G = 1.22956622 (ave = 1.20208104)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.258889, max value: 0.457312\n",
      "D grad l2-norm: 5.752978, max value: 0.704973\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000959)\n",
      "Loss_D = 1.02619386 (ave = 0.97149855)\n",
      "Loss_G = 1.28894067 (ave = 1.25335627)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.520098, max value: 0.489280\n",
      "D grad l2-norm: 6.177631, max value: 0.759277\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.95354873 (ave = 0.93868639)\n",
      "Loss_G = 1.35316086 (ave = 1.31214979)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.392101, max value: 0.497464\n",
      "D grad l2-norm: 6.299392, max value: 0.779449\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.85837406 (ave = 0.89120964)\n",
      "Loss_G = 1.39864326 (ave = 1.38058980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.431571, max value: 0.501358\n",
      "D grad l2-norm: 6.598253, max value: 0.810373\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.79302514 (ave = 0.84489189)\n",
      "Loss_G = 1.46941650 (ave = 1.44779944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.285270, max value: 0.475460\n",
      "D grad l2-norm: 6.684453, max value: 0.831908\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 0.75961357 (ave = 0.81534388)\n",
      "Loss_G = 1.52114332 (ave = 1.51528273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.337161, max value: 0.484056\n",
      "D grad l2-norm: 6.777543, max value: 0.846473\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 0.79501331 (ave = 0.79015388)\n",
      "Loss_G = 1.58631337 (ave = 1.56746805)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.351175, max value: 0.483509\n",
      "D grad l2-norm: 6.965046, max value: 0.867646\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.82542759 (ave = 0.77380339)\n",
      "Loss_G = 1.59898269 (ave = 1.59002881)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.214589, max value: 0.473568\n",
      "D grad l2-norm: 6.815751, max value: 0.835879\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.61464846 (ave = 0.73033499)\n",
      "Loss_G = 1.60774326 (ave = 1.61170874)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.470345, max value: 0.479320\n",
      "D grad l2-norm: 6.956356, max value: 0.823689\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.74628687 (ave = 0.73552221)\n",
      "Loss_G = 1.63467050 (ave = 1.61501725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.683231, max value: 0.474340\n",
      "D grad l2-norm: 7.067962, max value: 0.835100\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.70877659 (ave = 0.72693248)\n",
      "Loss_G = 1.60388982 (ave = 1.60324457)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.695654, max value: 0.463475\n",
      "D grad l2-norm: 6.845432, max value: 0.798141\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001002)\n",
      "Loss_D = 0.67347413 (ave = 0.72113931)\n",
      "Loss_G = 1.52711499 (ave = 1.57852011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.937424, max value: 0.494703\n",
      "D grad l2-norm: 6.694985, max value: 0.778972\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000995)\n",
      "Loss_D = 0.69340599 (ave = 0.73507491)\n",
      "Loss_G = 1.52314222 (ave = 1.54739656)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.212033, max value: 0.534837\n",
      "D grad l2-norm: 6.693602, max value: 0.778788\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.79688358 (ave = 0.76518089)\n",
      "Loss_G = 1.46583426 (ave = 1.47362998)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.267623, max value: 0.522171\n",
      "D grad l2-norm: 6.645326, max value: 0.764476\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 0.83393818 (ave = 0.78984252)\n",
      "Loss_G = 1.42763400 (ave = 1.43252504)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.271129, max value: 0.524788\n",
      "D grad l2-norm: 6.515671, max value: 0.754726\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000998)\n",
      "Loss_D = 0.82013559 (ave = 0.80536585)\n",
      "Loss_G = 1.35322511 (ave = 1.40752838)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.379355, max value: 0.539157\n",
      "D grad l2-norm: 6.431812, max value: 0.736697\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 0.79402280 (ave = 0.81970176)\n",
      "Loss_G = 1.32949972 (ave = 1.34171338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.530063, max value: 0.555625\n",
      "D grad l2-norm: 6.440398, max value: 0.729184\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.79594851 (ave = 0.85659109)\n",
      "Loss_G = 1.30364513 (ave = 1.30354519)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.516982, max value: 0.530555\n",
      "D grad l2-norm: 6.280210, max value: 0.722287\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.94020301 (ave = 0.89855603)\n",
      "Loss_G = 1.24210382 (ave = 1.26828136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.635009, max value: 0.545691\n",
      "D grad l2-norm: 6.256457, max value: 0.705569\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.012s / 800 iters, (0.002391)\n",
      "Loss_D = 0.99886239 (ave = 0.93133461)\n",
      "Loss_G = 1.24684024 (ave = 1.24555845)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.763352, max value: 0.564580\n",
      "D grad l2-norm: 6.391790, max value: 0.706991\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 1.07523251 (ave = 0.97044708)\n",
      "Loss_G = 1.16545665 (ave = 1.19881675)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.228680, max value: 0.577410\n",
      "D grad l2-norm: 6.526613, max value: 0.680359\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.015s / 800 iters, (0.003098)\n",
      "Loss_D = 0.96368945 (ave = 1.00298789)\n",
      "Loss_G = 1.17514110 (ave = 1.16867487)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.360665, max value: 0.578082\n",
      "D grad l2-norm: 6.572765, max value: 0.685696\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.90898144 (ave = 1.01930037)\n",
      "Loss_G = 1.17312431 (ave = 1.14442170)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.314682, max value: 0.557810\n",
      "D grad l2-norm: 6.816721, max value: 0.684136\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.022s / 800 iters, (0.004411)\n",
      "Loss_D = 1.06109476 (ave = 1.03458962)\n",
      "Loss_G = 1.20124733 (ave = 1.17794442)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.944022, max value: 0.537781\n",
      "D grad l2-norm: 6.874862, max value: 0.694965\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001091)\n",
      "Loss_D = 1.13243294 (ave = 1.02305939)\n",
      "Loss_G = 1.25638938 (ave = 1.23018219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.858458, max value: 0.514531\n",
      "D grad l2-norm: 7.128712, max value: 0.735976\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.92937577 (ave = 0.97695366)\n",
      "Loss_G = 1.29029858 (ave = 1.29587061)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.197141, max value: 0.503190\n",
      "D grad l2-norm: 7.650989, max value: 0.815452\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.19409966 (ave = 0.99488289)\n",
      "Loss_G = 1.32628810 (ave = 1.33899405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.678648, max value: 0.507099\n",
      "D grad l2-norm: 7.840995, max value: 0.842845\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.008s / 800 iters, (0.001623)\n",
      "Loss_D = 1.01627302 (ave = 0.97785645)\n",
      "Loss_G = 1.34683394 (ave = 1.33287408)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.109529, max value: 0.520280\n",
      "D grad l2-norm: 8.036434, max value: 0.859087\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 1.05217957 (ave = 0.98885092)\n",
      "Loss_G = 1.33668554 (ave = 1.33165908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.019474, max value: 0.519460\n",
      "D grad l2-norm: 8.055903, max value: 0.865440\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 1.03884983 (ave = 0.98928707)\n",
      "Loss_G = 1.36893058 (ave = 1.37104499)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.353754, max value: 0.538595\n",
      "D grad l2-norm: 8.428169, max value: 0.908801\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001030)\n",
      "Loss_D = 0.84561402 (ave = 0.96550040)\n",
      "Loss_G = 1.35307074 (ave = 1.35491552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.321923, max value: 0.525991\n",
      "D grad l2-norm: 8.382154, max value: 0.894056\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.020s / 800 iters, (0.004049)\n",
      "Loss_D = 0.84988749 (ave = 0.96177423)\n",
      "Loss_G = 1.37998366 (ave = 1.36633523)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.992184, max value: 0.499044\n",
      "D grad l2-norm: 8.369726, max value: 0.900829\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.90343988 (ave = 0.95457387)\n",
      "Loss_G = 1.42113650 (ave = 1.41814785)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.605597, max value: 0.510566\n",
      "D grad l2-norm: 8.350920, max value: 0.915590\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.98500395 (ave = 0.93628877)\n",
      "Loss_G = 1.42407286 (ave = 1.43345435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.467425, max value: 0.543803\n",
      "D grad l2-norm: 8.201084, max value: 0.888941\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.95460826 (ave = 0.92203040)\n",
      "Loss_G = 1.45008588 (ave = 1.46163673)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.669750, max value: 0.585607\n",
      "D grad l2-norm: 8.373274, max value: 0.910916\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.88024843 (ave = 0.90076159)\n",
      "Loss_G = 1.47311103 (ave = 1.45779450)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.587954, max value: 0.611145\n",
      "D grad l2-norm: 8.323569, max value: 0.902922\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.87481678 (ave = 0.88505915)\n",
      "Loss_G = 1.48627579 (ave = 1.48894873)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.719897, max value: 0.646330\n",
      "D grad l2-norm: 8.480881, max value: 0.898927\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.73640013 (ave = 0.85416951)\n",
      "Loss_G = 1.52508211 (ave = 1.50291665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.677426, max value: 0.646776\n",
      "D grad l2-norm: 8.543496, max value: 0.900972\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.80766952 (ave = 0.84605627)\n",
      "Loss_G = 1.53054404 (ave = 1.50938447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.723598, max value: 0.649989\n",
      "D grad l2-norm: 8.462918, max value: 0.869575\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.76039040 (ave = 0.82922560)\n",
      "Loss_G = 1.51210535 (ave = 1.50045373)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.947938, max value: 0.677157\n",
      "D grad l2-norm: 8.725576, max value: 0.877841\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001173)\n",
      "Loss_D = 0.68180871 (ave = 0.81921386)\n",
      "Loss_G = 1.52804184 (ave = 1.49203939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.209282, max value: 0.588599\n",
      "D grad l2-norm: 8.185936, max value: 0.847800\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 1.02912831 (ave = 0.84564078)\n",
      "Loss_G = 1.55388236 (ave = 1.52667882)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.757680, max value: 0.548160\n",
      "D grad l2-norm: 7.947086, max value: 0.835855\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.016s / 800 iters, (0.003148)\n",
      "Loss_D = 0.69296920 (ave = 0.78055409)\n",
      "Loss_G = 1.56607747 (ave = 1.55184944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.707836, max value: 0.523543\n",
      "D grad l2-norm: 8.011102, max value: 0.840595\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 800 iters, (0.027)\tData load 0.014s / 800 iters, (0.002832)\n",
      "Loss_D = 0.86082733 (ave = 0.78607676)\n",
      "Loss_G = 1.55310571 (ave = 1.57602892)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.586269, max value: 0.506586\n",
      "D grad l2-norm: 7.893484, max value: 0.812804\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001170)\n",
      "Loss_D = 0.66399574 (ave = 0.74986440)\n",
      "Loss_G = 1.54651141 (ave = 1.55262237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.747218, max value: 0.513510\n",
      "D grad l2-norm: 7.913858, max value: 0.786248\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.139s / 800 iters, (0.028)\tData load 0.006s / 800 iters, (0.001178)\n",
      "Loss_D = 0.76554263 (ave = 0.75890863)\n",
      "Loss_G = 1.52805388 (ave = 1.54296663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.902354, max value: 0.510415\n",
      "D grad l2-norm: 7.909115, max value: 0.778807\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 800 iters, (0.027)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 0.83400500 (ave = 0.76640310)\n",
      "Loss_G = 1.50178206 (ave = 1.51027222)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.840474, max value: 0.494223\n",
      "D grad l2-norm: 7.690861, max value: 0.773602\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 0.87297773 (ave = 0.76987299)\n",
      "Loss_G = 1.49104273 (ave = 1.50558228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.011441, max value: 0.500771\n",
      "D grad l2-norm: 7.833539, max value: 0.770329\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 0.61827064 (ave = 0.73738509)\n",
      "Loss_G = 1.48552418 (ave = 1.47084563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.011310, max value: 0.498783\n",
      "D grad l2-norm: 7.798710, max value: 0.769810\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001154)\n",
      "Loss_D = 0.66472054 (ave = 0.73824629)\n",
      "Loss_G = 1.49793363 (ave = 1.49628322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.070980, max value: 0.518228\n",
      "D grad l2-norm: 7.763159, max value: 0.772637\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.79171562 (ave = 0.74626291)\n",
      "Loss_G = 1.47365379 (ave = 1.49837885)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.199381, max value: 0.535745\n",
      "D grad l2-norm: 7.638325, max value: 0.765275\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002780)\n",
      "Loss_D = 0.74286723 (ave = 0.75571952)\n",
      "Loss_G = 1.43095458 (ave = 1.43884568)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.805763, max value: 0.581601\n",
      "D grad l2-norm: 7.617216, max value: 0.756565\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.86231267 (ave = 0.79261240)\n",
      "Loss_G = 1.34298480 (ave = 1.37609794)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.424282, max value: 0.627422\n",
      "D grad l2-norm: 7.693264, max value: 0.732080\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.97352362 (ave = 0.84804460)\n",
      "Loss_G = 1.32270598 (ave = 1.30685859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.219618, max value: 0.620923\n",
      "D grad l2-norm: 7.548435, max value: 0.728744\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.88362974 (ave = 0.84076877)\n",
      "Loss_G = 1.31614971 (ave = 1.31251273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.364445, max value: 0.630720\n",
      "D grad l2-norm: 7.828972, max value: 0.727637\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001174)\n",
      "Loss_D = 0.82035804 (ave = 0.83463328)\n",
      "Loss_G = 1.32712793 (ave = 1.32179954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.440610, max value: 0.657155\n",
      "D grad l2-norm: 7.829620, max value: 0.730214\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.82935196 (ave = 0.84304495)\n",
      "Loss_G = 1.30909169 (ave = 1.31194255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.660611, max value: 0.718384\n",
      "D grad l2-norm: 7.904770, max value: 0.725260\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.012s / 800 iters, (0.002322)\n",
      "Loss_D = 0.87598419 (ave = 0.86480826)\n",
      "Loss_G = 1.29204869 (ave = 1.31128633)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.871094, max value: 0.744316\n",
      "D grad l2-norm: 8.009220, max value: 0.719094\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.91963780 (ave = 0.87783370)\n",
      "Loss_G = 1.25419116 (ave = 1.28297486)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.936771, max value: 0.734052\n",
      "D grad l2-norm: 7.945180, max value: 0.715572\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.90909529 (ave = 0.90304402)\n",
      "Loss_G = 1.26362920 (ave = 1.26647565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.200661, max value: 0.771297\n",
      "D grad l2-norm: 8.069772, max value: 0.748311\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 1.13123012 (ave = 0.95033864)\n",
      "Loss_G = 1.20386958 (ave = 1.24747162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.508613, max value: 0.812142\n",
      "D grad l2-norm: 8.070526, max value: 0.743628\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.82272273 (ave = 0.95975938)\n",
      "Loss_G = 1.23458898 (ave = 1.22262387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.405786, max value: 0.826145\n",
      "D grad l2-norm: 8.115884, max value: 0.767553\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.92087299 (ave = 0.96679177)\n",
      "Loss_G = 1.23400521 (ave = 1.22613082)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.036569, max value: 0.785114\n",
      "D grad l2-norm: 8.176546, max value: 0.791666\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 1.04864800 (ave = 0.97239136)\n",
      "Loss_G = 1.26929867 (ave = 1.27208200)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.532104, max value: 0.768506\n",
      "D grad l2-norm: 8.076044, max value: 0.804106\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002728)\n",
      "Loss_D = 0.94989514 (ave = 0.94097631)\n",
      "Loss_G = 1.35609686 (ave = 1.31416547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.842383, max value: 0.783728\n",
      "D grad l2-norm: 8.628512, max value: 0.866669\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.98880398 (ave = 0.93488578)\n",
      "Loss_G = 1.34364772 (ave = 1.32078438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.867412, max value: 0.862773\n",
      "D grad l2-norm: 8.587758, max value: 0.840919\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.010s / 800 iters, (0.001914)\n",
      "Loss_D = 0.89968097 (ave = 0.92439998)\n",
      "Loss_G = 1.28002429 (ave = 1.33014507)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.995655, max value: 0.822100\n",
      "D grad l2-norm: 8.483183, max value: 0.793081\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.94936800 (ave = 0.94376576)\n",
      "Loss_G = 1.29675102 (ave = 1.29418499)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.935498, max value: 0.793271\n",
      "D grad l2-norm: 8.420572, max value: 0.805782\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 1.09837866 (ave = 0.97702533)\n",
      "Loss_G = 1.30973446 (ave = 1.30184453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.723692, max value: 0.698152\n",
      "D grad l2-norm: 8.412425, max value: 0.845156\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.02683866 (ave = 0.96396490)\n",
      "Loss_G = 1.32489240 (ave = 1.30375977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.648034, max value: 0.631165\n",
      "D grad l2-norm: 8.447562, max value: 0.892990\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.89061701 (ave = 0.93438185)\n",
      "Loss_G = 1.36591887 (ave = 1.34618063)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.566240, max value: 0.582733\n",
      "D grad l2-norm: 8.634856, max value: 0.947827\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 0.93087244 (ave = 0.93145481)\n",
      "Loss_G = 1.36022520 (ave = 1.36017218)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.619614, max value: 0.593345\n",
      "D grad l2-norm: 8.906207, max value: 0.978894\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 0.93403184 (ave = 0.92739377)\n",
      "Loss_G = 1.41137803 (ave = 1.39647496)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.043641, max value: 0.589398\n",
      "D grad l2-norm: 8.541059, max value: 0.946279\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001195)\n",
      "Loss_D = 0.76287746 (ave = 0.88891802)\n",
      "Loss_G = 1.46894383 (ave = 1.44028120)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.910208, max value: 0.567460\n",
      "D grad l2-norm: 8.792997, max value: 0.975102\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.89018118 (ave = 0.89559141)\n",
      "Loss_G = 1.48471713 (ave = 1.48393848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.004354, max value: 0.609799\n",
      "D grad l2-norm: 8.918367, max value: 0.950619\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.15262818 (ave = 0.90940799)\n",
      "Loss_G = 1.51496065 (ave = 1.52617872)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.200996, max value: 0.671244\n",
      "D grad l2-norm: 9.060027, max value: 0.917297\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.89718294 (ave = 0.87404641)\n",
      "Loss_G = 1.47779775 (ave = 1.50093462)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.031732, max value: 0.684127\n",
      "D grad l2-norm: 8.740461, max value: 0.804255\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.73338020 (ave = 0.85341283)\n",
      "Loss_G = 1.49668109 (ave = 1.48827574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.822216, max value: 0.669461\n",
      "D grad l2-norm: 8.717331, max value: 0.770915\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.91475159 (ave = 0.85963113)\n",
      "Loss_G = 1.55333424 (ave = 1.52094312)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.267920, max value: 0.604886\n",
      "D grad l2-norm: 8.743705, max value: 0.784352\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.78179157 (ave = 0.81773868)\n",
      "Loss_G = 1.58954751 (ave = 1.57024863)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.000314, max value: 0.568353\n",
      "D grad l2-norm: 8.710951, max value: 0.818628\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001032)\n",
      "Loss_D = 0.64669740 (ave = 0.77629716)\n",
      "Loss_G = 1.60928524 (ave = 1.61561897)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.981824, max value: 0.530492\n",
      "D grad l2-norm: 8.667167, max value: 0.853103\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.85817277 (ave = 0.78597866)\n",
      "Loss_G = 1.60459185 (ave = 1.63549559)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.136153, max value: 0.527560\n",
      "D grad l2-norm: 8.674585, max value: 0.877111\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.85346782 (ave = 0.77243241)\n",
      "Loss_G = 1.61401165 (ave = 1.61589890)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.511513, max value: 0.541589\n",
      "D grad l2-norm: 8.735861, max value: 0.905429\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001177)\n",
      "Loss_D = 0.63634491 (ave = 0.74471830)\n",
      "Loss_G = 1.57593012 (ave = 1.57926338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.782969, max value: 0.542475\n",
      "D grad l2-norm: 8.520975, max value: 0.891087\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001190)\n",
      "Loss_D = 0.70990181 (ave = 0.76060383)\n",
      "Loss_G = 1.51715660 (ave = 1.53705842)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.096615, max value: 0.556957\n",
      "D grad l2-norm: 8.494474, max value: 0.884914\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 800 iters, (0.024)\tData load 0.018s / 800 iters, (0.003593)\n",
      "Loss_D = 0.65015638 (ave = 0.76326454)\n",
      "Loss_G = 1.45821238 (ave = 1.48076079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.131843, max value: 0.582314\n",
      "D grad l2-norm: 8.070494, max value: 0.851249\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002737)\n",
      "Loss_D = 0.71509302 (ave = 0.79567242)\n",
      "Loss_G = 1.38251853 (ave = 1.40567925)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.676765, max value: 0.646804\n",
      "D grad l2-norm: 7.992067, max value: 0.816143\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002794)\n",
      "Loss_D = 0.88549829 (ave = 0.84580412)\n",
      "Loss_G = 1.32992280 (ave = 1.34731441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.911188, max value: 0.706771\n",
      "D grad l2-norm: 7.886411, max value: 0.790037\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.024s / 800 iters, (0.004785)\n",
      "Loss_D = 0.96579731 (ave = 0.89222448)\n",
      "Loss_G = 1.29441404 (ave = 1.29429862)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.228764, max value: 0.763015\n",
      "D grad l2-norm: 8.021272, max value: 0.788481\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.82065856 (ave = 0.88794366)\n",
      "Loss_G = 1.25543618 (ave = 1.25488389)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.403170, max value: 0.728303\n",
      "D grad l2-norm: 7.506736, max value: 0.734728\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.86968499 (ave = 0.89148309)\n",
      "Loss_G = 1.28274703 (ave = 1.28498209)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.474988, max value: 0.708967\n",
      "D grad l2-norm: 7.680910, max value: 0.751920\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001032)\n",
      "Loss_D = 0.92378360 (ave = 0.88850063)\n",
      "Loss_G = 1.28732133 (ave = 1.29056141)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.330536, max value: 0.714365\n",
      "D grad l2-norm: 7.472251, max value: 0.723451\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001015)\n",
      "Loss_D = 0.71049887 (ave = 0.85724636)\n",
      "Loss_G = 1.29648209 (ave = 1.29699152)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.247349, max value: 0.744310\n",
      "D grad l2-norm: 7.503532, max value: 0.723086\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.007s / 800 iters, (0.001454)\n",
      "Loss_D = 0.83703023 (ave = 0.86959785)\n",
      "Loss_G = 1.32684433 (ave = 1.32389128)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.209745, max value: 0.784647\n",
      "D grad l2-norm: 7.529999, max value: 0.730187\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.68511653 (ave = 0.84317869)\n",
      "Loss_G = 1.28746700 (ave = 1.30782657)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.894292, max value: 0.747271\n",
      "D grad l2-norm: 7.299622, max value: 0.720593\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.78346729 (ave = 0.84037501)\n",
      "Loss_G = 1.36496460 (ave = 1.33504295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.678663, max value: 0.718874\n",
      "D grad l2-norm: 7.226376, max value: 0.740741\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.68301612 (ave = 0.81663042)\n",
      "Loss_G = 1.33409989 (ave = 1.34564390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.816160, max value: 0.722038\n",
      "D grad l2-norm: 7.206239, max value: 0.732492\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.77283287 (ave = 0.82511345)\n",
      "Loss_G = 1.34593010 (ave = 1.35640428)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.034276, max value: 0.698352\n",
      "D grad l2-norm: 7.188000, max value: 0.736298\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.76595640 (ave = 0.82350750)\n",
      "Loss_G = 1.30521369 (ave = 1.31336377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.467475, max value: 0.694198\n",
      "D grad l2-norm: 7.266490, max value: 0.724508\n",
      "üîÅ TSCV for Asset 7\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.37589622 (ave = 1.38777938)\n",
      "Loss_G = 0.68105286 (ave = 0.68175602)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961716, max value: 0.028885\n",
      "D grad l2-norm: 0.712973, max value: 0.493915\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.38324940 (ave = 1.37849908)\n",
      "Loss_G = 0.68008143 (ave = 0.68045049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.957913, max value: 0.020352\n",
      "D grad l2-norm: 0.713722, max value: 0.493422\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 1.35306001 (ave = 1.36450474)\n",
      "Loss_G = 0.67828965 (ave = 0.67907686)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963480, max value: 0.019455\n",
      "D grad l2-norm: 0.715736, max value: 0.492513\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 1.33490205 (ave = 1.35272806)\n",
      "Loss_G = 0.67776293 (ave = 0.67828598)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961876, max value: 0.022734\n",
      "D grad l2-norm: 0.715606, max value: 0.492246\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.34896636 (ave = 1.34479387)\n",
      "Loss_G = 0.67726672 (ave = 0.67747654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962989, max value: 0.028436\n",
      "D grad l2-norm: 0.718657, max value: 0.491994\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 1.33198190 (ave = 1.33350208)\n",
      "Loss_G = 0.67627555 (ave = 0.67678088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966587, max value: 0.021045\n",
      "D grad l2-norm: 0.720976, max value: 0.491490\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001170)\n",
      "Loss_D = 1.31597066 (ave = 1.32271273)\n",
      "Loss_G = 0.67610317 (ave = 0.67653095)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967445, max value: 0.028878\n",
      "D grad l2-norm: 0.723659, max value: 0.491402\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 1.30871439 (ave = 1.31307452)\n",
      "Loss_G = 0.67621905 (ave = 0.67620801)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967623, max value: 0.028683\n",
      "D grad l2-norm: 0.727605, max value: 0.491460\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001091)\n",
      "Loss_D = 1.31809902 (ave = 1.30541389)\n",
      "Loss_G = 0.67634630 (ave = 0.67632861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967139, max value: 0.027549\n",
      "D grad l2-norm: 0.728652, max value: 0.491525\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.30694008 (ave = 1.29555180)\n",
      "Loss_G = 0.67660666 (ave = 0.67685620)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969634, max value: 0.024501\n",
      "D grad l2-norm: 0.733675, max value: 0.491657\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 1.29164243 (ave = 1.28505497)\n",
      "Loss_G = 0.67732787 (ave = 0.67729832)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965181, max value: 0.034918\n",
      "D grad l2-norm: 0.738674, max value: 0.492023\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.28422773 (ave = 1.27584271)\n",
      "Loss_G = 0.67788738 (ave = 0.67796524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969258, max value: 0.025449\n",
      "D grad l2-norm: 0.745140, max value: 0.492306\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 1.27954018 (ave = 1.26686077)\n",
      "Loss_G = 0.67919695 (ave = 0.67895786)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967262, max value: 0.041334\n",
      "D grad l2-norm: 0.750874, max value: 0.492971\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.23580134 (ave = 1.25312111)\n",
      "Loss_G = 0.68059260 (ave = 0.67989719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966285, max value: 0.028296\n",
      "D grad l2-norm: 0.755349, max value: 0.493677\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.25260830 (ave = 1.24742153)\n",
      "Loss_G = 0.68132347 (ave = 0.68047377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966920, max value: 0.031053\n",
      "D grad l2-norm: 0.761857, max value: 0.494046\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 1.23418713 (ave = 1.23704998)\n",
      "Loss_G = 0.68143630 (ave = 0.68181405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973394, max value: 0.028354\n",
      "D grad l2-norm: 0.766740, max value: 0.494102\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 1.22992146 (ave = 1.22858875)\n",
      "Loss_G = 0.68248785 (ave = 0.68274721)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970101, max value: 0.037758\n",
      "D grad l2-norm: 0.770601, max value: 0.494632\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001270)\n",
      "Loss_D = 1.20398211 (ave = 1.21766791)\n",
      "Loss_G = 0.68491596 (ave = 0.68394766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971669, max value: 0.026109\n",
      "D grad l2-norm: 0.776263, max value: 0.495859\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.014s / 800 iters, (0.002801)\n",
      "Loss_D = 1.21388388 (ave = 1.21107829)\n",
      "Loss_G = 0.68637443 (ave = 0.68522183)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968851, max value: 0.036983\n",
      "D grad l2-norm: 0.783692, max value: 0.496591\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001767)\n",
      "Loss_D = 1.19938993 (ave = 1.20150259)\n",
      "Loss_G = 0.68742752 (ave = 0.68685052)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976561, max value: 0.036880\n",
      "D grad l2-norm: 0.792189, max value: 0.497120\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000988)\n",
      "Loss_D = 1.17735934 (ave = 1.19152486)\n",
      "Loss_G = 0.68906271 (ave = 0.68791953)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970315, max value: 0.031666\n",
      "D grad l2-norm: 0.797614, max value: 0.497940\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001264)\n",
      "Loss_D = 1.17651498 (ave = 1.18347642)\n",
      "Loss_G = 0.69069564 (ave = 0.68968964)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974691, max value: 0.033782\n",
      "D grad l2-norm: 0.804983, max value: 0.498757\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.17713022 (ave = 1.17636111)\n",
      "Loss_G = 0.69229621 (ave = 0.69137602)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980607, max value: 0.036836\n",
      "D grad l2-norm: 0.813516, max value: 0.499552\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 1.17411852 (ave = 1.16930881)\n",
      "Loss_G = 0.69443297 (ave = 0.69359995)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986530, max value: 0.034672\n",
      "D grad l2-norm: 0.822519, max value: 0.500620\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 1.17879701 (ave = 1.16335053)\n",
      "Loss_G = 0.69656068 (ave = 0.69529446)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.982979, max value: 0.032265\n",
      "D grad l2-norm: 0.834562, max value: 0.501681\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 1.13393247 (ave = 1.15086761)\n",
      "Loss_G = 0.69917715 (ave = 0.69791170)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.988160, max value: 0.048567\n",
      "D grad l2-norm: 0.848464, max value: 0.502984\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 1.14112473 (ave = 1.14431341)\n",
      "Loss_G = 0.70202625 (ave = 0.70018021)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.989165, max value: 0.043639\n",
      "D grad l2-norm: 0.858315, max value: 0.504395\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000987)\n",
      "Loss_D = 1.10994494 (ave = 1.13388431)\n",
      "Loss_G = 0.70416796 (ave = 0.70413749)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993485, max value: 0.050646\n",
      "D grad l2-norm: 0.872487, max value: 0.505443\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000992)\n",
      "Loss_D = 1.11187017 (ave = 1.12641685)\n",
      "Loss_G = 0.71010596 (ave = 0.70752531)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993185, max value: 0.052502\n",
      "D grad l2-norm: 0.887325, max value: 0.508377\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.008s / 800 iters, (0.001638)\n",
      "Loss_D = 1.09892976 (ave = 1.11611080)\n",
      "Loss_G = 0.71147257 (ave = 0.71106527)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.008770, max value: 0.059748\n",
      "D grad l2-norm: 0.899092, max value: 0.509041\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002802)\n",
      "Loss_D = 1.08870804 (ave = 1.10701625)\n",
      "Loss_G = 0.71478570 (ave = 0.71502718)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.007930, max value: 0.067100\n",
      "D grad l2-norm: 0.916849, max value: 0.510650\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 1.11688256 (ave = 1.10342846)\n",
      "Loss_G = 0.72197896 (ave = 0.72114860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.010297, max value: 0.074828\n",
      "D grad l2-norm: 0.937827, max value: 0.514175\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.008s / 800 iters, (0.001653)\n",
      "Loss_D = 1.07334626 (ave = 1.08995378)\n",
      "Loss_G = 0.72896814 (ave = 0.72635821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.007581, max value: 0.073027\n",
      "D grad l2-norm: 0.954026, max value: 0.517555\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 1.07647538 (ave = 1.08080983)\n",
      "Loss_G = 0.73275554 (ave = 0.73241745)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.014780, max value: 0.078034\n",
      "D grad l2-norm: 0.969765, max value: 0.519372\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 1.04979968 (ave = 1.06863723)\n",
      "Loss_G = 0.73899746 (ave = 0.73592901)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.021806, max value: 0.092026\n",
      "D grad l2-norm: 0.986215, max value: 0.522344\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.04073727 (ave = 1.05805173)\n",
      "Loss_G = 0.74641716 (ave = 0.74345611)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.024966, max value: 0.077420\n",
      "D grad l2-norm: 1.009544, max value: 0.525886\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 1.06328857 (ave = 1.05187774)\n",
      "Loss_G = 0.75356096 (ave = 0.75180284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.036502, max value: 0.087611\n",
      "D grad l2-norm: 1.026470, max value: 0.529250\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 1.07233179 (ave = 1.04385860)\n",
      "Loss_G = 0.76119208 (ave = 0.75923238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.045796, max value: 0.089011\n",
      "D grad l2-norm: 1.053060, max value: 0.532827\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.00611949 (ave = 1.02574284)\n",
      "Loss_G = 0.76784313 (ave = 0.76408465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.046199, max value: 0.086841\n",
      "D grad l2-norm: 1.083077, max value: 0.535928\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.00867927 (ave = 1.01690547)\n",
      "Loss_G = 0.78187627 (ave = 0.77589842)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.052526, max value: 0.089089\n",
      "D grad l2-norm: 1.099155, max value: 0.542396\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 1.00528407 (ave = 1.00448041)\n",
      "Loss_G = 0.78629738 (ave = 0.78405205)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.059220, max value: 0.093525\n",
      "D grad l2-norm: 1.138502, max value: 0.544394\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001003)\n",
      "Loss_D = 1.00887692 (ave = 0.99409032)\n",
      "Loss_G = 0.79854238 (ave = 0.79300616)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.071777, max value: 0.079754\n",
      "D grad l2-norm: 1.156409, max value: 0.549960\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001009)\n",
      "Loss_D = 1.01340508 (ave = 0.98327867)\n",
      "Loss_G = 0.80923450 (ave = 0.80492617)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.072329, max value: 0.083397\n",
      "D grad l2-norm: 1.178427, max value: 0.554738\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.022s / 800 iters, (0.004449)\n",
      "Loss_D = 0.95619643 (ave = 0.96373330)\n",
      "Loss_G = 0.82167321 (ave = 0.81457514)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.072909, max value: 0.084115\n",
      "D grad l2-norm: 1.205899, max value: 0.560241\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.010s / 800 iters, (0.002060)\n",
      "Loss_D = 0.92133510 (ave = 0.94775202)\n",
      "Loss_G = 0.82817888 (ave = 0.82484895)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.096004, max value: 0.101743\n",
      "D grad l2-norm: 1.256783, max value: 0.563095\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.93173432 (ave = 0.93588735)\n",
      "Loss_G = 0.84020299 (ave = 0.83727572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.105363, max value: 0.099722\n",
      "D grad l2-norm: 1.280193, max value: 0.568313\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 0.94743562 (ave = 0.92576243)\n",
      "Loss_G = 0.85406113 (ave = 0.84786191)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.109596, max value: 0.101418\n",
      "D grad l2-norm: 1.313652, max value: 0.574249\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.88997197 (ave = 0.90638171)\n",
      "Loss_G = 0.86166191 (ave = 0.85930725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.128462, max value: 0.112218\n",
      "D grad l2-norm: 1.339067, max value: 0.577464\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.91526294 (ave = 0.89772269)\n",
      "Loss_G = 0.87956321 (ave = 0.87276412)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.155077, max value: 0.127372\n",
      "D grad l2-norm: 1.369286, max value: 0.584953\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 0.85510671 (ave = 0.87755412)\n",
      "Loss_G = 0.88858622 (ave = 0.88579148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.183274, max value: 0.134426\n",
      "D grad l2-norm: 1.412457, max value: 0.588664\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.82704222 (ave = 0.86271379)\n",
      "Loss_G = 0.90437585 (ave = 0.89631879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.211097, max value: 0.138339\n",
      "D grad l2-norm: 1.431585, max value: 0.595093\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.86067021 (ave = 0.85966859)\n",
      "Loss_G = 0.90652871 (ave = 0.90365076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.256535, max value: 0.144268\n",
      "D grad l2-norm: 1.447656, max value: 0.595927\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000984)\n",
      "Loss_D = 0.83733690 (ave = 0.85000778)\n",
      "Loss_G = 0.90535820 (ave = 0.90437280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.297046, max value: 0.155436\n",
      "D grad l2-norm: 1.454204, max value: 0.595359\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.000995)\n",
      "Loss_D = 0.87353110 (ave = 0.85210382)\n",
      "Loss_G = 0.89892197 (ave = 0.90559888)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.346796, max value: 0.154146\n",
      "D grad l2-norm: 1.467364, max value: 0.592734\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.82431173 (ave = 0.84469086)\n",
      "Loss_G = 0.89589065 (ave = 0.90181324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.379524, max value: 0.162920\n",
      "D grad l2-norm: 1.455859, max value: 0.591511\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001748)\n",
      "Loss_D = 0.88934493 (ave = 0.85306377)\n",
      "Loss_G = 0.88790607 (ave = 0.89504088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.455345, max value: 0.170621\n",
      "D grad l2-norm: 1.464331, max value: 0.588176\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 0.85016668 (ave = 0.85565706)\n",
      "Loss_G = 0.86789167 (ave = 0.87930371)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.514792, max value: 0.169062\n",
      "D grad l2-norm: 1.454168, max value: 0.579733\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.87891942 (ave = 0.87015812)\n",
      "Loss_G = 0.84669095 (ave = 0.86167734)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.569294, max value: 0.171632\n",
      "D grad l2-norm: 1.441659, max value: 0.570499\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001091)\n",
      "Loss_D = 0.86431384 (ave = 0.88275828)\n",
      "Loss_G = 0.82786995 (ave = 0.83841677)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.627016, max value: 0.171851\n",
      "D grad l2-norm: 1.452936, max value: 0.562432\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.91857791 (ave = 0.90448171)\n",
      "Loss_G = 0.80484957 (ave = 0.81494813)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.640251, max value: 0.182169\n",
      "D grad l2-norm: 1.442771, max value: 0.552200\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.96501261 (ave = 0.93040237)\n",
      "Loss_G = 0.77683723 (ave = 0.78867117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.673281, max value: 0.198989\n",
      "D grad l2-norm: 1.471222, max value: 0.539224\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001032)\n",
      "Loss_D = 0.93858469 (ave = 0.93842399)\n",
      "Loss_G = 0.76015317 (ave = 0.77173057)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.717265, max value: 0.214030\n",
      "D grad l2-norm: 1.531918, max value: 0.531443\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 0.91774809 (ave = 0.94697922)\n",
      "Loss_G = 0.75524312 (ave = 0.76191771)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.728134, max value: 0.235559\n",
      "D grad l2-norm: 1.570194, max value: 0.529140\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 1.00676394 (ave = 0.96844982)\n",
      "Loss_G = 0.76542288 (ave = 0.76092691)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.713812, max value: 0.244806\n",
      "D grad l2-norm: 1.642304, max value: 0.533891\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.007s / 800 iters, (0.001358)\n",
      "Loss_D = 0.94810379 (ave = 0.95152818)\n",
      "Loss_G = 0.78347325 (ave = 0.77042767)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.720363, max value: 0.253836\n",
      "D grad l2-norm: 1.729605, max value: 0.542303\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002724)\n",
      "Loss_D = 0.98418844 (ave = 0.94655274)\n",
      "Loss_G = 0.81042290 (ave = 0.79547018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.746825, max value: 0.259520\n",
      "D grad l2-norm: 1.845890, max value: 0.554375\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 0.90276015 (ave = 0.91420155)\n",
      "Loss_G = 0.84866923 (ave = 0.82921375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.770453, max value: 0.273874\n",
      "D grad l2-norm: 1.957321, max value: 0.571263\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001034)\n",
      "Loss_D = 0.83717525 (ave = 0.88506324)\n",
      "Loss_G = 0.88122779 (ave = 0.86066620)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.846732, max value: 0.286924\n",
      "D grad l2-norm: 2.106853, max value: 0.585043\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.84922040 (ave = 0.86193777)\n",
      "Loss_G = 0.92033994 (ave = 0.90472509)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.896847, max value: 0.300047\n",
      "D grad l2-norm: 2.283664, max value: 0.600762\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.79641747 (ave = 0.82777872)\n",
      "Loss_G = 0.97168368 (ave = 0.95702085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.946549, max value: 0.304831\n",
      "D grad l2-norm: 2.404821, max value: 0.620808\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.83196282 (ave = 0.80739213)\n",
      "Loss_G = 1.01500261 (ave = 1.00221155)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.107956, max value: 0.321548\n",
      "D grad l2-norm: 2.563297, max value: 0.637075\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.82360888 (ave = 0.78666161)\n",
      "Loss_G = 1.05630505 (ave = 1.03642948)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.223506, max value: 0.327061\n",
      "D grad l2-norm: 2.664752, max value: 0.651501\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.86088645 (ave = 0.77720280)\n",
      "Loss_G = 1.06605053 (ave = 1.06328382)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.484640, max value: 0.341522\n",
      "D grad l2-norm: 2.848556, max value: 0.654812\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.012s / 800 iters, (0.002379)\n",
      "Loss_D = 0.81980181 (ave = 0.77088356)\n",
      "Loss_G = 1.07271159 (ave = 1.07206876)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.704406, max value: 0.357996\n",
      "D grad l2-norm: 3.016548, max value: 0.657141\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 0.78505927 (ave = 0.76604421)\n",
      "Loss_G = 1.07792187 (ave = 1.07875757)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.758045, max value: 0.344336\n",
      "D grad l2-norm: 3.033653, max value: 0.658681\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.74501735 (ave = 0.76191556)\n",
      "Loss_G = 1.08115995 (ave = 1.08372300)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.852461, max value: 0.333058\n",
      "D grad l2-norm: 3.099382, max value: 0.659885\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.81086886 (ave = 0.77592317)\n",
      "Loss_G = 1.07629073 (ave = 1.07704437)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.023248, max value: 0.330408\n",
      "D grad l2-norm: 3.185144, max value: 0.658016\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.75965452 (ave = 0.78652904)\n",
      "Loss_G = 1.03481448 (ave = 1.05176642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.296896, max value: 0.346245\n",
      "D grad l2-norm: 3.238228, max value: 0.643587\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.80803829 (ave = 0.82705044)\n",
      "Loss_G = 0.99959934 (ave = 1.02057972)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.358642, max value: 0.352170\n",
      "D grad l2-norm: 3.159772, max value: 0.629893\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.91734517 (ave = 0.86913656)\n",
      "Loss_G = 0.96726143 (ave = 0.98038706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.402989, max value: 0.372179\n",
      "D grad l2-norm: 3.169444, max value: 0.617518\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.89849401 (ave = 0.90299990)\n",
      "Loss_G = 0.93673974 (ave = 0.95072744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.502334, max value: 0.357797\n",
      "D grad l2-norm: 3.265966, max value: 0.606084\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 0.96918404 (ave = 0.93402734)\n",
      "Loss_G = 0.92841315 (ave = 0.93468519)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.412468, max value: 0.338959\n",
      "D grad l2-norm: 3.245418, max value: 0.602716\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.97367817 (ave = 0.94788858)\n",
      "Loss_G = 0.94994348 (ave = 0.94261638)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.430074, max value: 0.358138\n",
      "D grad l2-norm: 3.350518, max value: 0.610022\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.91113353 (ave = 0.93771936)\n",
      "Loss_G = 0.94553041 (ave = 0.94875959)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.543213, max value: 0.363054\n",
      "D grad l2-norm: 3.487118, max value: 0.607968\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 0.89350832 (ave = 0.94274114)\n",
      "Loss_G = 0.94443882 (ave = 0.95775431)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.871973, max value: 0.364806\n",
      "D grad l2-norm: 3.637702, max value: 0.607334\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.83739722 (ave = 0.95155730)\n",
      "Loss_G = 0.96669149 (ave = 0.96193110)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.085756, max value: 0.367076\n",
      "D grad l2-norm: 3.786856, max value: 0.616347\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001018)\n",
      "Loss_D = 0.92754400 (ave = 0.98380058)\n",
      "Loss_G = 0.93785322 (ave = 0.94728146)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.009024, max value: 0.351350\n",
      "D grad l2-norm: 3.748959, max value: 0.604361\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001271)\n",
      "Loss_D = 0.87604010 (ave = 0.97041570)\n",
      "Loss_G = 0.97104573 (ave = 0.96594524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.229469, max value: 0.345397\n",
      "D grad l2-norm: 4.023126, max value: 0.617631\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001146)\n",
      "Loss_D = 0.96150625 (ave = 0.98820742)\n",
      "Loss_G = 0.98794281 (ave = 0.98236804)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.288522, max value: 0.323681\n",
      "D grad l2-norm: 4.200153, max value: 0.623757\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 0.89514160 (ave = 0.97682660)\n",
      "Loss_G = 1.02804184 (ave = 1.00318195)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.297469, max value: 0.382559\n",
      "D grad l2-norm: 4.335543, max value: 0.637629\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.01535344 (ave = 0.96348740)\n",
      "Loss_G = 1.04825413 (ave = 1.04178185)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.487002, max value: 0.454800\n",
      "D grad l2-norm: 4.663424, max value: 0.645797\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.93552601 (ave = 0.94226997)\n",
      "Loss_G = 1.10246897 (ave = 1.07832603)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.370196, max value: 0.487229\n",
      "D grad l2-norm: 4.898682, max value: 0.664496\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.80394602 (ave = 0.88945793)\n",
      "Loss_G = 1.19268191 (ave = 1.16558647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.257332, max value: 0.523099\n",
      "D grad l2-norm: 5.188611, max value: 0.693962\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 0.85796487 (ave = 0.85029954)\n",
      "Loss_G = 1.30116820 (ave = 1.25983467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.427512, max value: 0.558643\n",
      "D grad l2-norm: 5.580000, max value: 0.725358\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002723)\n",
      "Loss_D = 0.82090187 (ave = 0.80563724)\n",
      "Loss_G = 1.34926867 (ave = 1.32247369)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.831619, max value: 0.622407\n",
      "D grad l2-norm: 5.969299, max value: 0.738623\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002813)\n",
      "Loss_D = 0.72029614 (ave = 0.77010316)\n",
      "Loss_G = 1.39801645 (ave = 1.38725080)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.281634, max value: 0.675510\n",
      "D grad l2-norm: 6.273395, max value: 0.751042\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002872)\n",
      "Loss_D = 0.67179823 (ave = 0.74933946)\n",
      "Loss_G = 1.40559947 (ave = 1.40019948)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.469973, max value: 0.716744\n",
      "D grad l2-norm: 6.381282, max value: 0.750939\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.77910125 (ave = 0.75888269)\n",
      "Loss_G = 1.44899201 (ave = 1.42939286)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.715244, max value: 0.743323\n",
      "D grad l2-norm: 6.546226, max value: 0.762403\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001219)\n",
      "Loss_D = 0.68756735 (ave = 0.73599733)\n",
      "Loss_G = 1.43687689 (ave = 1.44791763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.952695, max value: 0.760621\n",
      "D grad l2-norm: 6.581029, max value: 0.759371\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.61717570 (ave = 0.73688042)\n",
      "Loss_G = 1.36806703 (ave = 1.39593010)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.217039, max value: 0.763902\n",
      "D grad l2-norm: 6.514940, max value: 0.742054\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.86844164 (ave = 0.78247821)\n",
      "Loss_G = 1.35263765 (ave = 1.37501931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.317379, max value: 0.723984\n",
      "D grad l2-norm: 6.443577, max value: 0.737539\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001012)\n",
      "Loss_D = 0.82561767 (ave = 0.80390117)\n",
      "Loss_G = 1.27395868 (ave = 1.30338781)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.246170, max value: 0.661190\n",
      "D grad l2-norm: 6.249295, max value: 0.715550\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001197)\n",
      "Loss_D = 0.76401532 (ave = 0.82253604)\n",
      "Loss_G = 1.21521091 (ave = 1.24794486)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.134049, max value: 0.610608\n",
      "D grad l2-norm: 6.025902, max value: 0.698066\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001155)\n",
      "Loss_D = 0.89216161 (ave = 0.86306630)\n",
      "Loss_G = 1.22849202 (ave = 1.21926386)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.096768, max value: 0.555037\n",
      "D grad l2-norm: 5.797645, max value: 0.701966\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.82230294 (ave = 0.88308245)\n",
      "Loss_G = 1.13516915 (ave = 1.15526147)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.189463, max value: 0.507380\n",
      "D grad l2-norm: 5.579081, max value: 0.673968\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.92998075 (ave = 0.94381988)\n",
      "Loss_G = 1.08563685 (ave = 1.10531871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.107748, max value: 0.444159\n",
      "D grad l2-norm: 5.472317, max value: 0.657611\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.11504507 (ave = 0.99949671)\n",
      "Loss_G = 1.04854667 (ave = 1.06560318)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.996875, max value: 0.409111\n",
      "D grad l2-norm: 5.416896, max value: 0.643206\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.88342047 (ave = 0.98684883)\n",
      "Loss_G = 1.05441630 (ave = 1.05390351)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.976643, max value: 0.416152\n",
      "D grad l2-norm: 5.537631, max value: 0.646624\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.91205847 (ave = 0.99509465)\n",
      "Loss_G = 1.13123405 (ave = 1.10142639)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.942976, max value: 0.451371\n",
      "D grad l2-norm: 5.718335, max value: 0.673037\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001020)\n",
      "Loss_D = 0.90431762 (ave = 0.97045610)\n",
      "Loss_G = 1.13373506 (ave = 1.12183046)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.813946, max value: 0.471661\n",
      "D grad l2-norm: 5.772969, max value: 0.673662\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 1.11033726 (ave = 0.99080610)\n",
      "Loss_G = 1.17002726 (ave = 1.17140808)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.262753, max value: 0.520019\n",
      "D grad l2-norm: 6.043627, max value: 0.684537\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 1.05977798 (ave = 0.98017021)\n",
      "Loss_G = 1.17778301 (ave = 1.17010889)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.459192, max value: 0.516753\n",
      "D grad l2-norm: 6.142394, max value: 0.686747\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 0.90342844 (ave = 0.97838746)\n",
      "Loss_G = 1.18980694 (ave = 1.17608461)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.816311, max value: 0.576067\n",
      "D grad l2-norm: 6.318225, max value: 0.691013\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.87887728 (ave = 0.97944566)\n",
      "Loss_G = 1.16925013 (ave = 1.18401668)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.216751, max value: 0.610054\n",
      "D grad l2-norm: 6.575229, max value: 0.685063\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 1.02797031 (ave = 1.01265483)\n",
      "Loss_G = 1.16925883 (ave = 1.18645134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.316999, max value: 0.586759\n",
      "D grad l2-norm: 6.661497, max value: 0.685127\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.015s / 800 iters, (0.002918)\n",
      "Loss_D = 1.08460927 (ave = 1.02851088)\n",
      "Loss_G = 1.14623129 (ave = 1.16621344)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.260497, max value: 0.540263\n",
      "D grad l2-norm: 6.555201, max value: 0.677315\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 1.24208140 (ave = 1.05199817)\n",
      "Loss_G = 1.17392302 (ave = 1.16227486)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.312514, max value: 0.502538\n",
      "D grad l2-norm: 6.625254, max value: 0.686204\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.06244636 (ave = 1.04034144)\n",
      "Loss_G = 1.19316626 (ave = 1.19105442)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.316354, max value: 0.500361\n",
      "D grad l2-norm: 6.713360, max value: 0.692107\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001207)\n",
      "Loss_D = 0.83962005 (ave = 1.00388095)\n",
      "Loss_G = 1.20848644 (ave = 1.19022894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.233879, max value: 0.479842\n",
      "D grad l2-norm: 6.729159, max value: 0.695942\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 1.00040126 (ave = 1.01476725)\n",
      "Loss_G = 1.24251199 (ave = 1.21229050)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.453579, max value: 0.523073\n",
      "D grad l2-norm: 7.098581, max value: 0.706440\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.91610467 (ave = 0.99887949)\n",
      "Loss_G = 1.28150356 (ave = 1.23999867)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.954651, max value: 0.568586\n",
      "D grad l2-norm: 7.536292, max value: 0.718175\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 1.13035679 (ave = 1.03191538)\n",
      "Loss_G = 1.25358212 (ave = 1.26257944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.008679, max value: 0.596935\n",
      "D grad l2-norm: 7.482798, max value: 0.708996\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 1.17646551 (ave = 1.03955208)\n",
      "Loss_G = 1.27349567 (ave = 1.26974909)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.394972, max value: 0.620750\n",
      "D grad l2-norm: 7.966157, max value: 0.714527\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.013s / 800 iters, (0.002590)\n",
      "Loss_D = 1.02395272 (ave = 1.01922239)\n",
      "Loss_G = 1.28649497 (ave = 1.27717366)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.617484, max value: 0.639899\n",
      "D grad l2-norm: 8.374519, max value: 0.719448\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.97804528 (ave = 1.01113895)\n",
      "Loss_G = 1.29529738 (ave = 1.29128411)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.585740, max value: 0.602523\n",
      "D grad l2-norm: 8.367710, max value: 0.736696\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.11372459 (ave = 1.02793902)\n",
      "Loss_G = 1.29603434 (ave = 1.30484757)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.723520, max value: 0.566490\n",
      "D grad l2-norm: 8.692129, max value: 0.777654\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.92675787 (ave = 0.99610603)\n",
      "Loss_G = 1.39574432 (ave = 1.36795936)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.529145, max value: 0.578520\n",
      "D grad l2-norm: 9.027989, max value: 0.830825\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 0.91521782 (ave = 0.96157551)\n",
      "Loss_G = 1.48784387 (ave = 1.45425785)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.618316, max value: 0.621561\n",
      "D grad l2-norm: 9.546039, max value: 0.886556\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.88741231 (ave = 0.93765398)\n",
      "Loss_G = 1.51313722 (ave = 1.49477139)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.255903, max value: 0.604108\n",
      "D grad l2-norm: 9.514131, max value: 0.875581\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.98474693 (ave = 0.92503766)\n",
      "Loss_G = 1.54368925 (ave = 1.56236951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.233765, max value: 0.608573\n",
      "D grad l2-norm: 9.778449, max value: 0.885144\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.86235297 (ave = 0.89212066)\n",
      "Loss_G = 1.62568402 (ave = 1.63343685)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.210378, max value: 0.595831\n",
      "D grad l2-norm: 10.057439, max value: 0.922649\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 1.08638024 (ave = 0.89664038)\n",
      "Loss_G = 1.67123902 (ave = 1.67407424)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.127425, max value: 0.583044\n",
      "D grad l2-norm: 10.170755, max value: 0.942787\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.90251404 (ave = 0.86035404)\n",
      "Loss_G = 1.67966533 (ave = 1.64821007)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.061855, max value: 0.562348\n",
      "D grad l2-norm: 10.130026, max value: 0.967900\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.86107403 (ave = 0.84292244)\n",
      "Loss_G = 1.68588638 (ave = 1.69200752)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.095026, max value: 0.545354\n",
      "D grad l2-norm: 10.097927, max value: 0.984117\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001192)\n",
      "Loss_D = 0.76541507 (ave = 0.82509918)\n",
      "Loss_G = 1.66041017 (ave = 1.67723918)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.125491, max value: 0.536886\n",
      "D grad l2-norm: 10.013134, max value: 0.971743\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.011s / 800 iters, (0.002199)\n",
      "Loss_D = 0.86284542 (ave = 0.83617202)\n",
      "Loss_G = 1.66347051 (ave = 1.67638645)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.862658, max value: 0.497354\n",
      "D grad l2-norm: 9.823611, max value: 0.955736\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001171)\n",
      "Loss_D = 0.78267229 (ave = 0.82776079)\n",
      "Loss_G = 1.68734264 (ave = 1.66257880)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.045122, max value: 0.487712\n",
      "D grad l2-norm: 9.747117, max value: 0.951920\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001187)\n",
      "Loss_D = 0.89674294 (ave = 0.84699438)\n",
      "Loss_G = 1.59716916 (ave = 1.62464559)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.162262, max value: 0.539249\n",
      "D grad l2-norm: 9.412825, max value: 0.870781\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 800 iters, (0.027)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.93562424 (ave = 0.86918744)\n",
      "Loss_G = 1.52280426 (ave = 1.56873271)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.446880, max value: 0.574792\n",
      "D grad l2-norm: 9.190594, max value: 0.809488\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.009s / 800 iters, (0.001847)\n",
      "Loss_D = 1.00220215 (ave = 0.89744781)\n",
      "Loss_G = 1.49333346 (ave = 1.52284262)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.389446, max value: 0.544928\n",
      "D grad l2-norm: 9.003521, max value: 0.771655\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.77903628 (ave = 0.88950968)\n",
      "Loss_G = 1.43336511 (ave = 1.46647348)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.313620, max value: 0.574459\n",
      "D grad l2-norm: 8.777143, max value: 0.756366\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.88896036 (ave = 0.92364769)\n",
      "Loss_G = 1.42699063 (ave = 1.42901046)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.950181, max value: 0.590120\n",
      "D grad l2-norm: 8.483199, max value: 0.754687\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.78008676 (ave = 0.91468288)\n",
      "Loss_G = 1.38023782 (ave = 1.40811296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.096522, max value: 0.650207\n",
      "D grad l2-norm: 8.594852, max value: 0.742990\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.00977087 (ave = 0.95611477)\n",
      "Loss_G = 1.45639646 (ave = 1.42369726)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.113110, max value: 0.672596\n",
      "D grad l2-norm: 8.648234, max value: 0.762465\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.89338350 (ave = 0.93129963)\n",
      "Loss_G = 1.42268229 (ave = 1.42137580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.923954, max value: 0.681168\n",
      "D grad l2-norm: 8.574070, max value: 0.753774\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 0.97584379 (ave = 0.94208988)\n",
      "Loss_G = 1.45337462 (ave = 1.43206897)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.845899, max value: 0.682558\n",
      "D grad l2-norm: 8.582067, max value: 0.761924\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001006)\n",
      "Loss_D = 1.04476953 (ave = 0.93668236)\n",
      "Loss_G = 1.47340560 (ave = 1.44346893)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.160030, max value: 0.618263\n",
      "D grad l2-norm: 8.392196, max value: 0.768233\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.015s / 800 iters, (0.002913)\n",
      "Loss_D = 0.78501236 (ave = 0.86890666)\n",
      "Loss_G = 1.52474093 (ave = 1.51561003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.391466, max value: 0.609773\n",
      "D grad l2-norm: 8.861192, max value: 0.779817\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 1.02842093 (ave = 0.87269058)\n",
      "Loss_G = 1.53834772 (ave = 1.55122051)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.457490, max value: 0.554885\n",
      "D grad l2-norm: 8.702181, max value: 0.781935\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 0.85265434 (ave = 0.83764962)\n",
      "Loss_G = 1.56269503 (ave = 1.54161046)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.844627, max value: 0.620062\n",
      "D grad l2-norm: 8.980193, max value: 0.787358\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.68503958 (ave = 0.80789316)\n",
      "Loss_G = 1.53367758 (ave = 1.54757133)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.777048, max value: 0.618353\n",
      "D grad l2-norm: 8.746340, max value: 0.781220\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.81652808 (ave = 0.80846682)\n",
      "Loss_G = 1.54295945 (ave = 1.54632514)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.948572, max value: 0.610062\n",
      "D grad l2-norm: 8.814114, max value: 0.782750\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.76200819 (ave = 0.79525915)\n",
      "Loss_G = 1.51621020 (ave = 1.54539938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.832956, max value: 0.568412\n",
      "D grad l2-norm: 8.712878, max value: 0.776961\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.72908080 (ave = 0.77968633)\n",
      "Loss_G = 1.55471468 (ave = 1.55494483)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.540785, max value: 0.536907\n",
      "D grad l2-norm: 8.544883, max value: 0.785208\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.72342741 (ave = 0.76116503)\n",
      "Loss_G = 1.56643271 (ave = 1.55268986)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.870900, max value: 0.587035\n",
      "D grad l2-norm: 8.785895, max value: 0.786658\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.015s / 800 iters, (0.002929)\n",
      "Loss_D = 0.75358927 (ave = 0.75549223)\n",
      "Loss_G = 1.56048167 (ave = 1.54464750)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.532496, max value: 0.592908\n",
      "D grad l2-norm: 8.307443, max value: 0.786207\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 0.62920177 (ave = 0.73216627)\n",
      "Loss_G = 1.54030848 (ave = 1.54025290)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.841992, max value: 0.654207\n",
      "D grad l2-norm: 8.395503, max value: 0.782336\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.011s / 800 iters, (0.002162)\n",
      "Loss_D = 0.82195079 (ave = 0.74952555)\n",
      "Loss_G = 1.50107801 (ave = 1.53441267)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.141221, max value: 0.705902\n",
      "D grad l2-norm: 8.440789, max value: 0.771653\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001193)\n",
      "Loss_D = 0.67058897 (ave = 0.73149587)\n",
      "Loss_G = 1.52076733 (ave = 1.52468741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.176341, max value: 0.727544\n",
      "D grad l2-norm: 8.536587, max value: 0.778495\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 0.68113357 (ave = 0.71938865)\n",
      "Loss_G = 1.51057732 (ave = 1.53110023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.907889, max value: 0.725848\n",
      "D grad l2-norm: 8.525302, max value: 0.783014\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.013s / 800 iters, (0.002544)\n",
      "Loss_D = 0.77491617 (ave = 0.71550624)\n",
      "Loss_G = 1.60801089 (ave = 1.57594357)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.546928, max value: 0.699911\n",
      "D grad l2-norm: 8.544400, max value: 0.816698\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.65430254 (ave = 0.66733594)\n",
      "Loss_G = 1.65110278 (ave = 1.62480648)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.037500, max value: 0.673126\n",
      "D grad l2-norm: 8.672699, max value: 0.851112\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.62039435 (ave = 0.64244508)\n",
      "Loss_G = 1.66560793 (ave = 1.67427135)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.137436, max value: 0.683300\n",
      "D grad l2-norm: 8.763405, max value: 0.869802\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.74287885 (ave = 0.63678437)\n",
      "Loss_G = 1.69781685 (ave = 1.70560527)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.429960, max value: 0.681412\n",
      "D grad l2-norm: 8.820110, max value: 0.882907\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.61782342 (ave = 0.61391143)\n",
      "Loss_G = 1.70513928 (ave = 1.69764884)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.920853, max value: 0.686861\n",
      "D grad l2-norm: 8.976210, max value: 0.886444\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001194)\n",
      "Loss_D = 0.73428881 (ave = 0.63464901)\n",
      "Loss_G = 1.66212964 (ave = 1.67074094)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.808821, max value: 0.721423\n",
      "D grad l2-norm: 8.623296, max value: 0.847390\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 0.70620215 (ave = 0.62570519)\n",
      "Loss_G = 1.60301101 (ave = 1.64572210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.362246, max value: 0.786206\n",
      "D grad l2-norm: 8.985842, max value: 0.846309\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.012s / 800 iters, (0.002354)\n",
      "Loss_D = 0.57846326 (ave = 0.61974914)\n",
      "Loss_G = 1.67363286 (ave = 1.64241037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.359891, max value: 0.824518\n",
      "D grad l2-norm: 8.849783, max value: 0.848095\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001171)\n",
      "Loss_D = 0.58809173 (ave = 0.63384202)\n",
      "Loss_G = 1.54997373 (ave = 1.57307909)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.517532, max value: 0.873254\n",
      "D grad l2-norm: 8.593172, max value: 0.786777\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.66737473 (ave = 0.66218061)\n",
      "Loss_G = 1.56612372 (ave = 1.55254023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.661780, max value: 0.905451\n",
      "D grad l2-norm: 8.631817, max value: 0.785163\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001162)\n",
      "Loss_D = 0.65096986 (ave = 0.67516786)\n",
      "Loss_G = 1.54433620 (ave = 1.52698164)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.328096, max value: 0.900576\n",
      "D grad l2-norm: 8.510125, max value: 0.781499\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.79365325 (ave = 0.68740879)\n",
      "Loss_G = 1.55374968 (ave = 1.51791794)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.799036, max value: 0.864814\n",
      "D grad l2-norm: 8.415174, max value: 0.782701\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.68575799 (ave = 0.66559250)\n",
      "Loss_G = 1.56567490 (ave = 1.55164330)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.924519, max value: 0.884623\n",
      "D grad l2-norm: 8.405445, max value: 0.785806\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001165)\n",
      "Loss_D = 0.60399556 (ave = 0.65995704)\n",
      "Loss_G = 1.54382789 (ave = 1.54930859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.258903, max value: 0.892242\n",
      "D grad l2-norm: 8.460235, max value: 0.796873\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001034)\n",
      "Loss_D = 0.67535692 (ave = 0.68894171)\n",
      "Loss_G = 1.43929839 (ave = 1.47790003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.514697, max value: 0.895996\n",
      "D grad l2-norm: 8.147307, max value: 0.755192\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.64877075 (ave = 0.72793747)\n",
      "Loss_G = 1.35293698 (ave = 1.41233008)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.478258, max value: 0.852191\n",
      "D grad l2-norm: 7.745933, max value: 0.734733\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 0.82695621 (ave = 0.78795877)\n",
      "Loss_G = 1.30971289 (ave = 1.33875742)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.550292, max value: 0.778305\n",
      "D grad l2-norm: 7.651355, max value: 0.737444\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.71980023 (ave = 0.80622665)\n",
      "Loss_G = 1.27883887 (ave = 1.29348674)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.613876, max value: 0.734485\n",
      "D grad l2-norm: 7.573981, max value: 0.728507\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.018s / 800 iters, (0.003644)\n",
      "Loss_D = 0.79382551 (ave = 0.85022005)\n",
      "Loss_G = 1.23846161 (ave = 1.24035406)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.457149, max value: 0.752031\n",
      "D grad l2-norm: 7.343381, max value: 0.701669\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.84533691 (ave = 0.88732057)\n",
      "Loss_G = 1.23584032 (ave = 1.24206898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.704919, max value: 0.768423\n",
      "D grad l2-norm: 7.542862, max value: 0.699414\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.84311378 (ave = 0.90301197)\n",
      "Loss_G = 1.20087075 (ave = 1.22274878)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.380901, max value: 0.771390\n",
      "D grad l2-norm: 7.289882, max value: 0.690733\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.13917828 (ave = 0.95964733)\n",
      "Loss_G = 1.26039040 (ave = 1.22884743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.393217, max value: 0.781097\n",
      "D grad l2-norm: 7.380961, max value: 0.709941\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000935)\n",
      "Loss_D = 1.06539941 (ave = 0.95221282)\n",
      "Loss_G = 1.21112943 (ave = 1.21326902)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.397467, max value: 0.799963\n",
      "D grad l2-norm: 7.261964, max value: 0.695893\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 1.01904058 (ave = 0.95942289)\n",
      "Loss_G = 1.21466362 (ave = 1.22130806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.593568, max value: 0.790565\n",
      "D grad l2-norm: 7.209010, max value: 0.696964\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 0.79836488 (ave = 0.94941860)\n",
      "Loss_G = 1.17230654 (ave = 1.17682681)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.111501, max value: 0.734116\n",
      "D grad l2-norm: 6.867991, max value: 0.683714\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001034)\n",
      "Loss_D = 0.71585393 (ave = 0.94394071)\n",
      "Loss_G = 1.18990684 (ave = 1.17017655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.122331, max value: 0.689726\n",
      "D grad l2-norm: 7.075126, max value: 0.690256\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.008s / 800 iters, (0.001609)\n",
      "Loss_D = 0.87172532 (ave = 0.95566118)\n",
      "Loss_G = 1.17973971 (ave = 1.19875224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.430611, max value: 0.635011\n",
      "D grad l2-norm: 6.647467, max value: 0.686616\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.98887736 (ave = 0.95651495)\n",
      "Loss_G = 1.20889819 (ave = 1.21082649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.262308, max value: 0.573565\n",
      "D grad l2-norm: 6.801012, max value: 0.697495\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001009)\n",
      "Loss_D = 0.98802209 (ave = 0.93380607)\n",
      "Loss_G = 1.28359795 (ave = 1.26752210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.232631, max value: 0.549295\n",
      "D grad l2-norm: 6.968270, max value: 0.719537\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 0.93552446 (ave = 0.90693924)\n",
      "Loss_G = 1.32069623 (ave = 1.31125083)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.329570, max value: 0.553461\n",
      "D grad l2-norm: 7.046024, max value: 0.729182\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.81045038 (ave = 0.87494798)\n",
      "Loss_G = 1.33534420 (ave = 1.31122725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.284409, max value: 0.567863\n",
      "D grad l2-norm: 6.920146, max value: 0.732152\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 0.80444944 (ave = 0.87075791)\n",
      "Loss_G = 1.30524492 (ave = 1.31496513)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.251019, max value: 0.556613\n",
      "D grad l2-norm: 6.858460, max value: 0.725120\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 1.04811800 (ave = 0.88888425)\n",
      "Loss_G = 1.32170486 (ave = 1.31649113)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.378875, max value: 0.566569\n",
      "D grad l2-norm: 6.911391, max value: 0.727936\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 0.84201807 (ave = 0.86319435)\n",
      "Loss_G = 1.31138802 (ave = 1.30322032)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.384230, max value: 0.610525\n",
      "D grad l2-norm: 6.878238, max value: 0.726319\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001184)\n",
      "Loss_D = 0.98142791 (ave = 0.87537981)\n",
      "Loss_G = 1.28028154 (ave = 1.29296937)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.004981, max value: 0.607413\n",
      "D grad l2-norm: 6.482311, max value: 0.717012\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.82274055 (ave = 0.84912636)\n",
      "Loss_G = 1.30717742 (ave = 1.30101507)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.236097, max value: 0.635816\n",
      "D grad l2-norm: 6.638322, max value: 0.725335\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 0.84824193 (ave = 0.84608660)\n",
      "Loss_G = 1.29727817 (ave = 1.28669763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.139509, max value: 0.630319\n",
      "D grad l2-norm: 6.602701, max value: 0.722854\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.71114552 (ave = 0.82673469)\n",
      "Loss_G = 1.28378522 (ave = 1.27991147)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.897740, max value: 0.588473\n",
      "D grad l2-norm: 6.443040, max value: 0.719607\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.97100896 (ave = 0.85021478)\n",
      "Loss_G = 1.30552602 (ave = 1.30130153)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.996152, max value: 0.588324\n",
      "D grad l2-norm: 6.485328, max value: 0.724830\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.90283310 (ave = 0.84509999)\n",
      "Loss_G = 1.27560282 (ave = 1.27760465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.172941, max value: 0.592723\n",
      "D grad l2-norm: 6.427905, max value: 0.716317\n",
      "üîÅ TSCV for Asset 8\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 800 iters, (0.026)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 1.36845744 (ave = 1.37216213)\n",
      "Loss_G = 0.65546477 (ave = 0.65507363)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964428, max value: 0.033729\n",
      "D grad l2-norm: 0.666384, max value: 0.480797\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.007s / 800 iters, (0.001319)\n",
      "Loss_D = 1.36535954 (ave = 1.36331086)\n",
      "Loss_G = 0.65449023 (ave = 0.65452006)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967085, max value: 0.025617\n",
      "D grad l2-norm: 0.667118, max value: 0.480290\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 1.35279727 (ave = 1.35373759)\n",
      "Loss_G = 0.65372670 (ave = 0.65387788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964524, max value: 0.023377\n",
      "D grad l2-norm: 0.665732, max value: 0.479893\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 1.32821941 (ave = 1.34293163)\n",
      "Loss_G = 0.65375561 (ave = 0.65345594)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968597, max value: 0.037445\n",
      "D grad l2-norm: 0.669699, max value: 0.479908\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000978)\n",
      "Loss_D = 1.33932602 (ave = 1.33587623)\n",
      "Loss_G = 0.65295506 (ave = 0.65315818)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969692, max value: 0.029053\n",
      "D grad l2-norm: 0.672528, max value: 0.479491\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000983)\n",
      "Loss_D = 1.32457793 (ave = 1.32635293)\n",
      "Loss_G = 0.65288478 (ave = 0.65268428)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967836, max value: 0.027719\n",
      "D grad l2-norm: 0.671599, max value: 0.479453\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.30594993 (ave = 1.31656642)\n",
      "Loss_G = 0.65206087 (ave = 0.65183153)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968486, max value: 0.038328\n",
      "D grad l2-norm: 0.677364, max value: 0.479024\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 1.30752468 (ave = 1.31037817)\n",
      "Loss_G = 0.65070289 (ave = 0.65113302)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974512, max value: 0.034555\n",
      "D grad l2-norm: 0.680308, max value: 0.478314\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 1.29837966 (ave = 1.30238504)\n",
      "Loss_G = 0.65095466 (ave = 0.65100291)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970971, max value: 0.033677\n",
      "D grad l2-norm: 0.684127, max value: 0.478446\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.30192578 (ave = 1.29609475)\n",
      "Loss_G = 0.65059185 (ave = 0.65056924)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.981112, max value: 0.030355\n",
      "D grad l2-norm: 0.687756, max value: 0.478258\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.28866839 (ave = 1.28849075)\n",
      "Loss_G = 0.64974624 (ave = 0.65012540)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979476, max value: 0.034402\n",
      "D grad l2-norm: 0.693809, max value: 0.477814\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 1.29403758 (ave = 1.28271847)\n",
      "Loss_G = 0.64921081 (ave = 0.64976023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979653, max value: 0.033892\n",
      "D grad l2-norm: 0.700806, max value: 0.477535\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 1.25046968 (ave = 1.27125704)\n",
      "Loss_G = 0.64910138 (ave = 0.64933692)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979459, max value: 0.031251\n",
      "D grad l2-norm: 0.703451, max value: 0.477474\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 1.25987124 (ave = 1.26689973)\n",
      "Loss_G = 0.64880347 (ave = 0.64883118)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980680, max value: 0.031620\n",
      "D grad l2-norm: 0.709714, max value: 0.477319\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.009s / 800 iters, (0.001857)\n",
      "Loss_D = 1.26174021 (ave = 1.26200297)\n",
      "Loss_G = 0.64909172 (ave = 0.64892114)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.983179, max value: 0.034765\n",
      "D grad l2-norm: 0.715251, max value: 0.477469\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 1.26675797 (ave = 1.25659878)\n",
      "Loss_G = 0.64918745 (ave = 0.64912775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986040, max value: 0.034424\n",
      "D grad l2-norm: 0.720949, max value: 0.477519\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 1.26200771 (ave = 1.25074658)\n",
      "Loss_G = 0.64899647 (ave = 0.64879203)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986022, max value: 0.035702\n",
      "D grad l2-norm: 0.728399, max value: 0.477411\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001216)\n",
      "Loss_D = 1.22532725 (ave = 1.24024379)\n",
      "Loss_G = 0.64931780 (ave = 0.64892606)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984056, max value: 0.039783\n",
      "D grad l2-norm: 0.734959, max value: 0.477582\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002702)\n",
      "Loss_D = 1.24543285 (ave = 1.23788021)\n",
      "Loss_G = 0.65007144 (ave = 0.65026380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.998913, max value: 0.043730\n",
      "D grad l2-norm: 0.746453, max value: 0.477975\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.20212448 (ave = 1.22624049)\n",
      "Loss_G = 0.65054268 (ave = 0.65073820)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992721, max value: 0.036176\n",
      "D grad l2-norm: 0.751362, max value: 0.478220\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.22194886 (ave = 1.22138183)\n",
      "Loss_G = 0.65306723 (ave = 0.65240095)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992872, max value: 0.048807\n",
      "D grad l2-norm: 0.760560, max value: 0.479534\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002873)\n",
      "Loss_D = 1.21238375 (ave = 1.21471519)\n",
      "Loss_G = 0.65442270 (ave = 0.65460287)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986502, max value: 0.049627\n",
      "D grad l2-norm: 0.770240, max value: 0.480236\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.21106052 (ave = 1.20706253)\n",
      "Loss_G = 0.65837628 (ave = 0.65695339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993171, max value: 0.050935\n",
      "D grad l2-norm: 0.776822, max value: 0.482288\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.18776560 (ave = 1.19720531)\n",
      "Loss_G = 0.66039449 (ave = 0.65968723)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992078, max value: 0.051549\n",
      "D grad l2-norm: 0.787745, max value: 0.483332\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.18718696 (ave = 1.18920670)\n",
      "Loss_G = 0.66504014 (ave = 0.66354086)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992075, max value: 0.053264\n",
      "D grad l2-norm: 0.796156, max value: 0.485726\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002767)\n",
      "Loss_D = 1.16243231 (ave = 1.17836931)\n",
      "Loss_G = 0.66768008 (ave = 0.66666160)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.000562, max value: 0.050512\n",
      "D grad l2-norm: 0.808402, max value: 0.487082\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.17242932 (ave = 1.17099593)\n",
      "Loss_G = 0.67267257 (ave = 0.67105045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.998028, max value: 0.050700\n",
      "D grad l2-norm: 0.818416, max value: 0.489633\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.14349282 (ave = 1.15920339)\n",
      "Loss_G = 0.67530531 (ave = 0.67451898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.997514, max value: 0.050347\n",
      "D grad l2-norm: 0.829873, max value: 0.490973\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001013)\n",
      "Loss_D = 1.15573192 (ave = 1.15276868)\n",
      "Loss_G = 0.68333161 (ave = 0.68035941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.995769, max value: 0.050870\n",
      "D grad l2-norm: 0.835140, max value: 0.495037\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 1.13098180 (ave = 1.14118133)\n",
      "Loss_G = 0.68729103 (ave = 0.68460103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004414, max value: 0.053726\n",
      "D grad l2-norm: 0.847419, max value: 0.497034\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.12524128 (ave = 1.13078718)\n",
      "Loss_G = 0.69020164 (ave = 0.68965343)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.013925, max value: 0.055663\n",
      "D grad l2-norm: 0.858889, max value: 0.498502\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001014)\n",
      "Loss_D = 1.11966693 (ave = 1.12175689)\n",
      "Loss_G = 0.69911432 (ave = 0.69515495)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.006090, max value: 0.051617\n",
      "D grad l2-norm: 0.865996, max value: 0.502944\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 1.13368297 (ave = 1.11471126)\n",
      "Loss_G = 0.70230067 (ave = 0.69976195)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.019421, max value: 0.071504\n",
      "D grad l2-norm: 0.878914, max value: 0.504528\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.07644236 (ave = 1.09854019)\n",
      "Loss_G = 0.70940924 (ave = 0.70480567)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.021724, max value: 0.066040\n",
      "D grad l2-norm: 0.890209, max value: 0.508026\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 1.06836200 (ave = 1.08885980)\n",
      "Loss_G = 0.71326143 (ave = 0.70949267)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.026877, max value: 0.076975\n",
      "D grad l2-norm: 0.907797, max value: 0.509921\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 1.05164337 (ave = 1.07741492)\n",
      "Loss_G = 0.71613503 (ave = 0.71411607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.031911, max value: 0.089500\n",
      "D grad l2-norm: 0.929733, max value: 0.511324\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.008s / 800 iters, (0.001640)\n",
      "Loss_D = 1.09414136 (ave = 1.07335584)\n",
      "Loss_G = 0.72258794 (ave = 0.72090626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.042099, max value: 0.086095\n",
      "D grad l2-norm: 0.937683, max value: 0.514470\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 1.05202091 (ave = 1.05854661)\n",
      "Loss_G = 0.72851044 (ave = 0.72645452)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.041321, max value: 0.082987\n",
      "D grad l2-norm: 0.957004, max value: 0.517336\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 1.03475809 (ave = 1.04697924)\n",
      "Loss_G = 0.73338723 (ave = 0.73163621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.059843, max value: 0.092207\n",
      "D grad l2-norm: 0.973497, max value: 0.519677\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001005)\n",
      "Loss_D = 1.00160980 (ave = 1.03412926)\n",
      "Loss_G = 0.73968637 (ave = 0.73715131)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.072742, max value: 0.090680\n",
      "D grad l2-norm: 0.995065, max value: 0.522695\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 1.02564347 (ave = 1.02728496)\n",
      "Loss_G = 0.74506652 (ave = 0.74358233)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.095634, max value: 0.095781\n",
      "D grad l2-norm: 1.008808, max value: 0.525258\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.97360611 (ave = 1.01392868)\n",
      "Loss_G = 0.75008857 (ave = 0.74690425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.121318, max value: 0.099859\n",
      "D grad l2-norm: 1.031348, max value: 0.527609\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 0.97947675 (ave = 1.00784374)\n",
      "Loss_G = 0.75312960 (ave = 0.75121123)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.119546, max value: 0.100352\n",
      "D grad l2-norm: 1.036164, max value: 0.529044\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.00751948 (ave = 1.00590097)\n",
      "Loss_G = 0.75264025 (ave = 0.75280927)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.153834, max value: 0.103467\n",
      "D grad l2-norm: 1.071828, max value: 0.528803\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.013s / 800 iters, (0.002697)\n",
      "Loss_D = 0.95174980 (ave = 0.99362051)\n",
      "Loss_G = 0.75825095 (ave = 0.75552875)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.170015, max value: 0.108675\n",
      "D grad l2-norm: 1.096568, max value: 0.531458\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 0.98946559 (ave = 0.99501569)\n",
      "Loss_G = 0.76299083 (ave = 0.75911444)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.180520, max value: 0.103094\n",
      "D grad l2-norm: 1.115511, max value: 0.533668\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.97964823 (ave = 0.98709854)\n",
      "Loss_G = 0.76258528 (ave = 0.76146741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.205941, max value: 0.111045\n",
      "D grad l2-norm: 1.145519, max value: 0.533458\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.018s / 800 iters, (0.003512)\n",
      "Loss_D = 0.95363069 (ave = 0.97965770)\n",
      "Loss_G = 0.76285493 (ave = 0.76324911)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.219117, max value: 0.114116\n",
      "D grad l2-norm: 1.181769, max value: 0.533571\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.94035232 (ave = 0.97277366)\n",
      "Loss_G = 0.76945055 (ave = 0.76697187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.241893, max value: 0.105360\n",
      "D grad l2-norm: 1.207978, max value: 0.536620\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.98832560 (ave = 0.97535235)\n",
      "Loss_G = 0.77023488 (ave = 0.76795930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.267505, max value: 0.103404\n",
      "D grad l2-norm: 1.238136, max value: 0.536989\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.98695558 (ave = 0.97251623)\n",
      "Loss_G = 0.76857936 (ave = 0.77054119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.303494, max value: 0.120168\n",
      "D grad l2-norm: 1.276332, max value: 0.536169\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001009)\n",
      "Loss_D = 0.95880795 (ave = 0.96706553)\n",
      "Loss_G = 0.77275801 (ave = 0.77368858)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.325957, max value: 0.127672\n",
      "D grad l2-norm: 1.300920, max value: 0.538112\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 1.04358351 (ave = 0.97369689)\n",
      "Loss_G = 0.77776891 (ave = 0.77484576)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.341316, max value: 0.135814\n",
      "D grad l2-norm: 1.337804, max value: 0.540412\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.89578569 (ave = 0.95339942)\n",
      "Loss_G = 0.78138822 (ave = 0.77983347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.349343, max value: 0.146391\n",
      "D grad l2-norm: 1.370279, max value: 0.542065\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 0.92939830 (ave = 0.95016522)\n",
      "Loss_G = 0.79309821 (ave = 0.78724812)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.339936, max value: 0.150229\n",
      "D grad l2-norm: 1.395098, max value: 0.547392\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001031)\n",
      "Loss_D = 0.90850580 (ave = 0.94274955)\n",
      "Loss_G = 0.79783100 (ave = 0.79638644)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.358800, max value: 0.141786\n",
      "D grad l2-norm: 1.435665, max value: 0.549530\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001197)\n",
      "Loss_D = 0.98611820 (ave = 0.94151112)\n",
      "Loss_G = 0.80359238 (ave = 0.80235654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.375016, max value: 0.150262\n",
      "D grad l2-norm: 1.455467, max value: 0.552051\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.93512678 (ave = 0.93038292)\n",
      "Loss_G = 0.81717801 (ave = 0.81172047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.383270, max value: 0.142751\n",
      "D grad l2-norm: 1.479100, max value: 0.558115\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.89365840 (ave = 0.91837214)\n",
      "Loss_G = 0.81560928 (ave = 0.81639640)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.454672, max value: 0.139763\n",
      "D grad l2-norm: 1.504326, max value: 0.557358\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.90357113 (ave = 0.91597685)\n",
      "Loss_G = 0.82083517 (ave = 0.82117170)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.522367, max value: 0.167317\n",
      "D grad l2-norm: 1.536970, max value: 0.559681\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 0.90734959 (ave = 0.91631352)\n",
      "Loss_G = 0.81747097 (ave = 0.81913582)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.578843, max value: 0.178010\n",
      "D grad l2-norm: 1.573550, max value: 0.558164\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.87990677 (ave = 0.91546892)\n",
      "Loss_G = 0.80750716 (ave = 0.81325933)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.592321, max value: 0.185426\n",
      "D grad l2-norm: 1.569369, max value: 0.553622\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001046)\n",
      "Loss_D = 0.88096094 (ave = 0.91940998)\n",
      "Loss_G = 0.80363876 (ave = 0.80479727)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.625411, max value: 0.184092\n",
      "D grad l2-norm: 1.591202, max value: 0.551819\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.99646974 (ave = 0.93881062)\n",
      "Loss_G = 0.80184710 (ave = 0.80180669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.680788, max value: 0.199075\n",
      "D grad l2-norm: 1.616199, max value: 0.551045\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.90612841 (ave = 0.92938334)\n",
      "Loss_G = 0.79646087 (ave = 0.79956743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.737454, max value: 0.208094\n",
      "D grad l2-norm: 1.633914, max value: 0.548565\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.86717290 (ave = 0.92830074)\n",
      "Loss_G = 0.78414232 (ave = 0.78682970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.830337, max value: 0.220813\n",
      "D grad l2-norm: 1.674595, max value: 0.542991\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.009s / 800 iters, (0.001865)\n",
      "Loss_D = 0.98322642 (ave = 0.95435225)\n",
      "Loss_G = 0.77387166 (ave = 0.78168294)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:01:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.902033, max value: 0.220548\n",
      "D grad l2-norm: 1.691088, max value: 0.537925\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.95002151 (ave = 0.96047599)\n",
      "Loss_G = 0.76319993 (ave = 0.76534914)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.959893, max value: 0.235107\n",
      "D grad l2-norm: 1.742195, max value: 0.532910\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.91546321 (ave = 0.96326504)\n",
      "Loss_G = 0.76443231 (ave = 0.76708397)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.026431, max value: 0.251204\n",
      "D grad l2-norm: 1.796574, max value: 0.533641\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001160)\n",
      "Loss_D = 0.94359088 (ave = 0.97588682)\n",
      "Loss_G = 0.76322424 (ave = 0.76452502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.094507, max value: 0.268388\n",
      "D grad l2-norm: 1.845315, max value: 0.532635\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.92622888 (ave = 0.96926601)\n",
      "Loss_G = 0.75905061 (ave = 0.75827750)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.172171, max value: 0.284066\n",
      "D grad l2-norm: 1.889053, max value: 0.530589\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001016)\n",
      "Loss_D = 0.98631418 (ave = 0.98708756)\n",
      "Loss_G = 0.76910377 (ave = 0.76426594)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.196241, max value: 0.286017\n",
      "D grad l2-norm: 1.930631, max value: 0.535145\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.007s / 800 iters, (0.001325)\n",
      "Loss_D = 0.98333442 (ave = 0.98522847)\n",
      "Loss_G = 0.78061610 (ave = 0.77393177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.271106, max value: 0.281606\n",
      "D grad l2-norm: 2.019556, max value: 0.540855\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.01988506 (ave = 0.98838991)\n",
      "Loss_G = 0.78812438 (ave = 0.77752124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:00\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.322628, max value: 0.287071\n",
      "D grad l2-norm: 2.104438, max value: 0.543878\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.95597482 (ave = 0.98234705)\n",
      "Loss_G = 0.78905255 (ave = 0.78623136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.325474, max value: 0.283648\n",
      "D grad l2-norm: 2.201705, max value: 0.544347\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.96506369 (ave = 0.98006489)\n",
      "Loss_G = 0.81192142 (ave = 0.80045563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.309893, max value: 0.266992\n",
      "D grad l2-norm: 2.329633, max value: 0.554829\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.91616464 (ave = 0.95756510)\n",
      "Loss_G = 0.85066646 (ave = 0.83536347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.314487, max value: 0.253567\n",
      "D grad l2-norm: 2.476012, max value: 0.571713\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.95672154 (ave = 0.94287497)\n",
      "Loss_G = 0.88983750 (ave = 0.87302593)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.427985, max value: 0.253219\n",
      "D grad l2-norm: 2.675915, max value: 0.588373\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.95055729 (ave = 0.92612423)\n",
      "Loss_G = 0.92858577 (ave = 0.90851128)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.449374, max value: 0.240819\n",
      "D grad l2-norm: 2.803667, max value: 0.604057\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 0.90845144 (ave = 0.90548663)\n",
      "Loss_G = 0.97376674 (ave = 0.95644855)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.526738, max value: 0.278262\n",
      "D grad l2-norm: 2.973655, max value: 0.621609\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.99728864 (ave = 0.89905584)\n",
      "Loss_G = 0.99365699 (ave = 0.99204742)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.690706, max value: 0.304228\n",
      "D grad l2-norm: 3.168991, max value: 0.629017\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001202)\n",
      "Loss_D = 0.83805054 (ave = 0.86890682)\n",
      "Loss_G = 1.02681804 (ave = 1.01606567)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.821585, max value: 0.338676\n",
      "D grad l2-norm: 3.321217, max value: 0.640867\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 1.04612935 (ave = 0.90367479)\n",
      "Loss_G = 1.04822981 (ave = 1.03712115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.925863, max value: 0.335456\n",
      "D grad l2-norm: 3.424180, max value: 0.648294\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 0.89065170 (ave = 0.88433771)\n",
      "Loss_G = 1.05095220 (ave = 1.04578996)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.112533, max value: 0.337864\n",
      "D grad l2-norm: 3.572011, max value: 0.649103\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 0.88911390 (ave = 0.88688003)\n",
      "Loss_G = 1.06660461 (ave = 1.06377547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.196662, max value: 0.339834\n",
      "D grad l2-norm: 3.677930, max value: 0.654416\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 0.96198171 (ave = 0.89746779)\n",
      "Loss_G = 1.05959189 (ave = 1.07052960)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.354530, max value: 0.331317\n",
      "D grad l2-norm: 3.786880, max value: 0.651337\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.86004174 (ave = 0.89696823)\n",
      "Loss_G = 1.06916559 (ave = 1.06769748)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.472333, max value: 0.333208\n",
      "D grad l2-norm: 3.764000, max value: 0.654921\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001195)\n",
      "Loss_D = 1.00712025 (ave = 0.93283762)\n",
      "Loss_G = 1.03636253 (ave = 1.05862751)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.838421, max value: 0.332837\n",
      "D grad l2-norm: 3.879725, max value: 0.643237\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.88803053 (ave = 0.95401497)\n",
      "Loss_G = 0.98478758 (ave = 1.00336447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.084168, max value: 0.318482\n",
      "D grad l2-norm: 3.939957, max value: 0.624191\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002841)\n",
      "Loss_D = 0.94480669 (ave = 1.00524118)\n",
      "Loss_G = 0.98143506 (ave = 0.97671578)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.971969, max value: 0.313880\n",
      "D grad l2-norm: 3.861859, max value: 0.622110\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 1.05057573 (ave = 1.04867966)\n",
      "Loss_G = 0.94896424 (ave = 0.95965141)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.159582, max value: 0.341258\n",
      "D grad l2-norm: 4.000625, max value: 0.610032\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002778)\n",
      "Loss_D = 1.12423670 (ave = 1.08224287)\n",
      "Loss_G = 0.94093597 (ave = 0.94857649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.245983, max value: 0.360514\n",
      "D grad l2-norm: 4.089116, max value: 0.606411\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 1.18874657 (ave = 1.10844660)\n",
      "Loss_G = 0.96465093 (ave = 0.95210232)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.200491, max value: 0.371825\n",
      "D grad l2-norm: 4.129601, max value: 0.616065\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.16805017 (ave = 1.10231600)\n",
      "Loss_G = 0.97877043 (ave = 0.96989871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.197059, max value: 0.380758\n",
      "D grad l2-norm: 4.294629, max value: 0.621589\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 1.17133141 (ave = 1.09018157)\n",
      "Loss_G = 1.04580247 (ave = 1.01919702)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.284562, max value: 0.396753\n",
      "D grad l2-norm: 4.507612, max value: 0.646624\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.009s / 800 iters, (0.001867)\n",
      "Loss_D = 1.06341696 (ave = 1.05644405)\n",
      "Loss_G = 1.06441927 (ave = 1.05008440)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.389958, max value: 0.395785\n",
      "D grad l2-norm: 4.733921, max value: 0.653105\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 1.06076038 (ave = 1.03774137)\n",
      "Loss_G = 1.11997175 (ave = 1.10638220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.481233, max value: 0.388418\n",
      "D grad l2-norm: 5.012722, max value: 0.672049\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 1.05671597 (ave = 1.01098105)\n",
      "Loss_G = 1.18693435 (ave = 1.15645406)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.399567, max value: 0.378090\n",
      "D grad l2-norm: 5.110777, max value: 0.693508\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001145)\n",
      "Loss_D = 1.02890801 (ave = 0.98432175)\n",
      "Loss_G = 1.22206891 (ave = 1.20275445)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.371754, max value: 0.397770\n",
      "D grad l2-norm: 5.151317, max value: 0.703843\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 1.01778793 (ave = 0.95595887)\n",
      "Loss_G = 1.26635408 (ave = 1.24925647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.739444, max value: 0.435187\n",
      "D grad l2-norm: 5.519657, max value: 0.719375\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.87506217 (ave = 0.92205038)\n",
      "Loss_G = 1.28747749 (ave = 1.28222005)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.520145, max value: 0.425153\n",
      "D grad l2-norm: 5.409550, max value: 0.722935\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001246)\n",
      "Loss_D = 0.98284614 (ave = 0.91330786)\n",
      "Loss_G = 1.32311356 (ave = 1.30830836)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.628316, max value: 0.433418\n",
      "D grad l2-norm: 5.529248, max value: 0.743829\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 0.77826953 (ave = 0.87497313)\n",
      "Loss_G = 1.35520589 (ave = 1.33962126)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.758260, max value: 0.425594\n",
      "D grad l2-norm: 5.634812, max value: 0.758766\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 0.83286643 (ave = 0.86561511)\n",
      "Loss_G = 1.38997388 (ave = 1.36697998)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.832671, max value: 0.429066\n",
      "D grad l2-norm: 5.590764, max value: 0.760656\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002809)\n",
      "Loss_D = 0.86136413 (ave = 0.85969421)\n",
      "Loss_G = 1.34816432 (ave = 1.35727265)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.003964, max value: 0.454656\n",
      "D grad l2-norm: 5.543016, max value: 0.738739\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 800 iters, (0.026)\tData load 0.010s / 800 iters, (0.001989)\n",
      "Loss_D = 0.88076305 (ave = 0.86407855)\n",
      "Loss_G = 1.31114590 (ave = 1.33846765)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.251335, max value: 0.469113\n",
      "D grad l2-norm: 5.710222, max value: 0.728968\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.87555158 (ave = 0.86533215)\n",
      "Loss_G = 1.33448827 (ave = 1.32219880)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.314528, max value: 0.472575\n",
      "D grad l2-norm: 5.688889, max value: 0.735002\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.010s / 800 iters, (0.001975)\n",
      "Loss_D = 0.79208994 (ave = 0.85585240)\n",
      "Loss_G = 1.29431748 (ave = 1.30500643)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.343663, max value: 0.492153\n",
      "D grad l2-norm: 5.554427, max value: 0.723944\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.99333692 (ave = 0.88737624)\n",
      "Loss_G = 1.25925350 (ave = 1.27692466)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.398865, max value: 0.497254\n",
      "D grad l2-norm: 5.513252, max value: 0.714269\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001017)\n",
      "Loss_D = 0.85236681 (ave = 0.87384254)\n",
      "Loss_G = 1.27092481 (ave = 1.25942619)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.393138, max value: 0.494373\n",
      "D grad l2-norm: 5.486498, max value: 0.717175\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.85173750 (ave = 0.87539880)\n",
      "Loss_G = 1.23020720 (ave = 1.23573036)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.424432, max value: 0.490448\n",
      "D grad l2-norm: 5.397776, max value: 0.705505\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.93013227 (ave = 0.88840441)\n",
      "Loss_G = 1.22937107 (ave = 1.23998649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.414674, max value: 0.482270\n",
      "D grad l2-norm: 5.262358, max value: 0.704943\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001227)\n",
      "Loss_D = 0.96589398 (ave = 0.89880673)\n",
      "Loss_G = 1.20669770 (ave = 1.22112358)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.380080, max value: 0.488628\n",
      "D grad l2-norm: 5.076219, max value: 0.698337\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001100)\n",
      "Loss_D = 0.87502539 (ave = 0.90097768)\n",
      "Loss_G = 1.18871486 (ave = 1.19010286)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.490153, max value: 0.475216\n",
      "D grad l2-norm: 5.071120, max value: 0.692768\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.87265819 (ave = 0.90999478)\n",
      "Loss_G = 1.14897442 (ave = 1.16101532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.290156, max value: 0.430189\n",
      "D grad l2-norm: 4.925026, max value: 0.680864\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 1.05045867 (ave = 0.93431633)\n",
      "Loss_G = 1.16772676 (ave = 1.16096315)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.323202, max value: 0.447350\n",
      "D grad l2-norm: 4.938348, max value: 0.686084\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.86771452 (ave = 0.91905465)\n",
      "Loss_G = 1.14987898 (ave = 1.14240463)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.454369, max value: 0.459236\n",
      "D grad l2-norm: 4.890962, max value: 0.680539\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.81753844 (ave = 0.92867596)\n",
      "Loss_G = 1.09566891 (ave = 1.11827936)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.551787, max value: 0.460186\n",
      "D grad l2-norm: 4.902612, max value: 0.661870\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.007s / 800 iters, (0.001362)\n",
      "Loss_D = 1.02540755 (ave = 0.96331151)\n",
      "Loss_G = 1.11025405 (ave = 1.09840508)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.582039, max value: 0.456608\n",
      "D grad l2-norm: 4.908644, max value: 0.666508\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 800 iters, (0.021)\tData load 0.018s / 800 iters, (0.003531)\n",
      "Loss_D = 1.01186764 (ave = 0.96769639)\n",
      "Loss_G = 1.09717560 (ave = 1.09039133)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.441485, max value: 0.434292\n",
      "D grad l2-norm: 4.874378, max value: 0.663438\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.155s / 800 iters, (0.031)\tData load 0.006s / 800 iters, (0.001205)\n",
      "Loss_D = 0.91403031 (ave = 0.95291008)\n",
      "Loss_G = 1.11910164 (ave = 1.11271839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.146348, max value: 0.445155\n",
      "D grad l2-norm: 4.879232, max value: 0.670132\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 800 iters, (0.026)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.95528919 (ave = 0.93487468)\n",
      "Loss_G = 1.15968668 (ave = 1.15623646)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.129668, max value: 0.449155\n",
      "D grad l2-norm: 4.984972, max value: 0.683916\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001162)\n",
      "Loss_D = 0.97203571 (ave = 0.91117625)\n",
      "Loss_G = 1.19742489 (ave = 1.18096611)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.878942, max value: 0.430627\n",
      "D grad l2-norm: 4.925496, max value: 0.696262\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.024s / 800 iters, (0.004792)\n",
      "Loss_D = 0.80056345 (ave = 0.87149588)\n",
      "Loss_G = 1.25217891 (ave = 1.21080120)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.981131, max value: 0.445045\n",
      "D grad l2-norm: 5.051945, max value: 0.712074\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.91738719 (ave = 0.87334237)\n",
      "Loss_G = 1.25257802 (ave = 1.23445470)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.194084, max value: 0.454691\n",
      "D grad l2-norm: 5.148569, max value: 0.712143\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.87016463 (ave = 0.86340189)\n",
      "Loss_G = 1.23988378 (ave = 1.23446567)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.311730, max value: 0.476195\n",
      "D grad l2-norm: 5.228346, max value: 0.710696\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.007s / 800 iters, (0.001336)\n",
      "Loss_D = 0.81674129 (ave = 0.85308715)\n",
      "Loss_G = 1.23400545 (ave = 1.23142371)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.388394, max value: 0.490892\n",
      "D grad l2-norm: 5.369079, max value: 0.740857\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.85436070 (ave = 0.84502709)\n",
      "Loss_G = 1.24295294 (ave = 1.24263666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.470963, max value: 0.490124\n",
      "D grad l2-norm: 5.305360, max value: 0.748228\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.80583900 (ave = 0.84379469)\n",
      "Loss_G = 1.22731888 (ave = 1.23081043)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.801156, max value: 0.450944\n",
      "D grad l2-norm: 5.413419, max value: 0.762721\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 0.77597648 (ave = 0.85716136)\n",
      "Loss_G = 1.20281613 (ave = 1.20363464)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.772773, max value: 0.432005\n",
      "D grad l2-norm: 5.280019, max value: 0.745881\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.71955097 (ave = 0.86025141)\n",
      "Loss_G = 1.17832780 (ave = 1.18008823)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.047930, max value: 0.442718\n",
      "D grad l2-norm: 5.420268, max value: 0.753887\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.87648499 (ave = 0.89883813)\n",
      "Loss_G = 1.16929829 (ave = 1.16850739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.983254, max value: 0.394692\n",
      "D grad l2-norm: 5.322614, max value: 0.742815\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.89108801 (ave = 0.90855671)\n",
      "Loss_G = 1.15734911 (ave = 1.14640083)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.953934, max value: 0.395684\n",
      "D grad l2-norm: 5.265813, max value: 0.729465\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.012s / 800 iters, (0.002389)\n",
      "Loss_D = 0.86246216 (ave = 0.92591277)\n",
      "Loss_G = 1.10430467 (ave = 1.11669865)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.010636, max value: 0.415742\n",
      "D grad l2-norm: 5.410863, max value: 0.710382\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.05800033 (ave = 0.95192815)\n",
      "Loss_G = 1.11736453 (ave = 1.11382446)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.085692, max value: 0.464742\n",
      "D grad l2-norm: 5.549087, max value: 0.707916\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 0.89977598 (ave = 0.93950173)\n",
      "Loss_G = 1.11273146 (ave = 1.11123993)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.988315, max value: 0.479930\n",
      "D grad l2-norm: 5.690576, max value: 0.688456\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001175)\n",
      "Loss_D = 0.90487039 (ave = 0.92993988)\n",
      "Loss_G = 1.16435695 (ave = 1.13939848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.897533, max value: 0.485114\n",
      "D grad l2-norm: 5.844415, max value: 0.684948\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 0.89598560 (ave = 0.90712434)\n",
      "Loss_G = 1.20944226 (ave = 1.19383788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.876873, max value: 0.502100\n",
      "D grad l2-norm: 6.060452, max value: 0.699015\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.87594855 (ave = 0.88075881)\n",
      "Loss_G = 1.29277313 (ave = 1.25323846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.674958, max value: 0.459034\n",
      "D grad l2-norm: 6.161833, max value: 0.723236\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.84627014 (ave = 0.85212113)\n",
      "Loss_G = 1.34636676 (ave = 1.30887556)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.798738, max value: 0.453838\n",
      "D grad l2-norm: 6.535109, max value: 0.737925\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 800 iters, (0.027)\tData load 0.014s / 800 iters, (0.002774)\n",
      "Loss_D = 0.76450622 (ave = 0.80851960)\n",
      "Loss_G = 1.37413526 (ave = 1.38211005)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.016779, max value: 0.488941\n",
      "D grad l2-norm: 6.802266, max value: 0.745176\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 0.81585789 (ave = 0.80490887)\n",
      "Loss_G = 1.44227576 (ave = 1.42452250)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.093579, max value: 0.549657\n",
      "D grad l2-norm: 6.986733, max value: 0.761769\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.80366719 (ave = 0.78278404)\n",
      "Loss_G = 1.47765398 (ave = 1.47141080)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.068430, max value: 0.585065\n",
      "D grad l2-norm: 7.086792, max value: 0.769951\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002797)\n",
      "Loss_D = 0.83240008 (ave = 0.76134949)\n",
      "Loss_G = 1.52822900 (ave = 1.50960255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.406170, max value: 0.661956\n",
      "D grad l2-norm: 7.537565, max value: 0.783445\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001208)\n",
      "Loss_D = 0.84715772 (ave = 0.74975172)\n",
      "Loss_G = 1.54405677 (ave = 1.53354185)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.648698, max value: 0.675467\n",
      "D grad l2-norm: 7.723752, max value: 0.791367\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.69888115 (ave = 0.72015784)\n",
      "Loss_G = 1.55111790 (ave = 1.55210369)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.833625, max value: 0.671934\n",
      "D grad l2-norm: 7.770014, max value: 0.785500\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.61411059 (ave = 0.70791342)\n",
      "Loss_G = 1.57213211 (ave = 1.56469946)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.935363, max value: 0.688672\n",
      "D grad l2-norm: 7.845564, max value: 0.790104\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001003)\n",
      "Loss_D = 0.74853539 (ave = 0.71663102)\n",
      "Loss_G = 1.56973493 (ave = 1.56560481)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.038030, max value: 0.669091\n",
      "D grad l2-norm: 7.812831, max value: 0.789439\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.008s / 800 iters, (0.001657)\n",
      "Loss_D = 0.79331088 (ave = 0.72112767)\n",
      "Loss_G = 1.54398906 (ave = 1.55266261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.297358, max value: 0.691442\n",
      "D grad l2-norm: 7.804126, max value: 0.783859\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.74889421 (ave = 0.71894070)\n",
      "Loss_G = 1.52284646 (ave = 1.53200283)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.300701, max value: 0.707749\n",
      "D grad l2-norm: 7.807880, max value: 0.780206\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 800 iters, (0.020)\tData load 0.011s / 800 iters, (0.002213)\n",
      "Loss_D = 0.60765696 (ave = 0.70350296)\n",
      "Loss_G = 1.53331876 (ave = 1.52333851)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.383696, max value: 0.716116\n",
      "D grad l2-norm: 7.790840, max value: 0.789513\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.007s / 800 iters, (0.001466)\n",
      "Loss_D = 0.68477976 (ave = 0.71123153)\n",
      "Loss_G = 1.53122544 (ave = 1.53261003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.895580, max value: 0.742319\n",
      "D grad l2-norm: 7.951194, max value: 0.797577\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.66348600 (ave = 0.72444813)\n",
      "Loss_G = 1.44970322 (ave = 1.47232544)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.009537, max value: 0.741723\n",
      "D grad l2-norm: 7.732110, max value: 0.762239\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.83556354 (ave = 0.76641421)\n",
      "Loss_G = 1.40361011 (ave = 1.43013129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.020629, max value: 0.711731\n",
      "D grad l2-norm: 7.645812, max value: 0.750805\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.73446608 (ave = 0.77030084)\n",
      "Loss_G = 1.37870598 (ave = 1.38274217)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.566883, max value: 0.691080\n",
      "D grad l2-norm: 7.257650, max value: 0.745361\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 0.82386303 (ave = 0.79690750)\n",
      "Loss_G = 1.37598908 (ave = 1.36737037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.656669, max value: 0.652447\n",
      "D grad l2-norm: 7.150772, max value: 0.743180\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001760)\n",
      "Loss_D = 0.84477043 (ave = 0.81591607)\n",
      "Loss_G = 1.30449653 (ave = 1.31815524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.623240, max value: 0.624338\n",
      "D grad l2-norm: 6.801613, max value: 0.725185\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 1.01700878 (ave = 0.85927244)\n",
      "Loss_G = 1.21156394 (ave = 1.25942984)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.715322, max value: 0.584767\n",
      "D grad l2-norm: 6.719601, max value: 0.696495\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001207)\n",
      "Loss_D = 0.96458936 (ave = 0.89197217)\n",
      "Loss_G = 1.18133759 (ave = 1.19710281)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.935210, max value: 0.563200\n",
      "D grad l2-norm: 6.573994, max value: 0.688829\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.018s / 800 iters, (0.003644)\n",
      "Loss_D = 0.97603619 (ave = 0.94302351)\n",
      "Loss_G = 1.08982587 (ave = 1.11682861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.749646, max value: 0.534496\n",
      "D grad l2-norm: 6.344557, max value: 0.659190\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 0.88941336 (ave = 0.97682494)\n",
      "Loss_G = 1.05801177 (ave = 1.06958790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.578797, max value: 0.533180\n",
      "D grad l2-norm: 6.292010, max value: 0.648528\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001210)\n",
      "Loss_D = 1.12357593 (ave = 1.03981872)\n",
      "Loss_G = 1.04547775 (ave = 1.03759317)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.562542, max value: 0.565890\n",
      "D grad l2-norm: 6.237313, max value: 0.644160\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 1.03887630 (ave = 1.04721088)\n",
      "Loss_G = 1.01394272 (ave = 1.03005404)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.311383, max value: 0.561082\n",
      "D grad l2-norm: 6.205585, max value: 0.632520\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.01959777 (ave = 1.05599127)\n",
      "Loss_G = 1.06275976 (ave = 1.04826298)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.009179, max value: 0.581964\n",
      "D grad l2-norm: 6.436906, max value: 0.649958\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002783)\n",
      "Loss_D = 1.11872196 (ave = 1.03578345)\n",
      "Loss_G = 1.18888676 (ave = 1.13642743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.094635, max value: 0.639993\n",
      "D grad l2-norm: 6.990090, max value: 0.692081\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002769)\n",
      "Loss_D = 0.94059336 (ave = 0.96950974)\n",
      "Loss_G = 1.25505531 (ave = 1.21549706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.125995, max value: 0.646166\n",
      "D grad l2-norm: 7.283916, max value: 0.711688\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.87099761 (ave = 0.92960523)\n",
      "Loss_G = 1.33168387 (ave = 1.28706067)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.275858, max value: 0.643997\n",
      "D grad l2-norm: 7.650159, max value: 0.735521\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001212)\n",
      "Loss_D = 0.94563591 (ave = 0.91483685)\n",
      "Loss_G = 1.38906169 (ave = 1.36190853)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.619846, max value: 0.676149\n",
      "D grad l2-norm: 7.949388, max value: 0.793746\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.76734173 (ave = 0.87866673)\n",
      "Loss_G = 1.42259622 (ave = 1.40230954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.966036, max value: 0.692680\n",
      "D grad l2-norm: 8.287218, max value: 0.844721\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 0.75976562 (ave = 0.86522346)\n",
      "Loss_G = 1.38385022 (ave = 1.41283891)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.193495, max value: 0.716231\n",
      "D grad l2-norm: 8.321079, max value: 0.848035\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001186)\n",
      "Loss_D = 0.77857906 (ave = 0.86331793)\n",
      "Loss_G = 1.42336869 (ave = 1.41406021)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.630512, max value: 0.750860\n",
      "D grad l2-norm: 8.529056, max value: 0.885311\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001169)\n",
      "Loss_D = 0.87218320 (ave = 0.88134832)\n",
      "Loss_G = 1.39994001 (ave = 1.40680404)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.521468, max value: 0.755216\n",
      "D grad l2-norm: 8.414309, max value: 0.873753\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.96267116 (ave = 0.89093482)\n",
      "Loss_G = 1.41538107 (ave = 1.41362169)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.572542, max value: 0.726663\n",
      "D grad l2-norm: 8.323729, max value: 0.869058\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.97268403 (ave = 0.90409570)\n",
      "Loss_G = 1.34190142 (ave = 1.36504829)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.871810, max value: 0.724750\n",
      "D grad l2-norm: 8.317812, max value: 0.827699\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.79722291 (ave = 0.90372369)\n",
      "Loss_G = 1.34813952 (ave = 1.35241451)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.768976, max value: 0.753731\n",
      "D grad l2-norm: 8.042425, max value: 0.784508\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.97687382 (ave = 0.93239987)\n",
      "Loss_G = 1.31645608 (ave = 1.34255316)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.201107, max value: 0.847015\n",
      "D grad l2-norm: 8.327802, max value: 0.755162\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.08522975 (ave = 0.96420337)\n",
      "Loss_G = 1.32320035 (ave = 1.32470593)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.360702, max value: 0.835619\n",
      "D grad l2-norm: 7.651761, max value: 0.729676\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.95664519 (ave = 0.95053941)\n",
      "Loss_G = 1.30185747 (ave = 1.29158618)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.668118, max value: 0.881891\n",
      "D grad l2-norm: 7.715074, max value: 0.727173\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002747)\n",
      "Loss_D = 0.97880471 (ave = 0.97208996)\n",
      "Loss_G = 1.26185727 (ave = 1.27593269)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.823519, max value: 0.896604\n",
      "D grad l2-norm: 7.727388, max value: 0.734275\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.96734405 (ave = 0.98497633)\n",
      "Loss_G = 1.26798022 (ave = 1.25531337)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.461369, max value: 0.874050\n",
      "D grad l2-norm: 7.378201, max value: 0.718139\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.06855369 (ave = 1.00518498)\n",
      "Loss_G = 1.22736800 (ave = 1.22899063)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.438219, max value: 0.875231\n",
      "D grad l2-norm: 7.291261, max value: 0.707137\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.00536585 (ave = 1.01594788)\n",
      "Loss_G = 1.20634532 (ave = 1.20845766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.099786, max value: 0.835475\n",
      "D grad l2-norm: 6.993797, max value: 0.697575\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 1.06900370 (ave = 1.02185725)\n",
      "Loss_G = 1.20644414 (ave = 1.20332873)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.913919, max value: 0.798780\n",
      "D grad l2-norm: 6.875578, max value: 0.696774\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.014s / 800 iters, (0.002784)\n",
      "Loss_D = 1.06494713 (ave = 1.02550236)\n",
      "Loss_G = 1.19921279 (ave = 1.19642215)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.700976, max value: 0.728497\n",
      "D grad l2-norm: 6.722210, max value: 0.695195\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.018s / 800 iters, (0.003581)\n",
      "Loss_D = 1.06287682 (ave = 1.03168044)\n",
      "Loss_G = 1.16630018 (ave = 1.18678746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.056950, max value: 0.706163\n",
      "D grad l2-norm: 6.743322, max value: 0.685202\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001166)\n",
      "Loss_D = 1.04855561 (ave = 1.05121202)\n",
      "Loss_G = 1.14868391 (ave = 1.15436635)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.069328, max value: 0.673207\n",
      "D grad l2-norm: 6.660133, max value: 0.679975\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001170)\n",
      "Loss_D = 0.97106445 (ave = 1.05824742)\n",
      "Loss_G = 1.11153698 (ave = 1.14355390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.968291, max value: 0.612299\n",
      "D grad l2-norm: 6.592736, max value: 0.666309\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.01930916 (ave = 1.07923403)\n",
      "Loss_G = 1.10469174 (ave = 1.09336493)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.563461, max value: 0.507855\n",
      "D grad l2-norm: 6.392037, max value: 0.665218\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 1.15943110 (ave = 1.10455719)\n",
      "Loss_G = 1.13790202 (ave = 1.12069173)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.314956, max value: 0.469952\n",
      "D grad l2-norm: 6.530423, max value: 0.675761\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000930)\n",
      "Loss_D = 1.04049814 (ave = 1.07516747)\n",
      "Loss_G = 1.19347954 (ave = 1.16417854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.280987, max value: 0.493260\n",
      "D grad l2-norm: 6.757523, max value: 0.693654\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.86307466 (ave = 1.02913518)\n",
      "Loss_G = 1.21470690 (ave = 1.19632769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.144133, max value: 0.502336\n",
      "D grad l2-norm: 6.749308, max value: 0.699497\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001017)\n",
      "Loss_D = 0.96902335 (ave = 1.03289645)\n",
      "Loss_G = 1.22855198 (ave = 1.21929350)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.130951, max value: 0.523850\n",
      "D grad l2-norm: 6.591658, max value: 0.704642\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001020)\n",
      "Loss_D = 0.91490960 (ave = 1.02254586)\n",
      "Loss_G = 1.21418977 (ave = 1.21754084)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.548900, max value: 0.583188\n",
      "D grad l2-norm: 6.708230, max value: 0.698690\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001191)\n",
      "Loss_D = 1.08469892 (ave = 1.05660808)\n",
      "Loss_G = 1.18152547 (ave = 1.19368660)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.379741, max value: 0.612722\n",
      "D grad l2-norm: 6.478784, max value: 0.688676\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.05060911 (ave = 1.05747473)\n",
      "Loss_G = 1.18000031 (ave = 1.19282608)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.163430, max value: 0.661791\n",
      "D grad l2-norm: 6.361235, max value: 0.688615\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.99155962 (ave = 1.05259482)\n",
      "Loss_G = 1.20208323 (ave = 1.19582598)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.308459, max value: 0.706178\n",
      "D grad l2-norm: 6.577016, max value: 0.717939\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.13163865 (ave = 1.06573186)\n",
      "Loss_G = 1.19179106 (ave = 1.18380671)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.280457, max value: 0.758764\n",
      "D grad l2-norm: 6.656030, max value: 0.723325\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.05236149 (ave = 1.05276338)\n",
      "Loss_G = 1.23902714 (ave = 1.22299268)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.232931, max value: 0.779758\n",
      "D grad l2-norm: 6.605817, max value: 0.714476\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001172)\n",
      "Loss_D = 0.93313301 (ave = 1.02297306)\n",
      "Loss_G = 1.23533273 (ave = 1.23029699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.202739, max value: 0.814851\n",
      "D grad l2-norm: 6.499758, max value: 0.704645\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.96412939 (ave = 1.02405698)\n",
      "Loss_G = 1.24556780 (ave = 1.23835864)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.266484, max value: 0.815108\n",
      "D grad l2-norm: 6.500254, max value: 0.707906\n",
      "üîÅ TSCV for Asset 9\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 1.39095390 (ave = 1.41047416)\n",
      "Loss_G = 0.66372705 (ave = 0.66430883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.960042, max value: 0.021236\n",
      "D grad l2-norm: 0.688745, max value: 0.485070\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 1.38943470 (ave = 1.39950957)\n",
      "Loss_G = 0.66265464 (ave = 0.66294538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.960285, max value: 0.019058\n",
      "D grad l2-norm: 0.687027, max value: 0.484518\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001016)\n",
      "Loss_D = 1.39163697 (ave = 1.38939610)\n",
      "Loss_G = 0.66146725 (ave = 0.66190234)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964228, max value: 0.019101\n",
      "D grad l2-norm: 0.690207, max value: 0.483905\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001238)\n",
      "Loss_D = 1.37481427 (ave = 1.37731864)\n",
      "Loss_G = 0.66080809 (ave = 0.66089728)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963766, max value: 0.020759\n",
      "D grad l2-norm: 0.693322, max value: 0.483564\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 1.34507024 (ave = 1.36421444)\n",
      "Loss_G = 0.66048521 (ave = 0.66056809)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.960832, max value: 0.018908\n",
      "D grad l2-norm: 0.695564, max value: 0.483398\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 1.35606861 (ave = 1.35634100)\n",
      "Loss_G = 0.66011369 (ave = 0.66002218)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963737, max value: 0.018257\n",
      "D grad l2-norm: 0.697786, max value: 0.483206\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 1.33945954 (ave = 1.34526925)\n",
      "Loss_G = 0.66052032 (ave = 0.65983163)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963554, max value: 0.029648\n",
      "D grad l2-norm: 0.700576, max value: 0.483416\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 800 iters, (0.026)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.32827151 (ave = 1.33493776)\n",
      "Loss_G = 0.65937036 (ave = 0.65985007)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963672, max value: 0.024030\n",
      "D grad l2-norm: 0.703861, max value: 0.482821\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.33101010 (ave = 1.32665203)\n",
      "Loss_G = 0.65988207 (ave = 0.65990340)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969041, max value: 0.026978\n",
      "D grad l2-norm: 0.710609, max value: 0.483085\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001014)\n",
      "Loss_D = 1.30867195 (ave = 1.31596429)\n",
      "Loss_G = 0.66072738 (ave = 0.66058172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964075, max value: 0.026970\n",
      "D grad l2-norm: 0.715987, max value: 0.483520\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.27800465 (ave = 1.30419087)\n",
      "Loss_G = 0.66187894 (ave = 0.66173102)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971893, max value: 0.029682\n",
      "D grad l2-norm: 0.719851, max value: 0.484115\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.26477003 (ave = 1.29431055)\n",
      "Loss_G = 0.66212809 (ave = 0.66213719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970373, max value: 0.034209\n",
      "D grad l2-norm: 0.728685, max value: 0.484244\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 1.26875448 (ave = 1.28740261)\n",
      "Loss_G = 0.66316038 (ave = 0.66263840)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972543, max value: 0.040453\n",
      "D grad l2-norm: 0.734369, max value: 0.484775\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 1.25869203 (ave = 1.27900541)\n",
      "Loss_G = 0.66420043 (ave = 0.66387471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972135, max value: 0.029896\n",
      "D grad l2-norm: 0.739194, max value: 0.485310\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.013s / 800 iters, (0.002700)\n",
      "Loss_D = 1.24422193 (ave = 1.27004316)\n",
      "Loss_G = 0.66515201 (ave = 0.66479456)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968008, max value: 0.035055\n",
      "D grad l2-norm: 0.750019, max value: 0.485798\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.26344860 (ave = 1.26553137)\n",
      "Loss_G = 0.66658193 (ave = 0.66607102)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971733, max value: 0.038613\n",
      "D grad l2-norm: 0.758585, max value: 0.486534\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.26784480 (ave = 1.25965309)\n",
      "Loss_G = 0.66773140 (ave = 0.66743157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975386, max value: 0.039189\n",
      "D grad l2-norm: 0.762950, max value: 0.487121\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 1.21846318 (ave = 1.24640274)\n",
      "Loss_G = 0.66992354 (ave = 0.66906815)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972765, max value: 0.037729\n",
      "D grad l2-norm: 0.770540, max value: 0.488244\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.24157548 (ave = 1.24283199)\n",
      "Loss_G = 0.67217094 (ave = 0.67021561)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980847, max value: 0.039822\n",
      "D grad l2-norm: 0.779558, max value: 0.489394\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 1.21659231 (ave = 1.23309312)\n",
      "Loss_G = 0.67334318 (ave = 0.67229338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.978061, max value: 0.040695\n",
      "D grad l2-norm: 0.787950, max value: 0.489990\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.21392965 (ave = 1.22598157)\n",
      "Loss_G = 0.67696786 (ave = 0.67496676)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980491, max value: 0.036100\n",
      "D grad l2-norm: 0.797777, max value: 0.491833\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 1.22778487 (ave = 1.22070749)\n",
      "Loss_G = 0.67835563 (ave = 0.67781883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.982977, max value: 0.036345\n",
      "D grad l2-norm: 0.806670, max value: 0.492540\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.21381307 (ave = 1.21232028)\n",
      "Loss_G = 0.68136573 (ave = 0.67987441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979924, max value: 0.039494\n",
      "D grad l2-norm: 0.818565, max value: 0.494064\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.009s / 800 iters, (0.001785)\n",
      "Loss_D = 1.19695139 (ave = 1.20394406)\n",
      "Loss_G = 0.68344194 (ave = 0.68223115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986623, max value: 0.042524\n",
      "D grad l2-norm: 0.826126, max value: 0.495108\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.012s / 800 iters, (0.002347)\n",
      "Loss_D = 1.18040168 (ave = 1.19525247)\n",
      "Loss_G = 0.68610638 (ave = 0.68533013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985532, max value: 0.043442\n",
      "D grad l2-norm: 0.836081, max value: 0.496450\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 1.20754766 (ave = 1.19239202)\n",
      "Loss_G = 0.68832278 (ave = 0.68742573)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.986724, max value: 0.042481\n",
      "D grad l2-norm: 0.842871, max value: 0.497568\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001164)\n",
      "Loss_D = 1.18421495 (ave = 1.18325078)\n",
      "Loss_G = 0.69176930 (ave = 0.69037954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993240, max value: 0.043859\n",
      "D grad l2-norm: 0.852731, max value: 0.499295\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 1.20499253 (ave = 1.18015616)\n",
      "Loss_G = 0.69423980 (ave = 0.69325364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991623, max value: 0.047416\n",
      "D grad l2-norm: 0.860458, max value: 0.500523\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.014s / 800 iters, (0.002789)\n",
      "Loss_D = 1.13958251 (ave = 1.16646168)\n",
      "Loss_G = 0.69909143 (ave = 0.69669441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.992312, max value: 0.049953\n",
      "D grad l2-norm: 0.868819, max value: 0.502950\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.17012298 (ave = 1.16510842)\n",
      "Loss_G = 0.69841701 (ave = 0.69831331)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.003852, max value: 0.067174\n",
      "D grad l2-norm: 0.878136, max value: 0.502609\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 1.17327404 (ave = 1.16105952)\n",
      "Loss_G = 0.69991767 (ave = 0.69990485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.010429, max value: 0.060626\n",
      "D grad l2-norm: 0.885194, max value: 0.503350\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 1.09665859 (ave = 1.14675159)\n",
      "Loss_G = 0.70289779 (ave = 0.70224121)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.014297, max value: 0.070559\n",
      "D grad l2-norm: 0.886511, max value: 0.504831\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.16483998 (ave = 1.15200422)\n",
      "Loss_G = 0.70008010 (ave = 0.70147305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.017002, max value: 0.070579\n",
      "D grad l2-norm: 0.900682, max value: 0.503420\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.17303884 (ave = 1.14980288)\n",
      "Loss_G = 0.70202750 (ave = 0.70291929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.023007, max value: 0.074851\n",
      "D grad l2-norm: 0.905390, max value: 0.504382\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.14098847 (ave = 1.14323459)\n",
      "Loss_G = 0.70363814 (ave = 0.70290775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.037585, max value: 0.066473\n",
      "D grad l2-norm: 0.911207, max value: 0.505183\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 1.17085481 (ave = 1.14436576)\n",
      "Loss_G = 0.70227337 (ave = 0.70351062)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.035677, max value: 0.070760\n",
      "D grad l2-norm: 0.913586, max value: 0.504498\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001180)\n",
      "Loss_D = 1.10945129 (ave = 1.13450513)\n",
      "Loss_G = 0.70173037 (ave = 0.70230459)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.047632, max value: 0.079727\n",
      "D grad l2-norm: 0.926211, max value: 0.504231\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 1.15813744 (ave = 1.13911779)\n",
      "Loss_G = 0.70220417 (ave = 0.70202473)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.051965, max value: 0.069002\n",
      "D grad l2-norm: 0.926842, max value: 0.504457\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.10145080 (ave = 1.13059511)\n",
      "Loss_G = 0.70141685 (ave = 0.70192951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.055608, max value: 0.079867\n",
      "D grad l2-norm: 0.929219, max value: 0.504056\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.10033607 (ave = 1.13010287)\n",
      "Loss_G = 0.69932818 (ave = 0.70051088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.071865, max value: 0.088915\n",
      "D grad l2-norm: 0.941790, max value: 0.503006\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.12291276 (ave = 1.12969353)\n",
      "Loss_G = 0.69995928 (ave = 0.70057092)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.082284, max value: 0.080303\n",
      "D grad l2-norm: 0.955938, max value: 0.503294\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.13301039 (ave = 1.12989645)\n",
      "Loss_G = 0.69993317 (ave = 0.70147439)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.100199, max value: 0.091112\n",
      "D grad l2-norm: 0.968453, max value: 0.503284\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.14124739 (ave = 1.12718160)\n",
      "Loss_G = 0.70320082 (ave = 0.70177836)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.106810, max value: 0.086617\n",
      "D grad l2-norm: 0.976037, max value: 0.504911\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 1.07805288 (ave = 1.11767986)\n",
      "Loss_G = 0.70214176 (ave = 0.70420612)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.120276, max value: 0.087513\n",
      "D grad l2-norm: 1.000579, max value: 0.504379\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.10498750 (ave = 1.11853042)\n",
      "Loss_G = 0.70630032 (ave = 0.70663059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.127352, max value: 0.100978\n",
      "D grad l2-norm: 1.016391, max value: 0.506415\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 1.10531795 (ave = 1.11302311)\n",
      "Loss_G = 0.71470308 (ave = 0.71020297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.117078, max value: 0.111819\n",
      "D grad l2-norm: 1.033742, max value: 0.510522\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 1.14591336 (ave = 1.10999684)\n",
      "Loss_G = 0.71822703 (ave = 0.71730049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.133384, max value: 0.119331\n",
      "D grad l2-norm: 1.063507, max value: 0.512260\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 1.09517241 (ave = 1.09494617)\n",
      "Loss_G = 0.72629136 (ave = 0.72489021)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.134362, max value: 0.122100\n",
      "D grad l2-norm: 1.088370, max value: 0.516188\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 1.07844472 (ave = 1.08317323)\n",
      "Loss_G = 0.74321586 (ave = 0.73908491)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.136356, max value: 0.128632\n",
      "D grad l2-norm: 1.120261, max value: 0.524325\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.01364982 (ave = 1.06011050)\n",
      "Loss_G = 0.75224137 (ave = 0.74929100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.144663, max value: 0.126129\n",
      "D grad l2-norm: 1.147167, max value: 0.528573\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 1.04330063 (ave = 1.05191784)\n",
      "Loss_G = 0.76703048 (ave = 0.76272328)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.158746, max value: 0.132761\n",
      "D grad l2-norm: 1.178329, max value: 0.535502\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001018)\n",
      "Loss_D = 1.08679438 (ave = 1.04493492)\n",
      "Loss_G = 0.77960646 (ave = 0.77363131)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.159195, max value: 0.133350\n",
      "D grad l2-norm: 1.198152, max value: 0.541317\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.04191399 (ave = 1.02561529)\n",
      "Loss_G = 0.79130530 (ave = 0.78714942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.168492, max value: 0.136600\n",
      "D grad l2-norm: 1.234572, max value: 0.546674\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.96906066 (ave = 1.00312554)\n",
      "Loss_G = 0.80765140 (ave = 0.80016876)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.169671, max value: 0.125871\n",
      "D grad l2-norm: 1.253491, max value: 0.554026\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.91565323 (ave = 0.98205773)\n",
      "Loss_G = 0.82104588 (ave = 0.81615038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.192281, max value: 0.115074\n",
      "D grad l2-norm: 1.293404, max value: 0.559964\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 1.01447320 (ave = 0.98290111)\n",
      "Loss_G = 0.83647287 (ave = 0.82995883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.204060, max value: 0.117678\n",
      "D grad l2-norm: 1.315461, max value: 0.566699\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.015s / 800 iters, (0.002976)\n",
      "Loss_D = 1.01315928 (ave = 0.96979249)\n",
      "Loss_G = 0.84650636 (ave = 0.84246607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.236008, max value: 0.113999\n",
      "D grad l2-norm: 1.352272, max value: 0.570995\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 0.86913466 (ave = 0.94198914)\n",
      "Loss_G = 0.85624814 (ave = 0.85098097)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.271594, max value: 0.115908\n",
      "D grad l2-norm: 1.383044, max value: 0.575160\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.94927955 (ave = 0.94468442)\n",
      "Loss_G = 0.85822260 (ave = 0.85889190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.328974, max value: 0.120849\n",
      "D grad l2-norm: 1.429506, max value: 0.575949\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.92767370 (ave = 0.93824617)\n",
      "Loss_G = 0.86073351 (ave = 0.86089211)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.355713, max value: 0.136950\n",
      "D grad l2-norm: 1.430864, max value: 0.576992\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 0.97525918 (ave = 0.94340546)\n",
      "Loss_G = 0.85754740 (ave = 0.85815611)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.415780, max value: 0.132554\n",
      "D grad l2-norm: 1.471105, max value: 0.575687\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.013s / 800 iters, (0.002693)\n",
      "Loss_D = 0.89151859 (ave = 0.93594440)\n",
      "Loss_G = 0.85030919 (ave = 0.85424507)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.464610, max value: 0.137604\n",
      "D grad l2-norm: 1.494367, max value: 0.572559\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.90059888 (ave = 0.94064397)\n",
      "Loss_G = 0.84030169 (ave = 0.84630861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.520172, max value: 0.137267\n",
      "D grad l2-norm: 1.517500, max value: 0.568207\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.89324546 (ave = 0.94861579)\n",
      "Loss_G = 0.83688277 (ave = 0.83911748)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.537342, max value: 0.133522\n",
      "D grad l2-norm: 1.515042, max value: 0.566735\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.95562744 (ave = 0.96635847)\n",
      "Loss_G = 0.81249017 (ave = 0.82324551)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.600207, max value: 0.147696\n",
      "D grad l2-norm: 1.537302, max value: 0.555975\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.02534604 (ave = 0.99004638)\n",
      "Loss_G = 0.80603522 (ave = 0.81022224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.617956, max value: 0.164331\n",
      "D grad l2-norm: 1.546508, max value: 0.553098\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 1.03168499 (ave = 1.00167032)\n",
      "Loss_G = 0.78899860 (ave = 0.79822115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.683247, max value: 0.169853\n",
      "D grad l2-norm: 1.586863, max value: 0.545317\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 1.02557433 (ave = 1.01516633)\n",
      "Loss_G = 0.78368056 (ave = 0.78646595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.687458, max value: 0.171404\n",
      "D grad l2-norm: 1.595356, max value: 0.542927\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002856)\n",
      "Loss_D = 1.08830810 (ave = 1.03221855)\n",
      "Loss_G = 0.77836764 (ave = 0.77938747)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.729228, max value: 0.169923\n",
      "D grad l2-norm: 1.632086, max value: 0.540371\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.96785617 (ave = 1.02402341)\n",
      "Loss_G = 0.77730167 (ave = 0.77413224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.742652, max value: 0.179304\n",
      "D grad l2-norm: 1.659662, max value: 0.539869\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001292)\n",
      "Loss_D = 0.95500290 (ave = 1.03082633)\n",
      "Loss_G = 0.77557731 (ave = 0.77517091)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.768611, max value: 0.201994\n",
      "D grad l2-norm: 1.694550, max value: 0.538901\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 1.02752912 (ave = 1.04026062)\n",
      "Loss_G = 0.77955878 (ave = 0.77877612)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.795156, max value: 0.201703\n",
      "D grad l2-norm: 1.757516, max value: 0.540732\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 1.10105443 (ave = 1.05152370)\n",
      "Loss_G = 0.79104811 (ave = 0.79065045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.825911, max value: 0.202503\n",
      "D grad l2-norm: 1.826005, max value: 0.546042\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001242)\n",
      "Loss_D = 1.03102493 (ave = 1.03864920)\n",
      "Loss_G = 0.81527507 (ave = 0.80315306)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.838527, max value: 0.203502\n",
      "D grad l2-norm: 1.886887, max value: 0.556769\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.92805475 (ave = 1.01193049)\n",
      "Loss_G = 0.83654433 (ave = 0.82513241)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.872549, max value: 0.209153\n",
      "D grad l2-norm: 1.992016, max value: 0.566037\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 1.05506337 (ave = 1.01393672)\n",
      "Loss_G = 0.86142957 (ave = 0.84938641)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.897456, max value: 0.220391\n",
      "D grad l2-norm: 2.096661, max value: 0.576758\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 1.12765694 (ave = 1.00602171)\n",
      "Loss_G = 0.88974172 (ave = 0.87911011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.916870, max value: 0.218540\n",
      "D grad l2-norm: 2.186784, max value: 0.588613\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.98299813 (ave = 0.97121937)\n",
      "Loss_G = 0.91736615 (ave = 0.90695840)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.021640, max value: 0.228791\n",
      "D grad l2-norm: 2.287590, max value: 0.599791\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.92030501 (ave = 0.94869212)\n",
      "Loss_G = 0.93891913 (ave = 0.93188888)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.130114, max value: 0.240310\n",
      "D grad l2-norm: 2.373266, max value: 0.608248\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 1.01340866 (ave = 0.95234572)\n",
      "Loss_G = 0.96252030 (ave = 0.95320249)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.234506, max value: 0.265354\n",
      "D grad l2-norm: 2.503641, max value: 0.617475\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.89481080 (ave = 0.93364949)\n",
      "Loss_G = 0.96906906 (ave = 0.96677438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.422300, max value: 0.313862\n",
      "D grad l2-norm: 2.619475, max value: 0.619863\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.93070155 (ave = 0.93501405)\n",
      "Loss_G = 0.97302568 (ave = 0.97760378)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.572334, max value: 0.371469\n",
      "D grad l2-norm: 2.670101, max value: 0.621229\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001185)\n",
      "Loss_D = 0.96001208 (ave = 0.94185046)\n",
      "Loss_G = 0.97124165 (ave = 0.97419953)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.729016, max value: 0.419541\n",
      "D grad l2-norm: 2.740927, max value: 0.620380\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.018s / 800 iters, (0.003644)\n",
      "Loss_D = 1.14501047 (ave = 0.97752167)\n",
      "Loss_G = 0.93968183 (ave = 0.95516957)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.968015, max value: 0.467165\n",
      "D grad l2-norm: 2.834382, max value: 0.607857\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 1.07669711 (ave = 0.99577322)\n",
      "Loss_G = 0.92348981 (ave = 0.93475883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:25\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.074164, max value: 0.481942\n",
      "D grad l2-norm: 2.859750, max value: 0.601031\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.04926527 (ave = 1.01567850)\n",
      "Loss_G = 0.89534706 (ave = 0.90587517)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.101651, max value: 0.496692\n",
      "D grad l2-norm: 2.852465, max value: 0.589621\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 1.08980250 (ave = 1.04692054)\n",
      "Loss_G = 0.85885394 (ave = 0.87241393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.233831, max value: 0.508215\n",
      "D grad l2-norm: 2.951660, max value: 0.574053\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001150)\n",
      "Loss_D = 1.05991459 (ave = 1.06744347)\n",
      "Loss_G = 0.84411246 (ave = 0.85446556)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.304700, max value: 0.511774\n",
      "D grad l2-norm: 3.011164, max value: 0.567536\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.00755751 (ave = 1.08257227)\n",
      "Loss_G = 0.85312599 (ave = 0.85654287)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.245255, max value: 0.501856\n",
      "D grad l2-norm: 3.026033, max value: 0.571657\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.10217845 (ave = 1.10345094)\n",
      "Loss_G = 0.87058771 (ave = 0.86751977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:26\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.227989, max value: 0.479835\n",
      "D grad l2-norm: 3.115837, max value: 0.579051\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 800 iters, (0.021)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 1.06014705 (ave = 1.09312742)\n",
      "Loss_G = 0.87218547 (ave = 0.87934039)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.363177, max value: 0.469107\n",
      "D grad l2-norm: 3.310359, max value: 0.579654\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.90291858 (ave = 1.06956389)\n",
      "Loss_G = 0.92587739 (ave = 0.90879447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.323450, max value: 0.467517\n",
      "D grad l2-norm: 3.352010, max value: 0.601747\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.22227788 (ave = 1.10313210)\n",
      "Loss_G = 0.95633823 (ave = 0.93882765)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.459782, max value: 0.435066\n",
      "D grad l2-norm: 3.507215, max value: 0.613759\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.008s / 800 iters, (0.001565)\n",
      "Loss_D = 0.96872514 (ave = 1.06790048)\n",
      "Loss_G = 0.93757969 (ave = 0.95199699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.623039, max value: 0.403557\n",
      "D grad l2-norm: 3.636146, max value: 0.605871\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 1.05648088 (ave = 1.07383153)\n",
      "Loss_G = 0.96634525 (ave = 0.96396583)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.632454, max value: 0.374925\n",
      "D grad l2-norm: 3.661241, max value: 0.617615\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 1.12211609 (ave = 1.08355737)\n",
      "Loss_G = 0.96589679 (ave = 0.96723850)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.562766, max value: 0.340100\n",
      "D grad l2-norm: 3.700745, max value: 0.617172\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001253)\n",
      "Loss_D = 1.10223937 (ave = 1.07769394)\n",
      "Loss_G = 0.99665099 (ave = 0.99275124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.633206, max value: 0.365686\n",
      "D grad l2-norm: 3.808329, max value: 0.628982\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 0.98173976 (ave = 1.05515451)\n",
      "Loss_G = 1.00760043 (ave = 1.00675435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.702817, max value: 0.377538\n",
      "D grad l2-norm: 3.829244, max value: 0.632745\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.99246675 (ave = 1.05317701)\n",
      "Loss_G = 1.01817465 (ave = 1.01265929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.900156, max value: 0.403469\n",
      "D grad l2-norm: 4.014919, max value: 0.636858\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001150)\n",
      "Loss_D = 1.07724023 (ave = 1.07174811)\n",
      "Loss_G = 1.00863266 (ave = 1.01388056)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:27\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.015552, max value: 0.404921\n",
      "D grad l2-norm: 4.114598, max value: 0.633770\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 0.96744299 (ave = 1.05948250)\n",
      "Loss_G = 1.04941869 (ave = 1.02599580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.035908, max value: 0.412859\n",
      "D grad l2-norm: 4.108029, max value: 0.648348\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001171)\n",
      "Loss_D = 1.15394163 (ave = 1.08347392)\n",
      "Loss_G = 1.03381014 (ave = 1.04021800)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.189253, max value: 0.418208\n",
      "D grad l2-norm: 4.271403, max value: 0.642896\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 1.02050948 (ave = 1.07437017)\n",
      "Loss_G = 1.05560017 (ave = 1.04418328)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.096002, max value: 0.408726\n",
      "D grad l2-norm: 4.264044, max value: 0.650484\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 1.09956741 (ave = 1.08041632)\n",
      "Loss_G = 1.06958091 (ave = 1.05777392)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.158143, max value: 0.384816\n",
      "D grad l2-norm: 4.419066, max value: 0.655234\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001214)\n",
      "Loss_D = 1.06745100 (ave = 1.07232900)\n",
      "Loss_G = 1.06831419 (ave = 1.07620769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.131145, max value: 0.356164\n",
      "D grad l2-norm: 4.475531, max value: 0.654858\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002742)\n",
      "Loss_D = 1.01002860 (ave = 1.06223114)\n",
      "Loss_G = 1.11660278 (ave = 1.10252442)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.101458, max value: 0.332199\n",
      "D grad l2-norm: 4.677447, max value: 0.671166\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.94287264 (ave = 1.03833230)\n",
      "Loss_G = 1.14350355 (ave = 1.12498615)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.977284, max value: 0.306287\n",
      "D grad l2-norm: 4.695840, max value: 0.679780\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 1.05493021 (ave = 1.03663704)\n",
      "Loss_G = 1.18405974 (ave = 1.16478493)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.089102, max value: 0.286302\n",
      "D grad l2-norm: 4.923496, max value: 0.692703\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 1.23609328 (ave = 1.05242114)\n",
      "Loss_G = 1.19730461 (ave = 1.19616582)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.038389, max value: 0.269760\n",
      "D grad l2-norm: 5.042539, max value: 0.696464\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.89628839 (ave = 0.99076145)\n",
      "Loss_G = 1.25272620 (ave = 1.22526970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:28\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.809843, max value: 0.262878\n",
      "D grad l2-norm: 4.967035, max value: 0.712944\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 0.90639579 (ave = 0.97091526)\n",
      "Loss_G = 1.27832150 (ave = 1.26438377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.006419, max value: 0.305800\n",
      "D grad l2-norm: 5.135367, max value: 0.720177\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002712)\n",
      "Loss_D = 0.94474471 (ave = 0.96388857)\n",
      "Loss_G = 1.28529239 (ave = 1.29051759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.067772, max value: 0.347503\n",
      "D grad l2-norm: 5.041872, max value: 0.721835\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.016s / 800 iters, (0.003133)\n",
      "Loss_D = 0.93425834 (ave = 0.95664126)\n",
      "Loss_G = 1.28428674 (ave = 1.29198575)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.112220, max value: 0.374748\n",
      "D grad l2-norm: 4.941993, max value: 0.721101\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.013s / 800 iters, (0.002694)\n",
      "Loss_D = 0.98563939 (ave = 0.96612555)\n",
      "Loss_G = 1.26557112 (ave = 1.27701173)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.469876, max value: 0.402953\n",
      "D grad l2-norm: 5.111967, max value: 0.715909\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.90207124 (ave = 0.95858525)\n",
      "Loss_G = 1.28318679 (ave = 1.26790724)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.571429, max value: 0.439516\n",
      "D grad l2-norm: 5.140318, max value: 0.719914\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000968)\n",
      "Loss_D = 1.04279041 (ave = 0.98510082)\n",
      "Loss_G = 1.23139977 (ave = 1.24052579)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.778848, max value: 0.468126\n",
      "D grad l2-norm: 5.135081, max value: 0.705514\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.88926589 (ave = 0.96227722)\n",
      "Loss_G = 1.24048567 (ave = 1.25042980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.833935, max value: 0.503967\n",
      "D grad l2-norm: 5.174778, max value: 0.708116\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 1.02056646 (ave = 0.97419196)\n",
      "Loss_G = 1.25382578 (ave = 1.25190573)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.735055, max value: 0.495336\n",
      "D grad l2-norm: 5.096022, max value: 0.711891\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 1.04570889 (ave = 0.97110416)\n",
      "Loss_G = 1.25635457 (ave = 1.26150494)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.841582, max value: 0.503352\n",
      "D grad l2-norm: 5.119746, max value: 0.713106\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.96687502 (ave = 0.96009471)\n",
      "Loss_G = 1.25399518 (ave = 1.25938265)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:29\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.008735, max value: 0.506830\n",
      "D grad l2-norm: 5.108689, max value: 0.711750\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.88322216 (ave = 0.95152348)\n",
      "Loss_G = 1.22496307 (ave = 1.24666634)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.974164, max value: 0.522477\n",
      "D grad l2-norm: 4.924605, max value: 0.703350\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.93750709 (ave = 0.96423573)\n",
      "Loss_G = 1.22103524 (ave = 1.22312891)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.951580, max value: 0.533026\n",
      "D grad l2-norm: 4.824767, max value: 0.702141\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.00410616 (ave = 0.97416883)\n",
      "Loss_G = 1.16792178 (ave = 1.18818619)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.949833, max value: 0.534285\n",
      "D grad l2-norm: 4.711318, max value: 0.685228\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 1.00370693 (ave = 0.98877314)\n",
      "Loss_G = 1.16152155 (ave = 1.16191576)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.841445, max value: 0.535321\n",
      "D grad l2-norm: 4.613093, max value: 0.683859\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.91203630 (ave = 0.97893029)\n",
      "Loss_G = 1.14326596 (ave = 1.14915879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.752246, max value: 0.520373\n",
      "D grad l2-norm: 4.494489, max value: 0.678250\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 1.14050806 (ave = 1.01274415)\n",
      "Loss_G = 1.10667467 (ave = 1.13095858)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.511007, max value: 0.502547\n",
      "D grad l2-norm: 4.202422, max value: 0.667065\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.92267895 (ave = 0.98769062)\n",
      "Loss_G = 1.10465026 (ave = 1.11006622)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.412723, max value: 0.461136\n",
      "D grad l2-norm: 4.134007, max value: 0.666386\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 1.13760459 (ave = 1.01511806)\n",
      "Loss_G = 1.08435678 (ave = 1.09143388)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.514440, max value: 0.438646\n",
      "D grad l2-norm: 4.086347, max value: 0.659246\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 1.14375937 (ave = 1.02922893)\n",
      "Loss_G = 1.03837752 (ave = 1.05684671)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.417331, max value: 0.420180\n",
      "D grad l2-norm: 3.920014, max value: 0.643616\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.11104167 (ave = 1.03114774)\n",
      "Loss_G = 1.01625383 (ave = 1.02250581)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:30\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.255505, max value: 0.403041\n",
      "D grad l2-norm: 3.809944, max value: 0.635433\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 1.00221992 (ave = 1.02868690)\n",
      "Loss_G = 1.00777316 (ave = 1.01283789)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.149763, max value: 0.394666\n",
      "D grad l2-norm: 3.767271, max value: 0.632596\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.04255652 (ave = 1.02945250)\n",
      "Loss_G = 1.01936686 (ave = 1.00814011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.284611, max value: 0.403514\n",
      "D grad l2-norm: 3.854774, max value: 0.637181\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.97618473 (ave = 1.02032999)\n",
      "Loss_G = 0.98493958 (ave = 0.99380660)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.228421, max value: 0.417114\n",
      "D grad l2-norm: 3.777187, max value: 0.624734\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 800 iters, (0.027)\tData load 0.006s / 800 iters, (0.001169)\n",
      "Loss_D = 0.91777354 (ave = 1.01793742)\n",
      "Loss_G = 0.99660861 (ave = 1.00158736)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.110618, max value: 0.419741\n",
      "D grad l2-norm: 3.842147, max value: 0.629200\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.99975073 (ave = 1.01078118)\n",
      "Loss_G = 1.03436482 (ave = 1.02721581)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.143001, max value: 0.419986\n",
      "D grad l2-norm: 4.019748, max value: 0.642641\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.91773874 (ave = 0.98043793)\n",
      "Loss_G = 1.07913446 (ave = 1.06348515)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:31\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.305031, max value: 0.444577\n",
      "D grad l2-norm: 4.252540, max value: 0.658100\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.82075930 (ave = 0.94360716)\n",
      "Loss_G = 1.12702954 (ave = 1.11678414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.464862, max value: 0.437917\n",
      "D grad l2-norm: 4.425808, max value: 0.674350\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.90719843 (ave = 0.93622559)\n",
      "Loss_G = 1.16090095 (ave = 1.14323444)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.707468, max value: 0.460538\n",
      "D grad l2-norm: 4.570178, max value: 0.684772\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.89443731 (ave = 0.92245865)\n",
      "Loss_G = 1.15442646 (ave = 1.15518386)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.903681, max value: 0.465349\n",
      "D grad l2-norm: 4.598262, max value: 0.682661\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.95098108 (ave = 0.92808107)\n",
      "Loss_G = 1.13492203 (ave = 1.15136135)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.876022, max value: 0.477144\n",
      "D grad l2-norm: 4.560848, max value: 0.676284\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001027)\n",
      "Loss_D = 0.91379488 (ave = 0.91928538)\n",
      "Loss_G = 1.13732243 (ave = 1.13327894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.009821, max value: 0.495477\n",
      "D grad l2-norm: 4.667173, max value: 0.677150\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.00896847 (ave = 0.93484254)\n",
      "Loss_G = 1.11554360 (ave = 1.12860684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.235493, max value: 0.500507\n",
      "D grad l2-norm: 4.740398, max value: 0.669891\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 0.99950373 (ave = 0.93707834)\n",
      "Loss_G = 1.09382331 (ave = 1.11018252)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.469109, max value: 0.498107\n",
      "D grad l2-norm: 4.765255, max value: 0.662680\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.81219828 (ave = 0.93800306)\n",
      "Loss_G = 1.05416465 (ave = 1.07781649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.473403, max value: 0.500088\n",
      "D grad l2-norm: 4.698204, max value: 0.647521\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.01576960 (ave = 0.97345300)\n",
      "Loss_G = 1.05437708 (ave = 1.05257864)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.527254, max value: 0.529047\n",
      "D grad l2-norm: 4.780163, max value: 0.648881\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001007)\n",
      "Loss_D = 0.95104361 (ave = 0.97696790)\n",
      "Loss_G = 1.06254125 (ave = 1.04710422)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.631078, max value: 0.573632\n",
      "D grad l2-norm: 4.837494, max value: 0.650458\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.05412459 (ave = 0.99559507)\n",
      "Loss_G = 1.04373252 (ave = 1.04904449)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:32\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.727134, max value: 0.619152\n",
      "D grad l2-norm: 4.871244, max value: 0.643153\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.010s / 800 iters, (0.001930)\n",
      "Loss_D = 0.95998204 (ave = 0.99395155)\n",
      "Loss_G = 1.04195702 (ave = 1.03519249)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.887147, max value: 0.638884\n",
      "D grad l2-norm: 5.000647, max value: 0.642425\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.93817127 (ave = 0.99656745)\n",
      "Loss_G = 1.06786537 (ave = 1.05611026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.027192, max value: 0.657316\n",
      "D grad l2-norm: 5.219908, max value: 0.651744\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.00134683 (ave = 0.99447063)\n",
      "Loss_G = 1.08236647 (ave = 1.07102416)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.689707, max value: 0.641088\n",
      "D grad l2-norm: 5.091258, max value: 0.658128\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001235)\n",
      "Loss_D = 0.87232709 (ave = 0.96406630)\n",
      "Loss_G = 1.09441841 (ave = 1.08984394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.457203, max value: 0.615782\n",
      "D grad l2-norm: 5.014416, max value: 0.661639\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 800 iters, (0.024)\tData load 0.018s / 800 iters, (0.003675)\n",
      "Loss_D = 0.99267220 (ave = 0.97736242)\n",
      "Loss_G = 1.08150065 (ave = 1.10685167)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.324557, max value: 0.588396\n",
      "D grad l2-norm: 4.994206, max value: 0.657228\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001130)\n",
      "Loss_D = 1.01889682 (ave = 0.96930749)\n",
      "Loss_G = 1.13302088 (ave = 1.11909423)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:33\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.526706, max value: 0.566740\n",
      "D grad l2-norm: 5.230503, max value: 0.674398\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.94766730 (ave = 0.96596273)\n",
      "Loss_G = 1.15063715 (ave = 1.14801142)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.384264, max value: 0.550194\n",
      "D grad l2-norm: 4.994530, max value: 0.679590\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001132)\n",
      "Loss_D = 1.01986098 (ave = 0.97937095)\n",
      "Loss_G = 1.09601164 (ave = 1.12419074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.455160, max value: 0.510421\n",
      "D grad l2-norm: 5.058179, max value: 0.661741\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.97137845 (ave = 0.98056980)\n",
      "Loss_G = 1.14443552 (ave = 1.12589061)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.315018, max value: 0.454697\n",
      "D grad l2-norm: 5.110536, max value: 0.678246\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 0.91790545 (ave = 0.96700110)\n",
      "Loss_G = 1.12592280 (ave = 1.14603086)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.223706, max value: 0.429815\n",
      "D grad l2-norm: 5.179119, max value: 0.671863\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.047s / 800 iters, (0.009)\tData load 0.005s / 800 iters, (0.000946)\n",
      "Loss_D = 0.86687791 (ave = 0.95462632)\n",
      "Loss_G = 1.17394519 (ave = 1.15974188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.299869, max value: 0.403271\n",
      "D grad l2-norm: 5.374330, max value: 0.687585\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.92799270 (ave = 0.95480188)\n",
      "Loss_G = 1.18037724 (ave = 1.17560246)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.099073, max value: 0.411514\n",
      "D grad l2-norm: 5.212536, max value: 0.689851\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.84361088 (ave = 0.93635323)\n",
      "Loss_G = 1.18407798 (ave = 1.16999464)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.224846, max value: 0.424438\n",
      "D grad l2-norm: 5.290459, max value: 0.690632\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 1.09383106 (ave = 0.97213448)\n",
      "Loss_G = 1.17000151 (ave = 1.17013769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.319103, max value: 0.455895\n",
      "D grad l2-norm: 5.228613, max value: 0.686464\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.05137503 (ave = 0.98090601)\n",
      "Loss_G = 1.14181113 (ave = 1.15336819)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.398628, max value: 0.426019\n",
      "D grad l2-norm: 5.249826, max value: 0.677305\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.87269700 (ave = 0.96515326)\n",
      "Loss_G = 1.15255547 (ave = 1.14107993)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:34\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.498474, max value: 0.420016\n",
      "D grad l2-norm: 5.403041, max value: 0.681057\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001023)\n",
      "Loss_D = 1.00078869 (ave = 0.99965985)\n",
      "Loss_G = 1.12619805 (ave = 1.12413306)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.665543, max value: 0.416710\n",
      "D grad l2-norm: 5.360609, max value: 0.671929\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.99610651 (ave = 1.01374919)\n",
      "Loss_G = 1.07108641 (ave = 1.08084166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.647156, max value: 0.415359\n",
      "D grad l2-norm: 5.162724, max value: 0.653994\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 0.98379767 (ave = 1.02911654)\n",
      "Loss_G = 1.04262006 (ave = 1.05584598)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.613445, max value: 0.447462\n",
      "D grad l2-norm: 5.144526, max value: 0.643754\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 0.91157568 (ave = 1.04564433)\n",
      "Loss_G = 1.03254795 (ave = 1.03491323)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.395754, max value: 0.474668\n",
      "D grad l2-norm: 5.072599, max value: 0.640122\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 1.07386875 (ave = 1.06637516)\n",
      "Loss_G = 1.06459832 (ave = 1.05460653)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.501198, max value: 0.508319\n",
      "D grad l2-norm: 5.322624, max value: 0.651812\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 1.14113367 (ave = 1.06842523)\n",
      "Loss_G = 1.06702399 (ave = 1.05845075)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.346119, max value: 0.539281\n",
      "D grad l2-norm: 5.249280, max value: 0.652289\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001300)\n",
      "Loss_D = 1.01069963 (ave = 1.04771791)\n",
      "Loss_G = 1.09558904 (ave = 1.07587552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.313221, max value: 0.551176\n",
      "D grad l2-norm: 5.296934, max value: 0.662866\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001214)\n",
      "Loss_D = 1.01601052 (ave = 1.04182751)\n",
      "Loss_G = 1.12933993 (ave = 1.10346291)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:35\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.285616, max value: 0.561569\n",
      "D grad l2-norm: 5.401818, max value: 0.673639\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 1.03687084 (ave = 1.02752433)\n",
      "Loss_G = 1.15329611 (ave = 1.12752180)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.108362, max value: 0.578003\n",
      "D grad l2-norm: 5.404239, max value: 0.681407\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 1.13405979 (ave = 1.02933234)\n",
      "Loss_G = 1.17772448 (ave = 1.15201976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.080636, max value: 0.576165\n",
      "D grad l2-norm: 5.550404, max value: 0.689435\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002787)\n",
      "Loss_D = 0.96395767 (ave = 0.98932849)\n",
      "Loss_G = 1.18545806 (ave = 1.16788795)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.008891, max value: 0.573696\n",
      "D grad l2-norm: 5.541424, max value: 0.691286\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002794)\n",
      "Loss_D = 0.91747594 (ave = 0.96929486)\n",
      "Loss_G = 1.20109594 (ave = 1.18758812)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.019223, max value: 0.543370\n",
      "D grad l2-norm: 5.669395, max value: 0.696032\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 0.88776666 (ave = 0.95352031)\n",
      "Loss_G = 1.20759523 (ave = 1.19665508)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.969314, max value: 0.521090\n",
      "D grad l2-norm: 5.643993, max value: 0.698291\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.010s / 800 iters, (0.001962)\n",
      "Loss_D = 0.97138393 (ave = 0.95603825)\n",
      "Loss_G = 1.22278965 (ave = 1.22051802)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.878720, max value: 0.495490\n",
      "D grad l2-norm: 5.608084, max value: 0.702823\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 0.90077072 (ave = 0.93232958)\n",
      "Loss_G = 1.22831321 (ave = 1.23472359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.932058, max value: 0.468939\n",
      "D grad l2-norm: 5.592701, max value: 0.704511\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.017s / 800 iters, (0.003489)\n",
      "Loss_D = 0.98932827 (ave = 0.93643351)\n",
      "Loss_G = 1.21973288 (ave = 1.22340939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.999508, max value: 0.483885\n",
      "D grad l2-norm: 5.517026, max value: 0.702224\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.009s / 800 iters, (0.001858)\n",
      "Loss_D = 0.93591797 (ave = 0.93045614)\n",
      "Loss_G = 1.21165907 (ave = 1.20556314)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:36\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.988642, max value: 0.485974\n",
      "D grad l2-norm: 5.332885, max value: 0.699610\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.90052390 (ave = 0.94235362)\n",
      "Loss_G = 1.15287328 (ave = 1.16552083)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.068117, max value: 0.480138\n",
      "D grad l2-norm: 5.146310, max value: 0.681083\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001117)\n",
      "Loss_D = 0.98571742 (ave = 0.96235605)\n",
      "Loss_G = 1.13513589 (ave = 1.13304944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.094221, max value: 0.472698\n",
      "D grad l2-norm: 5.077921, max value: 0.675306\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.93228710 (ave = 0.96982605)\n",
      "Loss_G = 1.05618668 (ave = 1.07686913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.106373, max value: 0.440221\n",
      "D grad l2-norm: 4.925711, max value: 0.648745\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 0.98526001 (ave = 0.99277689)\n",
      "Loss_G = 1.03362191 (ave = 1.05487516)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.016881, max value: 0.433444\n",
      "D grad l2-norm: 4.737604, max value: 0.641457\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.95555782 (ave = 1.02025367)\n",
      "Loss_G = 1.00131023 (ave = 1.02039788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.009493, max value: 0.461186\n",
      "D grad l2-norm: 4.648594, max value: 0.628911\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001233)\n",
      "Loss_D = 1.02733886 (ave = 1.03683159)\n",
      "Loss_G = 1.01310027 (ave = 1.01238358)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.043209, max value: 0.480973\n",
      "D grad l2-norm: 4.643100, max value: 0.633625\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.011s / 800 iters, (0.002134)\n",
      "Loss_D = 0.94798410 (ave = 1.03888416)\n",
      "Loss_G = 1.00658298 (ave = 0.99880008)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.060320, max value: 0.495993\n",
      "D grad l2-norm: 4.633040, max value: 0.630833\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.05202949 (ave = 1.05365396)\n",
      "Loss_G = 0.97977215 (ave = 0.98770161)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.128206, max value: 0.517743\n",
      "D grad l2-norm: 4.660542, max value: 0.621565\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 1.02708471 (ave = 1.05501413)\n",
      "Loss_G = 1.00151587 (ave = 0.98560792)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.904520, max value: 0.512640\n",
      "D grad l2-norm: 4.593886, max value: 0.630186\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.04559469 (ave = 1.04657416)\n",
      "Loss_G = 1.02882648 (ave = 1.00726706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:37\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.996094, max value: 0.533982\n",
      "D grad l2-norm: 4.738545, max value: 0.640009\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.96120560 (ave = 1.02541800)\n",
      "Loss_G = 1.05970836 (ave = 1.05545940)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.092067, max value: 0.572035\n",
      "D grad l2-norm: 4.855681, max value: 0.650841\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.09687483 (ave = 1.03390070)\n",
      "Loss_G = 1.07263899 (ave = 1.06261232)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.251782, max value: 0.605948\n",
      "D grad l2-norm: 4.907699, max value: 0.654970\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.97154927 (ave = 1.01871164)\n",
      "Loss_G = 1.06857908 (ave = 1.06974456)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.213235, max value: 0.574955\n",
      "D grad l2-norm: 4.951985, max value: 0.653211\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.87403667 (ave = 0.98969576)\n",
      "Loss_G = 1.09268844 (ave = 1.08287523)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.137821, max value: 0.568535\n",
      "D grad l2-norm: 4.993907, max value: 0.661510\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 0.74966997 (ave = 0.96975855)\n",
      "Loss_G = 1.11018384 (ave = 1.09229102)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.291060, max value: 0.558395\n",
      "D grad l2-norm: 5.105973, max value: 0.667568\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.05899715 (ave = 1.01195369)\n",
      "Loss_G = 1.12211466 (ave = 1.11795530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.387303, max value: 0.534465\n",
      "D grad l2-norm: 5.213704, max value: 0.671608\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.94925708 (ave = 0.99453524)\n",
      "Loss_G = 1.10233307 (ave = 1.10757394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.148763, max value: 0.494831\n",
      "D grad l2-norm: 5.028236, max value: 0.665123\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.87948823 (ave = 0.98439939)\n",
      "Loss_G = 1.11107349 (ave = 1.11114821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.305865, max value: 0.539877\n",
      "D grad l2-norm: 5.171870, max value: 0.667813\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001146)\n",
      "Loss_D = 1.02369738 (ave = 1.00525436)\n",
      "Loss_G = 1.09601367 (ave = 1.10712590)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.356759, max value: 0.573622\n",
      "D grad l2-norm: 5.183936, max value: 0.662979\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 1.11359787 (ave = 1.02122324)\n",
      "Loss_G = 1.11269891 (ave = 1.10694852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:38\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.212274, max value: 0.589227\n",
      "D grad l2-norm: 5.160760, max value: 0.667526\n",
      "üîÅ TSCV for Asset 10\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 1.37187064 (ave = 1.38240676)\n",
      "Loss_G = 0.66808176 (ave = 0.66860856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963356, max value: 0.028670\n",
      "D grad l2-norm: 0.688566, max value: 0.487305\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 1.36738658 (ave = 1.36852257)\n",
      "Loss_G = 0.66602445 (ave = 0.66668942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961789, max value: 0.032958\n",
      "D grad l2-norm: 0.685313, max value: 0.486250\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001104)\n",
      "Loss_D = 1.34297585 (ave = 1.35295558)\n",
      "Loss_G = 0.66425538 (ave = 0.66510247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966447, max value: 0.036116\n",
      "D grad l2-norm: 0.685101, max value: 0.485341\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 1.34563684 (ave = 1.34094980)\n",
      "Loss_G = 0.66277206 (ave = 0.66342305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962754, max value: 0.025500\n",
      "D grad l2-norm: 0.685781, max value: 0.484577\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.31586659 (ave = 1.32517858)\n",
      "Loss_G = 0.66188121 (ave = 0.66214504)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968213, max value: 0.030695\n",
      "D grad l2-norm: 0.685861, max value: 0.484117\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001161)\n",
      "Loss_D = 1.30209374 (ave = 1.31242876)\n",
      "Loss_G = 0.66081345 (ave = 0.66150049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.964744, max value: 0.026426\n",
      "D grad l2-norm: 0.687827, max value: 0.483565\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001084)\n",
      "Loss_D = 1.28943682 (ave = 1.30016224)\n",
      "Loss_G = 0.66048115 (ave = 0.66079289)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968459, max value: 0.035101\n",
      "D grad l2-norm: 0.690894, max value: 0.483393\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001112)\n",
      "Loss_D = 1.28535509 (ave = 1.28918710)\n",
      "Loss_G = 0.66036469 (ave = 0.66039866)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967967, max value: 0.028797\n",
      "D grad l2-norm: 0.695506, max value: 0.483333\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.26486254 (ave = 1.27623489)\n",
      "Loss_G = 0.66121161 (ave = 0.66104497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:39\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968015, max value: 0.031850\n",
      "D grad l2-norm: 0.696587, max value: 0.483770\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.23166525 (ave = 1.26263034)\n",
      "Loss_G = 0.66158688 (ave = 0.66110042)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963194, max value: 0.031648\n",
      "D grad l2-norm: 0.703803, max value: 0.483963\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 1.26040971 (ave = 1.25668118)\n",
      "Loss_G = 0.66219157 (ave = 0.66168996)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969058, max value: 0.028932\n",
      "D grad l2-norm: 0.708950, max value: 0.484275\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001114)\n",
      "Loss_D = 1.23528469 (ave = 1.24425278)\n",
      "Loss_G = 0.66195428 (ave = 0.66181238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970103, max value: 0.026949\n",
      "D grad l2-norm: 0.714182, max value: 0.484150\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001091)\n",
      "Loss_D = 1.22374213 (ave = 1.23320327)\n",
      "Loss_G = 0.66461885 (ave = 0.66364038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967081, max value: 0.026523\n",
      "D grad l2-norm: 0.719267, max value: 0.485524\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001057)\n",
      "Loss_D = 1.21526277 (ave = 1.22295496)\n",
      "Loss_G = 0.66483420 (ave = 0.66418562)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974922, max value: 0.023523\n",
      "D grad l2-norm: 0.723944, max value: 0.485634\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001217)\n",
      "Loss_D = 1.21093750 (ave = 1.21365578)\n",
      "Loss_G = 0.66635025 (ave = 0.66589766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975370, max value: 0.027485\n",
      "D grad l2-norm: 0.732087, max value: 0.486411\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.009s / 800 iters, (0.001768)\n",
      "Loss_D = 1.18898630 (ave = 1.20173211)\n",
      "Loss_G = 0.66863286 (ave = 0.66792213)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966387, max value: 0.031219\n",
      "D grad l2-norm: 0.738317, max value: 0.487584\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 1.22668910 (ave = 1.19758210)\n",
      "Loss_G = 0.66956347 (ave = 0.66941680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974644, max value: 0.032330\n",
      "D grad l2-norm: 0.745564, max value: 0.488054\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 1.17804241 (ave = 1.18303499)\n",
      "Loss_G = 0.67233992 (ave = 0.67211217)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:40\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972024, max value: 0.029166\n",
      "D grad l2-norm: 0.753826, max value: 0.489477\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 800 iters, (0.026)\tData load 0.014s / 800 iters, (0.002795)\n",
      "Loss_D = 1.18673229 (ave = 1.17528613)\n",
      "Loss_G = 0.67602879 (ave = 0.67489202)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975098, max value: 0.039835\n",
      "D grad l2-norm: 0.760550, max value: 0.491356\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.022s / 800 iters, (0.004423)\n",
      "Loss_D = 1.11594355 (ave = 1.15733290)\n",
      "Loss_G = 0.67987430 (ave = 0.67795988)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973155, max value: 0.031125\n",
      "D grad l2-norm: 0.772341, max value: 0.493305\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 1.13234174 (ave = 1.15028622)\n",
      "Loss_G = 0.68204033 (ave = 0.68046275)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972598, max value: 0.035813\n",
      "D grad l2-norm: 0.784423, max value: 0.494400\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.14483213 (ave = 1.14423594)\n",
      "Loss_G = 0.68519843 (ave = 0.68393023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.978878, max value: 0.032584\n",
      "D grad l2-norm: 0.793570, max value: 0.495990\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.011s / 800 iters, (0.002258)\n",
      "Loss_D = 1.11370134 (ave = 1.13056257)\n",
      "Loss_G = 0.68882275 (ave = 0.68734038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980845, max value: 0.039780\n",
      "D grad l2-norm: 0.804905, max value: 0.497815\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001039)\n",
      "Loss_D = 1.11368525 (ave = 1.12178347)\n",
      "Loss_G = 0.69391948 (ave = 0.69184694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979919, max value: 0.042096\n",
      "D grad l2-norm: 0.816583, max value: 0.500366\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001003)\n",
      "Loss_D = 1.05006635 (ave = 1.10417104)\n",
      "Loss_G = 0.69878185 (ave = 0.69592946)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:41\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.983746, max value: 0.042740\n",
      "D grad l2-norm: 0.831691, max value: 0.502790\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001170)\n",
      "Loss_D = 1.10868371 (ave = 1.10320387)\n",
      "Loss_G = 0.70347625 (ave = 0.70127811)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985061, max value: 0.042868\n",
      "D grad l2-norm: 0.843047, max value: 0.505114\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 1.08657825 (ave = 1.09059689)\n",
      "Loss_G = 0.70784354 (ave = 0.70648276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980877, max value: 0.046937\n",
      "D grad l2-norm: 0.861197, max value: 0.507264\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.09182858 (ave = 1.08306189)\n",
      "Loss_G = 0.71455073 (ave = 0.71181453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.981907, max value: 0.043696\n",
      "D grad l2-norm: 0.877866, max value: 0.510561\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 1.02996576 (ave = 1.06484210)\n",
      "Loss_G = 0.72183448 (ave = 0.71845031)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.982019, max value: 0.038583\n",
      "D grad l2-norm: 0.891638, max value: 0.514118\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.07727921 (ave = 1.06097338)\n",
      "Loss_G = 0.72880054 (ave = 0.72537227)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993097, max value: 0.045265\n",
      "D grad l2-norm: 0.912752, max value: 0.517480\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 0.97290105 (ave = 1.03816346)\n",
      "Loss_G = 0.73529196 (ave = 0.73148237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.994830, max value: 0.050244\n",
      "D grad l2-norm: 0.930195, max value: 0.520605\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.03668427 (ave = 1.03577085)\n",
      "Loss_G = 0.74337810 (ave = 0.73981164)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991208, max value: 0.050751\n",
      "D grad l2-norm: 0.951106, max value: 0.524471\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 1.03880525 (ave = 1.02519717)\n",
      "Loss_G = 0.75170577 (ave = 0.74763854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.998191, max value: 0.054481\n",
      "D grad l2-norm: 0.976330, max value: 0.528405\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 1.01612616 (ave = 1.01188757)\n",
      "Loss_G = 0.75950110 (ave = 0.75535880)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.003502, max value: 0.055940\n",
      "D grad l2-norm: 0.998243, max value: 0.532072\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 0.98198891 (ave = 0.99721453)\n",
      "Loss_G = 0.76807529 (ave = 0.76424305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:42\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.009854, max value: 0.052752\n",
      "D grad l2-norm: 1.015425, max value: 0.536062\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.03090954 (ave = 0.99289253)\n",
      "Loss_G = 0.77743006 (ave = 0.77342039)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.008326, max value: 0.058038\n",
      "D grad l2-norm: 1.031271, max value: 0.540385\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.014s / 800 iters, (0.002864)\n",
      "Loss_D = 0.96720767 (ave = 0.97475734)\n",
      "Loss_G = 0.78271091 (ave = 0.78002254)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.025243, max value: 0.060568\n",
      "D grad l2-norm: 1.059239, max value: 0.542795\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.93114448 (ave = 0.96084231)\n",
      "Loss_G = 0.79006726 (ave = 0.78757807)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.027403, max value: 0.055114\n",
      "D grad l2-norm: 1.074445, max value: 0.546151\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.96913242 (ave = 0.95674464)\n",
      "Loss_G = 0.79972196 (ave = 0.79589280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.037480, max value: 0.062529\n",
      "D grad l2-norm: 1.093748, max value: 0.550513\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.92820156 (ave = 0.94356040)\n",
      "Loss_G = 0.80698031 (ave = 0.80195311)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.044132, max value: 0.072825\n",
      "D grad l2-norm: 1.115188, max value: 0.553765\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.86795688 (ave = 0.92717717)\n",
      "Loss_G = 0.80998796 (ave = 0.80816183)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.058866, max value: 0.074424\n",
      "D grad l2-norm: 1.136340, max value: 0.555089\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.90502453 (ave = 0.92591860)\n",
      "Loss_G = 0.81650615 (ave = 0.81471300)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.068330, max value: 0.067390\n",
      "D grad l2-norm: 1.150955, max value: 0.557980\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 0.97351241 (ave = 0.92646556)\n",
      "Loss_G = 0.81991673 (ave = 0.81807313)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:43\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.082311, max value: 0.079658\n",
      "D grad l2-norm: 1.176355, max value: 0.559468\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.008s / 800 iters, (0.001545)\n",
      "Loss_D = 0.88284677 (ave = 0.91060185)\n",
      "Loss_G = 0.82001197 (ave = 0.81915294)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.114848, max value: 0.088394\n",
      "D grad l2-norm: 1.183306, max value: 0.559498\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001125)\n",
      "Loss_D = 0.89624357 (ave = 0.90820738)\n",
      "Loss_G = 0.82221138 (ave = 0.82068986)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.126468, max value: 0.084422\n",
      "D grad l2-norm: 1.190727, max value: 0.560468\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 0.90967333 (ave = 0.90795171)\n",
      "Loss_G = 0.82010561 (ave = 0.82203406)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.157879, max value: 0.100972\n",
      "D grad l2-norm: 1.219429, max value: 0.559514\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 0.86828804 (ave = 0.90023165)\n",
      "Loss_G = 0.81835473 (ave = 0.81885597)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.175369, max value: 0.101278\n",
      "D grad l2-norm: 1.231461, max value: 0.558714\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.89881122 (ave = 0.90403782)\n",
      "Loss_G = 0.81428438 (ave = 0.81737696)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.196593, max value: 0.102727\n",
      "D grad l2-norm: 1.251828, max value: 0.556884\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001113)\n",
      "Loss_D = 0.91730130 (ave = 0.90854830)\n",
      "Loss_G = 0.81405228 (ave = 0.81330487)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.216178, max value: 0.106792\n",
      "D grad l2-norm: 1.271973, max value: 0.556750\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 0.87959164 (ave = 0.90331662)\n",
      "Loss_G = 0.80893660 (ave = 0.80975692)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.249958, max value: 0.107753\n",
      "D grad l2-norm: 1.311066, max value: 0.554475\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.88880461 (ave = 0.90707521)\n",
      "Loss_G = 0.80333459 (ave = 0.80698725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.255888, max value: 0.102949\n",
      "D grad l2-norm: 1.330463, max value: 0.551985\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001259)\n",
      "Loss_D = 0.91909236 (ave = 0.91138781)\n",
      "Loss_G = 0.80818832 (ave = 0.80858006)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:44\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.263946, max value: 0.110258\n",
      "D grad l2-norm: 1.361631, max value: 0.554142\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.008s / 800 iters, (0.001542)\n",
      "Loss_D = 0.91744065 (ave = 0.90880567)\n",
      "Loss_G = 0.81762141 (ave = 0.81291076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.252523, max value: 0.117190\n",
      "D grad l2-norm: 1.399978, max value: 0.558366\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.88799345 (ave = 0.89812557)\n",
      "Loss_G = 0.82669109 (ave = 0.82195042)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.245392, max value: 0.136518\n",
      "D grad l2-norm: 1.436752, max value: 0.562326\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.80964726 (ave = 0.87885830)\n",
      "Loss_G = 0.84384060 (ave = 0.83849013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.218400, max value: 0.127438\n",
      "D grad l2-norm: 1.471479, max value: 0.569794\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001182)\n",
      "Loss_D = 0.90480196 (ave = 0.87644229)\n",
      "Loss_G = 0.86595875 (ave = 0.85530144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.209063, max value: 0.135670\n",
      "D grad l2-norm: 1.534625, max value: 0.579192\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.88997364 (ave = 0.85974520)\n",
      "Loss_G = 0.88693523 (ave = 0.87501249)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.209785, max value: 0.138294\n",
      "D grad l2-norm: 1.595666, max value: 0.587937\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001183)\n",
      "Loss_D = 0.79681504 (ave = 0.82980684)\n",
      "Loss_G = 0.91002572 (ave = 0.90092636)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.222457, max value: 0.134781\n",
      "D grad l2-norm: 1.639226, max value: 0.597337\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001148)\n",
      "Loss_D = 0.73182821 (ave = 0.80480878)\n",
      "Loss_G = 0.93747032 (ave = 0.92612189)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.251658, max value: 0.149651\n",
      "D grad l2-norm: 1.692378, max value: 0.608257\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 800 iters, (0.024)\tData load 0.011s / 800 iters, (0.002167)\n",
      "Loss_D = 0.72148639 (ave = 0.78917419)\n",
      "Loss_G = 0.95636678 (ave = 0.94786717)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:45\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.297689, max value: 0.153731\n",
      "D grad l2-norm: 1.730659, max value: 0.615542\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001162)\n",
      "Loss_D = 0.78352594 (ave = 0.78510190)\n",
      "Loss_G = 0.97204041 (ave = 0.96702040)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.389318, max value: 0.155488\n",
      "D grad l2-norm: 1.809785, max value: 0.621488\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 800 iters, (0.024)\tData load 0.015s / 800 iters, (0.003016)\n",
      "Loss_D = 0.74037254 (ave = 0.77034003)\n",
      "Loss_G = 0.98409259 (ave = 0.97853339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.434882, max value: 0.163387\n",
      "D grad l2-norm: 1.833996, max value: 0.626036\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.73621911 (ave = 0.76266050)\n",
      "Loss_G = 0.98906940 (ave = 0.98311045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.501558, max value: 0.186830\n",
      "D grad l2-norm: 1.875024, max value: 0.627861\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001165)\n",
      "Loss_D = 0.81667650 (ave = 0.77030283)\n",
      "Loss_G = 0.98629200 (ave = 0.98777494)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.605314, max value: 0.215208\n",
      "D grad l2-norm: 1.906646, max value: 0.626719\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001174)\n",
      "Loss_D = 0.78062129 (ave = 0.76634277)\n",
      "Loss_G = 0.98039800 (ave = 0.98533750)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.731512, max value: 0.236643\n",
      "D grad l2-norm: 1.960684, max value: 0.624539\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 0.84432709 (ave = 0.77945911)\n",
      "Loss_G = 0.96207458 (ave = 0.97394096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.824223, max value: 0.251082\n",
      "D grad l2-norm: 1.986627, max value: 0.617467\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001143)\n",
      "Loss_D = 0.68936962 (ave = 0.76574167)\n",
      "Loss_G = 0.95937836 (ave = 0.96463953)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.851193, max value: 0.257337\n",
      "D grad l2-norm: 1.993230, max value: 0.616366\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 0.76308525 (ave = 0.77937604)\n",
      "Loss_G = 0.95866555 (ave = 0.96073974)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.901142, max value: 0.247577\n",
      "D grad l2-norm: 2.033854, max value: 0.616145\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 0.73875767 (ave = 0.78082530)\n",
      "Loss_G = 0.95864362 (ave = 0.95674627)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.972681, max value: 0.253795\n",
      "D grad l2-norm: 2.088932, max value: 0.616071\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001106)\n",
      "Loss_D = 0.76835465 (ave = 0.78776269)\n",
      "Loss_G = 0.94979280 (ave = 0.94903630)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:46\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.015686, max value: 0.238324\n",
      "D grad l2-norm: 2.155691, max value: 0.612539\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 0.72122931 (ave = 0.78625844)\n",
      "Loss_G = 0.95775616 (ave = 0.95022991)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.999997, max value: 0.225405\n",
      "D grad l2-norm: 2.194532, max value: 0.615656\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 0.83280051 (ave = 0.79978068)\n",
      "Loss_G = 0.96442413 (ave = 0.95451565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.054322, max value: 0.205663\n",
      "D grad l2-norm: 2.306878, max value: 0.618125\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 0.76477671 (ave = 0.78914982)\n",
      "Loss_G = 0.96996272 (ave = 0.96796250)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.120866, max value: 0.201357\n",
      "D grad l2-norm: 2.401550, max value: 0.620207\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.72898895 (ave = 0.77600623)\n",
      "Loss_G = 0.97823060 (ave = 0.97697073)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.206745, max value: 0.220374\n",
      "D grad l2-norm: 2.534590, max value: 0.623215\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 800 iters, (0.015)\tData load 0.010s / 800 iters, (0.002075)\n",
      "Loss_D = 0.78606683 (ave = 0.77865393)\n",
      "Loss_G = 1.00955546 (ave = 0.99745599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.249612, max value: 0.238349\n",
      "D grad l2-norm: 2.615935, max value: 0.634963\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.78437996 (ave = 0.76885889)\n",
      "Loss_G = 1.01712656 (ave = 1.01653886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.380245, max value: 0.247246\n",
      "D grad l2-norm: 2.748114, max value: 0.637634\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 0.70573699 (ave = 0.75707322)\n",
      "Loss_G = 1.02213466 (ave = 1.02651553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.578375, max value: 0.284571\n",
      "D grad l2-norm: 2.892670, max value: 0.639234\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001141)\n",
      "Loss_D = 0.68663621 (ave = 0.76228658)\n",
      "Loss_G = 1.02709448 (ave = 1.03266737)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.850031, max value: 0.335285\n",
      "D grad l2-norm: 2.966094, max value: 0.640558\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001140)\n",
      "Loss_D = 0.80468690 (ave = 0.79510212)\n",
      "Loss_G = 0.99771756 (ave = 1.00281765)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.108211, max value: 0.376973\n",
      "D grad l2-norm: 3.089479, max value: 0.629502\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001212)\n",
      "Loss_D = 0.89401436 (ave = 0.82919959)\n",
      "Loss_G = 0.97544408 (ave = 0.97742275)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:47\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.221442, max value: 0.409740\n",
      "D grad l2-norm: 3.167472, max value: 0.620865\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002800)\n",
      "Loss_D = 0.79960185 (ave = 0.83716711)\n",
      "Loss_G = 0.97965199 (ave = 0.96790015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.259764, max value: 0.405028\n",
      "D grad l2-norm: 3.375859, max value: 0.622121\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 800 iters, (0.022)\tData load 0.015s / 800 iters, (0.002948)\n",
      "Loss_D = 0.81406569 (ave = 0.83625281)\n",
      "Loss_G = 0.99376929 (ave = 0.98532690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.300727, max value: 0.403316\n",
      "D grad l2-norm: 3.565868, max value: 0.627514\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002835)\n",
      "Loss_D = 0.79045010 (ave = 0.82822936)\n",
      "Loss_G = 1.05562246 (ave = 1.03111215)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.346810, max value: 0.386168\n",
      "D grad l2-norm: 3.752334, max value: 0.650118\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002843)\n",
      "Loss_D = 0.81264383 (ave = 0.80263048)\n",
      "Loss_G = 1.08188784 (ave = 1.06932974)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.491059, max value: 0.374355\n",
      "D grad l2-norm: 3.959697, max value: 0.659001\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.69603306 (ave = 0.78264873)\n",
      "Loss_G = 1.10602784 (ave = 1.09876013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.532018, max value: 0.349898\n",
      "D grad l2-norm: 4.133263, max value: 0.666704\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.012s / 800 iters, (0.002319)\n",
      "Loss_D = 0.78557652 (ave = 0.78944471)\n",
      "Loss_G = 1.15521932 (ave = 1.14653153)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.536211, max value: 0.314217\n",
      "D grad l2-norm: 4.326113, max value: 0.683447\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000978)\n",
      "Loss_D = 0.75842398 (ave = 0.76884835)\n",
      "Loss_G = 1.20230353 (ave = 1.18755684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.537678, max value: 0.335067\n",
      "D grad l2-norm: 4.512887, max value: 0.698430\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 800 iters, (0.019)\tData load 0.014s / 800 iters, (0.002778)\n",
      "Loss_D = 0.77452213 (ave = 0.75312531)\n",
      "Loss_G = 1.26596415 (ave = 1.23893452)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:48\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.725920, max value: 0.380540\n",
      "D grad l2-norm: 4.770309, max value: 0.716682\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001105)\n",
      "Loss_D = 0.69702864 (ave = 0.73511679)\n",
      "Loss_G = 1.29183328 (ave = 1.26747713)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.062758, max value: 0.439159\n",
      "D grad l2-norm: 5.022069, max value: 0.723508\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 0.73908198 (ave = 0.74224260)\n",
      "Loss_G = 1.29496551 (ave = 1.28189621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.104937, max value: 0.473438\n",
      "D grad l2-norm: 5.090772, max value: 0.724805\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.76235235 (ave = 0.74049249)\n",
      "Loss_G = 1.32822919 (ave = 1.32116425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.187382, max value: 0.480003\n",
      "D grad l2-norm: 5.254097, max value: 0.733222\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 0.71615940 (ave = 0.73123958)\n",
      "Loss_G = 1.35038853 (ave = 1.32836423)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.234820, max value: 0.500430\n",
      "D grad l2-norm: 5.387075, max value: 0.739139\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001049)\n",
      "Loss_D = 0.87025678 (ave = 0.74399468)\n",
      "Loss_G = 1.37197459 (ave = 1.37347188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.438123, max value: 0.511677\n",
      "D grad l2-norm: 5.684817, max value: 0.750763\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 0.68675750 (ave = 0.71975515)\n",
      "Loss_G = 1.39902544 (ave = 1.40443497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.528873, max value: 0.533498\n",
      "D grad l2-norm: 5.701562, max value: 0.754827\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.82445192 (ave = 0.73466266)\n",
      "Loss_G = 1.38379598 (ave = 1.40643644)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.705352, max value: 0.520903\n",
      "D grad l2-norm: 5.734225, max value: 0.747431\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.65606922 (ave = 0.72121836)\n",
      "Loss_G = 1.37122798 (ave = 1.38565471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.779942, max value: 0.508212\n",
      "D grad l2-norm: 5.665176, max value: 0.744281\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.006s / 800 iters, (0.001118)\n",
      "Loss_D = 0.89403999 (ave = 0.77031145)\n",
      "Loss_G = 1.36561251 (ave = 1.36653926)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.908759, max value: 0.492532\n",
      "D grad l2-norm: 5.600238, max value: 0.742461\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.007s / 800 iters, (0.001364)\n",
      "Loss_D = 0.78472054 (ave = 0.77303531)\n",
      "Loss_G = 1.30955589 (ave = 1.32275612)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.170689, max value: 0.473352\n",
      "D grad l2-norm: 5.583817, max value: 0.727540\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.80743003 (ave = 0.81196579)\n",
      "Loss_G = 1.24738467 (ave = 1.25992126)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:49\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.355525, max value: 0.500933\n",
      "D grad l2-norm: 5.579126, max value: 0.709671\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 800 iters, (0.017)\tData load 0.013s / 800 iters, (0.002692)\n",
      "Loss_D = 0.86406314 (ave = 0.84518274)\n",
      "Loss_G = 1.21967638 (ave = 1.23187687)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.425881, max value: 0.507758\n",
      "D grad l2-norm: 5.550621, max value: 0.701501\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 0.71314687 (ave = 0.84564048)\n",
      "Loss_G = 1.17898512 (ave = 1.20685945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.450197, max value: 0.532848\n",
      "D grad l2-norm: 5.559846, max value: 0.688895\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.009s / 800 iters, (0.001712)\n",
      "Loss_D = 0.90502334 (ave = 0.87936360)\n",
      "Loss_G = 1.22279465 (ave = 1.21157837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.377479, max value: 0.507881\n",
      "D grad l2-norm: 5.759846, max value: 0.702892\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.74789798 (ave = 0.85191745)\n",
      "Loss_G = 1.29499257 (ave = 1.26183600)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.307652, max value: 0.497199\n",
      "D grad l2-norm: 5.936366, max value: 0.723680\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 0.70586920 (ave = 0.82691318)\n",
      "Loss_G = 1.31001854 (ave = 1.29246438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.672138, max value: 0.502081\n",
      "D grad l2-norm: 6.183920, max value: 0.727345\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.93788528 (ave = 0.85741987)\n",
      "Loss_G = 1.31786036 (ave = 1.31247115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.125602, max value: 0.563658\n",
      "D grad l2-norm: 6.203099, max value: 0.729849\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.009s / 800 iters, (0.001747)\n",
      "Loss_D = 0.96260333 (ave = 0.87209468)\n",
      "Loss_G = 1.27197802 (ave = 1.28433874)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:50\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.573671, max value: 0.598941\n",
      "D grad l2-norm: 6.305862, max value: 0.716608\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.88984358 (ave = 0.88342681)\n",
      "Loss_G = 1.25444007 (ave = 1.25144732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.520725, max value: 0.581175\n",
      "D grad l2-norm: 6.280596, max value: 0.711353\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 0.82330054 (ave = 0.88628604)\n",
      "Loss_G = 1.24681532 (ave = 1.25950937)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.744746, max value: 0.588755\n",
      "D grad l2-norm: 6.548774, max value: 0.708751\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.013s / 800 iters, (0.002560)\n",
      "Loss_D = 0.68027812 (ave = 0.85545105)\n",
      "Loss_G = 1.29503202 (ave = 1.27176030)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.638450, max value: 0.547391\n",
      "D grad l2-norm: 6.633663, max value: 0.722766\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.85646886 (ave = 0.87431473)\n",
      "Loss_G = 1.31238627 (ave = 1.30753174)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.732205, max value: 0.531700\n",
      "D grad l2-norm: 6.917844, max value: 0.740064\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001128)\n",
      "Loss_D = 0.81874704 (ave = 0.87019247)\n",
      "Loss_G = 1.33773065 (ave = 1.32649572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.864266, max value: 0.518282\n",
      "D grad l2-norm: 6.975943, max value: 0.772275\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.84020466 (ave = 0.86038465)\n",
      "Loss_G = 1.31215107 (ave = 1.33449907)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.998721, max value: 0.556202\n",
      "D grad l2-norm: 6.949039, max value: 0.765908\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 1.03909802 (ave = 0.90351957)\n",
      "Loss_G = 1.30752206 (ave = 1.32478225)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.045337, max value: 0.554671\n",
      "D grad l2-norm: 7.002585, max value: 0.763572\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 0.74812359 (ave = 0.86445125)\n",
      "Loss_G = 1.33123171 (ave = 1.30374269)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.722090, max value: 0.506522\n",
      "D grad l2-norm: 6.823433, max value: 0.766482\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.87027800 (ave = 0.87394944)\n",
      "Loss_G = 1.28219795 (ave = 1.29578772)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.735723, max value: 0.485664\n",
      "D grad l2-norm: 6.800243, max value: 0.772994\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 0.94628388 (ave = 0.89062798)\n",
      "Loss_G = 1.26845348 (ave = 1.28670413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:51\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.270724, max value: 0.519466\n",
      "D grad l2-norm: 6.879306, max value: 0.782683\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.72101939 (ave = 0.89086080)\n",
      "Loss_G = 1.23731256 (ave = 1.23959465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.310206, max value: 0.532076\n",
      "D grad l2-norm: 6.753101, max value: 0.781512\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.94297349 (ave = 0.93732418)\n",
      "Loss_G = 1.23790002 (ave = 1.22705801)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.151768, max value: 0.534420\n",
      "D grad l2-norm: 6.877985, max value: 0.814399\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.88444686 (ave = 0.92472262)\n",
      "Loss_G = 1.23650670 (ave = 1.21189346)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.871077, max value: 0.525799\n",
      "D grad l2-norm: 6.976529, max value: 0.823078\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.87152970 (ave = 0.89918888)\n",
      "Loss_G = 1.29307246 (ave = 1.27273962)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.713504, max value: 0.494414\n",
      "D grad l2-norm: 7.069571, max value: 0.834367\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.82816011 (ave = 0.87203809)\n",
      "Loss_G = 1.35541153 (ave = 1.32913282)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.586174, max value: 0.506346\n",
      "D grad l2-norm: 7.192218, max value: 0.850535\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.94413567 (ave = 0.85428315)\n",
      "Loss_G = 1.40269542 (ave = 1.36599112)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.516492, max value: 0.483644\n",
      "D grad l2-norm: 7.482845, max value: 0.873801\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.80601883 (ave = 0.80845339)\n",
      "Loss_G = 1.44767749 (ave = 1.43767304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.237691, max value: 0.502468\n",
      "D grad l2-norm: 7.602102, max value: 0.873545\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.000981)\n",
      "Loss_D = 0.81236243 (ave = 0.77146952)\n",
      "Loss_G = 1.54428506 (ave = 1.51124969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.301704, max value: 0.565212\n",
      "D grad l2-norm: 8.036662, max value: 0.922592\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.018s / 800 iters, (0.003554)\n",
      "Loss_D = 0.63626170 (ave = 0.71480937)\n",
      "Loss_G = 1.57978189 (ave = 1.56077306)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:52\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.171605, max value: 0.576887\n",
      "D grad l2-norm: 7.916165, max value: 0.951749\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.010s / 800 iters, (0.001929)\n",
      "Loss_D = 0.73793709 (ave = 0.70353347)\n",
      "Loss_G = 1.63833213 (ave = 1.60843799)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.140882, max value: 0.562286\n",
      "D grad l2-norm: 8.021665, max value: 1.004413\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 0.79269475 (ave = 0.67912322)\n",
      "Loss_G = 1.71463478 (ave = 1.67418964)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.287330, max value: 0.580529\n",
      "D grad l2-norm: 8.292338, max value: 1.070426\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 800 iters, (0.021)\tData load 0.022s / 800 iters, (0.004398)\n",
      "Loss_D = 0.51050973 (ave = 0.62121682)\n",
      "Loss_G = 1.70432365 (ave = 1.69125743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.422487, max value: 0.611480\n",
      "D grad l2-norm: 8.313926, max value: 1.085181\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.59766573 (ave = 0.61895022)\n",
      "Loss_G = 1.72253358 (ave = 1.72395709)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.029585, max value: 0.622248\n",
      "D grad l2-norm: 8.666306, max value: 1.133225\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001153)\n",
      "Loss_D = 0.53164673 (ave = 0.60034015)\n",
      "Loss_G = 1.69917667 (ave = 1.71118672)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.306359, max value: 0.602044\n",
      "D grad l2-norm: 8.413399, max value: 1.098315\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 0.69059169 (ave = 0.62306157)\n",
      "Loss_G = 1.64617240 (ave = 1.68049104)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.131348, max value: 0.651728\n",
      "D grad l2-norm: 8.731374, max value: 1.097495\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.70457822 (ave = 0.64118429)\n",
      "Loss_G = 1.62561536 (ave = 1.61817849)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.404817, max value: 0.664685\n",
      "D grad l2-norm: 8.635905, max value: 1.066712\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 0.60169947 (ave = 0.63511369)\n",
      "Loss_G = 1.63287413 (ave = 1.59817767)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:53\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.319758, max value: 0.616285\n",
      "D grad l2-norm: 8.618197, max value: 1.050783\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001004)\n",
      "Loss_D = 0.64866304 (ave = 0.64550250)\n",
      "Loss_G = 1.56231940 (ave = 1.57009025)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.312747, max value: 0.614097\n",
      "D grad l2-norm: 8.484292, max value: 0.991608\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.46505272 (ave = 0.62343222)\n",
      "Loss_G = 1.55599189 (ave = 1.56916420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.658529, max value: 0.623389\n",
      "D grad l2-norm: 8.526279, max value: 0.970456\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001015)\n",
      "Loss_D = 0.84131622 (ave = 0.68617564)\n",
      "Loss_G = 1.51897919 (ave = 1.52652860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.642656, max value: 0.617497\n",
      "D grad l2-norm: 8.386376, max value: 0.927087\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001018)\n",
      "Loss_D = 0.54395008 (ave = 0.66166272)\n",
      "Loss_G = 1.47735453 (ave = 1.48647220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.785894, max value: 0.628119\n",
      "D grad l2-norm: 8.394189, max value: 0.890579\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.006s / 800 iters, (0.001120)\n",
      "Loss_D = 0.89096010 (ave = 0.72225897)\n",
      "Loss_G = 1.46133184 (ave = 1.47368946)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.994405, max value: 0.637966\n",
      "D grad l2-norm: 8.438877, max value: 0.868838\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 0.74019599 (ave = 0.71860297)\n",
      "Loss_G = 1.44738674 (ave = 1.44926367)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.878259, max value: 0.604503\n",
      "D grad l2-norm: 8.222580, max value: 0.825492\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.81801099 (ave = 0.74022660)\n",
      "Loss_G = 1.42574215 (ave = 1.42823684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.845620, max value: 0.620221\n",
      "D grad l2-norm: 8.145652, max value: 0.786875\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.010s / 800 iters, (0.001908)\n",
      "Loss_D = 0.66270471 (ave = 0.73931561)\n",
      "Loss_G = 1.40162563 (ave = 1.42612650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.108034, max value: 0.691537\n",
      "D grad l2-norm: 8.341135, max value: 0.762462\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001038)\n",
      "Loss_D = 0.74102259 (ave = 0.76325365)\n",
      "Loss_G = 1.35112238 (ave = 1.37425935)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.898216, max value: 0.729380\n",
      "D grad l2-norm: 8.031007, max value: 0.747377\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001037)\n",
      "Loss_D = 0.93731838 (ave = 0.81807646)\n",
      "Loss_G = 1.31580293 (ave = 1.34224825)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:54\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.141399, max value: 0.720203\n",
      "D grad l2-norm: 8.114193, max value: 0.790774\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.74906069 (ave = 0.82442169)\n",
      "Loss_G = 1.33907187 (ave = 1.32705665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.283967, max value: 0.701997\n",
      "D grad l2-norm: 8.334779, max value: 0.854154\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 0.99858880 (ave = 0.88342565)\n",
      "Loss_G = 1.34516311 (ave = 1.31842296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.161480, max value: 0.684368\n",
      "D grad l2-norm: 8.485066, max value: 0.915727\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001077)\n",
      "Loss_D = 0.84919584 (ave = 0.86144600)\n",
      "Loss_G = 1.37613869 (ave = 1.35019991)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.938246, max value: 0.614830\n",
      "D grad l2-norm: 8.637888, max value: 0.966830\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 1.02084816 (ave = 0.88076940)\n",
      "Loss_G = 1.38541532 (ave = 1.37431979)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.215614, max value: 0.546513\n",
      "D grad l2-norm: 8.371101, max value: 0.973587\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001005)\n",
      "Loss_D = 0.76349342 (ave = 0.83051513)\n",
      "Loss_G = 1.45479119 (ave = 1.42788148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.929789, max value: 0.540785\n",
      "D grad l2-norm: 8.729821, max value: 1.037593\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002889)\n",
      "Loss_D = 0.79005110 (ave = 0.81295320)\n",
      "Loss_G = 1.47369921 (ave = 1.46146741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.232396, max value: 0.602252\n",
      "D grad l2-norm: 9.062587, max value: 1.124824\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.79893816 (ave = 0.81932845)\n",
      "Loss_G = 1.49683344 (ave = 1.51538849)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.078151, max value: 0.723343\n",
      "D grad l2-norm: 9.529048, max value: 1.208057\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 0.89174545 (ave = 0.83930877)\n",
      "Loss_G = 1.45310247 (ave = 1.47706826)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:55\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.548969, max value: 0.782079\n",
      "D grad l2-norm: 9.681348, max value: 1.228482\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 1.05590653 (ave = 0.89183143)\n",
      "Loss_G = 1.47692394 (ave = 1.47102950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.465922, max value: 0.829329\n",
      "D grad l2-norm: 9.737498, max value: 1.258171\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000994)\n",
      "Loss_D = 1.01926255 (ave = 0.88469106)\n",
      "Loss_G = 1.49633718 (ave = 1.47246854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.689673, max value: 0.848567\n",
      "D grad l2-norm: 9.833142, max value: 1.268377\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.017s / 800 iters, (0.003466)\n",
      "Loss_D = 0.74627054 (ave = 0.86623856)\n",
      "Loss_G = 1.48862040 (ave = 1.47931406)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.013862, max value: 0.865831\n",
      "D grad l2-norm: 10.115665, max value: 1.277418\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001008)\n",
      "Loss_D = 0.84578705 (ave = 0.88360698)\n",
      "Loss_G = 1.52277005 (ave = 1.49961064)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.804990, max value: 0.907944\n",
      "D grad l2-norm: 10.718812, max value: 1.316711\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 0.91477823 (ave = 0.90312738)\n",
      "Loss_G = 1.51336586 (ave = 1.50960560)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.985572, max value: 0.878535\n",
      "D grad l2-norm: 10.822128, max value: 1.294617\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.006s / 800 iters, (0.001177)\n",
      "Loss_D = 1.01752555 (ave = 0.91972961)\n",
      "Loss_G = 1.53452766 (ave = 1.53810558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.741234, max value: 0.759102\n",
      "D grad l2-norm: 10.887662, max value: 1.351851\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.64955223 (ave = 0.86792585)\n",
      "Loss_G = 1.58115745 (ave = 1.56861680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.332655, max value: 0.747850\n",
      "D grad l2-norm: 10.936047, max value: 1.406157\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.91916525 (ave = 0.88348526)\n",
      "Loss_G = 1.64423895 (ave = 1.62299421)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.040286, max value: 0.725761\n",
      "D grad l2-norm: 11.004102, max value: 1.448978\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001030)\n",
      "Loss_D = 0.63873768 (ave = 0.83180079)\n",
      "Loss_G = 1.67976391 (ave = 1.67770579)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.094450, max value: 0.742653\n",
      "D grad l2-norm: 11.239769, max value: 1.485175\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 0.70658422 (ave = 0.83711177)\n",
      "Loss_G = 1.65512478 (ave = 1.69255621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:56\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.288773, max value: 0.731301\n",
      "D grad l2-norm: 11.383271, max value: 1.484727\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001015)\n",
      "Loss_D = 0.82817256 (ave = 0.85238494)\n",
      "Loss_G = 1.66889155 (ave = 1.67437260)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.149808, max value: 0.676186\n",
      "D grad l2-norm: 11.239866, max value: 1.458288\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001012)\n",
      "Loss_D = 0.87968880 (ave = 0.85592635)\n",
      "Loss_G = 1.60775256 (ave = 1.66323903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.555132, max value: 0.608412\n",
      "D grad l2-norm: 10.691977, max value: 1.359908\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001256)\n",
      "Loss_D = 1.06705213 (ave = 0.87586854)\n",
      "Loss_G = 1.67075801 (ave = 1.66203849)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.789116, max value: 0.639838\n",
      "D grad l2-norm: 11.020386, max value: 1.379001\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002737)\n",
      "Loss_D = 0.80002850 (ave = 0.84331173)\n",
      "Loss_G = 1.60397482 (ave = 1.64147875)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.481750, max value: 0.662084\n",
      "D grad l2-norm: 10.597660, max value: 1.257335\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.99921763 (ave = 0.86309148)\n",
      "Loss_G = 1.63609517 (ave = 1.64008613)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.406540, max value: 0.683032\n",
      "D grad l2-norm: 10.462806, max value: 1.189086\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001090)\n",
      "Loss_D = 0.69648099 (ave = 0.82600411)\n",
      "Loss_G = 1.60557950 (ave = 1.61313722)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.690204, max value: 0.720228\n",
      "D grad l2-norm: 10.576075, max value: 1.112021\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.72099531 (ave = 0.83445572)\n",
      "Loss_G = 1.61256456 (ave = 1.61763680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.381396, max value: 0.721157\n",
      "D grad l2-norm: 10.342726, max value: 1.069750\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.80463779 (ave = 0.85098686)\n",
      "Loss_G = 1.57985985 (ave = 1.59714181)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.386736, max value: 0.700718\n",
      "D grad l2-norm: 10.398195, max value: 1.057717\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001109)\n",
      "Loss_D = 0.76792234 (ave = 0.84502298)\n",
      "Loss_G = 1.60322952 (ave = 1.60286484)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:57\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.276507, max value: 0.682248\n",
      "D grad l2-norm: 10.436647, max value: 1.057550\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.80831122 (ave = 0.85189806)\n",
      "Loss_G = 1.61044383 (ave = 1.61729109)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.184554, max value: 0.701269\n",
      "D grad l2-norm: 10.359812, max value: 1.028925\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002825)\n",
      "Loss_D = 0.93730617 (ave = 0.86530588)\n",
      "Loss_G = 1.60343599 (ave = 1.61571894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.375754, max value: 0.731389\n",
      "D grad l2-norm: 10.590025, max value: 1.005134\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001063)\n",
      "Loss_D = 0.91062230 (ave = 0.85261077)\n",
      "Loss_G = 1.60747921 (ave = 1.61856689)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.886867, max value: 0.766028\n",
      "D grad l2-norm: 10.232327, max value: 0.936227\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.61014682 (ave = 0.79728612)\n",
      "Loss_G = 1.66672111 (ave = 1.62592440)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.732946, max value: 0.789989\n",
      "D grad l2-norm: 10.421143, max value: 0.947885\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001050)\n",
      "Loss_D = 0.75268388 (ave = 0.79976087)\n",
      "Loss_G = 1.70653069 (ave = 1.67036338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.424920, max value: 0.803268\n",
      "D grad l2-norm: 10.360908, max value: 0.943642\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.000949)\n",
      "Loss_D = 0.66489321 (ave = 0.76781485)\n",
      "Loss_G = 1.72068250 (ave = 1.72118623)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.010373, max value: 0.828331\n",
      "D grad l2-norm: 10.162248, max value: 0.918869\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.89240152 (ave = 0.77436528)\n",
      "Loss_G = 1.77440155 (ave = 1.76783347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.063181, max value: 0.858374\n",
      "D grad l2-norm: 10.207369, max value: 0.946201\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.60541928 (ave = 0.71708252)\n",
      "Loss_G = 1.77451706 (ave = 1.77746179)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.492735, max value: 0.912058\n",
      "D grad l2-norm: 10.358470, max value: 1.002439\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 0.79521036 (ave = 0.72976638)\n",
      "Loss_G = 1.70106840 (ave = 1.75022211)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.636952, max value: 0.900882\n",
      "D grad l2-norm: 10.034427, max value: 0.993297\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 0.77123064 (ave = 0.72333448)\n",
      "Loss_G = 1.72021103 (ave = 1.72289488)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:58\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.060235, max value: 0.916001\n",
      "D grad l2-norm: 10.079980, max value: 1.028877\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 0.66785908 (ave = 0.71059256)\n",
      "Loss_G = 1.66672182 (ave = 1.67242661)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.495397, max value: 0.970321\n",
      "D grad l2-norm: 9.948422, max value: 1.020657\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.62775815 (ave = 0.71703974)\n",
      "Loss_G = 1.59894252 (ave = 1.62285457)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.559652, max value: 0.978681\n",
      "D grad l2-norm: 9.448239, max value: 0.978170\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001134)\n",
      "Loss_D = 0.90413654 (ave = 0.76826205)\n",
      "Loss_G = 1.54642344 (ave = 1.55724757)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.730937, max value: 0.979813\n",
      "D grad l2-norm: 9.304284, max value: 0.980339\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.009s / 800 iters, (0.001881)\n",
      "Loss_D = 0.76489508 (ave = 0.76801364)\n",
      "Loss_G = 1.49478674 (ave = 1.50539005)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.683993, max value: 0.993546\n",
      "D grad l2-norm: 8.967787, max value: 0.948295\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 0.85498989 (ave = 0.79710201)\n",
      "Loss_G = 1.49612355 (ave = 1.48571742)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.077688, max value: 0.995310\n",
      "D grad l2-norm: 9.107042, max value: 0.959172\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001069)\n",
      "Loss_D = 0.84226179 (ave = 0.79445826)\n",
      "Loss_G = 1.38524008 (ave = 1.41404440)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.676950, max value: 0.900231\n",
      "D grad l2-norm: 8.641371, max value: 0.893515\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 800 iters, (0.025)\tData load 0.013s / 800 iters, (0.002668)\n",
      "Loss_D = 0.70213437 (ave = 0.79887556)\n",
      "Loss_G = 1.41155338 (ave = 1.42220743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.371827, max value: 0.911448\n",
      "D grad l2-norm: 8.404828, max value: 0.857574\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 0.94505262 (ave = 0.82487296)\n",
      "Loss_G = 1.43633890 (ave = 1.41421065)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.445492, max value: 0.893349\n",
      "D grad l2-norm: 8.425340, max value: 0.849036\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001142)\n",
      "Loss_D = 0.80585957 (ave = 0.81347054)\n",
      "Loss_G = 1.38432026 (ave = 1.38501289)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.147053, max value: 0.880482\n",
      "D grad l2-norm: 8.095036, max value: 0.809741\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.84090173 (ave = 0.81157485)\n",
      "Loss_G = 1.33359170 (ave = 1.36502821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:02:59\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.983415, max value: 0.854680\n",
      "D grad l2-norm: 7.897905, max value: 0.779939\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.010s / 800 iters, (0.002033)\n",
      "Loss_D = 1.09131932 (ave = 0.86053947)\n",
      "Loss_G = 1.32293463 (ave = 1.32834966)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.641320, max value: 0.829194\n",
      "D grad l2-norm: 7.584325, max value: 0.740986\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001021)\n",
      "Loss_D = 0.64749682 (ave = 0.79652069)\n",
      "Loss_G = 1.33947492 (ave = 1.34978938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.508347, max value: 0.761704\n",
      "D grad l2-norm: 7.613707, max value: 0.730650\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001009)\n",
      "Loss_D = 0.80805421 (ave = 0.81171541)\n",
      "Loss_G = 1.37967861 (ave = 1.36200032)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.056443, max value: 0.681725\n",
      "D grad l2-norm: 7.448576, max value: 0.742656\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001055)\n",
      "Loss_D = 0.66826516 (ave = 0.78033783)\n",
      "Loss_G = 1.36840308 (ave = 1.36503882)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.751940, max value: 0.645732\n",
      "D grad l2-norm: 7.655290, max value: 0.746556\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 0.76326525 (ave = 0.76817995)\n",
      "Loss_G = 1.43790412 (ave = 1.41331239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.498465, max value: 0.636736\n",
      "D grad l2-norm: 7.632342, max value: 0.775660\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.014s / 800 iters, (0.002885)\n",
      "Loss_D = 0.75254071 (ave = 0.75032609)\n",
      "Loss_G = 1.41954815 (ave = 1.44145272)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.956957, max value: 0.580191\n",
      "D grad l2-norm: 7.257471, max value: 0.753218\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.69244701 (ave = 0.71395431)\n",
      "Loss_G = 1.50015831 (ave = 1.47045839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.164365, max value: 0.589327\n",
      "D grad l2-norm: 7.602480, max value: 0.782331\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.008s / 800 iters, (0.001619)\n",
      "Loss_D = 0.72962844 (ave = 0.71092144)\n",
      "Loss_G = 1.49781418 (ave = 1.50693059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.059825, max value: 0.561591\n",
      "D grad l2-norm: 7.495416, max value: 0.784686\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001210)\n",
      "Loss_D = 0.60367453 (ave = 0.67594777)\n",
      "Loss_G = 1.55089903 (ave = 1.51787977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.092682, max value: 0.561608\n",
      "D grad l2-norm: 7.553058, max value: 0.815122\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 800 iters, (0.017)\tData load 0.011s / 800 iters, (0.002125)\n",
      "Loss_D = 0.79235184 (ave = 0.68556054)\n",
      "Loss_G = 1.52598286 (ave = 1.52896419)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:01\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.376880, max value: 0.621068\n",
      "D grad l2-norm: 7.858621, max value: 0.836299\n",
      "üîÅ TSCV for Asset 11\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001280)\n",
      "Loss_D = 1.39958739 (ave = 1.40040472)\n",
      "Loss_G = 0.71006942 (ave = 0.71213433)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965494, max value: 0.024356\n",
      "D grad l2-norm: 0.721115, max value: 0.508387\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.005s / 800 iters, (0.001089)\n",
      "Loss_D = 1.38263130 (ave = 1.38395743)\n",
      "Loss_G = 0.70589530 (ave = 0.70732626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968631, max value: 0.027268\n",
      "D grad l2-norm: 0.717996, max value: 0.506331\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002742)\n",
      "Loss_D = 1.36466980 (ave = 1.36840403)\n",
      "Loss_G = 0.70237124 (ave = 0.70348214)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962421, max value: 0.030766\n",
      "D grad l2-norm: 0.718088, max value: 0.504588\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.33991933 (ave = 1.35320096)\n",
      "Loss_G = 0.69856775 (ave = 0.69990666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969700, max value: 0.035506\n",
      "D grad l2-norm: 0.717364, max value: 0.502700\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 800 iters, (0.022)\tData load 0.005s / 800 iters, (0.001079)\n",
      "Loss_D = 1.34727716 (ave = 1.34354041)\n",
      "Loss_G = 0.69520205 (ave = 0.69686166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.963981, max value: 0.027169\n",
      "D grad l2-norm: 0.717929, max value: 0.501023\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 1.33712041 (ave = 1.33265841)\n",
      "Loss_G = 0.69295979 (ave = 0.69341816)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:02\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969981, max value: 0.027933\n",
      "D grad l2-norm: 0.720918, max value: 0.499903\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 1.29214227 (ave = 1.31792848)\n",
      "Loss_G = 0.69102901 (ave = 0.69128792)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965857, max value: 0.023472\n",
      "D grad l2-norm: 0.723199, max value: 0.498936\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 1.30850232 (ave = 1.31181347)\n",
      "Loss_G = 0.68897575 (ave = 0.68981657)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967581, max value: 0.026769\n",
      "D grad l2-norm: 0.727534, max value: 0.497906\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001052)\n",
      "Loss_D = 1.32752275 (ave = 1.30616546)\n",
      "Loss_G = 0.68760705 (ave = 0.68833392)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965101, max value: 0.029991\n",
      "D grad l2-norm: 0.730913, max value: 0.497217\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 1.27064717 (ave = 1.29181049)\n",
      "Loss_G = 0.68728268 (ave = 0.68738593)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968147, max value: 0.031938\n",
      "D grad l2-norm: 0.733910, max value: 0.497055\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 1.29153764 (ave = 1.28777852)\n",
      "Loss_G = 0.68642628 (ave = 0.68665144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967917, max value: 0.028995\n",
      "D grad l2-norm: 0.738235, max value: 0.496623\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001144)\n",
      "Loss_D = 1.30167699 (ave = 1.28243072)\n",
      "Loss_G = 0.68699259 (ave = 0.68687079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968459, max value: 0.025345\n",
      "D grad l2-norm: 0.742716, max value: 0.496908\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.006s / 800 iters, (0.001189)\n",
      "Loss_D = 1.24735415 (ave = 1.26910229)\n",
      "Loss_G = 0.68659633 (ave = 0.68684720)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970251, max value: 0.031658\n",
      "D grad l2-norm: 0.747054, max value: 0.496706\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 1.26732087 (ave = 1.26518984)\n",
      "Loss_G = 0.68681026 (ave = 0.68681098)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.969479, max value: 0.024954\n",
      "D grad l2-norm: 0.752112, max value: 0.496814\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.24201894 (ave = 1.25585887)\n",
      "Loss_G = 0.68830389 (ave = 0.68743122)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979022, max value: 0.028654\n",
      "D grad l2-norm: 0.753927, max value: 0.497567\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.22300553 (ave = 1.24755876)\n",
      "Loss_G = 0.68807131 (ave = 0.68798043)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:03\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.967821, max value: 0.035494\n",
      "D grad l2-norm: 0.762277, max value: 0.497445\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 1.23338461 (ave = 1.24311345)\n",
      "Loss_G = 0.68916142 (ave = 0.68878809)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971062, max value: 0.028890\n",
      "D grad l2-norm: 0.768453, max value: 0.497995\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.20881820 (ave = 1.23368297)\n",
      "Loss_G = 0.69074214 (ave = 0.68958865)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973544, max value: 0.029464\n",
      "D grad l2-norm: 0.772262, max value: 0.498784\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 1.25355673 (ave = 1.23342342)\n",
      "Loss_G = 0.69160700 (ave = 0.69132376)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972649, max value: 0.031071\n",
      "D grad l2-norm: 0.782933, max value: 0.499215\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.011s / 800 iters, (0.002296)\n",
      "Loss_D = 1.22849286 (ave = 1.22447884)\n",
      "Loss_G = 0.69399834 (ave = 0.69286687)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973713, max value: 0.034765\n",
      "D grad l2-norm: 0.789113, max value: 0.500413\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.24226451 (ave = 1.21961918)\n",
      "Loss_G = 0.69632411 (ave = 0.69522558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973634, max value: 0.036381\n",
      "D grad l2-norm: 0.795873, max value: 0.501575\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 1.19334197 (ave = 1.20757039)\n",
      "Loss_G = 0.69884634 (ave = 0.69766688)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979126, max value: 0.031719\n",
      "D grad l2-norm: 0.804584, max value: 0.502828\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 800 iters, (0.025)\tData load 0.006s / 800 iters, (0.001245)\n",
      "Loss_D = 1.20496058 (ave = 1.20233159)\n",
      "Loss_G = 0.70090592 (ave = 0.70069031)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.973063, max value: 0.032167\n",
      "D grad l2-norm: 0.812639, max value: 0.503853\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001116)\n",
      "Loss_D = 1.12551129 (ave = 1.18580272)\n",
      "Loss_G = 0.70348150 (ave = 0.70301667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971167, max value: 0.027294\n",
      "D grad l2-norm: 0.819157, max value: 0.505126\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.014s / 800 iters, (0.002724)\n",
      "Loss_D = 1.25324845 (ave = 1.19547544)\n",
      "Loss_G = 0.70906734 (ave = 0.70643806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:04\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975832, max value: 0.036328\n",
      "D grad l2-norm: 0.825894, max value: 0.507885\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 800 iters, (0.025)\tData load 0.014s / 800 iters, (0.002778)\n",
      "Loss_D = 1.21128774 (ave = 1.18312819)\n",
      "Loss_G = 0.71108329 (ave = 0.70962538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976645, max value: 0.034792\n",
      "D grad l2-norm: 0.835285, max value: 0.508875\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 800 iters, (0.022)\tData load 0.014s / 800 iters, (0.002741)\n",
      "Loss_D = 1.09895349 (ave = 1.16186378)\n",
      "Loss_G = 0.71560359 (ave = 0.71396244)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.983789, max value: 0.035957\n",
      "D grad l2-norm: 0.844448, max value: 0.511089\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 800 iters, (0.019)\tData load 0.006s / 800 iters, (0.001126)\n",
      "Loss_D = 1.15552926 (ave = 1.16078801)\n",
      "Loss_G = 0.72009391 (ave = 0.71787101)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.975112, max value: 0.026521\n",
      "D grad l2-norm: 0.849948, max value: 0.513282\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.022s / 800 iters, (0.004360)\n",
      "Loss_D = 1.11863279 (ave = 1.14857059)\n",
      "Loss_G = 0.72258055 (ave = 0.72092482)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976802, max value: 0.036961\n",
      "D grad l2-norm: 0.859833, max value: 0.514491\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001035)\n",
      "Loss_D = 1.10286558 (ave = 1.13897934)\n",
      "Loss_G = 0.72844273 (ave = 0.72623134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.981141, max value: 0.031914\n",
      "D grad l2-norm: 0.870807, max value: 0.517332\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001034)\n",
      "Loss_D = 1.06827962 (ave = 1.12702739)\n",
      "Loss_G = 0.73175812 (ave = 0.72992164)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:05\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.977335, max value: 0.035879\n",
      "D grad l2-norm: 0.877600, max value: 0.518928\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.017s / 800 iters, (0.003302)\n",
      "Loss_D = 1.13948977 (ave = 1.12950134)\n",
      "Loss_G = 0.73582596 (ave = 0.73387021)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.983150, max value: 0.036889\n",
      "D grad l2-norm: 0.886293, max value: 0.520878\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 1.08145785 (ave = 1.11482601)\n",
      "Loss_G = 0.73877007 (ave = 0.73778254)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.988832, max value: 0.040797\n",
      "D grad l2-norm: 0.889204, max value: 0.522287\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 1.11724186 (ave = 1.11290543)\n",
      "Loss_G = 0.74201083 (ave = 0.74094384)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993577, max value: 0.043897\n",
      "D grad l2-norm: 0.900868, max value: 0.523828\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.14721632 (ave = 1.11059623)\n",
      "Loss_G = 0.74323410 (ave = 0.74349620)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.003137, max value: 0.049300\n",
      "D grad l2-norm: 0.901559, max value: 0.524403\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 1.09488857 (ave = 1.09860840)\n",
      "Loss_G = 0.74572563 (ave = 0.74466980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.009572, max value: 0.060137\n",
      "D grad l2-norm: 0.905869, max value: 0.525589\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001095)\n",
      "Loss_D = 1.12758923 (ave = 1.09975336)\n",
      "Loss_G = 0.74642980 (ave = 0.74584364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.024990, max value: 0.066393\n",
      "D grad l2-norm: 0.906895, max value: 0.525917\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001076)\n",
      "Loss_D = 1.08607924 (ave = 1.09100728)\n",
      "Loss_G = 0.74496627 (ave = 0.74613488)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.033599, max value: 0.077870\n",
      "D grad l2-norm: 0.912693, max value: 0.525202\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001042)\n",
      "Loss_D = 1.14471579 (ave = 1.09638574)\n",
      "Loss_G = 0.73985916 (ave = 0.74276683)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.058588, max value: 0.079539\n",
      "D grad l2-norm: 0.918520, max value: 0.522757\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001127)\n",
      "Loss_D = 1.03922832 (ave = 1.08376386)\n",
      "Loss_G = 0.73946983 (ave = 0.74078753)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:06\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.059118, max value: 0.087576\n",
      "D grad l2-norm: 0.918098, max value: 0.522573\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001122)\n",
      "Loss_D = 1.12606859 (ave = 1.09504297)\n",
      "Loss_G = 0.73566663 (ave = 0.73623614)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.080515, max value: 0.085714\n",
      "D grad l2-norm: 0.922767, max value: 0.520747\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 1.12535310 (ave = 1.09637907)\n",
      "Loss_G = 0.73112404 (ave = 0.73230205)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.086160, max value: 0.086870\n",
      "D grad l2-norm: 0.927604, max value: 0.518550\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 800 iters, (0.018)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 1.06320691 (ave = 1.09023745)\n",
      "Loss_G = 0.72430307 (ave = 0.72595022)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.087488, max value: 0.091427\n",
      "D grad l2-norm: 0.932544, max value: 0.515254\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.011s / 800 iters, (0.002246)\n",
      "Loss_D = 1.04056883 (ave = 1.08740714)\n",
      "Loss_G = 0.71877533 (ave = 0.72299370)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.100785, max value: 0.090177\n",
      "D grad l2-norm: 0.948224, max value: 0.512511\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 1.13396060 (ave = 1.10045826)\n",
      "Loss_G = 0.72382802 (ave = 0.72383057)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.094451, max value: 0.089817\n",
      "D grad l2-norm: 0.952979, max value: 0.514980\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 800 iters, (0.023)\tData load 0.010s / 800 iters, (0.001917)\n",
      "Loss_D = 1.04436612 (ave = 1.08784943)\n",
      "Loss_G = 0.72082973 (ave = 0.72159432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.097148, max value: 0.091229\n",
      "D grad l2-norm: 0.970886, max value: 0.513548\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 800 iters, (0.026)\tData load 0.025s / 800 iters, (0.005077)\n",
      "Loss_D = 0.98469663 (ave = 1.07781949)\n",
      "Loss_G = 0.72803938 (ave = 0.72464625)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.085764, max value: 0.082480\n",
      "D grad l2-norm: 0.984219, max value: 0.517059\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 800 iters, (0.024)\tData load 0.006s / 800 iters, (0.001193)\n",
      "Loss_D = 1.08072400 (ave = 1.08415632)\n",
      "Loss_G = 0.73345155 (ave = 0.73018420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.073621, max value: 0.086232\n",
      "D grad l2-norm: 0.998002, max value: 0.519646\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 800 iters, (0.023)\tData load 0.024s / 800 iters, (0.004805)\n",
      "Loss_D = 1.03789103 (ave = 1.07135785)\n",
      "Loss_G = 0.73908401 (ave = 0.73387600)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.079497, max value: 0.076475\n",
      "D grad l2-norm: 1.015222, max value: 0.522348\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 1.11834264 (ave = 1.07271361)\n",
      "Loss_G = 0.74665552 (ave = 0.74237174)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:07\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.084021, max value: 0.072685\n",
      "D grad l2-norm: 1.033894, max value: 0.525950\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 1.08429945 (ave = 1.06048112)\n",
      "Loss_G = 0.75848550 (ave = 0.75319862)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.060528, max value: 0.074223\n",
      "D grad l2-norm: 1.056124, max value: 0.531544\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001053)\n",
      "Loss_D = 1.06164777 (ave = 1.04790282)\n",
      "Loss_G = 0.76647514 (ave = 0.76317786)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.075569, max value: 0.076350\n",
      "D grad l2-norm: 1.084709, max value: 0.535279\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 0.92075598 (ave = 1.01822209)\n",
      "Loss_G = 0.78010845 (ave = 0.77539464)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.069632, max value: 0.066582\n",
      "D grad l2-norm: 1.100237, max value: 0.541592\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001074)\n",
      "Loss_D = 1.01929069 (ave = 1.01803031)\n",
      "Loss_G = 0.79336047 (ave = 0.78704040)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.067230, max value: 0.074090\n",
      "D grad l2-norm: 1.122512, max value: 0.547635\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 0.98066008 (ave = 1.00075109)\n",
      "Loss_G = 0.80464393 (ave = 0.79994974)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.066445, max value: 0.077182\n",
      "D grad l2-norm: 1.151384, max value: 0.552709\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001092)\n",
      "Loss_D = 1.02043617 (ave = 0.99398212)\n",
      "Loss_G = 0.82036871 (ave = 0.81346650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.076834, max value: 0.072043\n",
      "D grad l2-norm: 1.175570, max value: 0.559693\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.01928294 (ave = 0.98259847)\n",
      "Loss_G = 0.82898235 (ave = 0.82573414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.094972, max value: 0.088154\n",
      "D grad l2-norm: 1.206526, max value: 0.563473\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 0.99401033 (ave = 0.96830971)\n",
      "Loss_G = 0.84030151 (ave = 0.83623302)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.113480, max value: 0.092811\n",
      "D grad l2-norm: 1.230850, max value: 0.568370\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 1.01506579 (ave = 0.96353976)\n",
      "Loss_G = 0.84875083 (ave = 0.84558380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.124038, max value: 0.102792\n",
      "D grad l2-norm: 1.242922, max value: 0.572004\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001024)\n",
      "Loss_D = 0.99640632 (ave = 0.95313984)\n",
      "Loss_G = 0.85143888 (ave = 0.85156325)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:08\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.165237, max value: 0.119184\n",
      "D grad l2-norm: 1.261342, max value: 0.573114\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 0.97004962 (ave = 0.94521190)\n",
      "Loss_G = 0.86092615 (ave = 0.85951558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.206942, max value: 0.135146\n",
      "D grad l2-norm: 1.307943, max value: 0.577166\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001100)\n",
      "Loss_D = 0.91587883 (ave = 0.93622879)\n",
      "Loss_G = 0.85610253 (ave = 0.86002035)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.266560, max value: 0.150892\n",
      "D grad l2-norm: 1.303718, max value: 0.575077\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 0.92609453 (ave = 0.93818200)\n",
      "Loss_G = 0.85911083 (ave = 0.85686711)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.303899, max value: 0.160061\n",
      "D grad l2-norm: 1.315599, max value: 0.576347\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001031)\n",
      "Loss_D = 1.03286171 (ave = 0.95858073)\n",
      "Loss_G = 0.84646440 (ave = 0.84605987)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.373034, max value: 0.171571\n",
      "D grad l2-norm: 1.333385, max value: 0.570883\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 800 iters, (0.020)\tData load 0.011s / 800 iters, (0.002278)\n",
      "Loss_D = 1.05575430 (ave = 0.97031528)\n",
      "Loss_G = 0.82900411 (ave = 0.83308402)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.435068, max value: 0.188629\n",
      "D grad l2-norm: 1.331545, max value: 0.563292\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001067)\n",
      "Loss_D = 0.94300795 (ave = 0.97201265)\n",
      "Loss_G = 0.80779481 (ave = 0.81424018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.486221, max value: 0.185673\n",
      "D grad l2-norm: 1.337226, max value: 0.553931\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 800 iters, (0.023)\tData load 0.014s / 800 iters, (0.002724)\n",
      "Loss_D = 1.05068290 (ave = 1.00213125)\n",
      "Loss_G = 0.78378499 (ave = 0.79551651)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.517391, max value: 0.184207\n",
      "D grad l2-norm: 1.332748, max value: 0.542960\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 1.03584647 (ave = 1.01969905)\n",
      "Loss_G = 0.77375120 (ave = 0.77660667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:09\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.560548, max value: 0.180202\n",
      "D grad l2-norm: 1.347494, max value: 0.538285\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001107)\n",
      "Loss_D = 1.11959088 (ave = 1.05325043)\n",
      "Loss_G = 0.74219769 (ave = 0.75167044)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.592215, max value: 0.172632\n",
      "D grad l2-norm: 1.346460, max value: 0.523402\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001085)\n",
      "Loss_D = 1.09496510 (ave = 1.06775188)\n",
      "Loss_G = 0.72985649 (ave = 0.73186387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.615411, max value: 0.162935\n",
      "D grad l2-norm: 1.361051, max value: 0.517569\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 1.12752962 (ave = 1.09542942)\n",
      "Loss_G = 0.70326984 (ave = 0.71811395)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.645221, max value: 0.174107\n",
      "D grad l2-norm: 1.365873, max value: 0.504329\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 1.04169714 (ave = 1.10374539)\n",
      "Loss_G = 0.69954467 (ave = 0.70149056)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.641308, max value: 0.190323\n",
      "D grad l2-norm: 1.392081, max value: 0.502430\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 1.04185319 (ave = 1.12248216)\n",
      "Loss_G = 0.68962824 (ave = 0.69002625)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.645409, max value: 0.197264\n",
      "D grad l2-norm: 1.415192, max value: 0.497459\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.20330536 (ave = 1.15798788)\n",
      "Loss_G = 0.68157595 (ave = 0.68533311)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.667082, max value: 0.197676\n",
      "D grad l2-norm: 1.452689, max value: 0.493506\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.15567565 (ave = 1.16281414)\n",
      "Loss_G = 0.68862438 (ave = 0.68829452)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.677028, max value: 0.215689\n",
      "D grad l2-norm: 1.498702, max value: 0.496955\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001019)\n",
      "Loss_D = 1.13520920 (ave = 1.16678371)\n",
      "Loss_G = 0.69118702 (ave = 0.68884045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:10\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.704786, max value: 0.222533\n",
      "D grad l2-norm: 1.553116, max value: 0.498208\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 800 iters, (0.015)\tData load 0.008s / 800 iters, (0.001649)\n",
      "Loss_D = 1.25705338 (ave = 1.18477955)\n",
      "Loss_G = 0.69857293 (ave = 0.69615198)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.746630, max value: 0.234941\n",
      "D grad l2-norm: 1.637367, max value: 0.501761\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001110)\n",
      "Loss_D = 1.08807158 (ave = 1.16675134)\n",
      "Loss_G = 0.72116005 (ave = 0.71194432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.741587, max value: 0.243068\n",
      "D grad l2-norm: 1.701880, max value: 0.513087\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001138)\n",
      "Loss_D = 1.27837706 (ave = 1.18298078)\n",
      "Loss_G = 0.73463362 (ave = 0.72617775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.790965, max value: 0.254301\n",
      "D grad l2-norm: 1.821936, max value: 0.519601\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 1.08506620 (ave = 1.14554307)\n",
      "Loss_G = 0.77072865 (ave = 0.75756829)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.795517, max value: 0.250582\n",
      "D grad l2-norm: 1.922949, max value: 0.536677\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001149)\n",
      "Loss_D = 0.95559490 (ave = 1.11534240)\n",
      "Loss_G = 0.81071639 (ave = 0.78745030)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.781565, max value: 0.258425\n",
      "D grad l2-norm: 2.029473, max value: 0.554901\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001195)\n",
      "Loss_D = 1.09584093 (ave = 1.10929279)\n",
      "Loss_G = 0.85036200 (ave = 0.83236537)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.819120, max value: 0.249584\n",
      "D grad l2-norm: 2.201320, max value: 0.572145\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 800 iters, (0.014)\tData load 0.006s / 800 iters, (0.001175)\n",
      "Loss_D = 1.25234509 (ave = 1.10621853)\n",
      "Loss_G = 0.89769602 (ave = 0.87958854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.881181, max value: 0.248753\n",
      "D grad l2-norm: 2.396060, max value: 0.591937\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001115)\n",
      "Loss_D = 1.01873374 (ave = 1.04904139)\n",
      "Loss_G = 0.94155324 (ave = 0.92884398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.881705, max value: 0.243496\n",
      "D grad l2-norm: 2.496473, max value: 0.609520\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001119)\n",
      "Loss_D = 0.97181642 (ave = 1.02022080)\n",
      "Loss_G = 0.99738926 (ave = 0.97825842)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:11\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.910877, max value: 0.240052\n",
      "D grad l2-norm: 2.576811, max value: 0.630738\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 800 iters, (0.016)\tData load 0.012s / 800 iters, (0.002303)\n",
      "Loss_D = 0.95908225 (ave = 1.00209067)\n",
      "Loss_G = 1.03532648 (ave = 1.01840396)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.940856, max value: 0.233826\n",
      "D grad l2-norm: 2.667789, max value: 0.644523\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.013s / 800 iters, (0.002554)\n",
      "Loss_D = 0.99053937 (ave = 0.98948792)\n",
      "Loss_G = 1.06740713 (ave = 1.05413368)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.046602, max value: 0.220649\n",
      "D grad l2-norm: 2.854067, max value: 0.655686\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 800 iters, (0.024)\tData load 0.014s / 800 iters, (0.002772)\n",
      "Loss_D = 1.02532101 (ave = 0.98120587)\n",
      "Loss_G = 1.09376431 (ave = 1.08274465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.080848, max value: 0.215381\n",
      "D grad l2-norm: 2.900836, max value: 0.664695\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 800 iters, (0.025)\tData load 0.015s / 800 iters, (0.002957)\n",
      "Loss_D = 0.94350624 (ave = 0.95971448)\n",
      "Loss_G = 1.12917042 (ave = 1.11192291)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.146958, max value: 0.224137\n",
      "D grad l2-norm: 2.989234, max value: 0.676325\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001139)\n",
      "Loss_D = 0.90508759 (ave = 0.94441943)\n",
      "Loss_G = 1.14574754 (ave = 1.13895774)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.306911, max value: 0.260630\n",
      "D grad l2-norm: 3.124023, max value: 0.681435\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001097)\n",
      "Loss_D = 1.04308081 (ave = 0.95259956)\n",
      "Loss_G = 1.15159750 (ave = 1.15056431)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:12\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.419067, max value: 0.277748\n",
      "D grad l2-norm: 3.155681, max value: 0.683358\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 800 iters, (0.013)\tData load 0.011s / 800 iters, (0.002103)\n",
      "Loss_D = 0.86944902 (ave = 0.92690237)\n",
      "Loss_G = 1.15744376 (ave = 1.15893469)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.574039, max value: 0.308753\n",
      "D grad l2-norm: 3.232882, max value: 0.684999\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001137)\n",
      "Loss_D = 0.96221030 (ave = 0.94271806)\n",
      "Loss_G = 1.16413593 (ave = 1.16108079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.671550, max value: 0.322190\n",
      "D grad l2-norm: 3.275711, max value: 0.686977\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001133)\n",
      "Loss_D = 0.85611403 (ave = 0.93043100)\n",
      "Loss_G = 1.15474486 (ave = 1.15344326)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.717396, max value: 0.333689\n",
      "D grad l2-norm: 3.245544, max value: 0.683949\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001121)\n",
      "Loss_D = 0.96151519 (ave = 0.94652853)\n",
      "Loss_G = 1.15200949 (ave = 1.15525365)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.822876, max value: 0.344572\n",
      "D grad l2-norm: 3.330257, max value: 0.683202\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.01440156 (ave = 0.95561627)\n",
      "Loss_G = 1.15854454 (ave = 1.15042565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.832527, max value: 0.347741\n",
      "D grad l2-norm: 3.326645, max value: 0.685229\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001101)\n",
      "Loss_D = 1.02333307 (ave = 0.95763472)\n",
      "Loss_G = 1.16008353 (ave = 1.15676720)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.848908, max value: 0.363219\n",
      "D grad l2-norm: 3.298893, max value: 0.685578\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001039)\n",
      "Loss_D = 0.94977558 (ave = 0.94597815)\n",
      "Loss_G = 1.15285206 (ave = 1.15487928)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.965881, max value: 0.382324\n",
      "D grad l2-norm: 3.339304, max value: 0.683625\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.007s / 800 iters, (0.001470)\n",
      "Loss_D = 1.02374899 (ave = 0.95614219)\n",
      "Loss_G = 1.14656270 (ave = 1.15523183)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.051667, max value: 0.395714\n",
      "D grad l2-norm: 3.364127, max value: 0.681358\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001065)\n",
      "Loss_D = 0.84465998 (ave = 0.93579489)\n",
      "Loss_G = 1.12596607 (ave = 1.13978636)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:13\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.193036, max value: 0.398443\n",
      "D grad l2-norm: 3.326154, max value: 0.674443\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 800 iters, (0.022)\tData load 0.012s / 800 iters, (0.002496)\n",
      "Loss_D = 0.95445901 (ave = 0.96290876)\n",
      "Loss_G = 1.11641097 (ave = 1.11739497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.252671, max value: 0.413118\n",
      "D grad l2-norm: 3.270936, max value: 0.671320\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.97306478 (ave = 0.97669371)\n",
      "Loss_G = 1.07250237 (ave = 1.09004509)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.363801, max value: 0.409285\n",
      "D grad l2-norm: 3.204100, max value: 0.656612\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001075)\n",
      "Loss_D = 1.13096690 (ave = 1.02676027)\n",
      "Loss_G = 1.00740349 (ave = 1.03778074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.509501, max value: 0.400991\n",
      "D grad l2-norm: 3.148131, max value: 0.632878\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001066)\n",
      "Loss_D = 1.04176855 (ave = 1.04360392)\n",
      "Loss_G = 0.97270608 (ave = 0.98598981)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.324424, max value: 0.370247\n",
      "D grad l2-norm: 2.968754, max value: 0.620126\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001040)\n",
      "Loss_D = 1.07131326 (ave = 1.07880898)\n",
      "Loss_G = 0.93654442 (ave = 0.94963362)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.411638, max value: 0.335461\n",
      "D grad l2-norm: 3.015113, max value: 0.606047\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001082)\n",
      "Loss_D = 1.09956646 (ave = 1.10740414)\n",
      "Loss_G = 0.90564114 (ave = 0.91621339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.250249, max value: 0.314281\n",
      "D grad l2-norm: 2.917184, max value: 0.593848\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.96884370 (ave = 1.10128155)\n",
      "Loss_G = 0.91546851 (ave = 0.90826471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.064218, max value: 0.251404\n",
      "D grad l2-norm: 2.921392, max value: 0.597898\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001272)\n",
      "Loss_D = 1.09968686 (ave = 1.11227443)\n",
      "Loss_G = 0.92804575 (ave = 0.91823002)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.919572, max value: 0.241535\n",
      "D grad l2-norm: 2.929705, max value: 0.602853\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 800 iters, (0.020)\tData load 0.014s / 800 iters, (0.002805)\n",
      "Loss_D = 1.27904773 (ave = 1.12293985)\n",
      "Loss_G = 0.95948118 (ave = 0.95669065)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.911223, max value: 0.248195\n",
      "D grad l2-norm: 3.020981, max value: 0.615504\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001102)\n",
      "Loss_D = 1.32242751 (ave = 1.10687914)\n",
      "Loss_G = 0.97002649 (ave = 0.96677278)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:14\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.008216, max value: 0.268444\n",
      "D grad l2-norm: 3.127132, max value: 0.619486\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.17478871 (ave = 1.07387722)\n",
      "Loss_G = 0.99311900 (ave = 0.99143063)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.073898, max value: 0.282601\n",
      "D grad l2-norm: 3.216640, max value: 0.628219\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001048)\n",
      "Loss_D = 0.99630034 (ave = 1.04520638)\n",
      "Loss_G = 1.01265526 (ave = 1.00439876)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.181146, max value: 0.302723\n",
      "D grad l2-norm: 3.214894, max value: 0.635147\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000998)\n",
      "Loss_D = 1.14994764 (ave = 1.05296108)\n",
      "Loss_G = 1.02958131 (ave = 1.02295597)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.325656, max value: 0.317779\n",
      "D grad l2-norm: 3.298508, max value: 0.641003\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001054)\n",
      "Loss_D = 1.02330542 (ave = 1.03111218)\n",
      "Loss_G = 1.03533077 (ave = 1.03602715)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.449968, max value: 0.323697\n",
      "D grad l2-norm: 3.423422, max value: 0.642724\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001073)\n",
      "Loss_D = 1.01614332 (ave = 1.02905712)\n",
      "Loss_G = 1.04888940 (ave = 1.04027951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.437037, max value: 0.329307\n",
      "D grad l2-norm: 3.491417, max value: 0.647857\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.93983120 (ave = 1.00385973)\n",
      "Loss_G = 1.07123911 (ave = 1.06984315)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.624400, max value: 0.347914\n",
      "D grad l2-norm: 3.688387, max value: 0.655148\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001135)\n",
      "Loss_D = 0.89168811 (ave = 0.98227649)\n",
      "Loss_G = 1.10573566 (ave = 1.09356790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.708724, max value: 0.355219\n",
      "D grad l2-norm: 3.809577, max value: 0.666727\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 0.95531750 (ave = 0.97743928)\n",
      "Loss_G = 1.14078319 (ave = 1.12190223)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.820358, max value: 0.341970\n",
      "D grad l2-norm: 4.028187, max value: 0.678279\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001064)\n",
      "Loss_D = 0.90437889 (ave = 0.95171450)\n",
      "Loss_G = 1.15804362 (ave = 1.15130002)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.760683, max value: 0.341883\n",
      "D grad l2-norm: 4.080994, max value: 0.683679\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001025)\n",
      "Loss_D = 0.95947027 (ave = 0.94183295)\n",
      "Loss_G = 1.19906318 (ave = 1.18930478)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:15\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.900785, max value: 0.338085\n",
      "D grad l2-norm: 4.262774, max value: 0.696407\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001283)\n",
      "Loss_D = 0.88345367 (ave = 0.91396438)\n",
      "Loss_G = 1.24066234 (ave = 1.21718647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.996258, max value: 0.334719\n",
      "D grad l2-norm: 4.355338, max value: 0.708709\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001222)\n",
      "Loss_D = 0.82375979 (ave = 0.89289688)\n",
      "Loss_G = 1.20885348 (ave = 1.22570198)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.062332, max value: 0.345132\n",
      "D grad l2-norm: 4.279107, max value: 0.699188\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.85329998 (ave = 0.89620728)\n",
      "Loss_G = 1.21931756 (ave = 1.21948323)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.180642, max value: 0.342020\n",
      "D grad l2-norm: 4.343648, max value: 0.702070\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001072)\n",
      "Loss_D = 0.93868458 (ave = 0.91014659)\n",
      "Loss_G = 1.20785773 (ave = 1.21468947)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.410943, max value: 0.344674\n",
      "D grad l2-norm: 4.393802, max value: 0.698538\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.007s / 800 iters, (0.001417)\n",
      "Loss_D = 0.99702966 (ave = 0.92715015)\n",
      "Loss_G = 1.15423846 (ave = 1.17909424)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.591194, max value: 0.359401\n",
      "D grad l2-norm: 4.450830, max value: 0.681436\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 800 iters, (0.018)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.91549265 (ave = 0.93319803)\n",
      "Loss_G = 1.16906130 (ave = 1.16385787)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.687399, max value: 0.396269\n",
      "D grad l2-norm: 4.562723, max value: 0.686434\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 0.94266474 (ave = 0.93299618)\n",
      "Loss_G = 1.17931938 (ave = 1.17050869)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.524809, max value: 0.414010\n",
      "D grad l2-norm: 4.483832, max value: 0.690108\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001286)\n",
      "Loss_D = 1.04299402 (ave = 0.94261928)\n",
      "Loss_G = 1.19490433 (ave = 1.18887506)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.601318, max value: 0.426258\n",
      "D grad l2-norm: 4.766209, max value: 0.694445\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 0.91362703 (ave = 0.91271333)\n",
      "Loss_G = 1.24348474 (ave = 1.21148198)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.539574, max value: 0.438025\n",
      "D grad l2-norm: 4.835009, max value: 0.709610\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001029)\n",
      "Loss_D = 0.92151761 (ave = 0.90442252)\n",
      "Loss_G = 1.24196720 (ave = 1.23950603)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:16\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.660733, max value: 0.443091\n",
      "D grad l2-norm: 4.884404, max value: 0.709504\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 800 iters, (0.025)\tData load 0.022s / 800 iters, (0.004376)\n",
      "Loss_D = 0.85275501 (ave = 0.88984106)\n",
      "Loss_G = 1.25265837 (ave = 1.24313397)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.752331, max value: 0.419155\n",
      "D grad l2-norm: 4.907249, max value: 0.712251\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 800 iters, (0.020)\tData load 0.014s / 800 iters, (0.002741)\n",
      "Loss_D = 0.87330925 (ave = 0.89872658)\n",
      "Loss_G = 1.25798774 (ave = 1.25061288)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.791280, max value: 0.419701\n",
      "D grad l2-norm: 5.032681, max value: 0.713901\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001062)\n",
      "Loss_D = 0.96012354 (ave = 0.90512851)\n",
      "Loss_G = 1.25200415 (ave = 1.24827068)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.670409, max value: 0.395395\n",
      "D grad l2-norm: 5.010443, max value: 0.712568\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001080)\n",
      "Loss_D = 1.03440332 (ave = 0.91313879)\n",
      "Loss_G = 1.24997103 (ave = 1.24511955)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.749080, max value: 0.394597\n",
      "D grad l2-norm: 5.058519, max value: 0.711849\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001059)\n",
      "Loss_D = 1.02453780 (ave = 0.91773326)\n",
      "Loss_G = 1.23008478 (ave = 1.24977074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.622077, max value: 0.397204\n",
      "D grad l2-norm: 4.842339, max value: 0.705905\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 800 iters, (0.015)\tData load 0.008s / 800 iters, (0.001694)\n",
      "Loss_D = 0.89888334 (ave = 0.91281341)\n",
      "Loss_G = 1.20627630 (ave = 1.21594663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.587903, max value: 0.383685\n",
      "D grad l2-norm: 4.800707, max value: 0.698691\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001004)\n",
      "Loss_D = 1.08491433 (ave = 0.94893354)\n",
      "Loss_G = 1.18073416 (ave = 1.19459674)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.741371, max value: 0.386406\n",
      "D grad l2-norm: 4.775188, max value: 0.690641\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001036)\n",
      "Loss_D = 1.01938617 (ave = 0.97013106)\n",
      "Loss_G = 1.12665796 (ave = 1.14711361)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.821198, max value: 0.388265\n",
      "D grad l2-norm: 4.674984, max value: 0.673677\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001011)\n",
      "Loss_D = 1.00514388 (ave = 0.99343616)\n",
      "Loss_G = 1.09571636 (ave = 1.11234741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.504046, max value: 0.372166\n",
      "D grad l2-norm: 4.421827, max value: 0.662892\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 800 iters, (0.017)\tData load 0.005s / 800 iters, (0.001010)\n",
      "Loss_D = 0.94630134 (ave = 1.00748913)\n",
      "Loss_G = 1.06398189 (ave = 1.08164992)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:17\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.574160, max value: 0.331500\n",
      "D grad l2-norm: 4.437268, max value: 0.652076\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001108)\n",
      "Loss_D = 1.02762771 (ave = 1.04548395)\n",
      "Loss_G = 1.03579867 (ave = 1.03619351)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.495301, max value: 0.300650\n",
      "D grad l2-norm: 4.345784, max value: 0.642212\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 800 iters, (0.014)\tData load 0.007s / 800 iters, (0.001451)\n",
      "Loss_D = 1.15758944 (ave = 1.07954710)\n",
      "Loss_G = 1.01059580 (ave = 1.01101528)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.476226, max value: 0.290592\n",
      "D grad l2-norm: 4.263105, max value: 0.632613\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001131)\n",
      "Loss_D = 1.16740322 (ave = 1.10662169)\n",
      "Loss_G = 0.97395313 (ave = 0.98596137)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.626916, max value: 0.304583\n",
      "D grad l2-norm: 4.290451, max value: 0.619211\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001068)\n",
      "Loss_D = 1.12842250 (ave = 1.12293065)\n",
      "Loss_G = 0.94417787 (ave = 0.96366730)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.649865, max value: 0.319884\n",
      "D grad l2-norm: 4.245150, max value: 0.607963\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001028)\n",
      "Loss_D = 1.09924567 (ave = 1.12405666)\n",
      "Loss_G = 0.97351211 (ave = 0.97642418)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.607882, max value: 0.317591\n",
      "D grad l2-norm: 4.349053, max value: 0.619339\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001061)\n",
      "Loss_D = 1.10075068 (ave = 1.10891328)\n",
      "Loss_G = 1.02082992 (ave = 0.99485860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.635791, max value: 0.340585\n",
      "D grad l2-norm: 4.467170, max value: 0.667713\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 1.06392217 (ave = 1.09065664)\n",
      "Loss_G = 1.04064870 (ave = 1.01760162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.669512, max value: 0.382085\n",
      "D grad l2-norm: 4.495113, max value: 0.719707\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001099)\n",
      "Loss_D = 0.92558372 (ave = 1.05583341)\n",
      "Loss_G = 1.05652857 (ave = 1.05416539)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.858144, max value: 0.423222\n",
      "D grad l2-norm: 4.601137, max value: 0.771753\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001019)\n",
      "Loss_D = 1.02869248 (ave = 1.05024109)\n",
      "Loss_G = 1.09003937 (ave = 1.08513186)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.024440, max value: 0.450573\n",
      "D grad l2-norm: 4.751275, max value: 0.820523\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 1.09307921 (ave = 1.04999475)\n",
      "Loss_G = 1.07116985 (ave = 1.09389033)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:18\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.027068, max value: 0.473299\n",
      "D grad l2-norm: 4.787663, max value: 0.825163\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 1.15402460 (ave = 1.04071870)\n",
      "Loss_G = 1.12620378 (ave = 1.12888732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.138996, max value: 0.457878\n",
      "D grad l2-norm: 5.106018, max value: 0.895905\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 0.99806392 (ave = 0.99017162)\n",
      "Loss_G = 1.18528521 (ave = 1.16776350)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.033879, max value: 0.448485\n",
      "D grad l2-norm: 5.278437, max value: 0.941218\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001026)\n",
      "Loss_D = 1.06760406 (ave = 0.96642028)\n",
      "Loss_G = 1.23319399 (ave = 1.20460072)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.808814, max value: 0.448931\n",
      "D grad l2-norm: 5.226614, max value: 0.941348\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 800 iters, (0.021)\tData load 0.013s / 800 iters, (0.002615)\n",
      "Loss_D = 0.90763795 (ave = 0.91776391)\n",
      "Loss_G = 1.27172351 (ave = 1.25547442)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.895973, max value: 0.441938\n",
      "D grad l2-norm: 5.364360, max value: 0.956016\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001081)\n",
      "Loss_D = 0.89535278 (ave = 0.89307314)\n",
      "Loss_G = 1.30947495 (ave = 1.29450974)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.976998, max value: 0.451607\n",
      "D grad l2-norm: 5.434006, max value: 0.960169\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 800 iters, (0.023)\tData load 0.006s / 800 iters, (0.001111)\n",
      "Loss_D = 0.87500870 (ave = 0.88940384)\n",
      "Loss_G = 1.29094577 (ave = 1.28981495)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.945744, max value: 0.464617\n",
      "D grad l2-norm: 5.331616, max value: 0.904089\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.005s / 800 iters, (0.001098)\n",
      "Loss_D = 0.99752486 (ave = 0.89716340)\n",
      "Loss_G = 1.27841449 (ave = 1.29619906)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.187852, max value: 0.489021\n",
      "D grad l2-norm: 5.402094, max value: 0.876269\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 800 iters, (0.017)\tData load 0.013s / 800 iters, (0.002670)\n",
      "Loss_D = 0.93226194 (ave = 0.90124401)\n",
      "Loss_G = 1.25461876 (ave = 1.26191103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.230186, max value: 0.496143\n",
      "D grad l2-norm: 5.337406, max value: 0.804650\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 800 iters, (0.015)\tData load 0.005s / 800 iters, (0.001044)\n",
      "Loss_D = 0.94203931 (ave = 0.90989912)\n",
      "Loss_G = 1.19707978 (ave = 1.23752906)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.519726, max value: 0.518882\n",
      "D grad l2-norm: 5.341370, max value: 0.719222\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001088)\n",
      "Loss_D = 0.85058075 (ave = 0.93179344)\n",
      "Loss_G = 1.17143798 (ave = 1.18643405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:19\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.699422, max value: 0.522069\n",
      "D grad l2-norm: 5.359884, max value: 0.687086\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 0.84321153 (ave = 0.96031042)\n",
      "Loss_G = 1.12180924 (ave = 1.13505394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.409508, max value: 0.489185\n",
      "D grad l2-norm: 5.026862, max value: 0.670945\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001087)\n",
      "Loss_D = 0.99639332 (ave = 1.00381771)\n",
      "Loss_G = 1.12601113 (ave = 1.12112794)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.441787, max value: 0.465424\n",
      "D grad l2-norm: 5.111955, max value: 0.672869\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001096)\n",
      "Loss_D = 1.04272425 (ave = 1.03235009)\n",
      "Loss_G = 1.09196341 (ave = 1.09946251)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.599564, max value: 0.450554\n",
      "D grad l2-norm: 5.234575, max value: 0.661939\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001060)\n",
      "Loss_D = 1.08833778 (ave = 1.05946515)\n",
      "Loss_G = 1.06331527 (ave = 1.07485912)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.593025, max value: 0.436793\n",
      "D grad l2-norm: 5.261791, max value: 0.651304\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001056)\n",
      "Loss_D = 0.95993662 (ave = 1.06483035)\n",
      "Loss_G = 1.06323957 (ave = 1.05733836)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.227692, max value: 0.422240\n",
      "D grad l2-norm: 5.110895, max value: 0.652283\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.048s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.000988)\n",
      "Loss_D = 1.21574748 (ave = 1.09995768)\n",
      "Loss_G = 1.09271097 (ave = 1.08076317)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.192406, max value: 0.425551\n",
      "D grad l2-norm: 5.305632, max value: 0.662341\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.10554576 (ave = 1.08868904)\n",
      "Loss_G = 1.12397981 (ave = 1.10713701)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.102802, max value: 0.424821\n",
      "D grad l2-norm: 5.333316, max value: 0.673020\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 0.97054827 (ave = 1.06430972)\n",
      "Loss_G = 1.12889361 (ave = 1.12641525)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.264381, max value: 0.420226\n",
      "D grad l2-norm: 5.449479, max value: 0.674128\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001047)\n",
      "Loss_D = 1.14260828 (ave = 1.08776528)\n",
      "Loss_G = 1.15875721 (ave = 1.14202394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.409731, max value: 0.394930\n",
      "D grad l2-norm: 5.782376, max value: 0.683868\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001083)\n",
      "Loss_D = 1.23731375 (ave = 1.09552350)\n",
      "Loss_G = 1.19967282 (ave = 1.17408049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.208523, max value: 0.386607\n",
      "D grad l2-norm: 5.907052, max value: 0.696450\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.09369516 (ave = 1.05546799)\n",
      "Loss_G = 1.25584888 (ave = 1.22550914)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.209030, max value: 0.413835\n",
      "D grad l2-norm: 6.124518, max value: 0.711857\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001033)\n",
      "Loss_D = 0.99662507 (ave = 1.02228386)\n",
      "Loss_G = 1.26348615 (ave = 1.25623231)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.272601, max value: 0.455284\n",
      "D grad l2-norm: 6.156161, max value: 0.714679\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001078)\n",
      "Loss_D = 0.95825183 (ave = 1.00631516)\n",
      "Loss_G = 1.32534552 (ave = 1.29605334)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.486616, max value: 0.479596\n",
      "D grad l2-norm: 6.246266, max value: 0.730907\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.005s / 800 iters, (0.001071)\n",
      "Loss_D = 1.03593588 (ave = 1.01464903)\n",
      "Loss_G = 1.27289283 (ave = 1.30810044)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.594447, max value: 0.486039\n",
      "D grad l2-norm: 6.131614, max value: 0.716366\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001045)\n",
      "Loss_D = 1.04727721 (ave = 1.02698085)\n",
      "Loss_G = 1.28641856 (ave = 1.29407427)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.564124, max value: 0.479464\n",
      "D grad l2-norm: 6.141109, max value: 0.720504\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001043)\n",
      "Loss_D = 1.00861979 (ave = 1.01611776)\n",
      "Loss_G = 1.27603042 (ave = 1.27360587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.368998, max value: 0.473822\n",
      "D grad l2-norm: 6.055042, max value: 0.717426\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001016)\n",
      "Loss_D = 1.10303247 (ave = 1.01116505)\n",
      "Loss_G = 1.28785098 (ave = 1.28709230)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.328035, max value: 0.480648\n",
      "D grad l2-norm: 6.012173, max value: 0.741971\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001058)\n",
      "Loss_D = 1.11043370 (ave = 0.99858005)\n",
      "Loss_G = 1.26304567 (ave = 1.28409545)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.707047, max value: 0.508358\n",
      "D grad l2-norm: 6.094260, max value: 0.760798\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 800 iters, (0.019)\tData load 0.008s / 800 iters, (0.001688)\n",
      "Loss_D = 1.12623727 (ave = 1.01169984)\n",
      "Loss_G = 1.24247897 (ave = 1.26345489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.946392, max value: 0.514599\n",
      "D grad l2-norm: 6.063907, max value: 0.762335\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 800 iters, (0.010)\tData load 0.005s / 800 iters, (0.001039)\n",
      "Loss_D = 1.01849914 (ave = 1.00359614)\n",
      "Loss_G = 1.20065212 (ave = 1.22731125)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:21\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.896299, max value: 0.487445\n",
      "D grad l2-norm: 5.974821, max value: 0.742867\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 800 iters, (0.014)\tData load 0.005s / 800 iters, (0.001070)\n",
      "Loss_D = 1.08959103 (ave = 1.02266666)\n",
      "Loss_G = 1.22408211 (ave = 1.23055046)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.886339, max value: 0.461170\n",
      "D grad l2-norm: 5.850246, max value: 0.741585\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 800 iters, (0.017)\tData load 0.014s / 800 iters, (0.002720)\n",
      "Loss_D = 1.07731891 (ave = 1.02673335)\n",
      "Loss_G = 1.15587044 (ave = 1.18751576)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.130315, max value: 0.444909\n",
      "D grad l2-norm: 5.803419, max value: 0.700123\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001124)\n",
      "Loss_D = 1.06165314 (ave = 1.04500397)\n",
      "Loss_G = 1.15968931 (ave = 1.15065999)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.145045, max value: 0.410985\n",
      "D grad l2-norm: 5.694268, max value: 0.682721\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001103)\n",
      "Loss_D = 1.40229094 (ave = 1.10942258)\n",
      "Loss_G = 1.09143472 (ave = 1.11833572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.981705, max value: 0.420192\n",
      "D grad l2-norm: 5.601706, max value: 0.660633\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001094)\n",
      "Loss_D = 1.06672871 (ave = 1.08137410)\n",
      "Loss_G = 1.11079919 (ave = 1.09665079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.653047, max value: 0.422234\n",
      "D grad l2-norm: 5.390644, max value: 0.667119\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001151)\n",
      "Loss_D = 1.11750746 (ave = 1.08431773)\n",
      "Loss_G = 1.07289267 (ave = 1.08370090)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.555377, max value: 0.428474\n",
      "D grad l2-norm: 5.285803, max value: 0.654130\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.05838418 (ave = 1.07977052)\n",
      "Loss_G = 1.10933280 (ave = 1.09819391)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:22\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.512030, max value: 0.427485\n",
      "D grad l2-norm: 5.352307, max value: 0.666937\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 800 iters, (0.012)\tData load 0.005s / 800 iters, (0.001093)\n",
      "Loss_D = 1.17048526 (ave = 1.08442760)\n",
      "Loss_G = 1.12913918 (ave = 1.11141510)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.215912, max value: 0.416730\n",
      "D grad l2-norm: 5.359280, max value: 0.673811\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 800 iters, (0.022)\tData load 0.006s / 800 iters, (0.001156)\n",
      "Loss_D = 0.85334373 (ave = 1.02039640)\n",
      "Loss_G = 1.17281508 (ave = 1.14310000)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.822841, max value: 0.382449\n",
      "D grad l2-norm: 5.343697, max value: 0.687895\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 800 iters, (0.013)\tData load 0.006s / 800 iters, (0.001159)\n",
      "Loss_D = 0.87145138 (ave = 0.99294059)\n",
      "Loss_G = 1.23448050 (ave = 1.20684946)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.581145, max value: 0.363560\n",
      "D grad l2-norm: 5.377770, max value: 0.706796\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 800 iters, (0.019)\tData load 0.005s / 800 iters, (0.001086)\n",
      "Loss_D = 0.94120383 (ave = 0.96799550)\n",
      "Loss_G = 1.26328063 (ave = 1.25993474)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.683627, max value: 0.366153\n",
      "D grad l2-norm: 5.548839, max value: 0.715411\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001129)\n",
      "Loss_D = 1.07751834 (ave = 0.95923073)\n",
      "Loss_G = 1.30355036 (ave = 1.30127811)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.606512, max value: 0.385893\n",
      "D grad l2-norm: 5.541396, max value: 0.725912\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 800 iters, (0.014)\tData load 0.009s / 800 iters, (0.001828)\n",
      "Loss_D = 0.93555748 (ave = 0.91351432)\n",
      "Loss_G = 1.33127332 (ave = 1.31921041)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.545500, max value: 0.380116\n",
      "D grad l2-norm: 5.538913, max value: 0.734128\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001147)\n",
      "Loss_D = 0.92568231 (ave = 0.89477593)\n",
      "Loss_G = 1.34525049 (ave = 1.32991047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.505276, max value: 0.388691\n",
      "D grad l2-norm: 5.504053, max value: 0.737054\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 800 iters, (0.011)\tData load 0.006s / 800 iters, (0.001123)\n",
      "Loss_D = 0.82550114 (ave = 0.85902982)\n",
      "Loss_G = 1.35418129 (ave = 1.36180270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:23\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.389504, max value: 0.402680\n",
      "D grad l2-norm: 5.396335, max value: 0.739411\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 800 iters, (0.012)\tData load 0.006s / 800 iters, (0.001136)\n",
      "Loss_D = 0.78722966 (ave = 0.83741093)\n",
      "Loss_G = 1.35649955 (ave = 1.37304947)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.397233, max value: 0.438522\n",
      "D grad l2-norm: 5.309799, max value: 0.740164\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 800 iters, (0.013)\tData load 0.009s / 800 iters, (0.001799)\n",
      "Loss_D = 0.84900630 (ave = 0.83134575)\n",
      "Loss_G = 1.36473310 (ave = 1.37400742)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.580077, max value: 0.466122\n",
      "D grad l2-norm: 5.390077, max value: 0.742189\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 800 iters, (0.016)\tData load 0.005s / 800 iters, (0.001051)\n",
      "Loss_D = 0.83354664 (ave = 0.82102014)\n",
      "Loss_G = 1.34249508 (ave = 1.35078561)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.675437, max value: 0.492666\n",
      "D grad l2-norm: 5.234589, max value: 0.736335\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 800 iters, (0.016)\tData load 0.006s / 800 iters, (0.001252)\n",
      "Loss_D = 0.83185494 (ave = 0.82367741)\n",
      "Loss_G = 1.30211246 (ave = 1.32190704)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.744137, max value: 0.525759\n",
      "D grad l2-norm: 5.068340, max value: 0.725367\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 800 iters, (0.024)\tData load 0.022s / 800 iters, (0.004381)\n",
      "Loss_D = 0.83032084 (ave = 0.82769411)\n",
      "Loss_G = 1.27441490 (ave = 1.28435197)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 21:03:24\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.750888, max value: 0.524059\n",
      "D grad l2-norm: 4.866418, max value: 0.717000\n"
     ]
    }
   ],
   "source": [
    "# -- TIME SERIES CROSS-VALIDATION LOOP --\n",
    "for asset_index in range(NUM_ASSETS):\n",
    "    print(f\"\\U0001F501 TSCV for Asset {asset_index}\")\n",
    "    returns = raw_returns_all_assets[:, asset_index].reshape(-1, 1)\n",
    "    scaler = StandardScaler().fit(returns)\n",
    "    returns_scaled = scaler.transform(returns).squeeze()\n",
    "\n",
    "    splits = time_series_cv_split(returns_scaled, window_size=300, val_window=100, step=100)\n",
    "\n",
    "    for fold, (train_seq, val_seq) in enumerate(splits):\n",
    "        print(f\"\\U0001F4E6 Fold {fold + 1} | Train: {len(train_seq)}, Val: {len(val_seq)}\")\n",
    "\n",
    "        # -- DEFINE CUSTOM DATASET FOR TSCV --\n",
    "        class FoldDataset(Dataset):\n",
    "            def __init__(self, series, window_size):\n",
    "                self.samples = [series[i:i+window_size] for i in range(len(series) - window_size)]\n",
    "\n",
    "            def __len__(self): return len(self.samples)\n",
    "            def __getitem__(self, idx):\n",
    "                return torch.tensor(self.samples[idx], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "        config.get_dataset = lambda: FoldDataset(train_seq, window_size=20)\n",
    "\n",
    "        # -- MODEL INIT AND TRAINING --\n",
    "        G, D = construct_model(args, config)\n",
    "        train_net(G, D, args, config)\n",
    "\n",
    "        # -- SAVE MODELS --\n",
    "        fold_dir = f\"tscv_asset_{asset_index}/fold_{fold}\"\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "        torch.save(G.state_dict(), os.path.join(fold_dir, \"G.pt\"))\n",
    "        torch.save(D.state_dict(), os.path.join(fold_dir, \"D.pt\"))\n",
    "\n",
    "        # -- EVALUATE ON PRICE LEVEL --\n",
    "        real_returns_flat = val_seq.flatten()\n",
    "        real_prices = np.cumprod(1 + real_returns_flat)\n",
    "\n",
    "        G.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, config.z_size).to(device)\n",
    "            synthetic_returns = G(z).cpu().numpy().flatten()\n",
    "\n",
    "        # Convert synthetic returns to prices\n",
    "        synt_prices = [real_prices[0]]\n",
    "        for r in scaler.inverse_transform(synthetic_returns.reshape(-1, 1)).flatten():\n",
    "            synt_prices.append(synt_prices[-1] * (1 + r))\n",
    "        synt_prices = np.array(synt_prices[1:])\n",
    "\n",
    "        # -- EVALUATE AND STORE METRICS --\n",
    "        metrics_df = evaluate_synthetic_vs_real(real_prices, synt_prices)\n",
    "        metrics_df[\"Asset\"] = asset_index\n",
    "        metrics_df[\"Fold\"] = fold\n",
    "        all_metrics.append(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5201eed6-ce56-4cc6-a4bc-5720584505ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ All metrics saved to 'price_level_evaluation_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "# -- CONSOLIDATE METRICS --\n",
    "results_df = pd.concat(all_metrics, ignore_index=True)\n",
    "results_df.to_csv(\"price_level_evaluation_metrics.csv\", index=False)\n",
    "print(\"\\U0001F4C4 All metrics saved to 'price_level_evaluation_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23def949-e7c2-48c8-bff4-82c842c69e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- BOXPLOTS FOR VISUAL COMPARISON PER ASSET --\n",
    "def plot_boxplots(real_all, synthetic_all, asset_names=None):\n",
    "    data = []\n",
    "    for i, (real, synthetic) in enumerate(zip(real_all, synthetic_all)):\n",
    "        asset = asset_names[i] if asset_names else f\"Asset {i}\"\n",
    "        data += [{\"Asset\": asset, \"Price\": p, \"Type\": \"Real\"} for p in real]\n",
    "        data += [{\"Asset\": asset, \"Price\": p, \"Type\": \"Synthetic\"} for p in synthetic]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.boxplot(data=df, x=\"Asset\", y=\"Price\", hue=\"Type\", palette=\"Set2\")\n",
    "    plt.title(\"Boxplots of Real vs Synthetic Prices per Asset\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"price_boxplots_per_asset.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e134f60-6f73-4c6a-b29e-be8e27e6b95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAGoCAYAAACwmRWfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3wddZ3/8fenSS9QCkkvaxaQFHBBEXqBQEtTWpS7C0jiTwGVCkWRXZRdF2+oLUp1xQUUuajUBaEgImCDyspuhaUpBChN2QJqW8uloQFiQ5pAWyhN0s/vj5mUNE1OknPOZOac83o+HjzonDNn5pPvuc57vt/vmLsLAAAAAAAgyYbFXQAAAAAAAEB/CDAAAAAAAEDiEWAAAAAAAIDEI8AAAAAAAACJR4ABAAAAAAASjwADAAAAAAAkHgEGACDvmdltZvbdmGt4j5ktM7PNZnbtEO/722Z251DuM0pmtt7MTszStg4wsy1mVpSN7aXYz3FmtjbKfQAAkO8IMAAAQyY88Hw7PGBsNbP/MrP3xl1Xd2bmZva+CDZ9kaTXJe3t7pf1st/bzGx72DabzOyPZvb+COqIhJnNNLPHzeyNsP46Mzs6C9vNavjUM/xw95fdfS937xzkds43s87w+XrTzFaZ2el9re/uj7r7oZnUnkRmtjR8L4+MeD95FcIBANJDgAEAGGpnuPtekv5e0t8k3RBzPUOlXNJf3N1TrPMfYdvsJ+kVSbcMSWUZMrO9JT2g4Lkcq6D+70h6J866hsAT4fNVouC5usfMxvZcycyKh7yyLLFAr78XzWyipOMkuaQzh7AsAECBIsAAAMTC3bdJuk/SYV23mdk+ZrbIzJrNrMHMvtV18GRmPzWz+7qt+wMzezg8wDrezBrN7Btm9np4lv1Tfe3bzD5nZs+HPQV+Z2b7hrcvC1d5JjyzfraZjTezB8ysLVz/0RQHdDPMbEXYC2GFmc0Ib79N0mckfTXcbsrhD+7+tqR7JE3psf25ZrY6POP9P2ZW3u2+H5vZhrA3wEozOy7VPro9bnX3ngNmVhy24ZFmNsrM7jSzlvDvX2Fm7+llM4eEdf/K3Tvd/W13X+Luz5rZyLDdjui2j78Le+JM6PbcXWZmG83sNTO7IFzvIkmf6tZuv++2zylm9mzY1r82s1Hdtn962COiLewVMim8/Q5JB0j6fbi9r5rZRAt63RSH64w1s1+Y2athO9/fXxu6+w5Jt0raQ9JB3f6mr5lZk6RfdN3Wrcb3mtni8LXeYmY3druv1+c5fK3/KGynN8K///A+ntelZvZ9M3sqXPe31i1cMbPpYdu0mdkzZnZ8j8d+z8zqJL0l6aA+/vQ5kp6UdJuC13f3/X/EzP5iwZCpV8zsy+Htfb6fzGxfM/tN2CYvmdml4e2nSvqGpLPD5+2Z/p4TAEB+IsAAAMTCzPaUdLaCA6AuN0jaR8EB02wFB0gXhPddJmmSBV33j5N0oaTPdOvRUCZpvIKz/5+RtNDMduuyb2YflvR9SZ9Q0AukQdLdkuTus8LVJofDCn4d7rdR0gRJ71FwILVbL4rw4PC/JF0vaZykH0r6LzMb5+7nS/qlwh4W7v5QP20zWtK5kp7vdttZ4b6rw1oelfSrbg9boSDwGCvpLkn3dj+oT+FX4b66nCLpdXd/WkE77iPpveHfdLGkt3vZxl8ldZrZ7WZ2mpmVdt3h7u8oaN9Pd1v/XEkPuXtzuFwW7mc/Bc/rTWZW6u4LtWu7ndFtG5+QdKqkAyVNknS+JJnZkQrChM+HNd8s6XdmNtLdz5P0ssJeQO7+H738LXdI2lPSByX9naQf9d5s7wrDj89K2iJpXbe/aayCnjcX9Vi/SEGPlQZJE8O/++7wvlTP88mSZikIjEoUvH9aUpQ2R9JcSftK6lDw2pSZ7afgtfrdsMYvS/qNmU3o9tjzwrrHhHX2tf1fhv+d0iPcukXS5919jKTDJf1veHuv76cwxPi9pGfC9jhB0r+a2Snu/t+S/l3Sr8PnbXKKvxkAkMcIMAAAQ+1+M2uT9KakkyRdLe08qDtb0uXuvtnd10u6VsGBlNz9LQUHwT+UdKekL7p7Y49tz3P3d9y9VsEB2id62f+nJN3q7k+HB9eXSzrWgu7wvWlXEHSUu3t7OJdBb8NA/lHSOne/w9073P1XktZIOqOXdfvy5bBtNkuaqfBvD31e0vfdfbW7dyg4oJvSdXbe3e9095Zw39dKGilpIHMu3CXpzDBQkqRPhrd1/e3jJL0v7Fmx0t3f7LmB8LaZCoKdn0tqtqBnS9cB7e2SPmnv9lw5T0FQ0KVd0pVh+/5BQRDQX+3Xu/ur7r5JwYFvV2+Vz0m62d2XhzXfrmAoy/T+GsLM/l7SaZIudvfWsJ7aFA+ZHj5fTQpCmSp3fyO8b4ekK8LXY8/Q5xgFocJX3H2ru29z98fC+1I9z+0KAoX3S7JwnddS1HeHu//J3bdKmifpE+H77NOS/uDuf3D3He7+R0n1kj7S7bG3ufufw9dTey9tNVNBOHOPu6+U9IKC106XdkmHmdneYVs+3e323t5PR0ua4O5Xuvt2d39RwWvpnBR/HwCgwBBgAACG2lnuXqLgAPsLkmrNrKv3xAjtera3QcHZWEmSuz8l6UVJpmCIRXet4YFa98fu28v+9+2+D3ffouAs9n69rCsFAcvzkpaY2Ytm9vU+1ttlu73VPwDXhG0zUUFPh+4H8eWSfhx2vW+TtElBO+wnSRYMwVgdDhdoU9CjYXx/O3T35yWtlnRGGGKcqXcDjDsk/Y+ku8MhFf9hZsP72M5qdz/f3fdXcMZ9X0nXhfctl7RV0mwLJiZ9n6TfdXt4S3iw3uUtSXv1U3pTH+uXS7qsq53Ctniven8t9PReSZvcvXUA60rSk+5e4u7j3X16j541zeEwqb7209Djb+7S5/Ps7v8r6UZJN0n6m5kttGD+kb5s6PbvBknDFbwmyiV9vEcbzVQQLPT22N58RtISd389XL5Luw4j+ZiCQKTBzGrN7Njw9r7eT+WS9u1R0zcU9NIAAEASAQYAICbh2fHFkjoVHDy9ruDsbHm31Q5QMJmlJMnMLlEQfLwq6as9NlkaDr3o/thXe9n1q933ET5mXPf99Khzs7tf5u4HKehN8W9mdkJ/2+2t/oFy95cl/YuCA9k9wps3KOiSX9Ltvz3c/fFwSM3XFPQ4KQ1DkDcUHPgORNcwko8qmGj0+bCOdnf/jrsfJmmGpNMVDBvor/41CuZF6D4/w+0KzvyfJ+m+FAf3u21ugOt12SDpez3aac+wR0x/29sgaayZlQxyn73pbz8HWO+Te/b5PEuSu1/v7kcpGOJyiKSvpNhP9yv8HKDg/fV6uI87euxjtLtfNZD6w9fkJxQEUk0WzPPxJUmTzWxyWOcKd/+ogmE49ysMHFO8nzZIeqlHTWPcvatXyGBfBwCAPESAAQCIRTAfoX1UUqmk1R5cxvIeSd8zszFhl/l/UzBcRGZ2iIIx+10HwV81syk9NvsdMxsRHtCfLuneXnZ9l6QLzGyKBZd+/HdJyz0YsiIFV0bZOWmhBRNCvs/MTMGwl87wv57+IOkQM/ukBRNhnq1ggtIHBtk0kqSwW/+renf+hJ9JutzMPhjWtY+ZfTy8b4yCOQ6aJRWb2XxJqc7M93S3gvkV/knv9r6QmX3IzI4Ihx28qeAAeLe/3czeH/YA2T9cfq+CQKT7/CZ3SKpS8PwtGkRtuzwfA/BzSReb2bTwNTbazP7RzMb0t71wOMaDkn5iZqVmNtzMZvW2boaekvSapKvC+kaZWWV4X5/Ps5kdHf5dwxX0aNmm3l+LXT5tZoeFPWuuVBAcdSp4T51hZqeYWVG4/+O7nr8BOCvc72EKhu5MkfQBBfN1zAnfg58ys33C4Sdd75tU76enJL1pwcSne4R1HW7vXor3b5ImWh8T6AIACgNfAgCAofZ7M9ui4ODlewom4vxzeN8XFRyYvSjpMQUH07eGZ6rvlPQDd3/G3dcp6F5+RxhCSMGQglYFB/2/VDCPwZqeO3f3hxXMB/AbBQeRB2vXcfbflnR72I39E5L+QdJDCuZleELST9x9aS/bbVEQmlymYEjKVyWd3q2LfTquVhDUjHT3Gkk/UDCc401Jf1IwX4MUDPN4UMFkmg0KDmz7GwLQvfbXFPxtMyT9uttdZQquFPOmgmEmtQoDpR42S5omabmZbVUQXPxJQVt07aNR0tMKzqQ/OtDaFEwGeVj4fAzkiiD1CubBuFHB6+F5hRN8hr4v6Vvh9r7cyybOUxDUrJG0UdK/DqLWAQlDhDMUDKV5WcGklmeH96V6nvdWENC0KnieWyRdk2JXdyjoCdMkaZSkS8N9bFDQ2+YbCkKvDQp6cgz0d+FnJP3C3V9296au/xS0edfVf86TtD78Gy7Wu5O49vp+6tYmUyS9pKCnyH8qGAolvRtGtphZ13waAIACY57ycvQAACSfBZeAvDOcfwEJZWa3SnrV3b8Vdy35zsyWKnhP/GfctQAAkC29jb0EAADIKguu8lItaWq8lQAAgFzFEBIAABApM1ugYCjE1e7+Utz1AACA3MQQEgAAAAAAkHj0wAAAAAAAAIkX6RwYZvYlSZ9VMOP4c5IuSHXd9/Hjx/vEiROjLAkAAAAAACTYypUrX3f3CT1vjyzAMLP9FFyu6zB3f9vM7lFwmbrb+nrMxIkTVV9fH1VJAAAAAAAg4cysobfbox5CUixpDzMrlrSnpFcj3h8AAAAAAMhDkQUY7v6KpGskvSzpNUlvuPuSnuuZ2UVmVm9m9c3NzVGVAwAAAAAAclhkAYaZlUr6qKQDJe0rabSZfbrneu6+0N0r3L1iwoTdhrgAAAAAAABEOonniZJecvdmSTKzxZJmSLpzMBtpb29XY2Ojtm3rc+5PDMCoUaO0//77a/jw4XGXAgAAAADAoEUZYLwsabqZ7SnpbUknSBr0DJ2NjY0aM2aMJk6cKDPLdo0Fwd3V0tKixsZGHXjggXGXAwAAAADAoEU5B8ZySfdJelrBJVSHSVo42O1s27ZN48aNI7zIgJlp3Lhx9GIBAAAAAOSsKHtgyN2vkHRFptshvMgcbQgAAAAAyGVRX0YVAAAAAAAgY5H2wMhVLS0tOuGEEyRJTU1NKioqUtcVUp566imNGDEizvIAAAAAACg4BBi9GDdunFatWiVJ+va3v6299tpLX/7yl2OuCgAAAACAwsUQkkG4/PLLddNNN+1c/trXvqaf/OQneuihh/ShD31IZ511lg477DBdcsklcndJ0oMPPqhjjz1WRx55pM4++2xt3bo1rvIBAAAAADmktbVVV155pdra2uIuJREIMAbhs5/9rG677TZJUmdnp+69916de+65kqTly5fruuuu03PPPafVq1frt7/9rTZu3KirrrpKDz/8sJ5++mlNmjRJP/7xj2P8CwAAAAAAuaKmpkZr167V4sWL4y4lERhCMggHH3ywxowZo+eee04NDQ065phjVFpaKkmaPn26Jk6cKEk655xz9Nhjj0mS/vKXv2jGjBmSpO3bt2vmzJmx1A4AAAAAyB2tra2qra2Vu2vZsmWqrq5WSUlJ3GXFigBjkC688ELddtttWr9+vT7/+c/vvL3nZUrNTO6uU089VXfcccdQlwkAAAAAyGE1NTU7pybYsWOHFi9erLlz58ZcVbwYQjJIH/vYx/T73/9eq1at0oknnrjz9ieffFIvv/yyOjs7dc8992jmzJmaMWOGamtr9eKLL0qStm7dqnXr1sVVOgAAAAAgR9TV1amjo0OS1NHRobq6upgrih8BxiCNGjVKs2bN0rnnnqthw95tvhkzZuiyyy7TEUccoUMOOURnnnmm3vOe9+iWW27R2WefrcmTJ2vGjBn661//GmP1AAAAAIBcUFlZqeLiYNBEcXGxKisrY64ofgwh6ce3v/3tXZZ37Nihp556Svfff/8ut48ePVr33nvvbo8/6aSTdNJJJ0VZIgAAAAAgz1RVVam2tlaSNGzYMFVXV8dcUfzogTEIzz33nA4++GCdeuqpOuigg+IuBwAAAACQp0pLSzV79myZmWbNmlXwE3hK9MAYlCOOOEIvvfTSbrefeOKJu8yHAQAAAABApqqqqtTY2EjvixABBgAAAAAACVRaWqr58+fHXUZiMIQEAAAAAAAkHgEGAAAAAABIPAIMAAAAAACQeDk3B8aCq76vTW+2ZW17Y/cu0byvX55ynaKiIh1xxBHq6OjQgQceqDvuuCPtGWAnTpyo+vp6jR8/Pq3HAwAAAABQiHIuwNj0ZpuGHffB7G3v0T/3u84ee+yhVatWSZI+85nP6KabbtI3v/nNrNUAAAAAAABSYwjJIB177LF65ZVXdi5fffXVOvroozVp0iRdccUVO28/66yzdNRRR+mDH/ygFi5cGEepAAAAAADkDQKMQejs7NTDDz+sM888U5K0ZMkSrVu3Tk899ZRWrVqllStXatmyZZKkW2+9VStXrlR9fb2uv/56tbS0xFk6AAAAAAA5jQBjAN5++21NmTJF48aN06ZNm3TSSSdJCgKMJUuWaOrUqTryyCO1Zs0arVu3TpJ0/fXXa/LkyZo+fbo2bNiw83YAAAAAADB4BBgD0DUHRkNDg7Zv366bbrpJkuTuuvzyy7Vq1SqtWrVKzz//vC688EItXbpUDz30kJ544gk988wzmjp1qrZt2xbzXwEAAAAAQO4iwBiEffbZR9dff72uueYatbe365RTTtGtt96qLVu2SJJeeeUVbdy4UW+88YZKS0u15557as2aNXryySdjrhwAAAAAgNyWc1chGbt3yYCuHDKY7Q3G1KlTNXnyZN19990677zztHr1ah177LGSpL322kt33nmnTj31VP3sZz/TpEmTdOihh2r69OlZqxcAAAAAgEJk7h53DTtVVFR4fX39LretXr1aH/jAB2KqKL/QlgAAAACApDOzle5e0fN2hpAAAAAAAIDEI8AAAAAAAACJR4ABAAAAAEACtba26sorr1RbW1vcpSQCAQYAAAAAAAlUU1OjtWvXavHixXGXkggEGAAAAAAAJExra6tqa2vl7lq2bBm9MESAAQAAAABA4tTU1KjrqqE7duygF4ak4rgLGKxr/32BNrdtytr2xpSM1WXfmJdyne9973u66667VFRUpGHDhunmm2/WtGnTBrWf+++/X4cccogOO+wwSdLxxx+va665RhUVu10Zplfr16/X448/rk9+8pOSpPr6ei1atEjXX3/9oOoAAAAAACRfXV2dOjo6JEkdHR2qq6vT3LlzY64qXpEFGGZ2qKRfd7vpIEnz3f26TLa7uW2T/vnA4RnV1t1PXkodhjzxxBN64IEH9PTTT2vkyJF6/fXXtX379kHv5/7779fpp5++M8AYrPXr1+uuu+7aGWBUVFQMOPwAAAAAAOSWyspKLV26VB0dHSouLlZlZWXcJcUusiEk7r7W3ae4+xRJR0l6S1JNVPuLymuvvabx48dr5MiRkqTx48dr9erVqqqq2rnOH//4R1VXV0uS9tprL33zm9/U5MmTNX36dP3tb3/T448/rt/97nf6yle+oilTpuiFF16QJN1777065phjdMghh+jRRx+VJHV2duorX/mKjj76aE2aNEk333yzJOnrX/+6Hn30UU2ZMkU/+tGPtHTpUp1++umSpC1btuiCCy7QEUccoUmTJuk3v/nNkLUPAAAAACD7qqqqZGaSpGHDhu085ixkQzUHxgmSXnD3hiHaX9acfPLJ2rBhgw455BD98z//s2pra/XhD39Yq1evVnNzsyTpF7/4hS644AJJ0tatWzV9+nQ988wzmjVrln7+859rxowZOvPMM3X11Vdr1apVOvjggyUF3YCeeuopXXfddfrOd74jSbrlllu0zz77aMWKFVqxYoV+/vOf66WXXtJVV12l4447TqtWrdKXvvSlXWpcsGCB9tlnHz333HN69tln9eEPf3gIWwgAAAAAkG2lpaWaPXu2zEyzZs1SSUlJ3CXFbqgCjHMk/aq3O8zsIjOrN7P6rkAgSfbaay+tXLlSCxcu1IQJE3T22Wfr9ttv13nnnac777xTbW1teuKJJ3TaaadJkkaMGLGzZ8RRRx2l9evX97ntrgSt+3pLlizRokWLNGXKFE2bNk0tLS1at25dyhofeughXXLJJTuXS0tLM/iLAQAAAABJUFVVpUMPPZTeF6HIJ/E0sxGSzpR0eW/3u/tCSQslqaKiwqOuJx1FRUU6/vjjdfzxx+uII47Q7bffrptvvllnnHGGRo0apY9//OMqLg6acvjw4Tu7+RQVFe2cdKU3XcNSuq/n7rrhhht0yimn7LLu0qVL+9yOu+/cJwAAAAAgP5SWlmr+/Plxl5EYQ9ED4zRJT7v734ZgX1m3du3aXXpArFq1SuXl5dp3332177776rvf/a7OP//8frczZswYbd68ud/1TjnlFP30pz9Ve3u7JOmvf/2rtm7dmvLxJ598sm688cady62trf3uBwAAAACAXDIUl1E9V30MH0nHmJKx/V45ZLDbS2XLli364he/qLa2NhUXF+t973ufFi5cKEn61Kc+pebm5gFdWeScc87R5z73OV1//fW67777+lzvs5/9rNavX68jjzxS7q4JEybo/vvv16RJk1RcXKzJkyfr/PPP19SpU3c+5lvf+pYuueQSHX744SoqKtIVV1xBFyMAAAAAQF4x9+hGbZjZnpI2SDrI3d/ob/2Kigqvr6/f5bbVq1frAx/4QEQVZuYLX/iCpk6dqgsvvDDuUgYkyW0JAAAAAIAkmdlKd6/oeXukPTDc/S1J46LcR1yOOuoojR49Wtdee23cpQAAAAAAkPeGYghJXlq5cmXcJQAAAAAAUDCG6jKqGYlymEuhoA0BAAAAALks8QHGqFGj1NLSwgF4BtxdLS0tGjVqVNylAAAAAACQlsQPIdl///3V2Nio5ubmuEvJaaNGjdL+++8fdxkAAAAAgNCiRYvU0NDQ5/1NTU2SpLKyspTbKS8v15w5c7JaWxIlPsAYPny4DjzwwLjLAAAAAABgSL3zzjtxl5AoiQ8wAAAAAADIR/31mliwYIEkad68eUNRTuIlfg4MAAAAAAAAAgwAAAAAAJB4BBgAAAAAACDxmAMDAAAAAIAI9HeVkf50PbZrLox05ctVSggwAAAAAACIQENDg9Y8v07Dx45J6/Ed6pQkvbCpKe0a2jdtTvuxSUOAAQAAAABARIaPHaNxJ0+Lbf8tS5bHtu9sI8AAAAAAACACTU1Nat+yOdYQoX3TZjVtj233WcUkngAAAAAAIPEIMAAAAAAAiEBZWVlGj+/Y/JY6Nr8Vex1JwRASAAAAAAAiUF5entHjGzYHVyEpH5tBADG2LOM6koIAAwAAAACACGR66dKuy6fOmzcvG+XkPIaQAAAAAACAxKMHBgAAAAAAMVi0aJEaGhr6vL/rvq6eGH0pLy/PuLdHLqAHBgAAAAAACWRmeuutt7Rly5a4S0kEemAAAAAAABCD/npNzJ07V5LU3NysH/zgB0NRUqLRAwMAAAAAgIR59tlntW3bNknStm3b9Kc//SnmiuJHgAEAAAAAQMJcd911uyz/8Ic/jKmS5GAICQAAAIC80d+kiJLU1NQkSSorK+tznUKZFBHJ1dX7oq/lQkSAAQAAAKCgvPPOO3GXACANBBgAAAAA8sZAek10XZJy3rx5UZcDIIuYAwMAAAAAgIQZOXJkyuVCRIABAAAAAEDC9BzqxNAnAgwAAAAAAJADCDAAAAAAAEDiEWAAAAAAAJAwZpZyuRBFGmCYWYmZ3Wdma8xstZkdG+X+AAAAAADIB6NGjUq5XIiivozqjyX9t7v/PzMbIWnPiPcHAAAAAEDOe/vtt1MuF6LIemCY2d6SZkm6RZLcfbu7t0W1PwAAAAAA8sXo0aNTLheiKIeQHCSpWdIvzOz/zOw/zWy3Fjezi8ys3szqm5ubIywHAAAAAIDc0NHRkXK5EEUZYBRLOlLST919qqStkr7ecyV3X+juFe5eMWHChAjLAQAAAAAgNxx33HEplwtRlAFGo6RGd18eLt+nINAAAAAAAAApVFVVqaioSJJUVFSk6urqmCuKX2QBhrs3SdpgZoeGN50g6S9R7Q8AAAAAgHxRWlqqsrIySVJZWZlKSkpirih+UV+F5IuSfhlegeRFSRdEvD8AAAAAAHJea2urNm7cKEnauHGj2traCj7EiHIIidx9VTi/xSR3P8vdW6PcHwAAAAAA+aCmpkY7duyQJO3YsUOLFy+OuaL4RRpgAAAAAACAwaurq1NnZ6ckqbOzU3V1dTFXFD8CDAAAAAAAEqaioiLlciEiwAAAAAAAIOHMLO4SYkeAAQAAAABAwtTX1++yvGLFipgqSQ4CDAAAAAAAEqayslJFRUWSpKKiIlVWVsZcUfwIMAAAAAAASJiqqqpdJvGsrq6OuaL4EWAAAAAAAJAwb7zxRsrlQkSAAQAAAABAwtx00027LN94440xVZIcBBgAAAAAACTMK6+8knK5EBFgAAAAAACQMHvuuWfK5UJEgAEAAAAAQMJs27Yt5XIhIsAAAAAAAACJR4ABAAAAAEDCjBw5MuVyISLAAAAAAAAgYd5+++2Uy4WIAAMAAAAAgITZb7/9Ui4XIgIMAAAAAAAS5pJLLtll+Qtf+EJMlSQHAQYAAAAAAAmzzz77pFwuRAQYAAAAAAAkzN13351yuRARYAAAAAAAkDCPP/74Lst1dXUxVZIcBBgAAAAAACDxCDAAAAAAAEiYGTNmpFwuRAQYAAAAAAAkzDnnnCMzkyQNGzZM5557bswVxY8AAwAAAACAhCktLdXMmTMlSZWVlSopKYm5ovgVx10AAAAAAADY3TnnnKPm5mZ6X4QIMAAAAAAASKDS0lLNnz8/7jISgyEkAAAAAAAkUGtrq6688kq1tbXFXUoiEGAAAAAAAJBANTU1Wrt2rRYvXhx3KYlAgAEAAAAAQMK0traqtrZW7q7a2lp6YYgAAwAAAACAxKmpqVFHR4ckqaOjg14YIsAAAAAAACBxHnvsMbm7JMnd9dhjj8VcUfwIMAAAAAAASJhx48alXC5EBBgAAAAAACRMS0tLyuVCFGmAYYNbOrEAACAASURBVGbrzew5M1tlZvVR7gsAAAAAgHwxc+ZMmZkkycw0c+bMmCuK31D0wPiQu09x94oh2BcAAAAAADmvqqpKRUVFkqTi4mJVV1fHXFH8GEICAAAAAEDClJaW6vjjj5eZafbs2SopKYm7pNhFHWC4pCVmttLMLuptBTO7yMzqzay+ubk54nIAAAAAAMgNVVVVOvTQQ+l9ESqOePuV7v6qmf2dpD+a2Rp3X9Z9BXdfKGmhJFVUVHjE9QAAAAAAkBNKS0s1f/78uMtIjEh7YLj7q+H/N0qqkXRMlPsDAAAAAAD5KbIAw8xGm9mYrn9LOlnSn6LaHwAAAAAAyF9RDiF5j6Sa8LIvxZLucvf/jnB/AAAAAAAgT0UWYLj7i5ImR7V9AAAAAABQOLiMKgAAAAAASDwCDAAAAAAAkHgEGAAAAAAAIPEIMAAAAAAAQOIRYAAAAAAAgMQjwAAAAAAAAIlHgAEAAAAAABKPAAMAAAAAACQeAQYAAAAAAEg8AgwAAAAAAJB4BBgAAAAAACDxCDAAAAAAAEDiEWAAAAAAAIDEI8AAAAAAAACJR4ABAAAAAAASjwADAAAAAAAkHgEGAAAAAABIPAIMAAAAAACQeAQYAAAAAAAg8QgwAAAAAABA4hFgAAAAAACAxCPAAAAAAAAAiUeAAQAAAAAAEo8AAwAAAAAAJB4BBgAAAAAASDwCDAAAAAAAkHgEGAAAAAAAIPEGFWCY2eioCgEAAAAAAOjLgAIMM5thZn+RtDpcnmxmP4m0MgAAAAAAgNBAe2D8SNIpklokyd2fkTQrqqIAAAAAAAC6G/AQEnff0OOmzizXAgAAAAAA0KviAa63wcxmSHIzGyHpUoXDSQAAAAAAAKI20B4YF0u6RNJ+kholTQmX+2VmRWb2f2b2QHolAgAAAACAQjegHhju/rqkT6W5j39R0Ftj7zQfDwAAAAAACtxAr0Jyu5mVdFsuNbNbB/C4/SX9o6T/TL9EAAAAAABQ6AY6hGSSu7d1Lbh7q6SpA3jcdZK+KmlHXyuY2UVmVm9m9c3NzQMsBwAAAAAAFJKBBhjDzKy0a8HMxqqf4Sdmdrqkje6+MtV67r7Q3SvcvWLChAkDLAcAAAAAABSSgV6F5FpJj5vZfeHyxyV9r5/HVEo608w+ImmUpL3N7E53/3R6pQIAAAAAgEI1oB4Y7r5I0sck/U3SRknV7n5HP4+53N33d/eJks6R9L+EFwAAAAAAIB39DQPZ293fDIeMNEm6q9t9Y919U9QFAgAAAAAA9DeE5C5Jp0taKcm73W7h8kED2Ym7L5W0dPDlAQAAAAAA9BNguPvpZmaSZrv7y0NUEwAAAAAAwC76nQPD3V1SzRDUAgAAAAAA0KuBXkb1STM7OtJKAAAAAAAA+jDQy6h+SNLFZrZe0laFc2C4+6SoCgMAAAAAAOgy0ADjtEirAAAAAAAASKG/y6iOknSxpPdJek7SLe7eMRSFAQAAAAAAdOlvDozbJVUoCC9Ok3Rt5BUBAAAAAAD00N8QksPc/QhJMrNbJD0VfUkAAAAA0LtFixapoaEho210PX7BggVpb6O8vFxz5szJqA4Ag9NfgNHe9Q937zCziMsBAAAAgL41NDRozfPrNHzsmLS30aFOSdILm5rSenz7ps1p7xtA+voLMCab2Zvhv03SHuFy11VI9o60OgAAAADoYfjYMRp38rTY9t+yZHls+wYKWcoAw92LhqoQAAAAAACAvvQ3iScAAAAAAEDsCDAAAAAAAEDiEWAAAAAAAIDEI8AAAAAAAACJR4ABAAAAAAASjwADAAAAAAAkHgEGAAAAAABIPAIMAAAAAACQeAQYAAAAAAAg8QgwAAAAAABA4hFgAAAAAACAxCPAAAAAAAAAiUeAAQAAAAAAEo8AAwAAAAAAJB4BBgAAAAAASDwCDAAAAAAAkHgEGAAAAAAAIPEIMAAAAAAAQOIRYAAAAAAAgMQjwAAAAAAAAIkXWYBhZqPM7Ckze8bM/mxm34lqXwAAAAAAIL8VR7jtdyR92N23mNlwSY+Z2YPu/mSE+wQAAAAAAHkosgDD3V3SlnBxePifR7U/AAAAAACQvyKdA8PMisxslaSNkv7o7st7WeciM6s3s/rm5uYoywEAAAAAADkq0gDD3TvdfYqk/SUdY2aH97LOQnevcPeKCRMmRFkOAAAAAADIUUNyFRJ3b5O0VNKpQ7E/AAAAAACQX6K8CskEMysJ/72HpBMlrYlqfwAAAAAAIH9FeRWSv5d0u5kVKQhK7nH3ByLcHwAAAAAAyFNRXoXkWUlTo9o+AAAAAAAoHEMyBwYAAAAAAEAmCDAAAAAAAEDiEWAAAAAAAIDEI8AAAAAAAACJR4ABAAAAAAASjwADAAAAAIAEam1t1ZVXXqm2tra4S0kEAgwAAAAAABKopqZGa9eu1eLFi+MuJREIMAAAAAAASJjW1lbV1tbK3bVs2TJ6YYgAAwAAAACAxKmpqZG7S5J27NhBLwwRYAAAAAAAkDh1dXXq6OiQJHV0dKiuri7miuJHgAEAAAAAQMJUVlaquLhYklRcXKzKysqYK4ofAQYAAAAAAAlTVVUlM5MkDRs2TNXV1TFXFD8CDAAAAAAAEqa0tFSzZ8+WmWnWrFkqKSmJu6TYFcddAAAAAAAA2F1VVZUaGxvpfREiwAAAAAAAIIFKS0s1f/78uMtIDIaQAAAAAACAxCPAAAAAAAAAiUeAAQAAAAAAEo8AAwAAAAAAJB4BBgAAAAAASDwCDAAAAAAAkHgEGAAAAAAAIPEIMAAAAAAAQOIRYAAAAAAAgMQjwAAAAAAAAIlHgAEAAAAAABKPAAMAAAAAACQeAQYAAAAAAEg8AgwAAAAAAJB4BBgAAAAAACDxCDAAAAAAAEDiEWAAAAAAAIDEiyzAMLP3mtkjZrbazP5sZv8S1b4AAAAAAEB+K45w2x2SLnP3p81sjKSVZvZHd/9LhPsEAAAAkMeamprUvmWzWpYsj62G9k2b1bQ9tt0DBSuyAMPdX5P0WvjvzWa2WtJ+kggwAABAJBYtWqSGhoaU6zQ1NUmSysrK+lynvLxcc+bMyWptAAAMVmtrq2644QZdeumlKikpibuc2EXZA2MnM5soaaqk3WJSM7tI0kWSdMABBwxFOQAAoIC98847cZcASCJwS1dZWZm2bpLGnTwtthpalixX2di+nxMgW2pqarR27VotXrxYc+fOjbuc2EUeYJjZXpJ+I+lf3f3Nnve7+0JJCyWpoqLCo64HAADkr4EcxC1YsECSNG/evKjLATJG4AYUrtbWVtXW1srdtWzZMlVXVxd8L4xIAwwzG64gvPiluy+Ocl8AAABALiFwA5BKTU2N3INz/Dt27KAXhqK9ColJukXSanf/YVT7AQAAAAAg39TV1amjo0OS1NHRobq6upgril9kAYakSknnSfqwma0K//tIhPsDAAAAACAvVFZWqrg4GDRRXFysysrKmCuKX5RXIXlMkkW1fQAAAAAA8lVVVZVqa2slScOGDVN1dXXMFcUvyh4YAAAAAAAgDaWlpZo9e7bMTLNmzSr4CTylIbqMKgAAAAAAGJyqqio1NjbS+yJEgAEAAAAAQAKVlpZq/vz5cZeRGAwhAQAAAAAAiUcPDAAAACACixYtUkNDQ0bb6Hr8ggULMtpOeXm55syZk9E2ACBuBBgAAABABBoaGrTm+XUaPnZM2tvoUKck6YVNTWlvo33T5rQfCwBJQoABAAAARGT42DEad/K0WGtoWbI81v0DQLYwBwYAAAAAAEg8AgwAAAAAAJB4BBgAAAAAACDxCDAAAAAAAEDiEWAAAAAAAIDEI8AAAAAAAACJR4ABAAAAAEACtba26sorr1RbW1vcpSQCAQYAAAAAAAlUU1OjtWvXavHixXGXkgjFcRcAAAAwUIsWLVJDQ0NG2+h6/IIFCzLaTnl5uebMmZPRNgAA6Etra6tqa2vl7lq2bJmqq6tVUlISd1mxIsAAAAA5o6GhQWueX6fhY8ekvY0OdUqSXtjUlPY22jdtTvuxKBxNTU1q37JZLUuWx1pH+6bNatoeawkA0lBTUyN3lyTt2LFDixcv1ty5c2OuKl4EGAAAIKcMHztG406eFmsNcR+QAoWufVNmwVDH5rckScVj9kx7/xpblvb+gYGoq6tTR0eHJKmjo0N1dXUEGHEXAAAAAOSjsrIybd2kRARuZXl0sF1eXp7xNho2B0PJytNtl7FlWakDSKWyslJLly5VR0eHiouLVVlZGXdJsSPAAAAAAJAzsjH3TNccOPPmzct4W0BUqqqqVFtbK0kaNmyYqqurY64ofgQYAAAASGkgk6c2NQVzipSV9X1Gm4lPAWDgSktLNXv2bD388MOaNWtWwU/gKRFgAAAAIAveeeeduEsAgLxTVVWlxsZGel+ECDAAAACQ0kB6TdAlHwCyr7S0VPPnz4+7jMQYFncBAAAAAAAA/aEHBgAAAAAgJebCQRIQYAAAABS4gRyY9Kfr8V1DSdLFwQ2Qu5gLJ/taW1t1ww036NJLL2USTxFgAAAAFLyGhgateX6dho8dk/Y2OtQpSXphU1Pa22jftDntxyZV+6bNalmyPO3Hd2x+S5JUPGbPjGrQ2L7PiAMDwVw48aipqdHatWu1ePFizZ07N+5yYkeAAQAAAA0fO0bjTp4Waw2ZHOgnUXl5ecbbaNgc9GwpzySAGFuWlVoADK3W1lY98sgjcnc98sgjqq6uLvheGAQYAAAAQASyMRSGM9pA4aqpqVFnZ9C7rbOzk14YIsAAACA2/c07wGRou2tqalL7lsy65GdD+6bNatoeawlZRbsCQPIsW7Zst2UCDAAAkHUDna091YRn27Ztk5R6UrSmpqZ+91NoIQcAYPCSMpkv31nv6up90ddyIcqrACMbZ7Ik3jRALuNzIBr0FBi8AU2KOELSiJEpthL8UOkY0/c6HUo9aWK+TYpYVlamrZuUiLkayvJoUsSysjK1PZ/ZayUbk0121QJg6CVhMt98+87KFAHG7iILMMzsVkmnS9ro7odHtZ/B4LI+APgc2B09BaLDpIjIFUw2CaDrZEQmMg0ws1UH8leUPTBuk3SjpEUR7mMX/f3oZRKk9HBGG0mRja6NA9XQ0JCy+2M+vZ7pKRAN5hRALmGySQBALogswHD3ZWY2MZvbzPTgJRtjsqT8OnDJBs5op4dgaPCWL1+u1rZWWXH6H10edr1b8/y69LfR0aGmpqa8afeknHGROOsCAEBckjKUjGFkSCX2OTDM7CJJF0nSAQcckHLdTMdlZTomS8q/M4SXX365mpubM9pGV9fx/sKlhoaG3WbS7W7ChAn6/ve/n1EtSTFUXfK7tpNqX4UUcABJkpQfgl21AACQSiKGkjGMbBejR4/W1q1bd1kudLEHGO6+UNJCSaqoqPBU62Z6Zo4zhLt788039dZbb2VlW5lu580338xKHUkwVF3ypdTd8vMtcJs2bVrWZsfO9Msxn75cOdCORiJ+CEp5+WOwfVNmQ3Oy8Xpt37RZyqNJPAGAoWTJ0z286G25EMUeYCBeHBBGo6mpSd7RkVGA0DXUob09/dmGu4Y65IuBfLFma56MQuq5woF2NPghGA1er/EYyGfrQIbqFtJnKwAg+3IqwMj0LCFnCHfHAWE09t5774znBtnWGQwhGTV8RPobGT5Ce++9d0Z15JuRI1P3aClEQ/U5UEifAYgOwVBy8fk6eARD+Y/LkAPZFeVlVH8l6XhJ482sUdIV7n5LJtvM9EwHZ1yiwQ+W3WVjLg9+YKeHL/h48DmQnv5+2HLggqTgNRYfPl/zG5PhI5Xi4mJ1dHTsslzoorwKybnZ3mZ/X55J6Skw0AkcpdxIW5NQQz7KxoGLlJzXCfIbr7F4cOAC7C6fruIV9/4Rvf6e41w6YUWPoaF37LHH6tFHH91lOSq5cgxbUBFOkn4IkraiP0P1es2VDysgH/GeAbKP31jpYagDsiFJx1v5yMxi3X8SPl/zKsBIygfmQOrIpbQV0UjK63UgkvBhBSA6+XRGG/kvn85o5xJ+C4DP96FXX1+/y/KKFSt08cUXR7KvXDmGzasAA8Dg5cqHVa7hgDAatGs8OHBJD69X5BKCISB5Kisr9cgjj6izs1NFRUWqrKyMu6TYEWAgZzDUAfmEA8Jo0K7p4cAlHrxed5eN+cwGOodUf/i9ACBuVVVVqq2t3RlgVFdXx11S7AgwkFf4MYik4IAwGrQrcgmv18FraGjQS39do/32Gp72NoaHM/Zvf/WFtLfxypb2tB+bRARD0aBd41FIJzVLS0s1e/ZsPfzww5o1a5ZKSkriLil2BBhp4MMqHgx1AAAg/+2313B9cdLfxVrDDc9ujHX/2UYwFA3aNbny6aRmVVWVGhsb6X0RIsBIAx9WAAAkE5f5A3pHMJR9XWf5MzF+j+wcjmWjllxRaCc1S0tLNX/+/LjLSAwCjDTxJYBckZQeQxwMAEgKLvOXXE1NTXp7S3vsv3Fe2dKuPQrogBBA/kvKMYGU2XEBAUYa+HKNRlLeVPl2oJ2EHkP52Fso09drEr4AgHzE+wHYXaH9dh2qnlhlZWXavmNrIk5qjujnakZAEo4JpMyPCwgwkBhJeFPl44F2Uro35lvXxkxfr0n4AgCApOGAEEOFnlgoRPkwioAAIw18uUYn7jdV3GcmkFt4vQIAckGh/XalJxawu3zpiUWAgcRIwpsq34blSMn40ZKPYRuvVwAA8EqGvwVefzvokZlJb9dXtrTrwLQfDeQWAow08WEFAMgFSZlfSMqvOVtoVwDl5eUZb6M9/BwYsW/62zowS7UkBZ+v0UjCSU0p8xObBBhp4MMqGkl4U+VjTwEp/sAtH8M2Xq/RYHLU7EvC/EJS/s3ZQrtGJ+7vrK4a8u17i3bNvmx8T+TT5T6zhc/X6OTD5wABRhr4sEIuSULglm9hG6LD5KjZl5SJfKX8msyXdo1GEr6zpPz73qJdkUv4fI1GvnwOEGBEYKgu3ZSP4k4F8+3MgETghtzD5KhA4eI7Kxq0K4B8+RwgwIgJl27aXRJSQc4MAPFictTsS8JwJyn/hjzRrgAGor8Tm5zU3B2fr0iFACMChfQBk035kgoCAAAAA8FJTWBwCDCAAseQp/RlMuQpCZMgJVESzrpwxgUAkC2F9tsIiBoBBoB+cXZgd5kONUrCJEgAkIuy0SVfKszgHQD6kisnNQkwgALHj7f0ZNpuDHcCgGgQuqeHuRqQJHFP7N9VQ771dM1UEj5fCTCQM3IlFQQkzhAiWfghGA3aNR58JsYjCQcuKAxJmNhfKryerrny2UqAgbzClytyBa/VvjG3SHbxQzAatCvyTa4cvCD/MbE/UiHAQM7gixW5hNdrephbJPv4IRgN2hUAgKFHgAEASAzmFkE+YSgZAADZRYABAECB40A7HgwlAwBgcAgwAAA5gwPteHCgnR5eYwCQfUzsX9gIMAAAeYMD7fTwAw4AkE/4PZC/zN3jrmGniooKr6+vj7sMAAAAAAAQEzNb6e4VPW8fFkcxAAAAAAAAg0GAAQAAAAAAEi/SAMPMTjWztWb2vJl9Pcp9AQAAAACA/BVZgGFmRZJuknSapMMknWtmh0W1PwAAAAAAkL+i7IFxjKTn3f1Fd98u6W5JH41wfwAAAAAAIE9FGWDsJ2lDt+XG8LZdmNlFZlZvZvXNzc0RlgMAAAAAAHJVlAGG9XLbbtdsdfeF7l7h7hUTJkyIsBwAAAAAAJCrogwwGiW9t9vy/pJejXB/AAAAAAAgT0UZYKyQ9A9mdqCZjZB0jqTfRbg/AAAAAACQp4qj2rC7d5jZFyT9j6QiSbe6+5+j2h8AAAAAAMhfkQUYkuTuf5D0hyj3AQAAAAAA8l+UQ0gAAAAAAACyggADAAAAAAAknrnvdmXT2JhZs6SGuOsYoPGSXo+7iDxDm0aDdo0G7RoN2jUatGs0aNdo0K7RoF2jQbtGg3aNRi61a7m7T+h5Y6ICjFxiZvXuXhF3HfmENo0G7RoN2jUatGs0aNdo0K7RoF2jQbtGg3aNBu0ajXxoV4aQAAAAAACAxCPAAAAAAAAAiUeAkb6FcReQh2jTaNCu0aBdo0G7RoN2jQbtGg3aNRq0azRo12jQrtHI+XZlDgwAAAAAAJB49MAAAAAAAACJR4ABAAAAAAASjwADAAAAAJCzzMziriGfJLk9CTAiYGYj4q4BGAgzK467hnxkZqNo2+wzs/fEXUM+MrP3m1l53HXkGzObaWbHx11HvjGzfzSzi+KuI9+YWYmZjYu7jnxjZsN7LCf2oDAXmdnhZnaCmZU6EztmhZmNlyR396S+XgkwsszMzpC02Myu5Qs2e8xsmpkd1/OLAOkzs5Ml3WVm15nZeXHXky/M7FRJ90j6mZl9Lu568oWZTZb0gpmdbmYj464nX5jZaZJukUTglkVm9lFJN0naI+5a8omZnSjpZkn/ZGaHxV1PvjCz0yX9XlKNmV0edz35Ivx8vcvMvtt1TMBBdvaY2ZmSlki6QNIDZvZ5Mzs45rJyWvhZsMTMzpeSG2IQYGSRmU2R9ANJP5f0P5K+ZWbzut2fuBdALgh/sDwh6Z8kVRJiZC78Uv2hpAckPSnpAjM7Nt6qcl/Yrv8h6TZJD0o6wcyGdbufz4D07ZD0tqQ5kk6kp1vmwrDtx5L+1d1f6P5aDe/n9ZoGM9tH0hcl/ZO7P2hmI8xsVNx15TozO0XSNZK+pOCg5f3h7UVx1pXrzGympO9K+pqC1+00Pl8zZ2aVCn4P3CrpXknfN7N/73Y/n68ZCI8FTpU0x90/raCt3yfpHDM7KNbicpSZHSLpJ5IekvQRM/uMlMwQgzMu2VUs6S/u/ltJMrPjJP3GzOTuC0hdBy/8Ev0HBeHF3pI+Edxsj7l7e6zF5SgzK5FULenf3H1J2MbHSBobb2W5zcxKFXyZXuruS81shqQDJM01s23ufiefAelz9+fM7BZJGyV9RdLrZvaGpBZ3b463utxjZqMlnSFpnbuvMLMxkr5pZu9IesXdF/J6TZtJGiHpz2ZWJulGSSPM7E+SfsTrdfDMbH8FvwO+4O6PmdkESdeYWa27t8RcXq4bL+kP7v64mR0o6WAFB9vN7n5VzLXlsgmSfufuD0qSmX1d0tVm9rq7/5DP18y4e7uZ7SHpNEkPuftvzaxN0umSjpf04v9v7+6D5arrO46/vwnQmEFIAYUUKQY78lBRCDAQeZhKW0ildkCCBFNKU6UEZLDCWMQZRLFMfSiF1gGpWCi0HWEAhdRSpA6jlQe1WLWAJVFRlIcQkBAI4UHIp3/8zpq9l5u7d2/O9549dz+vmR1ys8udX97ZnLvnt+f324gId544SSsj4nTgTuAQyutXJF01aB19BUa9ngTWdS5rlPQg5UTx5IhY2ujIWkrSi8CXgM9R3nlZDRwHHOYrMSZH0lOUdwTurg7uLwJrgN9vdmTtJmkN8NfV5MUc4GPA9ynP2U9GxJmNDrDFImJmRMwGdgRuorS9DPg2sEuTY2srSc8CVwJ3RMRVwH8DLwE/BT4aEe9vcHitVh1jbwPeDlxIuSLzQ8BewFkNDq21JD0ELJN0e/X1pcAtlNdYfjd787wI7B0RH6Nc2XJDdXt3RJzX6MjabQYwPyLmVl9vT7ny9bTqMn3bfH8DvKpaSoKkrwPfoiwx22bQTrrbQNJySU9Qfm59Hji2s5wkIuZVb340zldg1EjSAxHxKOVkZamkJyT9rJrN2q/p8bWVpFWdWdSI+DjwEeBY4NGIOIzyDux1zY6yHTodJd016q7VwNzqMccBayXdOuUDbKmurquq39oK+Einc0Ssp0y82SRIehlYHxFfB14HPALsBDxAefGypa/I6p+kuyNCwK7AZZIuBoiIh4BjGh1c+z1I+Tm1AbhR0uMRcSplPfx2kp5sdnjtMfr42vWu6v3A4cDlnUucfcLSP0k3V+9kbwHcI+mjABFxAnBhRMyWtL7JMbaRpC9G2Wvs8xHxPLCtpN+LiMeBbRseXitFxIGU11ffrH7mrwJWAIdWVwosl3R9RBwP7EmZzLBxjG7adbx9LiJuo1xReHw16bYT5QqXxvkKjJp0Zv8lnUP5B3VFROxb3T0P2NPrNCevenEyozqROZ/ywuUK4DxgZaODa5HRL+663rX6MWWDxIWUdwofnOqxtdnorpJWj5ok2guY7WPAZlsLXATcDCyhrNv+S8D7C0ySpO9Qjql/1/Xbvw282s/XyZN0JXAHZRnZkRGxDXAAIOCFJsfWNmMcXztfXwLsFhEfHutx1ltn3xtJNwD/CayKjZ/29ObqvxuaGFubdXVdRvkZdS5wZHX3b1ImjX3lUB9i5H54h0TEVtXyseuBh4A/jIhLIuK9wEHAz5sbbTvEGHsMdu93IWldtS3COuCtwPuqKwwb5yswJqm6nPllSS9ExNaS1kXETEkvSzo5Is4HTq9+EOwCnFidfNs4xurauU/Shs4kRrVO+43AIZJ+0NiAW6BH084LvgA+DXyXsiHSigaG2irjde16TFBOtE/Cx4AJ6fF8/VKUT3e4SdJt1eO/KumZpsbbFj26Ptz1uBMpz9clfr72tonXAjMkbZB0UUSsA3anLNfZkbKHw7ONDroFeh1fO6+3IuJiYL+ImCXp+WZG2x49jgNPVife10bESmB/4CR37a3HceC+rsedDCymmszwpNvExCv3wzuu+v07JD0cEVcDvw6cSTneHiXpkabG2wZjNB2xx2DXle8LKEvMj5R0T4NDHiH8b6d/1YFqIfAL4FBgDnB29cN0ZudFX7XubXvgKZX1mzaO8bqOetws4M+AOyR9f8oH2iJ9NF1A2WfknZJ+OOUDbZk+u34QOLf7RYyNrcexdYakDV2P7ZzA+LLxHvp4vr6F8kkEF/j52ttEn69RPvZ3J+A5SasbG3BLTPT5Wj12HqXrqtH32Ug9nq+/Oo5GxDuAmcC9CDYQTQAACaxJREFUkn7U2IBboo/j687Ae4EvDtKJYFtE2RD5serL84DXUvZquV3SC12PmznWscJeaZym/6WuZbkR8bpBO4/1BMYkVWuBPkk5yC+W9L2u+/yCepLG6zrqcSNOZmzT+mj6Wr+4nrg+um4rae2UDq7FJtrV+tPH83UbSU9P6eBazM/XHO6ao8drV5/4TVIfx9etVDZOt0nouipgJmU/vNdQPuXpMGCNpGsbHWAL9Wi6VtIXGh3gJngPjD6MWqv2VeCblM1j5natGfQlYX2aaNdunrwYXz9Nu9ZqevKihz67dtYQevKih8kcA6y3ST5fPXnRg5+vOdw1Rx+vXT150YdJvnb15MVmqE60N7Uf3v2NDq6lejQd2CX63gNjgkZdXreAspncB4E3AcsoOwpfU933gKTHNvnN7FfctX5umsNdc7hrDnfN4a453DWHu+Zw11zh/fBqN92aegJjgroOVO8D/pjy+bjHA/tQdhNeGOXjkhYCBzY1zrZx1/q5aQ53zeGuOdw1h7vmcNcc7prDXfNE154iEXEoMCciRuwpUp1wz6Is2XnbIJ9oD4Lp2NRLSPoQEQcBR1N2Y/0l8LCkFyT9M/D3wK3A70jyR/f0wV3r56Y53DWHu+Zw1xzumsNdc7hrDnfNIWk98CJwKWVy6F/GWt6k8uk4l8mb+fc0HZt6E89xdF8iVn39RuAPgK0oB6w/kvR8RBwDfKV6glgP7lo/N83hrjncNYe75nDXHO6aw11zuGuuUctyZgGXADsAlwH/42U4/ZvOTT2BsQmj/tKPAFZRPmrmTgBJb6juOxFYAiyR9IuGhtsa7lo/N83hrjncNYe75nDXHO6aw11zuGuuUX07e4qsYuOeIssleU+RPkz3pp7A6CEizgLeCbxH0v0RsS/lM3K/AIiypmip/JnOfXHX+rlpDnfN4a453DWHu+Zw1xzumsNdc8XYe4q8C/hdYAPVniJeljNx07Wp98AYR0QcDCySdDCwIiIOAGYBBwFPA2sos6w+UPXBXevnpjncNYe75nDXHO6aw11zuGsOd80V3lOkdtO5qa/A6DLG+rbfovwF30NZ47Y78HrgHEk3NTLIFnLX+rlpDnfN4a453DWHu+Zw1xzumsNdc43R13uKbKZhauorMCqj1gr9eUQsBp4ArgTmAddQZrH+gfL5zjYB7lo/N83hrjncNYe75nDXHO6aw11zuGuuUX2PiIg3U/ZoOANYJumI6kT7ROAU4FUNDrcVhq6pJN+6bsBpwHeAeWPcdxLwv8AeTY+zbTd3ddO23NzVXdt0c1d3bdPNXd21TTd3Te97FnBHpyGwL/AAcAHwV8DdwN5Nj7NNt2FpusV4kxvDJCJmANtTNjh5D/BoRCwBdgbuA35a/f67Jd3f1Djbxl3r56Y53DWHu+Zw1xzumsNdc7hrDnfN17WnyIIoDgC2oOwpshR4ibKnyIomx9kmw9R0qPfAiIgd1fWxMVE+I/ccYAFlM57ngGeBR4BPAFtLWtvEWNvEXevnpjncNYe75nDXHO6aw11zuGsOd83lPUXqN8xNh/YKjIjYA/hBRFwM/J+ky1XWBv0rcC/wLUk/i4hTKBufhA9Uvblr/dw0h7vmcNcc7prDXXO4aw53zeGuuUbvKUL51JZbKHuKHAdcCHwXOBXvKTIhw950aCcwKLOodwGPAYsi4jDK5zh/Q9JKgIhYCpwOLJb0UmMjbRd3rZ+b5nDXHO6aw11zuGsOd83hrjncNVHXifZplKU3iyQ9BVxX3YiIk6r73tXUONtk2JsO+xKSi4DfAJZQZqsWA9sBHwB2APYEbpV0X2ODbCF3rZ+b5nDXHO6aw11zuGsOd83hrjncNU/XniLXA+8H7geOZeSeIp8FTpN0b0PDbJVhbzqUH6MaEVH98mxAlAPTo8DelL/0DwNvB672gWri3LV+bprDXXO4aw53zeGuOdw1h7vmcNccEbFj59eSNgDPAF8DPgVcRVmKsyuwD+Xk+x3T8US7Tm660VAuIZGk6oAVwI+AvwXmA2dKujEidgdWS1rT5Djbxl3r56Y53DWHu+Zw1xzumsNdc7hrDnetn/cUqZ+bjjTUS0gAqgPTN4DPSPp40+OZLty1fm6aw11zuGsOd83hrjncNYe75nDXekTELsA1wHLgcGA1G/cUeaZ6zFLgTMqeIr6ypQc3HWkol5B0U/ks3LOBmRExu+nxTBfuWj83zeGuOdw1h7vmcNcc7prDXXO4az0k/Rz4NuVKlqOAm4FTgJsjYv+IWAjMYQhOtOvipiMN/QRG5S5gv6YHMQ25a/3cNIe75nDXHO6aw11zuGsOd83hrpvBe4rUz01faeiXkHRExGxJ65sex3TjrvVz0xzumsNdc7hrDnfN4a453DWHu26e6oR7K+BcYDfKVQMf8p4ik+emI3kCw8zMzMzMzGrjPUXq56aFl5CYmZmZmZlZbbynSP3ctPAEhpmZmZmZmdXNe4rUb+ibegmJmZmZmZmZ1c57itRv2Jt6AsPMzMzMzMzMBp6XkJiZmZmZmZnZwPMEhpmZmZmZmZkNPE9gmJmZmZmZmdnA8wSGmZmZmZmZmQ08T2CYmZlZmog4JiIUEXvU+D2Pjoi96vp+ZmZm1g6ewDAzM7NMJwC3A4tr/J5HA57AMDMzGzL+GFUzMzNLERFbAyuAtwHLJe0REXOBa4FtgC2AU4E7gX8E9gcEXCHpooh4A3AJ8BpgPXAysB3wZWBtdTtW0o+n9A9mZmZmjdii6QGYmZnZtHU0cIuklRHxZETMp0xmfEXSBRExE5gN7APsLOlNABExp/r/Pwcsk/TDiDgQuFTS4RGxHPiypOun/o9kZmZmTfEEhpmZmWU5Abi4+vU11df/BlwREVsCN0r6XkQ8AOwWEZ8B/h24tbp6463AdRHR+X6/NqWjNzMzs4HiJSRmZmZWu4jYHngIWE1ZFjKz+u+uwFzgKOAM4NOSrq4mLI4E/hR4HPgLYIWkuWN873/CV2CYmZkNHW/iaWZmZhkWAVdL2lXS6yXtAvwEOAxYLelyyr4X8yNiB2CGpBuAc4H5kp4GfhIRxwFE8Zbqez8DvHqq/0BmZmbWLF+BYWZmZrWLiK8Bn5B0S9fvnQF8AHgW+CWwDvgTyoaeV7LxjZVzJP1HRMwDPku5YmNL4BpJ50fEwcDlwAvAIm/iaWZmNhw8gWFmZmZmZmZmA89LSMzMzMzMzMxs4HkCw8zMzMzMzMwGnicwzMzMzMzMzGzgeQLDzMzMzMzMzAaeJzDMzMzMzMzMbOB5AsPMzMzMzMzMBp4nMMzMzMzMzMxs4P0/dWG02g/zY6gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- COLLECT FINAL PRICE TRAJECTORIES FOR COMPARISON --\n",
    "real_all, synthetic_all = [], []\n",
    "for asset_index in range(NUM_ASSETS):\n",
    "    prices_real = np.cumprod(1 + raw_returns_all_assets[-300:, asset_index])\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, config.z_size).to(device)\n",
    "        synthetic = G(z).cpu().numpy().flatten()\n",
    "        returns_unscaled = scaler.inverse_transform(synthetic.reshape(-1, 1)).flatten()\n",
    "        prices_synth = [prices_real[0]]\n",
    "        for r in returns_unscaled:\n",
    "            prices_synth.append(prices_synth[-1] * (1 + r))\n",
    "        prices_synth = prices_synth[1:]\n",
    "\n",
    "    real_all.append(prices_real)\n",
    "    synthetic_all.append(prices_synth)\n",
    "\n",
    "plot_boxplots(real_all, synthetic_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "deed9890-ce22-40b1-ac16-11c83e6aaa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- KS DISTANCE HEATMAP --\n",
    "ks_matrix = results_df.pivot(index=\"Fold\", columns=\"Asset\", values=\"KS_Distance\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(ks_matrix, annot=True, fmt=\".3f\", cmap=\"coolwarm\")\n",
    "plt.title(\"KS Distance between Real and Synthetic Prices (per Fold/Asset)\")\n",
    "plt.ylabel(\"Fold\"); plt.xlabel(\"Asset\")\n",
    "plt.tight_layout(); plt.savefig(\"ks_distance_heatmap.png\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f67e660b-6a25-4b56-a57c-f4c4685a06e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (300, 1), indices imply (300, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 blocks = [\n\u001b[0;32m-> 1654\u001b[0;31m                     \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m                 ]\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise ValueError(\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 12",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-73e0a07b3b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Put generator in evaluation mode and generate a synthetic forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msynthetic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_synthetic_forecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynthetic_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-d1c966c52a65>\u001b[0m in \u001b[0;36mgenerate_synthetic_forecast\u001b[0;34m(G, forecast_horizon, n_samples, steps_per_pass)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdf_synthetic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mdf_synthetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"synthetic_prices.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_synthetic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1662\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1664\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (300, 1), indices imply (300, 12)"
     ]
    }
   ],
   "source": [
    "# -- üîÆ Synthetic Forecast Generation from Final Model --\n",
    "\n",
    "# Final known real prices used to bootstrap synthetic price paths\n",
    "LAST_KNOWN_PRICES = np.array([\n",
    "    15.136, 20.3352, 17.563, 8.6973, 1.1579, 1.3435,\n",
    "    20.716, 141.5, 164.252, 9.95, 30.14, 2004.0\n",
    "])\n",
    "\n",
    "# Put generator in evaluation mode and generate a synthetic forecast\n",
    "G.eval()\n",
    "synthetic_df = generate_synthetic_forecast(G)\n",
    "display(synthetic_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d10504e-0988-46ab-a29f-508573a3a90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean_Real  Mean_Synthetic  Std_Real  Std_Synthetic  Skew_Real  Skew_Synthetic  Kurt_Real  Kurt_Synthetic  KS_Distance  Jarque_Bera_Real  Jarque_Bera_Synthetic\n",
      "  0.028898        0.020622  0.933006       0.193035   6.133508       10.928279  49.433831      195.867231     0.538306      10809.097061           1.098896e+06\n"
     ]
    }
   ],
   "source": [
    "# -- üìä Compare Real vs Synthetic Return Distributions --\n",
    "\n",
    "# These variables must be defined in your CV loop:\n",
    "# - `val_seq`: validation returns from the most recent TSCV fold\n",
    "# - `returns`: synthetic returns from the generator\n",
    "real_returns_flat = val_seq.flatten()\n",
    "synthetic_returns_flat = returns.flatten()\n",
    "\n",
    "# Evaluate and display stylized statistical metrics\n",
    "metrics_df = evaluate_synthetic_vs_real(real_returns_flat, synthetic_returns_flat)\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a024e77-0e86-4de6-a3af-cddab728d1fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-f3533983cc1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# -- üìà Run Dimensionality Reduction Plots --\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mplot_dimensionality_reduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynthetic_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PCA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mplot_dimensionality_reduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynthetic_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tSNE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-f3533983cc1a>\u001b[0m in \u001b[0;36mplot_dimensionality_reduction\u001b[0;34m(real_all, synthetic_all, method)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mX_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Format results for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \"\"\"\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 391\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/miniconda3/envs/bgan_env36/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "\n",
    "# -- üìâ Dimensionality Reduction Visualization --\n",
    "\n",
    "\n",
    "def plot_dimensionality_reduction(real_all, synthetic_all, method=\"PCA\"):\n",
    "    \"\"\"\n",
    "    Visualize differences between real and synthetic price trajectories\n",
    "    using PCA or t-SNE for dimensionality reduction.\n",
    "\n",
    "    Parameters:\n",
    "        real_all, synthetic_all: list of 1D price arrays per asset\n",
    "        method (str): \"PCA\" or \"tSNE\"\n",
    "    \"\"\"\n",
    "    all_series = []\n",
    "    labels = []\n",
    "\n",
    "    # Flatten and label all real and synthetic price series\n",
    "    for i, series in enumerate(real_all):\n",
    "        all_series.append(series)\n",
    "        labels.append(f\"Real_{i}\")\n",
    "    for i, series in enumerate(synthetic_all):\n",
    "        all_series.append(series)\n",
    "        labels.append(f\"Synth_{i}\")\n",
    "\n",
    "    X = np.array(all_series)\n",
    "\n",
    "    # Choose dimensionality reduction method\n",
    "    if method == \"PCA\":\n",
    "        reducer = PCA(n_components=2)\n",
    "    elif method == \"tSNE\":\n",
    "        reducer = TSNE(n_components=2, perplexity=5, learning_rate='auto', init='random', random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'PCA' or 'tSNE'.\")\n",
    "\n",
    "    # Reduce dimensionality\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "    # Format results for plotting\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"x\": X_reduced[:, 0],\n",
    "        \"y\": X_reduced[:, 1],\n",
    "        \"Type\": [\"Real\"] * len(real_all) + [\"Synthetic\"] * len(synthetic_all),\n",
    "        \"Asset\": [f\"A{i}\" for i in range(len(real_all))] * 2\n",
    "    })\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"Type\", style=\"Asset\", s=100)\n",
    "    plt.title(f\"{method} Projection of Real vs Synthetic Prices\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{method.lower()}_price_trajectories.png\")\n",
    "    plt.show()\n",
    "\n",
    "# -- üìà Run Dimensionality Reduction Plots --\n",
    "plot_dimensionality_reduction(real_all, synthetic_all, method=\"PCA\")\n",
    "plot_dimensionality_reduction(real_all, synthetic_all, method=\"tSNE\")\n",
    "\n",
    "\n",
    "# -- üñºÔ∏è Plot Final Generator Output Sample --\n",
    "fixed_noise = torch.randn(1, 100).to(device)\n",
    "plot_result(G, fixed_noise, image_size=1, num_epoch=\"final\", save_dir=\".\", n_series=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778aedf-97e7-474b-a552-422f89643d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765cad1-d76a-4112-84cc-415cd3595fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37181002-bb1f-4b57-b81b-d6d332df5cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
