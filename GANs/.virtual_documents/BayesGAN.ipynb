# !pip install ipykernel
# !python -m ipykernel install --user --name tf213-p310 --display-name "Python 3.10 (TF 2.13)"
# !pip uninstall -y tensorflow tensorflow-probability keras tf-keras-nightly
# !pip install tensorflow==2.13.0 tensorflow-probability==0.19.0



# # Reminder to restart 
# import tensorflow as tf
# import tensorflow_probability as tfp

# print("TF:", tf.__version__)  # Should be 2.13.0
# print("TFP:", tfp.__version__)  # Should be 0.19.0



import os
import sys
import argparse
import json
import time
import os 
import glob
import numpy as np
import six
import pickle

import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow.keras.layers import BatchNormalization

# Monkey patch tf.ones_like to avoid ValueError in tfp.internal.prefer_static
def patched_ones_like(input, dtype=None, name=None):
    return tf.ones_like(input, dtype=dtype, name=name)
tf.ones_like = patched_ones_like

from imageio import imread
import scipy.io as sio

import math
from math import ceil

import pandas as pd
from sklearn.preprocessing import StandardScaler

from collections import OrderedDict, defaultdict

df = pd.read_csv("raw (FX + EQ).csv")
data = df.values

# Normalize
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# Optionally: work with returns or PCA-reduced data
# returns = np.diff(np.log(data + 1e-5), axis=0)

class FXEQDataset:
    def __init__(self, data, batch_size):
        self.data = data
        self.batch_size = batch_size
        self.idx = 0
        self.num_samples = data.shape[0]

    def next_batch(self):
        if self.idx + self.batch_size > self.num_samples:
            self.idx = 0
        batch = self.data[self.idx:self.idx + self.batch_size]
        self.idx += self.batch_size
        return batch





def one_hot_encoded(class_numbers, num_classes):
    return np.eye(num_classes, dtype=float)[class_numbers]

class AttributeDict(dict):
    def __getattr__(self, attr):
        return self[attr]
    def __setattr__(self, attr, value):
        self[attr] = value
    def __hash__(self):
        return hash(tuple(sorted(self.items())))
        
class SynthDataset():
    
    def __init__(self, x_dim=100, num_clusters=10, seed=1234):
        
        np.random.seed(seed)
        
        self.x_dim = x_dim
        self.N = 10000
        self.true_z_dim = 2
        # generate synthetic data
        self.Xs = []
        for _ in range(num_clusters):
            cluster_mean = np.random.randn(self.true_z_dim) * 5 # to make them more spread
            A = np.random.randn(self.x_dim, self.true_z_dim) * 5
            X = np.dot(np.random.randn(self.N // num_clusters, self.true_z_dim) + cluster_mean,A.T)
            self.Xs.append(X)
        X_raw = np.concatenate(self.Xs)
        self.X = (X_raw - X_raw.mean(0)) / (X_raw.std(0))
        print(self.X.shape)
        
        
    def next_batch(self, batch_size):

        rand_idx = np.random.choice(list(range(self.N)), size=(batch_size,), replace=False)
        return self.X[rand_idx]



class batch_norm(object):
    def __init__(self, name="batch_norm"):
        self.bn = BatchNormalization(momentum=0.9, epsilon=1e-5, name=name)

    def __call__(self, x, train=True):
        return self.bn(x, training=train)


def linear(input_, output_size, name=None, stddev=0.02, bias_start=0.0):
    initializer = tf.random_normal_initializer(stddev=stddev)
    bias_initializer = tf.constant_initializer(bias_start)
    layer = tf.keras.layers.Dense(output_size, kernel_initializer=initializer, bias_initializer=bias_initializer, name=name)
    return layer(input_)

def get_session():
    if tf.get_default_session() is None:
        print("Creating new session")
        tf.reset_default_graph()
        _SESSION = tf.InteractiveSession()
    else:
        print("Using old session")
        _SESSION = tf.get_default_session()

    return _SESSION


def b_dcgan(dataset, args):

    z_dim = args.z_dim
    x_dim = dataset.x_dim
    batch_size = args.batch_size
    dataset_size = dataset.dataset_size

    session = get_session()
    tf.set_random_seed(args.random_seed)
    
    dcgan = BDCGAN(x_dim, z_dim, dataset_size, batch_size=batch_size,
                   J=args.J, J_d=args.J_d, M=args.M,
                   num_layers=args.num_layers,
                   lr=args.lr, optimizer=args.optimizer, gf_dim=args.gf_dim, 
                   df_dim=args.df_dim,
                   ml=(args.ml and args.J==1 and args.M==1 and args.J_d==1))
    
    print("Starting session")
    session.run(tf.global_variables_initializer())

    print("Starting training loop")
        
    num_train_iter = args.train_iter

    optimizer_dict = {"disc": dcgan.d_optims_adam,
                      "gen": dcgan.g_optims_adam}

    base_learning_rate = args.lr # for now we use same learning rate for Ds and Gs
    lr_decay_rate = args.lr_decay
    num_disc = args.J_d
    
    for train_iter in range(num_train_iter):

        if train_iter == 5000:
            print("Switching to user-specified optimizer")
            optimizer_dict = {"disc": dcgan.d_optims_adam,
                              "gen": dcgan.g_optims_adam}

        learning_rate = base_learning_rate * np.exp(-lr_decay_rate *
                                                    min(1.0, (train_iter*batch_size)/float(dataset_size)))

        image_batch, _ = dataset.next_batch(batch_size, class_id=None)       

        ### compute disc losses
        batch_z = np.random.uniform(-1, 1, [batch_size, z_dim, dcgan.num_gen])
        disc_info = session.run(optimizer_dict["disc"] + dcgan.d_losses, 
                                feed_dict={dcgan.inputs: image_batch,
                                           dcgan.z: batch_z,
                                           dcgan.d_learning_rate: learning_rate})

        d_losses = disc_info[num_disc:num_disc*2]

        ### compute generative losses
        batch_z = np.random.uniform(-1, 1, [batch_size, z_dim, dcgan.num_gen])
        gen_info = session.run(optimizer_dict["gen"] + dcgan.g_losses,
                               feed_dict={dcgan.z: batch_z,
                                          dcgan.inputs: image_batch,
                                          dcgan.g_learning_rate: learning_rate})
        g_losses = [g_ for g_ in gen_info if g_ is not None]

        if train_iter > 0 and train_iter % args.n_save == 0:

            def safe_print_losses(label, losses):
                if isinstance(losses, (list, tuple)):
                    cleaned = [float(x) for x in losses if x is not None]
                    if cleaned:
                        print("{} = {}".format(label, ", ".join(["%.2f" % x for x in cleaned])))
                    else:
                        print("{}: None".format(label))
                else:
                    if losses is not None:
                        print("{} = {:.2f}".format(label, float(losses)))
                    else:
                        print("{}: None".format(label))

            safe_print_losses("Disc losses", d_losses)
            safe_print_losses("Gen losses", g_losses)

            print("saving results and samples")

            # Save results safely
            results = {
                "disc_losses": [float(x) for x in d_losses if x is not None] if d_losses else [],
                "gen_losses": [float(x) for x in g_losses if x is not None] if g_losses else []
            }

            import pandas as pd

            # Save results to CSV
            # Safely handle missing discriminator losses
            gen_losses = results.get("gen_losses", [])
            disc_losses = results.get("disc_losses", [])

            # If discriminator losses are missing, fill with NaNs
            if len(disc_losses) == 0:
                disc_losses = [np.nan] * len(gen_losses)

            # Make sure they are same length
            min_len = min(len(disc_losses), len(gen_losses))
            disc_losses = disc_losses[:min_len]
            gen_losses = gen_losses[:min_len]

            # Save as DataFrame
            df = pd.DataFrame({
                "disc_loss": disc_losses,
                "gen_loss": gen_losses
            })
            df.to_csv(os.path.join(args.out_dir, "training_losses.csv"), index=False)
            print("Saved training losses to CSV.")


            with open(os.path.join(args.out_dir, 'results_%i.json' % train_iter), 'w') as fp:
                json.dump(results, fp)

            if args.save_weights:
                var_dict = {}
                for var in tf.trainable_variables():
                    var_dict[var.name] = session.run(var) 
                np.savez_compressed(os.path.join(args.out_dir, "weights_%i.npz" % train_iter), **var_dict)
            
            print(f"Step {train_iter}: D = {np.mean(d_losses):.4f}, G = {np.mean(g_losses):.4f}")
            
            # After training loop
            saver = tf.train.Saver()
            saver.save(session, os.path.join(args.out_dir, "model.ckpt"))
            print("Training complete. Model saved to: {}".format(args.out_dir))

            print("done")


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='Script to run Bayesian GAN experiments')

    parser.add_argument('--out_dir',
                        type=str,
                        required=True,
                        help="location of outputs (root location, which exists)")

    parser.add_argument('--n_save',
                        type=int,
                        default=100,
                        help="every n_save iteration save samples and weights")
    
    parser.add_argument('--z_dim',
                        type=int,
                        default=100,
                        help='dim of z for generator')
    
    parser.add_argument('--gf_dim',
                        type=int,
                        default=64,
                        help='num of gen features')
    
    parser.add_argument('--df_dim',
                        type=int,
                        default=96,
                        help='num of disc features')
    
    parser.add_argument('--data_path',
                        type=str,
                        required=True,
                        help='path to where the datasets live')

    parser.add_argument('--dataset',
                        type=str,
                        default="FXEQDataset",
                        help='datasate name FXEQDataset etc.')

    parser.add_argument('--batch_size',
                        type=int,
                        default=64,
                        help="minibatch size")

    parser.add_argument('--prior_std',
                        type=float,
                        default=1.0,
                        help="NN weight prior std.")

    parser.add_argument('--num_layers',
                        type=int,
                        default=4,
                        help="number of layers for G and D nets")

    parser.add_argument('--num_gen',
                        type=int,
                        dest="J",
                        default=1,
                        help="number of samples of z/generators")

    parser.add_argument('--num_disc',
                        type=int,
                        dest="J_d",
                        default=1,
                        help="number of discrimitor weight samples")

    parser.add_argument('--num_mcmc',
                        type=int,
                        dest="M",
                        default=1,
                        help="number of MCMC NN weight samples per z")

    parser.add_argument('--N',
                        type=int,
                        default=128,
                        help="number of supervised data samples")

    parser.add_argument('--train_iter',
                        type=int,
                        default=50000,
                        help="number of training iterations")

    parser.add_argument('--wasserstein',
                        action="store_true",
                        help="wasserstein GAN")

    parser.add_argument('--ml',
                        action="store_true",
                        help="if specified, disable bayesian things")

    parser.add_argument('--save_samples',
                        action="store_true",
                        help="wether to save generated samples")
    
    parser.add_argument('--save_weights',
                        action="store_true",
                        help="wether to save weights")

    parser.add_argument('--random_seed',
                        type=int,
                        default=2222,
                        help="random seed")
    
    parser.add_argument('--lr',
                        type=float,
                        default=0.005,
                        help="learning rate")

    parser.add_argument('--lr_decay',
                        type=float,
                        default=3.0,
                        help="learning rate")

    parser.add_argument('--optimizer',
                        type=str,
                        default="sgd",
                        help="optimizer --- 'adam' or 'sgd'")

    
    args = parser.parse_args()

    # set seeds
    np.random.seed(args.random_seed)
    tf.set_random_seed(args.random_seed)

    if not os.path.exists(args.out_dir):
        print("Creating %s" % args.out_dir)
        os.makedirs(args.out_dir)
    args.out_dir = os.path.join(args.out_dir, "bgan_%s_%i" % (args.dataset, int(time.time())))
    os.makedirs(args.out_dir)

    import pprint
    with open(os.path.join(args.out_dir, "hypers.txt"), "w") as hf:
        hf.write("Hyper settings:\n")
        hf.write("%s\n" % (pprint.pformat(args.__dict__)))

    if args.dataset.lower() == "fxeqdataset":
        df = pd.read_csv(args.data_path)
        dataset = FXEQDataset(data=df.values, batch_size=args.batch_size)
    else:
        raise RuntimeError("invalid dataset %s" % args.dataset)

    ### main call
    b_dcgan(dataset, args)


# Set up BDCGAN

def conv_out_size(size, stride):
    co = int(math.ceil(size / float(stride)))
    return co

def kernel_sizer(size, stride):
    ko = int(math.ceil(size / float(stride)))
    if ko % 2 == 0:
        ko += 1
    return ko


class BDCGAN(object):

    def __init__(self, x_dim, z_dim, dataset_size, batch_size=64, gf_dim=64, df_dim=64, 
                 prior_std=1.0, J=1, M=1, eta=2e-4, num_layers=4,
                 alpha=0.01, lr=0.0002, optimizer='adam', wasserstein=False, 
                 ml=False, J_d=None):

        if len(x_dim) == 1:
            c_dim = 1
            s_h = s_w = int(np.ceil(np.sqrt(x_dim[0])))  # reshape to square-like image
            self.x_dim = [s_h, s_w, 1]
        else:
            c_dim = x_dim[2]
            self.x_dim = x_dim
        self.is_grayscale = (c_dim == 1)
        self.optimizer = optimizer.lower()
        self.dataset_size = dataset_size
        self.batch_size = batch_size
        
        self.K = 2 # fake and real classes
        self.x_dim = x_dim
        self.z_dim = z_dim

        self.gf_dim = gf_dim
        self.df_dim = df_dim
        self.c_dim = c_dim
        self.lr = lr
        
        # Bayes
        self.prior_std = prior_std
        self.num_gen = J
        self.num_disc = J_d if J_d is not None else 1
        self.num_mcmc = M
        self.eta = eta
        self.alpha = alpha
        # ML
        self.ml = ml
        if self.ml:
            assert self.num_gen == 1 and self.num_disc == 1 and self.num_mcmc == 1, "invalid settings for ML training"

        self.noise_std = np.sqrt(2 * self.alpha * self.eta)

        def get_strides(num_layers, num_pool):
            interval = int(math.floor(num_layers/float(num_pool)))
            strides = np.array([1]*num_layers)
            strides[0:interval*num_pool:interval] = 2
            return strides

        self.num_pool = 4
        self.max_num_dfs = 512
        self.gen_strides = get_strides(num_layers, self.num_pool)
        self.disc_strides = self.gen_strides
        num_dfs = np.cumprod(np.array([self.df_dim] + list(self.disc_strides)))[:-1]
        num_dfs[num_dfs >= self.max_num_dfs] = self.max_num_dfs # memory
        self.num_dfs = list(num_dfs)
        self.num_gfs = self.num_dfs[::-1]

        # self.construct_from_hypers(gen_strides=self.gen_strides, disc_strides=self.disc_strides,
        #                            num_gfs=self.num_gfs, num_dfs=self.num_dfs)
        
        self.build_bgan_graph()
        

    # def construct_from_hypers(self, gen_kernel_size=5, gen_strides=[2,2,2,2],
    #                           disc_kernel_size=5, disc_strides=[2,2,2,2],
    #                           num_dfs=None, num_gfs=None):

        
    #     self.d_batch_norm = AttributeDict([("d_bn%i" % dbn_i, batch_norm(name='d_bn%i' % dbn_i)) for dbn_i in range(len(disc_strides))])
    #     self.sup_d_batch_norm = AttributeDict([("sd_bn%i" % dbn_i, batch_norm(name='sup_d_bn%i' % dbn_i)) for dbn_i in range(5)])
    #     self.g_batch_norm = AttributeDict([("g_bn%i" % gbn_i, batch_norm(name='g_bn%i' % gbn_i)) for gbn_i in range(len(gen_strides))])

    #     if num_dfs is None:
    #         num_dfs = [self.df_dim, self.df_dim*2, self.df_dim*4, self.df_dim*8]
            
    #     if num_gfs is None:
    #         num_gfs = [self.gf_dim*8, self.gf_dim*4, self.gf_dim*2, self.gf_dim]

    #     assert len(gen_strides) == len(num_gfs), "invalid hypers!"
    #     assert len(disc_strides) == len(num_dfs), "invalid hypers!"

    #     s_h, s_w = self.x_dim[0], self.x_dim[1]
    #     ks = gen_kernel_size
    #     self.gen_output_dims = OrderedDict()
    #     self.gen_weight_dims = OrderedDict()
    #     num_gfs = num_gfs + [self.c_dim]
    #     self.gen_kernel_sizes = [ks]
    #     for layer in range(len(gen_strides))[::-1]:
    #         self.gen_output_dims["g_h%i_out" % (layer+1)] = (s_h, s_w)
    #         assert gen_strides[layer] <= 2, "invalid stride"
    #         assert ks % 2 == 1, "invalid kernel size"
    #         self.gen_weight_dims["g_h%i_W" % (layer+1)] = (ks, ks, num_gfs[layer+1], num_gfs[layer])
    #         self.gen_weight_dims["g_h%i_b" % (layer+1)] = (num_gfs[layer+1],)
    #         s_h, s_w = conv_out_size(s_h, gen_strides[layer]), conv_out_size(s_w, gen_strides[layer])
    #         ks = kernel_sizer(ks, gen_strides[layer])
    #         self.gen_kernel_sizes.append(ks)


    #     self.gen_weight_dims.update(OrderedDict([("g_h0_lin_W", (self.z_dim, num_gfs[0] * s_h * s_w)),
    #                                              ("g_h0_lin_b", (num_gfs[0] * s_h * s_w,))]))
    #     self.gen_output_dims["g_h0_out"] = (s_h, s_w)

    #     self.disc_weight_dims = OrderedDict()
    #     s_h, s_w = self.x_dim[0], self.x_dim[1]
    #     num_dfs = [self.c_dim] + num_dfs
    #     ks = disc_kernel_size
    #     self.disc_kernel_sizes = [ks]
    #     for layer in range(len(disc_strides)):
    #         assert disc_strides[layer] <= 2, "invalid stride"
    #         assert ks % 2 == 1, "invalid kernel size"
    #         self.disc_weight_dims["d_h%i_W" % layer] = (ks, ks, num_dfs[layer], num_dfs[layer+1])
    #         self.disc_weight_dims["d_h%i_b" % layer] = (num_dfs[layer+1],)
    #         s_h, s_w = conv_out_size(s_h, disc_strides[layer]), conv_out_size(s_w, disc_strides[layer])
    #         ks = kernel_sizer(ks, disc_strides[layer])
    #         self.disc_kernel_sizes.append(ks)

    #     self.disc_weight_dims.update(OrderedDict([("d_h_end_lin_W", (num_dfs[-1] * s_h * s_w, num_dfs[-1])),
    #                                               ("d_h_end_lin_b", (num_dfs[-1],)),
    #                                               ("d_h_out_lin_W", (num_dfs[-1], self.K)),
    #                                               ("d_h_out_lin_b", (self.K,))]))


    #     for k, v in list(self.gen_output_dims.items()):
    #         print("%s: %s" % (k, v))
    #     print('****')
    #     for k, v in list(self.gen_weight_dims.items()):
    #         print("%s: %s" % (k, v))
    #     print('****')
    #     for k, v in list(self.disc_weight_dims.items()):
    #         print("%s: %s" % (k, v))





    # def construct_nets(self):

    #     self.num_disc_layers = 5
    #     self.num_gen_layers = 5
    #     self.d_batch_norm = AttributeDict([("d_bn%i" % dbn_i, batch_norm(name='d_bn%i' % dbn_i)) for dbn_i in range(self.num_disc_layers)])
    #     self.sup_d_batch_norm = AttributeDict([("sd_bn%i" % dbn_i, batch_norm(name='sup_d_bn%i' % dbn_i)) for dbn_i in range(self.num_disc_layers)])
    #     self.g_batch_norm = AttributeDict([("g_bn%i" % gbn_i, batch_norm(name='g_bn%i' % gbn_i)) for gbn_i in range(self.num_gen_layers)])


    #     s_h, s_w = self.x_dim[0], self.x_dim[1]
    #     s_h2, s_w2 = conv_out_size(s_h, 2), conv_out_size(s_w, 2)
    #     s_h4, s_w4 = conv_out_size(s_h2, 2), conv_out_size(s_w2, 2)
    #     s_h8, s_w8 = conv_out_size(s_h4, 2), conv_out_size(s_w4, 2)
    #     s_h16, s_w16 = conv_out_size(s_h8, 2), conv_out_size(s_w8, 2)

    #     self.gen_output_dims = OrderedDict([("g_h0_out", (s_h16, s_w16)),
    #                                         ("g_h1_out", (s_h8, s_w8)),
    #                                         ("g_h2_out", (s_h4, s_w4)),
    #                                         ("g_h3_out", (s_h2, s_w2)),
    #                                         ("g_h4_out", (s_h, s_w))])

        
    #     self.gen_weight_dims = OrderedDict([("g_h0_lin_W", (self.z_dim, self.gf_dim * 8 * s_h16 * s_w16)),
    #                                         ("g_h0_lin_b", (self.gf_dim * 8 * s_h16 * s_w16,)),
    #                                         ("g_h1_W", (5, 5, self.gf_dim*4, self.gf_dim*8)),
    #                                         ("g_h1_b", (self.gf_dim*4,)),
    #                                         ("g_h2_W", (5, 5, self.gf_dim*2, self.gf_dim*4)),
    #                                         ("g_h2_b", (self.gf_dim*2,)),
    #                                         ("g_h3_W", (5, 5, self.gf_dim*1, self.gf_dim*2)),
    #                                         ("g_h3_b", (self.gf_dim*1,)),
    #                                         ("g_h4_W", (5, 5, self.c_dim, self.gf_dim*1)),
    #                                         ("g_h4_b", (self.c_dim,))])

    #     self.disc_weight_dims = OrderedDict([("d_h0_W", (5, 5, self.c_dim, self.df_dim)),
    #                                          ("d_h0_b", (self.df_dim,)),
    #                                          ("d_h1_W", (5, 5, self.df_dim, self.df_dim*2)),
    #                                          ("d_h1_b", (self.df_dim*2,)),
    #                                          ("d_h2_W", (5, 5, self.df_dim*2, self.df_dim*4)),
    #                                          ("d_h2_b", (self.df_dim*4,)),
    #                                          ("d_h3_W", (5, 5, self.df_dim*4, self.df_dim*8)),
    #                                          ("d_h3_b", (self.df_dim*8,)),
    #                                          ("d_h_end_lin_W", (self.df_dim * 8 * s_h16 * s_w16, self.df_dim*4)),
    #                                          ("d_h_end_lin_b", (self.df_dim*4,)),
    #                                          ("d_h_out_lin_W", (self.df_dim*4, self.K)),
    #                                          ("d_h_out_lin_b", (self.K,))])



    def _get_optimizer(self, lr):
        if self.optimizer == 'adam':
            return tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5)
        elif self.optimizer == 'sgd':
            return tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.5)
        else:
            raise ValueError("Optimizer must be either 'adam' or 'sgd'")    

    def initialize_wgts(self, scope_str):

        if scope_str == "generator":
            weight_dims = self.gen_weight_dims
            numz = self.num_gen
        elif scope_str == "discriminator":
            weight_dims = self.disc_weight_dims
            numz = self.num_disc
        else:
            raise RuntimeError("invalid scope!")

        param_list = []
        with tf.variable_scope(scope_str) as scope:
            for zi in range(numz):
                for m in range(self.num_mcmc):
                    wgts_ = AttributeDict()
                    for name, shape in weight_dims.items():
                        wgts_[name] = tf.get_variable("%s_%04d_%04d" % (name, zi, m),
                                                      shape, initializer=tf.random_normal_initializer(stddev=0.02))
                    param_list.append(wgts_)
            return param_list
        

    def build_bgan_graph(self):
    
        self.inputs = tf.placeholder(tf.float32,
                                     [self.batch_size] + list(self.x_dim), name='real_images')

        self.z = tf.placeholder(tf.float32, [self.batch_size, self.z_dim, self.num_gen], name='z')
        self.z_sampler = tf.placeholder(tf.float32, [self.batch_size, self.z_dim], name='z_sampler')
        
        # initialize generator weights
        self.gen_param_list = self.initialize_wgts("generator")
        self.disc_param_list = self.initialize_wgts("discriminator")
        ### build discrimitive losses and optimizers
        # prep optimizer args
        self.d_learning_rate = tf.placeholder(tf.float32, shape=[])
        
        # compile all disciminative weights
        t_vars = tf.trainable_variables()
        self.d_vars = []
        for di in range(self.num_disc):
            for m in range(self.num_mcmc):
                self.d_vars.append([var for var in t_vars if 'd_' in var.name and "_%04d_%04d" % (di, m) in var.name])

        ### build disc losses and optimizers
        self.d_losses, self.d_optims, self.d_optims_adam = [], [], []
        for di, disc_params in enumerate(self.disc_param_list):

            d_probs, d_logits, _ = self.discriminator(self.inputs, self.K, disc_params)

            constant_labels = np.zeros((self.batch_size, 2))
            constant_labels[:, 1] = 1.0  # real
            d_loss_real = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=d_logits,
                                                                                 labels=tf.constant(constant_labels)))

            d_loss_fakes = []
            for gi, gen_params in enumerate(self.gen_param_list):
                d_probs_, d_logits_, _ = self.discriminator(self.generator(self.z[:, :, gi % self.num_gen], gen_params), 
                                                            self.K, disc_params)
                constant_labels = np.zeros((self.batch_size, self.K))
                constant_labels[:, 0] = 1.0 # class label indicating it came from generator, aka fake
                d_loss_fake_ = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=d_logits_,
                                                                                      labels=tf.constant(constant_labels)))
                d_loss_fakes.append(d_loss_fake_)

            d_losses = []
            for d_loss_fake_ in d_loss_fakes:
                d_loss_ = d_loss_real * float(self.num_gen) + d_loss_fake_
                if not self.ml:
                    d_loss_ += self.disc_prior(disc_params) + self.disc_noise(disc_params)
                d_losses.append(tf.reshape(d_loss_, [1]))

            d_loss = tf.reduce_logsumexp(tf.concat(d_losses, 0))
            self.d_losses.append(d_loss)
            d_opt = self._get_optimizer(self.d_learning_rate)
            self.d_optims.append(d_opt.minimize(d_loss, var_list=self.d_vars[di]))
            d_opt_adam = tf.train.AdamOptimizer(learning_rate=self.d_learning_rate, beta1=0.5)
            self.d_optims_adam.append(d_opt_adam.minimize(d_loss, var_list=self.d_vars[di]))

        ### build generative losses and optimizers
        self.g_learning_rate = tf.placeholder(tf.float32, shape=[])
        self.g_vars = []
        for gi in range(self.num_gen):
            for m in range(self.num_mcmc):
                self.g_vars.append([var for var in t_vars if 'g_' in var.name and "_%04d_%04d" % (gi, m) in var.name])
        
        self.g_losses, self.g_optims, self.g_optims_adam = [], [], []
        for gi, gen_params in enumerate(self.gen_param_list):

            gi_losses = []
            for disc_params in self.disc_param_list:
                d_probs_, d_logits_, d_features_fake = self.discriminator(self.generator(self.z[:, :, gi % self.num_gen],
                                                                                         gen_params),
                                                                          self.K, disc_params)
                _, _, d_features_real = self.discriminator(self.inputs, self.K, disc_params)
                constant_labels = np.zeros((self.batch_size, self.K))
                constant_labels[:, 1] = 1.0 # class label indicating that this fake is real
                g_loss_ = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=d_logits_,
                                                                                 labels=tf.constant(constant_labels)))
                g_loss_ += tf.reduce_mean(huber_loss(d_features_real[-1], d_features_fake[-1]))
                if not self.ml:
                    g_loss_ += self.gen_prior(gen_params) + self.gen_noise(gen_params)
                gi_losses.append(tf.reshape(g_loss_, [1]))
                
            g_loss = tf.reduce_logsumexp(tf.concat(gi_losses, 0))
            self.g_losses.append(g_loss)
            g_opt = self._get_optimizer(self.g_learning_rate)
            self.g_optims.append(g_opt.minimize(g_loss, var_list=self.g_vars[gi]))
            g_opt_adam = tf.train.AdamOptimizer(learning_rate=self.g_learning_rate, beta1=0.5)
            self.g_optims_adam.append(g_opt_adam.minimize(g_loss, var_list=self.g_vars[gi]))

        ### build samplers
        self.gen_samplers = []
        for gi, gen_params in enumerate(self.gen_param_list):
            self.gen_samplers.append(self.generator(self.z_sampler, gen_params))


    def discriminator(self, image, K, disc_params, train=True):

        with tf.variable_scope("discriminator") as scope:

            h = image
            for layer in range(len(self.disc_strides)):
                if layer == 0:
                    h = lrelu(conv2d(h,
                                     self.disc_weight_dims["d_h%i_W" % layer][-1],
                                     name='d_h%i_conv' % layer,
                                     k_h=self.disc_kernel_sizes[layer], k_w=self.disc_kernel_sizes[layer],
                                     d_h=self.disc_strides[layer], d_w=self.disc_strides[layer],
                                     w=disc_params["d_h%i_W" % layer], biases=disc_params["d_h%i_b" % layer]))
                else:
                    h = lrelu(self.d_batch_norm["d_bn%i" % layer](conv2d(h,
                                                                         self.disc_weight_dims["d_h%i_W" % layer][-1],
                                                                         name='d_h%i_conv' % layer,
                                                                         k_h=self.disc_kernel_sizes[layer], k_w=self.disc_kernel_sizes[layer],
                                                                         d_h=self.disc_strides[layer], d_w=self.disc_strides[layer],
                                                                         w=disc_params["d_h%i_W" % layer], biases=disc_params["d_h%i_b" % layer]), train=train))

            h_end = lrelu(linear(tf.reshape(h, [self.batch_size, -1]),
                              self.df_dim*4, "d_h_end_lin",
                              matrix=disc_params.d_h_end_lin_W, bias=disc_params.d_h_end_lin_b)) # for feature norm
            h_out = linear(h_end, K,
                           'd_h_out_lin',
                           matrix=disc_params.d_h_out_lin_W, bias=disc_params.d_h_out_lin_b)
            
            return tf.nn.softmax(h_out), h_out, [h_end]
            

    def generator(self, z, gen_params):

        with tf.variable_scope("generator") as scope:

            h = linear(z, self.gen_weight_dims["g_h0_lin_W"][-1], 'g_h0_lin',
                       matrix=gen_params.g_h0_lin_W, bias=gen_params.g_h0_lin_b)
            h = tf.nn.relu(self.g_batch_norm.g_bn0(h))

            h = tf.reshape(h, [self.batch_size, self.gen_output_dims["g_h0_out"][0],
                               self.gen_output_dims["g_h0_out"][1], -1])

            for layer in range(1, len(self.gen_strides)+1):

                out_shape = [self.batch_size, self.gen_output_dims["g_h%i_out" % layer][0],
                             self.gen_output_dims["g_h%i_out" % layer][1], self.gen_weight_dims["g_h%i_W" % layer][-2]]

                h = deconv2d(h,
                             out_shape,
                             k_h=self.gen_kernel_sizes[layer-1], k_w=self.gen_kernel_sizes[layer-1],
                             d_h=self.gen_strides[layer-1], d_w=self.gen_strides[layer-1],
                             name='g_h%i' % layer,
                             w=gen_params["g_h%i_W" % layer], biases=gen_params["g_h%i_b" % layer])
                if layer < len(self.gen_strides):
                    h = tf.nn.relu(self.g_batch_norm["g_bn%i" % layer](h))

            return tf.nn.tanh(h)        


    def gen_prior(self, gen_params):
        with tf.variable_scope("generator") as scope:
            prior_loss = 0.0
            for var in list(gen_params.values()):
                nn = tf.divide(var, self.prior_std)
                prior_loss += tf.reduce_mean(tf.multiply(nn, nn))
                
        prior_loss /= self.dataset_size

        return prior_loss

    def gen_noise(self, gen_params): 
        with tf.variable_scope("generator") as scope:
            noise_loss = 0.0
            for name, var in gen_params.items():
                noise_ = tfp.distributions.Normal(mu=0., sigma=self.noise_std*tf.ones(var.get_shape()))
                noise_loss += tf.reduce_sum(var * noise_.sample())
        noise_loss /= self.dataset_size
        return noise_loss

    def disc_prior(self, disc_params):
        with tf.variable_scope("discriminator") as scope:
            prior_loss = 0.0
            for var in list(disc_params.values()):
                nn = tf.divide(var, self.prior_std)
                prior_loss += tf.reduce_mean(tf.multiply(nn, nn))
                
        prior_loss /= self.dataset_size

        return prior_loss

    def disc_noise(self, disc_params): 
        with tf.variable_scope("discriminator") as scope:
            noise_loss = 0.0
            for var in list(disc_params.values()):
                noise_ = tfp.distributions.Normal(mu=0., sigma=self.noise_std*tf.ones(var.get_shape()))
                noise_loss += tf.reduce_sum(var * noise_.sample())
        noise_loss /= self.dataset_size
        return noise_loss


class Generator2(tf.keras.Model):
    def __init__(self, z_dim, output_dim, hidden_units=[128, 256, 512]):
        super(Generator, self).__init__()
        self.z_dim = z_dim
        self.hidden_layers = [tf.keras.layers.Dense(units, activation='relu') for units in hidden_units]
        self.out = tf.keras.layers.Dense(output_dim, activation='tanh')

    def call(self, z, training=False):
        x = z
        for layer in self.hidden_layers:
            x = layer(x, training=training)
        return self.out(x)


class Discriminator2(tf.keras.Model):
    def __init__(self, input_dim, hidden_units=[512, 256]):
        super(Discriminator, self).__init__()
        self.hidden_layers = [tf.keras.layers.Dense(units, activation='leaky_relu') for units in hidden_units]
        self.out = tf.keras.layers.Dense(1)  # logits for binary classification (real vs fake)

    def call(self, x, training=False):
        for layer in self.hidden_layers:
            x = layer(x, training=training)
        return self.out(x)

def add_gaussian_noise(x, stddev):
    noise = tfp.distributions.Normal(loc=0., scale=stddev).sample(sample_shape=tf.shape(x))
    return x + noise

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_logits, fake_logits):
    real_loss = cross_entropy(tf.ones_like(real_logits), real_logits)
    fake_loss = cross_entropy(tf.zeros_like(fake_logits), fake_logits)
    return real_loss + fake_loss

def generator_loss(fake_logits):
    return cross_entropy(tf.ones_like(fake_logits), fake_logits)

generator = Generator(z_dim=100, output_dim=scaled_data.shape[1])
discriminator = Discriminator(input_dim=scaled_data.shape[1])

g_optimizer = tf.keras.optimizers.Adam(1e-4)
d_optimizer = tf.keras.optimizers.Adam(1e-4)

@tf.function
def train_step(real_data):
    noise = tf.random.normal([real_data.shape[0], 100])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        fake_data = generator(noise, training=True)

        real_output = discriminator(real_data, training=True)
        fake_output = discriminator(fake_data, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    g_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    d_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    return gen_loss, disc_loss




import os
import json
import time
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from tensorflow.compat.v1.keras.layers import Dense
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

# ----------------------- Data Preprocessing -----------------------

df = pd.read_csv("raw (FX + EQ).csv")
df = df.drop(columns=["Date"], errors="ignore")  # Drop non-numeric columns
df = df.dropna(axis=0)  # Drop rows with NaNs
data = df.values

scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# ----------------------- Dataset Class -----------------------

class FXEQDataset:
    def __init__(self, data, batch_size):
        self.data = data
        self.batch_size = batch_size
        self.idx = 0
        self.num_samples = data.shape[0]

    def next_batch(self, batch_size=None, class_id=None):
        if batch_size is None:
            batch_size = self.batch_size
        if self.idx + batch_size > self.num_samples:
            self.idx = 0
        batch = self.data[self.idx:self.idx + batch_size]
        self.idx += batch_size
        return batch, None

# ----------------------- Minimal BayesGAN Mockup -----------------------

class MiniGAN:
    def __init__(self, x_dim, z_dim, batch_size, lr):
        self.x_dim = x_dim
        self.z_dim = z_dim
        self.batch_size = batch_size
        self.lr = lr
        self._build_model()

    def _build_generator(self, z):
        with tf.variable_scope("generator", reuse=tf.AUTO_REUSE):
            h1 = Dense(128, activation=tf.nn.relu)(z)
            out = tf.layers.dense(h1, self.x_dim)
        return out

    def _build_discriminator(self, x):
        with tf.variable_scope("discriminator", reuse=tf.AUTO_REUSE):
            h1 = Dense(128, activation=tf.nn.relu)(z)
            logits = tf.layers.dense(h1, 1)
        return logits

    def _build_model(self):
        self.z = tf.placeholder(tf.float32, [None, self.z_dim], name="z")
        self.x = tf.placeholder(tf.float32, [None, self.x_dim], name="x")

        self.fake_x = self._build_generator(self.z)
        real_logits = self._build_discriminator(self.x)
        fake_logits = self._build_discriminator(self.fake_x)

        # Losses
        self.d_loss = tf.reduce_mean(
            tf.nn.sigmoid_cross_entropy_with_logits(logits=real_logits, labels=tf.ones_like(real_logits))) + \
                      tf.reduce_mean(
                          tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.zeros_like(fake_logits)))

        self.g_loss = tf.reduce_mean(
            tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.ones_like(fake_logits)))

        # Variables
        all_vars = tf.trainable_variables()
        self.d_vars = [v for v in all_vars if "discriminator" in v.name]
        self.g_vars = [v for v in all_vars if "generator" in v.name]

        # Optimizers
        self.d_opt = tf.train.AdamOptimizer(self.lr).minimize(self.d_loss, var_list=self.d_vars)
        self.g_opt = tf.train.AdamOptimizer(self.lr).minimize(self.g_loss, var_list=self.g_vars)

# ----------------------- Training Function -----------------------

def train_gan(data, args):
    tf.reset_default_graph()
    dataset = FXEQDataset(data, batch_size=args["batch_size"])
    session = tf.InteractiveSession()
    tf.set_random_seed(args["random_seed"])

    model = MiniGAN(x_dim=data.shape[1],
                    z_dim=args["z_dim"],
                    batch_size=args["batch_size"],
                    lr=args["lr"])

    session.run(tf.global_variables_initializer())
    print("Training started...")

    for step in range(args["train_iter"]):
        batch_x, _ = dataset.next_batch()
        batch_z = np.random.uniform(-1, 1, [args["batch_size"], args["z_dim"]])

        # Train discriminator
        _ = session.run(model.d_opt, feed_dict={model.x: batch_x, model.z: batch_z})

        # Train generator
        _ = session.run(model.g_opt, feed_dict={model.z: batch_z})

        if step % args["n_save"] == 0:
            d_loss_val, g_loss_val = session.run([model.d_loss, model.g_loss],
                                                 feed_dict={model.x: batch_x, model.z: batch_z})
            print(f"Step {step}: D_loss = {d_loss_val:.4f}, G_loss = {g_loss_val:.4f}")

    print("Training complete.")
    session.close()

# ----------------------- Run -----------------------

args = {
    "batch_size": 64,
    "z_dim": 100,
    "lr": 0.001,
    "train_iter": 1000,
    "n_save": 100,
    "random_seed": 42,
}

train_gan(scaled_data, args)





