{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProbGAN - Synthetic FX + Equity Forecasting Notebook\n",
    "This notebook uses the `FXEQGenerator` from the ProbGAN repo to generate synthetic price paths based on FX and equity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (1.10.2)\n",
      "Collecting easydict\n",
      "  Downloading easydict-1.13-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: dataclasses in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/rootadmin/miniconda3/envs/bgan_env36/lib/python3.6/site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: easydict\n",
      "Successfully installed easydict-1.13\n",
      "üîÅ TSCV for Asset 0\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 5 iters, (0.027)\tData load 0.015s / 5 iters, (0.003089)\n",
      "Loss_D = 1.36263847 (ave = 1.36770527)\n",
      "Loss_G = 0.69383931 (ave = 0.69548810)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9601505570546686, value max: 0.02230174094438553\n",
      "D grad l2-norm: 0.7047106270076978, value max: 0.5003437995910645\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.958s / 5 iters, (0.192)\tData load 0.911s / 5 iters, (0.182154)\n",
      "Loss_D = 1.34052205 (ave = 1.35142019)\n",
      "Loss_G = 0.69135189 (ave = 0.69264959)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965247674333042, value max: 0.02311573177576065\n",
      "D grad l2-norm: 0.7046662030897001, value max: 0.49909937381744385\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.786s / 5 iters, (0.157)\tData load 0.683s / 5 iters, (0.136632)\n",
      "Loss_D = 1.33770597 (ave = 1.33869112)\n",
      "Loss_G = 0.68948686 (ave = 0.69040085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9649509619792441, value max: 0.02173931710422039\n",
      "D grad l2-norm: 0.7053304866966665, value max: 0.4981638491153717\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.932s / 5 iters, (0.186)\tData load 0.767s / 5 iters, (0.153348)\n",
      "Loss_D = 1.33443165 (ave = 1.32627985)\n",
      "Loss_G = 0.68805522 (ave = 0.68876538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9603078716509824, value max: 0.02153162471950054\n",
      "D grad l2-norm: 0.7055697381179853, value max: 0.497444748878479\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.787s / 5 iters, (0.157)\tData load 0.653s / 5 iters, (0.130525)\n",
      "Loss_D = 1.30199707 (ave = 1.31031635)\n",
      "Loss_G = 0.68682867 (ave = 0.68694034)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9687064596797388, value max: 0.022205399349331856\n",
      "D grad l2-norm: 0.7069537433437217, value max: 0.49682778120040894\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.488s / 5 iters, (0.298)\tData load 1.346s / 5 iters, (0.269288)\n",
      "Loss_D = 1.27438426 (ave = 1.29549105)\n",
      "Loss_G = 0.68517834 (ave = 0.68542621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9681283737812717, value max: 0.028050824999809265\n",
      "D grad l2-norm: 0.709118066960765, value max: 0.4959960877895355\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.770s / 5 iters, (0.154)\tData load 0.640s / 5 iters, (0.128072)\n",
      "Loss_D = 1.28679419 (ave = 1.28596640)\n",
      "Loss_G = 0.68387538 (ave = 0.68415833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9626670299955782, value max: 0.021118002012372017\n",
      "D grad l2-norm: 0.7113653513133564, value max: 0.49533867835998535\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.066s / 5 iters, (0.213)\tData load 0.993s / 5 iters, (0.198609)\n",
      "Loss_D = 1.25571167 (ave = 1.27153144)\n",
      "Loss_G = 0.68252438 (ave = 0.68328745)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968384314883721, value max: 0.030544593930244446\n",
      "D grad l2-norm: 0.713993306662896, value max: 0.4946563243865967\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.986s / 5 iters, (0.197)\tData load 0.865s / 5 iters, (0.173031)\n",
      "Loss_D = 1.27275765 (ave = 1.26302385)\n",
      "Loss_G = 0.68214500 (ave = 0.68250542)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9690742000110509, value max: 0.03264414891600609\n",
      "D grad l2-norm: 0.7196091680666781, value max: 0.4944630563259125\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.075s / 5 iters, (0.215)\tData load 0.910s / 5 iters, (0.182005)\n",
      "Loss_D = 1.25302398 (ave = 1.25047252)\n",
      "Loss_G = 0.68178636 (ave = 0.68198103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9659569947213332, value max: 0.027200354263186455\n",
      "D grad l2-norm: 0.7230975415390009, value max: 0.4942818284034729\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.597s / 5 iters, (0.319)\tData load 1.313s / 5 iters, (0.262689)\n",
      "Loss_D = 1.24044979 (ave = 1.23885167)\n",
      "Loss_G = 0.68202376 (ave = 0.68158807)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9658627486013224, value max: 0.02739877626299858\n",
      "D grad l2-norm: 0.7290556572788153, value max: 0.4944015443325043\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.284s / 5 iters, (0.057)\tData load 0.018s / 5 iters, (0.003689)\n",
      "Loss_D = 1.22649741 (ave = 1.22779083)\n",
      "Loss_G = 0.68113011 (ave = 0.68152759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9690859342206087, value max: 0.04078337922692299\n",
      "D grad l2-norm: 0.7356764382644699, value max: 0.4939478039741516\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.193s / 5 iters, (0.039)\tData load 0.022s / 5 iters, (0.004401)\n",
      "Loss_D = 1.20860600 (ave = 1.21653340)\n",
      "Loss_G = 0.68107837 (ave = 0.68125441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9703652478429191, value max: 0.03766900673508644\n",
      "D grad l2-norm: 0.7428511698746435, value max: 0.4939212203025818\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.152s / 5 iters, (0.030)\tData load 0.016s / 5 iters, (0.003263)\n",
      "Loss_D = 1.18861830 (ave = 1.20503049)\n",
      "Loss_G = 0.68209207 (ave = 0.68166795)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9726834719097204, value max: 0.03753995522856712\n",
      "D grad l2-norm: 0.7522235591945562, value max: 0.4944339692592621\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.189s / 5 iters, (0.038)\tData load 0.023s / 5 iters, (0.004652)\n",
      "Loss_D = 1.19542432 (ave = 1.19713340)\n",
      "Loss_G = 0.68222517 (ave = 0.68142092)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9745789899232095, value max: 0.03860217332839966\n",
      "D grad l2-norm: 0.7561181633966321, value max: 0.4944976270198822\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.172s / 5 iters, (0.034)\tData load 0.021s / 5 iters, (0.004202)\n",
      "Loss_D = 1.18665624 (ave = 1.18745372)\n",
      "Loss_G = 0.68193871 (ave = 0.68145958)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9813732303047162, value max: 0.03801678121089935\n",
      "D grad l2-norm: 0.7676475212773973, value max: 0.4943530261516571\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.007s / 5 iters, (0.001422)\n",
      "Loss_D = 1.17661715 (ave = 1.17835937)\n",
      "Loss_G = 0.68250895 (ave = 0.68199602)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9744774998490305, value max: 0.04298440366983414\n",
      "D grad l2-norm: 0.776025756316756, value max: 0.49463632702827454\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.210s / 5 iters, (0.042)\tData load 0.034s / 5 iters, (0.006713)\n",
      "Loss_D = 1.19329906 (ave = 1.17205343)\n",
      "Loss_G = 0.68436313 (ave = 0.68332551)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9772465378753847, value max: 0.04335467889904976\n",
      "D grad l2-norm: 0.7846731477022574, value max: 0.49557435512542725\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.220s / 5 iters, (0.044)\tData load 0.054s / 5 iters, (0.010725)\n",
      "Loss_D = 1.17650342 (ave = 1.16247263)\n",
      "Loss_G = 0.68489575 (ave = 0.68373885)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9884953144582251, value max: 0.04413090646266937\n",
      "D grad l2-norm: 0.7935027958673051, value max: 0.49583762884140015\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.008s / 5 iters, (0.001500)\n",
      "Loss_D = 1.15061879 (ave = 1.15110123)\n",
      "Loss_G = 0.68765724 (ave = 0.68562992)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9818577794748073, value max: 0.043650466948747635\n",
      "D grad l2-norm: 0.8006768132572071, value max: 0.49723342061042786\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.757s / 5 iters, (0.351)\tData load 1.576s / 5 iters, (0.315231)\n",
      "Loss_D = 1.14962530 (ave = 1.14369709)\n",
      "Loss_G = 0.68703270 (ave = 0.68611919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9872258491471485, value max: 0.040300097316503525\n",
      "D grad l2-norm: 0.8121633527839648, value max: 0.49690866470336914\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.220s / 5 iters, (0.044)\tData load 0.016s / 5 iters, (0.003235)\n",
      "Loss_D = 1.13856888 (ave = 1.13495142)\n",
      "Loss_G = 0.68654317 (ave = 0.68704277)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9863546835616961, value max: 0.05281735956668854\n",
      "D grad l2-norm: 0.823765185115431, value max: 0.49666112661361694\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.172s / 5 iters, (0.034)\tData load 0.031s / 5 iters, (0.006251)\n",
      "Loss_D = 1.11288130 (ave = 1.12406945)\n",
      "Loss_G = 0.68971556 (ave = 0.68845420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9942862815546959, value max: 0.04868369549512863\n",
      "D grad l2-norm: 0.8330180014358038, value max: 0.49826014041900635\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 5 iters, (0.025)\tData load 0.008s / 5 iters, (0.001568)\n",
      "Loss_D = 1.11267483 (ave = 1.11666763)\n",
      "Loss_G = 0.69248307 (ave = 0.69117929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9922441714771537, value max: 0.049522336572408676\n",
      "D grad l2-norm: 0.8466235468958758, value max: 0.4996388554573059\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.031s / 5 iters, (0.006238)\n",
      "Loss_D = 1.10869205 (ave = 1.10903330)\n",
      "Loss_G = 0.69292259 (ave = 0.69270015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9912087103667799, value max: 0.04804039001464844\n",
      "D grad l2-norm: 0.8575047277592881, value max: 0.49985644221305847\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.021s / 5 iters, (0.004118)\n",
      "Loss_D = 1.10021853 (ave = 1.10050054)\n",
      "Loss_G = 0.69543898 (ave = 0.69524797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0033898060313842, value max: 0.04847050458192825\n",
      "D grad l2-norm: 0.8681347167506943, value max: 0.5011064410209656\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.182s / 5 iters, (0.036)\tData load 0.025s / 5 iters, (0.005046)\n",
      "Loss_D = 1.08057451 (ave = 1.09054756)\n",
      "Loss_G = 0.69839811 (ave = 0.69838338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0045107050431983, value max: 0.04973646625876427\n",
      "D grad l2-norm: 0.878699092644146, value max: 0.5025847554206848\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.182s / 5 iters, (0.036)\tData load 0.029s / 5 iters, (0.005846)\n",
      "Loss_D = 1.08741808 (ave = 1.08482456)\n",
      "Loss_G = 0.70333660 (ave = 0.70111716)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0001849231339466, value max: 0.05052098259329796\n",
      "D grad l2-norm: 0.8892053092868959, value max: 0.5050235986709595\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003488)\n",
      "Loss_D = 1.07966447 (ave = 1.07662542)\n",
      "Loss_G = 0.70598686 (ave = 0.70464685)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0071778579932593, value max: 0.05339335277676582\n",
      "D grad l2-norm: 0.9063528021960852, value max: 0.5063328742980957\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.017s / 5 iters, (0.003415)\n",
      "Loss_D = 1.07221317 (ave = 1.06729712)\n",
      "Loss_G = 0.71005279 (ave = 0.70873533)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.012628243829626, value max: 0.04379068687558174\n",
      "D grad l2-norm: 0.9244323380189006, value max: 0.508332371711731\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.924s / 5 iters, (0.385)\tData load 1.770s / 5 iters, (0.353902)\n",
      "Loss_D = 1.04493260 (ave = 1.05566356)\n",
      "Loss_G = 0.71413797 (ave = 0.71197618)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0121698623669946, value max: 0.04540865495800972\n",
      "D grad l2-norm: 0.9377377417127833, value max: 0.5103367567062378\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.195s / 5 iters, (0.039)\tData load 0.033s / 5 iters, (0.006543)\n",
      "Loss_D = 1.05712199 (ave = 1.04878953)\n",
      "Loss_G = 0.72129977 (ave = 0.71849382)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0106890038901337, value max: 0.052844978868961334\n",
      "D grad l2-norm: 0.9569810915746331, value max: 0.5138258337974548\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.239s / 5 iters, (0.048)\tData load 0.028s / 5 iters, (0.005564)\n",
      "Loss_D = 1.02341914 (ave = 1.03615065)\n",
      "Loss_G = 0.72645390 (ave = 0.72422338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0166112001552212, value max: 0.0515889935195446\n",
      "D grad l2-norm: 0.977064741898045, value max: 0.5163313746452332\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.245s / 5 iters, (0.049)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 1.04021549 (ave = 1.02969408)\n",
      "Loss_G = 0.73578322 (ave = 0.73105719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0158672595185378, value max: 0.05889807268977165\n",
      "D grad l2-norm: 0.994866912690355, value max: 0.5208204984664917\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.223s / 5 iters, (0.045)\tData load 0.047s / 5 iters, (0.009480)\n",
      "Loss_D = 1.04209566 (ave = 1.02007048)\n",
      "Loss_G = 0.73964477 (ave = 0.73658617)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0190921432021975, value max: 0.05600426346063614\n",
      "D grad l2-norm: 1.0259326048005704, value max: 0.5226664543151855\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.210s / 5 iters, (0.042)\tData load 0.046s / 5 iters, (0.009164)\n",
      "Loss_D = 1.00120449 (ave = 1.00448440)\n",
      "Loss_G = 0.74885881 (ave = 0.74478873)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0169697318499176, value max: 0.05747609958052635\n",
      "D grad l2-norm: 1.051546863744754, value max: 0.5270379781723022\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.145s / 5 iters, (0.029)\tData load 0.008s / 5 iters, (0.001572)\n",
      "Loss_D = 0.95547986 (ave = 0.98673460)\n",
      "Loss_G = 0.75678486 (ave = 0.75518503)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0259918155138856, value max: 0.056118838489055634\n",
      "D grad l2-norm: 1.0863888368797472, value max: 0.5307818055152893\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.143s / 5 iters, (0.029)\tData load 0.016s / 5 iters, (0.003231)\n",
      "Loss_D = 0.97413504 (ave = 0.97704360)\n",
      "Loss_G = 0.76984388 (ave = 0.76678970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.022246742270075, value max: 0.05936635658144951\n",
      "D grad l2-norm: 1.102950163436271, value max: 0.5368619561195374\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 5 iters, (0.027)\tData load 0.025s / 5 iters, (0.005081)\n",
      "Loss_D = 0.96971405 (ave = 0.96304046)\n",
      "Loss_G = 0.78448564 (ave = 0.77936739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.02426681917382, value max: 0.06115342304110527\n",
      "D grad l2-norm: 1.1364548337516267, value max: 0.5436047911643982\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 5 iters, (0.027)\tData load 0.025s / 5 iters, (0.004921)\n",
      "Loss_D = 0.92739105 (ave = 0.94349679)\n",
      "Loss_G = 0.79747558 (ave = 0.79291399)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0335942347133893, value max: 0.06386339664459229\n",
      "D grad l2-norm: 1.169154130418271, value max: 0.5494875311851501\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.550s / 5 iters, (0.310)\tData load 1.449s / 5 iters, (0.289818)\n",
      "Loss_D = 0.94290912 (ave = 0.93268650)\n",
      "Loss_G = 0.80852306 (ave = 0.80584792)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0473881961377092, value max: 0.06509716808795929\n",
      "D grad l2-norm: 1.2017465239884848, value max: 0.554423451423645\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.018s / 5 iters, (0.003540)\n",
      "Loss_D = 0.87375844 (ave = 0.91126984)\n",
      "Loss_G = 0.82539499 (ave = 0.81918591)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.061732026326324, value max: 0.07272006571292877\n",
      "D grad l2-norm: 1.2359220695877673, value max: 0.5618721842765808\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 5 iters, (0.024)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.89126325 (ave = 0.90103511)\n",
      "Loss_G = 0.83482426 (ave = 0.82934182)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.093901803821808, value max: 0.08902247995138168\n",
      "D grad l2-norm: 1.2568790363569478, value max: 0.5659738779067993\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.035s / 5 iters, (0.007057)\n",
      "Loss_D = 0.86353278 (ave = 0.88804541)\n",
      "Loss_G = 0.84141582 (ave = 0.83632160)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1300689633897327, value max: 0.10035164654254913\n",
      "D grad l2-norm: 1.2970717424442761, value max: 0.568798840045929\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.019s / 5 iters, (0.003861)\n",
      "Loss_D = 0.86411297 (ave = 0.88043597)\n",
      "Loss_G = 0.84906763 (ave = 0.84311917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1603026062394834, value max: 0.12316858023405075\n",
      "D grad l2-norm: 1.3209208419438316, value max: 0.5720726251602173\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.171s / 5 iters, (0.034)\tData load 0.017s / 5 iters, (0.003394)\n",
      "Loss_D = 0.88061351 (ave = 0.87743320)\n",
      "Loss_G = 0.85524279 (ave = 0.85113983)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1808453940814854, value max: 0.1453688144683838\n",
      "D grad l2-norm: 1.363971716438341, value max: 0.5746869444847107\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.230s / 5 iters, (0.046)\tData load 0.022s / 5 iters, (0.004430)\n",
      "Loss_D = 0.84469742 (ave = 0.86523669)\n",
      "Loss_G = 0.85866785 (ave = 0.85704170)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1841256953933563, value max: 0.14095580577850342\n",
      "D grad l2-norm: 1.4028186582612787, value max: 0.5761531591415405\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.213s / 5 iters, (0.043)\tData load 0.027s / 5 iters, (0.005424)\n",
      "Loss_D = 0.84955060 (ave = 0.85777467)\n",
      "Loss_G = 0.87000775 (ave = 0.86523064)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1848140082813432, value max: 0.14572221040725708\n",
      "D grad l2-norm: 1.4280516266296837, value max: 0.5809066891670227\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.174s / 5 iters, (0.035)\tData load 0.016s / 5 iters, (0.003177)\n",
      "Loss_D = 0.84596121 (ave = 0.84863932)\n",
      "Loss_G = 0.88151705 (ave = 0.87786976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.18882148356143, value max: 0.14496871829032898\n",
      "D grad l2-norm: 1.4667914778712245, value max: 0.585731565952301\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.202s / 5 iters, (0.040)\tData load 0.020s / 5 iters, (0.004068)\n",
      "Loss_D = 0.85286748 (ave = 0.84031150)\n",
      "Loss_G = 0.89283460 (ave = 0.88848398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1989142174199134, value max: 0.14729245007038116\n",
      "D grad l2-norm: 1.494440241789157, value max: 0.5903634428977966\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.459s / 5 iters, (0.292)\tData load 1.410s / 5 iters, (0.281962)\n",
      "Loss_D = 0.83980268 (ave = 0.82785847)\n",
      "Loss_G = 0.91059011 (ave = 0.90338624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2077631185450926, value max: 0.13780894875526428\n",
      "D grad l2-norm: 1.5422146293559449, value max: 0.5976033210754395\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.163s / 5 iters, (0.033)\tData load 0.012s / 5 iters, (0.002351)\n",
      "Loss_D = 0.83088219 (ave = 0.81643292)\n",
      "Loss_G = 0.92258173 (ave = 0.91726438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2243258538453758, value max: 0.14588478207588196\n",
      "D grad l2-norm: 1.582228047451851, value max: 0.602332592010498\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.018s / 5 iters, (0.003573)\n",
      "Loss_D = 0.82641411 (ave = 0.80607797)\n",
      "Loss_G = 0.93242723 (ave = 0.92791815)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2391684202683442, value max: 0.13284258544445038\n",
      "D grad l2-norm: 1.6134688054228332, value max: 0.6062470078468323\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 5 iters, (0.024)\tData load 0.024s / 5 iters, (0.004861)\n",
      "Loss_D = 0.80090249 (ave = 0.79290397)\n",
      "Loss_G = 0.93846983 (ave = 0.93743833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2455122385497934, value max: 0.13378089666366577\n",
      "D grad l2-norm: 1.6179224867050828, value max: 0.6086259484291077\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.025s / 5 iters, (0.005080)\n",
      "Loss_D = 0.75666761 (ave = 0.77883177)\n",
      "Loss_G = 0.95072460 (ave = 0.94762557)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:29:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2614378794443981, value max: 0.12147603929042816\n",
      "D grad l2-norm: 1.653145545005839, value max: 0.6134263277053833\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.016s / 5 iters, (0.003278)\n",
      "Loss_D = 0.74494147 (ave = 0.77112384)\n",
      "Loss_G = 0.96173143 (ave = 0.95551816)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.267760257496698, value max: 0.12437754124403\n",
      "D grad l2-norm: 1.6742925970642626, value max: 0.6176285147666931\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.138s / 5 iters, (0.028)\tData load 0.048s / 5 iters, (0.009525)\n",
      "Loss_D = 0.73576713 (ave = 0.76264148)\n",
      "Loss_G = 0.96500850 (ave = 0.96197207)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2873440768558553, value max: 0.1293543428182602\n",
      "D grad l2-norm: 1.6932051898704001, value max: 0.6188903450965881\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.164s / 5 iters, (0.033)\tData load 0.018s / 5 iters, (0.003565)\n",
      "Loss_D = 0.74657267 (ave = 0.75871723)\n",
      "Loss_G = 0.97000480 (ave = 0.96984414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3182133042787911, value max: 0.14313457906246185\n",
      "D grad l2-norm: 1.7202475506270478, value max: 0.620723307132721\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.247s / 5 iters, (0.049)\tData load 0.035s / 5 iters, (0.006910)\n",
      "Loss_D = 0.76734006 (ave = 0.75837632)\n",
      "Loss_G = 0.97232324 (ave = 0.97359945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3480765341845986, value max: 0.15199534595012665\n",
      "D grad l2-norm: 1.7329655984886054, value max: 0.6216307878494263\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004573)\n",
      "Loss_D = 0.75208986 (ave = 0.75371493)\n",
      "Loss_G = 0.97486734 (ave = 0.97314917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3981159196405515, value max: 0.17776165902614594\n",
      "D grad l2-norm: 1.7417710637289323, value max: 0.6225045323371887\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.819s / 5 iters, (0.364)\tData load 1.627s / 5 iters, (0.325472)\n",
      "Loss_D = 0.75293964 (ave = 0.75545598)\n",
      "Loss_G = 0.95767981 (ave = 0.96727844)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4808280140630925, value max: 0.2131342887878418\n",
      "D grad l2-norm: 1.738083220047601, value max: 0.6159064769744873\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.228s / 5 iters, (0.046)\tData load 0.030s / 5 iters, (0.005923)\n",
      "Loss_D = 0.79976356 (ave = 0.76695610)\n",
      "Loss_G = 0.94175899 (ave = 0.95324626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5891486235456957, value max: 0.2399507761001587\n",
      "D grad l2-norm: 1.7641724519824005, value max: 0.6097319722175598\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.249s / 5 iters, (0.050)\tData load 0.012s / 5 iters, (0.002487)\n",
      "Loss_D = 0.76736760 (ave = 0.77595539)\n",
      "Loss_G = 0.92126596 (ave = 0.93485733)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6706408712643133, value max: 0.2523668706417084\n",
      "D grad l2-norm: 1.7577627336658947, value max: 0.6014379858970642\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.023s / 5 iters, (0.004597)\n",
      "Loss_D = 0.75046861 (ave = 0.79122330)\n",
      "Loss_G = 0.90352559 (ave = 0.90805358)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7155011410612218, value max: 0.27347543835639954\n",
      "D grad l2-norm: 1.7516217072950688, value max: 0.5942925214767456\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.017s / 5 iters, (0.003301)\n",
      "Loss_D = 0.81841433 (ave = 0.81773981)\n",
      "Loss_G = 0.87055206 (ave = 0.88042998)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7673778917596843, value max: 0.2747405767440796\n",
      "D grad l2-norm: 1.7589462715369708, value max: 0.5808315277099609\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.140s / 5 iters, (0.028)\tData load 0.035s / 5 iters, (0.007054)\n",
      "Loss_D = 0.93411863 (ave = 0.85753139)\n",
      "Loss_G = 0.84606546 (ave = 0.84931171)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8084237389727564, value max: 0.2731502652168274\n",
      "D grad l2-norm: 1.7935032597859912, value max: 0.5701910853385925\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.018s / 5 iters, (0.003672)\n",
      "Loss_D = 0.83879948 (ave = 0.86868473)\n",
      "Loss_G = 0.81278443 (ave = 0.82375354)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.860585140257837, value max: 0.27792689204216003\n",
      "D grad l2-norm: 1.8009707151086307, value max: 0.5553273558616638\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.018s / 5 iters, (0.003511)\n",
      "Loss_D = 0.92005420 (ave = 0.89849486)\n",
      "Loss_G = 0.80094969 (ave = 0.81075475)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9037055684223287, value max: 0.27345865964889526\n",
      "D grad l2-norm: 1.8478642846350088, value max: 0.5498932600021362\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 0.97960085 (ave = 0.92236971)\n",
      "Loss_G = 0.80684751 (ave = 0.80813806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9329104449759482, value max: 0.27879685163497925\n",
      "D grad l2-norm: 1.8727029242365438, value max: 0.5522855520248413\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.89025450 (ave = 0.92611655)\n",
      "Loss_G = 0.79070741 (ave = 0.79153944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0405514740134687, value max: 0.2835787832736969\n",
      "D grad l2-norm: 1.9429947568762853, value max: 0.5448991656303406\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.603s / 5 iters, (0.321)\tData load 1.481s / 5 iters, (0.296112)\n",
      "Loss_D = 0.90480030 (ave = 0.94552519)\n",
      "Loss_G = 0.78716582 (ave = 0.78467075)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.124151312619449, value max: 0.2783982455730438\n",
      "D grad l2-norm: 2.065416056557266, value max: 0.5428889989852905\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.023s / 5 iters, (0.004633)\n",
      "Loss_D = 0.99306750 (ave = 0.96728451)\n",
      "Loss_G = 0.79910862 (ave = 0.79402926)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.156691689215461, value max: 0.27209946513175964\n",
      "D grad l2-norm: 2.167292014310376, value max: 0.5484104156494141\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.145s / 5 iters, (0.029)\tData load 0.025s / 5 iters, (0.005010)\n",
      "Loss_D = 0.96116638 (ave = 0.95147514)\n",
      "Loss_G = 0.83385116 (ave = 0.81083003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1794983040202207, value max: 0.26206836104393005\n",
      "D grad l2-norm: 2.295967888174476, value max: 0.5640368461608887\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.008s / 5 iters, (0.001525)\n",
      "Loss_D = 0.88715285 (ave = 0.93875517)\n",
      "Loss_G = 0.83953887 (ave = 0.83498303)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2275021475970456, value max: 0.2370327115058899\n",
      "D grad l2-norm: 2.4863207688975137, value max: 0.5663279294967651\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.200s / 5 iters, (0.040)\tData load 0.015s / 5 iters, (0.003053)\n",
      "Loss_D = 0.92466211 (ave = 0.91597310)\n",
      "Loss_G = 0.90007031 (ave = 0.88913509)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.251497847621888, value max: 0.22009293735027313\n",
      "D grad l2-norm: 2.655390716585408, value max: 0.5921855568885803\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.213s / 5 iters, (0.043)\tData load 0.051s / 5 iters, (0.010146)\n",
      "Loss_D = 0.87998962 (ave = 0.88723611)\n",
      "Loss_G = 0.95309377 (ave = 0.93532658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.26436373669027, value max: 0.21566715836524963\n",
      "D grad l2-norm: 2.77946741021552, value max: 0.6130159497261047\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.178s / 5 iters, (0.036)\tData load 0.018s / 5 iters, (0.003667)\n",
      "Loss_D = 0.80714977 (ave = 0.84669018)\n",
      "Loss_G = 1.00551689 (ave = 0.98654673)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3294702532049008, value max: 0.19926679134368896\n",
      "D grad l2-norm: 2.976782901735813, value max: 0.6329440474510193\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.197s / 5 iters, (0.039)\tData load 0.024s / 5 iters, (0.004766)\n",
      "Loss_D = 0.84456730 (ave = 0.82420311)\n",
      "Loss_G = 1.05050278 (ave = 1.03697324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.42646459982415, value max: 0.21814380586147308\n",
      "D grad l2-norm: 3.130802952839455, value max: 0.6490787863731384\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.208s / 5 iters, (0.042)\tData load 0.043s / 5 iters, (0.008602)\n",
      "Loss_D = 0.84815955 (ave = 0.80383147)\n",
      "Loss_G = 1.08317137 (ave = 1.07318225)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6130448915870166, value max: 0.24877077341079712\n",
      "D grad l2-norm: 3.3482272750083606, value max: 0.6603050231933594\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.226s / 5 iters, (0.045)\tData load 0.017s / 5 iters, (0.003402)\n",
      "Loss_D = 0.68156517 (ave = 0.76512407)\n",
      "Loss_G = 1.13370752 (ave = 1.11426828)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.689704021999763, value max: 0.2568199336528778\n",
      "D grad l2-norm: 3.460657823253008, value max: 0.6770644783973694\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.589s / 5 iters, (0.318)\tData load 1.486s / 5 iters, (0.297163)\n",
      "Loss_D = 0.75001562 (ave = 0.75148220)\n",
      "Loss_G = 1.16156137 (ave = 1.14782939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.797727583202837, value max: 0.28988420963287354\n",
      "D grad l2-norm: 3.5942682518964584, value max: 0.6859815716743469\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 5 iters, (0.025)\tData load 0.021s / 5 iters, (0.004234)\n",
      "Loss_D = 0.62544185 (ave = 0.72023627)\n",
      "Loss_G = 1.18066561 (ave = 1.17335711)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.030669470134411, value max: 0.3108173608779907\n",
      "D grad l2-norm: 3.8481924307457724, value max: 0.6919375658035278\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.144s / 5 iters, (0.029)\tData load 0.025s / 5 iters, (0.005004)\n",
      "Loss_D = 0.65120614 (ave = 0.70511009)\n",
      "Loss_G = 1.20978403 (ave = 1.20379188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2103904943563477, value max: 0.33585238456726074\n",
      "D grad l2-norm: 3.9793339575885955, value max: 0.7006008625030518\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.159s / 5 iters, (0.032)\tData load 0.026s / 5 iters, (0.005105)\n",
      "Loss_D = 0.70039725 (ave = 0.70466607)\n",
      "Loss_G = 1.22722352 (ave = 1.22014408)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.276585185734276, value max: 0.33778536319732666\n",
      "D grad l2-norm: 4.0476994257916, value max: 0.7059018611907959\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.179s / 5 iters, (0.036)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 0.65372211 (ave = 0.68625376)\n",
      "Loss_G = 1.22196782 (ave = 1.23197124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.3257760333835433, value max: 0.3399467468261719\n",
      "D grad l2-norm: 4.107842225889226, value max: 0.7041417360305786\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.256s / 5 iters, (0.051)\tData load 0.035s / 5 iters, (0.007053)\n",
      "Loss_D = 0.66685283 (ave = 0.67260222)\n",
      "Loss_G = 1.25658071 (ave = 1.25650518)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.484201050108422, value max: 0.3255961835384369\n",
      "D grad l2-norm: 4.332810046188416, value max: 0.7141643762588501\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.015s / 5 iters, (0.003016)\n",
      "Loss_D = 0.58193237 (ave = 0.64821981)\n",
      "Loss_G = 1.27657616 (ave = 1.26851966)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.616767085619623, value max: 0.32380393147468567\n",
      "D grad l2-norm: 4.393431405448976, value max: 0.7194919586181641\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.017s / 5 iters, (0.003305)\n",
      "Loss_D = 0.68070602 (ave = 0.65312893)\n",
      "Loss_G = 1.29385245 (ave = 1.28997235)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7795564712068215, value max: 0.34996122121810913\n",
      "D grad l2-norm: 4.50866412336512, value max: 0.7240882515907288\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.025s / 5 iters, (0.004965)\n",
      "Loss_D = 0.61196965 (ave = 0.64144531)\n",
      "Loss_G = 1.28829873 (ave = 1.28494914)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.017304921689633, value max: 0.35843050479888916\n",
      "D grad l2-norm: 4.706403897818643, value max: 0.7221840620040894\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.017s / 5 iters, (0.003420)\n",
      "Loss_D = 0.70589316 (ave = 0.65233802)\n",
      "Loss_G = 1.29122341 (ave = 1.28561144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.116933028500447, value max: 0.3649008870124817\n",
      "D grad l2-norm: 4.656016545084993, value max: 0.7236906886100769\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 2.033s / 5 iters, (0.407)\tData load 1.789s / 5 iters, (0.357763)\n",
      "Loss_D = 0.62178373 (ave = 0.64523306)\n",
      "Loss_G = 1.24633694 (ave = 1.26875415)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.486866815218177, value max: 0.3693810999393463\n",
      "D grad l2-norm: 4.806487734386477, value max: 0.7107625603675842\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.166s / 5 iters, (0.033)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.65447688 (ave = 0.66545845)\n",
      "Loss_G = 1.21925092 (ave = 1.23385549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.4295068104572115, value max: 0.3836136758327484\n",
      "D grad l2-norm: 4.703834260840397, value max: 0.7025564312934875\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.026s / 5 iters, (0.005266)\n",
      "Loss_D = 0.70071018 (ave = 0.68240268)\n",
      "Loss_G = 1.23857331 (ave = 1.23202329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.544531750499048, value max: 0.4001564383506775\n",
      "D grad l2-norm: 4.924492160938061, value max: 0.7076764702796936\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001839)\n",
      "Loss_D = 0.67688310 (ave = 0.67204666)\n",
      "Loss_G = 1.25491762 (ave = 1.23859088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.497188810808147, value max: 0.40442484617233276\n",
      "D grad l2-norm: 4.980021515536464, value max: 0.7124258279800415\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.010s / 5 iters, (0.001964)\n",
      "Loss_D = 0.65703833 (ave = 0.66899849)\n",
      "Loss_G = 1.27897334 (ave = 1.26366978)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.646676971119337, value max: 0.4592794179916382\n",
      "D grad l2-norm: 5.195820251502878, value max: 0.7195168137550354\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.148s / 5 iters, (0.030)\tData load 0.011s / 5 iters, (0.002161)\n",
      "Loss_D = 0.69890863 (ave = 0.66252589)\n",
      "Loss_G = 1.30987585 (ave = 1.30054858)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.740308475068903, value max: 0.4934738576412201\n",
      "D grad l2-norm: 5.36258266508881, value max: 0.7275555729866028\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.161s / 5 iters, (0.032)\tData load 0.030s / 5 iters, (0.006066)\n",
      "Loss_D = 0.62206757 (ave = 0.64142137)\n",
      "Loss_G = 1.34836030 (ave = 1.33548231)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.922728034908558, value max: 0.5181403756141663\n",
      "D grad l2-norm: 5.595290367753776, value max: 0.7382558584213257\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.171s / 5 iters, (0.034)\tData load 0.019s / 5 iters, (0.003734)\n",
      "Loss_D = 0.62190890 (ave = 0.63401976)\n",
      "Loss_G = 1.38163090 (ave = 1.36966410)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.030377964441191, value max: 0.5325255393981934\n",
      "D grad l2-norm: 5.786990947745123, value max: 0.7471433877944946\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 5 iters, (0.023)\tData load 0.009s / 5 iters, (0.001712)\n",
      "Loss_D = 0.58987403 (ave = 0.62664670)\n",
      "Loss_G = 1.40241015 (ave = 1.40231726)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.24571881120885, value max: 0.562458336353302\n",
      "D grad l2-norm: 5.97749966269664, value max: 0.7520344257354736\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.179s / 5 iters, (0.036)\tData load 0.021s / 5 iters, (0.004186)\n",
      "Loss_D = 0.67744946 (ave = 0.63157556)\n",
      "Loss_G = 1.41598356 (ave = 1.42230911)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.380773288231753, value max: 0.5768589377403259\n",
      "D grad l2-norm: 6.054617066659196, value max: 0.7548983693122864\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 2.148s / 5 iters, (0.430)\tData load 1.965s / 5 iters, (0.392928)\n",
      "Loss_D = 0.71671128 (ave = 0.64724525)\n",
      "Loss_G = 1.40072739 (ave = 1.40982823)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.478178328043655, value max: 0.6188047528266907\n",
      "D grad l2-norm: 6.01110502447649, value max: 0.7505201101303101\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.174s / 5 iters, (0.035)\tData load 0.033s / 5 iters, (0.006642)\n",
      "Loss_D = 0.80583382 (ave = 0.67353528)\n",
      "Loss_G = 1.35012293 (ave = 1.38443768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.823814831779942, value max: 0.6287274956703186\n",
      "D grad l2-norm: 6.099107389485209, value max: 0.7371511459350586\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.202s / 5 iters, (0.040)\tData load 0.024s / 5 iters, (0.004706)\n",
      "Loss_D = 0.71853089 (ave = 0.69075381)\n",
      "Loss_G = 1.32440329 (ave = 1.34754634)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.702313042485075, value max: 0.6231496334075928\n",
      "D grad l2-norm: 5.916831265908839, value max: 0.7307552695274353\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.199s / 5 iters, (0.040)\tData load 0.063s / 5 iters, (0.012653)\n",
      "Loss_D = 0.59030813 (ave = 0.69947443)\n",
      "Loss_G = 1.28900862 (ave = 1.30222657)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.961983134340583, value max: 0.6073921918869019\n",
      "D grad l2-norm: 5.996842897757171, value max: 0.7206922769546509\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.272s / 5 iters, (0.054)\tData load 0.049s / 5 iters, (0.009794)\n",
      "Loss_D = 0.80458272 (ave = 0.75852469)\n",
      "Loss_G = 1.25824261 (ave = 1.26235833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.026570021508006, value max: 0.6020094156265259\n",
      "D grad l2-norm: 5.86634156907053, value max: 0.712809681892395\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.010s / 5 iters, (0.002066)\n",
      "Loss_D = 0.87033617 (ave = 0.81685995)\n",
      "Loss_G = 1.17829192 (ave = 1.19337142)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.461125162515888, value max: 0.6162083745002747\n",
      "D grad l2-norm: 5.825228849420812, value max: 0.6863195896148682\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003387)\n",
      "Loss_D = 0.87929690 (ave = 0.88061314)\n",
      "Loss_G = 1.09400773 (ave = 1.13011363)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.620258071056351, value max: 0.5856872200965881\n",
      "D grad l2-norm: 5.821850131926637, value max: 0.6586351990699768\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001506)\n",
      "Loss_D = 0.99536359 (ave = 0.94538754)\n",
      "Loss_G = 1.08542502 (ave = 1.09720738)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.708952624188238, value max: 0.5683416128158569\n",
      "D grad l2-norm: 5.89950821249848, value max: 0.6560553908348083\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 5 iters, (0.024)\tData load 0.014s / 5 iters, (0.002898)\n",
      "Loss_D = 0.92699492 (ave = 0.98084644)\n",
      "Loss_G = 1.06280375 (ave = 1.05285549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.7181758090993995, value max: 0.6129323840141296\n",
      "D grad l2-norm: 5.923417483136871, value max: 0.6477428674697876\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.214s / 5 iters, (0.043)\tData load 0.044s / 5 iters, (0.008747)\n",
      "Loss_D = 1.04164505 (ave = 1.02190759)\n",
      "Loss_G = 1.06489539 (ave = 1.06351256)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.602314121027017, value max: 0.6041010022163391\n",
      "D grad l2-norm: 6.028720350359866, value max: 0.6507205367088318\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.488s / 5 iters, (0.298)\tData load 1.374s / 5 iters, (0.274787)\n",
      "Loss_D = 1.01228404 (ave = 1.02538104)\n",
      "Loss_G = 1.06422830 (ave = 1.06487148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.740222080887213, value max: 0.5997090339660645\n",
      "D grad l2-norm: 6.181579117668107, value max: 0.6487398147583008\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.016s / 5 iters, (0.003168)\n",
      "Loss_D = 1.03957033 (ave = 1.03141329)\n",
      "Loss_G = 1.08502054 (ave = 1.08379886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.8531193545719775, value max: 0.6128790378570557\n",
      "D grad l2-norm: 6.323731135860852, value max: 0.6562924385070801\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 5 iters, (0.024)\tData load 0.008s / 5 iters, (0.001522)\n",
      "Loss_D = 1.14100909 (ave = 1.06035936)\n",
      "Loss_G = 1.13495040 (ave = 1.11037297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.106812914253079, value max: 0.6116386651992798\n",
      "D grad l2-norm: 6.684170671367408, value max: 0.6715850234031677\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.014s / 5 iters, (0.002842)\n",
      "Loss_D = 0.73742247 (ave = 1.00186157)\n",
      "Loss_G = 1.16110635 (ave = 1.14899180)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.225793021044527, value max: 0.6323650479316711\n",
      "D grad l2-norm: 6.854338461375375, value max: 0.6793896555900574\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.178s / 5 iters, (0.036)\tData load 0.015s / 5 iters, (0.003048)\n",
      "Loss_D = 1.19230974 (ave = 1.04818577)\n",
      "Loss_G = 1.20015788 (ave = 1.17276654)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.282253819647283, value max: 0.6347501277923584\n",
      "D grad l2-norm: 7.096255713880011, value max: 0.6928112506866455\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.201s / 5 iters, (0.040)\tData load 0.018s / 5 iters, (0.003506)\n",
      "Loss_D = 1.02448010 (ave = 1.02209556)\n",
      "Loss_G = 1.19997668 (ave = 1.19071414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.6592011047757005, value max: 0.6003230214118958\n",
      "D grad l2-norm: 7.531914221555409, value max: 0.7719436287879944\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.189s / 5 iters, (0.038)\tData load 0.032s / 5 iters, (0.006475)\n",
      "Loss_D = 0.78016901 (ave = 0.98489745)\n",
      "Loss_G = 1.20714331 (ave = 1.20194349)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.54369064168747, value max: 0.5728774070739746\n",
      "D grad l2-norm: 7.632972218709506, value max: 0.84869784116745\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.182s / 5 iters, (0.036)\tData load 0.015s / 5 iters, (0.002962)\n",
      "Loss_D = 1.12399960 (ave = 1.01933076)\n",
      "Loss_G = 1.25574994 (ave = 1.25096219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.3167615706745535, value max: 0.5126127600669861\n",
      "D grad l2-norm: 7.780880080223637, value max: 0.9277878403663635\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.161s / 5 iters, (0.032)\tData load 0.021s / 5 iters, (0.004252)\n",
      "Loss_D = 1.07602739 (ave = 0.98888366)\n",
      "Loss_G = 1.27367818 (ave = 1.26584239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.410558219961696, value max: 0.4943321645259857\n",
      "D grad l2-norm: 8.13196072825356, value max: 1.0040552616119385\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.223s / 5 iters, (0.045)\tData load 0.027s / 5 iters, (0.005348)\n",
      "Loss_D = 0.92077911 (ave = 0.94707670)\n",
      "Loss_G = 1.31152046 (ave = 1.31108191)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.503066927549235, value max: 0.48832741379737854\n",
      "D grad l2-norm: 8.225670324401312, value max: 1.0403344631195068\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.426s / 5 iters, (0.285)\tData load 1.333s / 5 iters, (0.266556)\n",
      "Loss_D = 0.85644734 (ave = 0.93521299)\n",
      "Loss_G = 1.34138238 (ave = 1.33205993)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.42439308898281, value max: 0.46578365564346313\n",
      "D grad l2-norm: 8.601267607638142, value max: 1.0947691202163696\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.024s / 5 iters, (0.004817)\n",
      "Loss_D = 1.05789685 (ave = 0.92904476)\n",
      "Loss_G = 1.39982891 (ave = 1.38336110)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.385706428816265, value max: 0.4773540198802948\n",
      "D grad l2-norm: 8.743505340747157, value max: 1.1120517253875732\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001581)\n",
      "Loss_D = 0.97543967 (ave = 0.89835486)\n",
      "Loss_G = 1.45735812 (ave = 1.42309887)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.595717341602148, value max: 0.48247072100639343\n",
      "D grad l2-norm: 8.943121443997263, value max: 1.1361982822418213\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.92415601 (ave = 0.88183674)\n",
      "Loss_G = 1.44832802 (ave = 1.43904250)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.832418325487576, value max: 0.4889996647834778\n",
      "D grad l2-norm: 9.08714119579507, value max: 1.135145664215088\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.16570878 (ave = 0.91151018)\n",
      "Loss_G = 1.44369733 (ave = 1.44439185)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.079228278141361, value max: 0.5333375334739685\n",
      "D grad l2-norm: 9.09326313470078, value max: 1.1095223426818848\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.016s / 5 iters, (0.003234)\n",
      "Loss_D = 0.77205968 (ave = 0.86643957)\n",
      "Loss_G = 1.49980617 (ave = 1.45332401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.351361923019212, value max: 0.5914608836174011\n",
      "D grad l2-norm: 9.43777816032384, value max: 1.1353380680084229\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.023s / 5 iters, (0.004531)\n",
      "Loss_D = 0.77569532 (ave = 0.85947137)\n",
      "Loss_G = 1.49612713 (ave = 1.48076828)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.46724648536445, value max: 0.6010849475860596\n",
      "D grad l2-norm: 9.394515729764127, value max: 1.0888036489486694\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.007s / 5 iters, (0.001430)\n",
      "Loss_D = 0.80071926 (ave = 0.86361083)\n",
      "Loss_G = 1.51446187 (ave = 1.50356662)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.974745909549616, value max: 0.5984169244766235\n",
      "D grad l2-norm: 9.774498307557588, value max: 1.0815316438674927\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.013s / 5 iters, (0.002520)\n",
      "Loss_D = 1.06252992 (ave = 0.90279908)\n",
      "Loss_G = 1.46165955 (ave = 1.49099944)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.03885103705142, value max: 0.6093171834945679\n",
      "D grad l2-norm: 9.678773365655713, value max: 1.0071096420288086\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.143s / 5 iters, (0.029)\tData load 0.027s / 5 iters, (0.005491)\n",
      "Loss_D = 1.02969801 (ave = 0.90849494)\n",
      "Loss_G = 1.48981595 (ave = 1.48127506)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.094414929382028, value max: 0.6221985816955566\n",
      "D grad l2-norm: 9.921087426999376, value max: 0.9959468245506287\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.358s / 5 iters, (0.272)\tData load 1.301s / 5 iters, (0.260161)\n",
      "Loss_D = 0.82062674 (ave = 0.88484203)\n",
      "Loss_G = 1.54402006 (ave = 1.50980868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.027641889944315, value max: 0.6364438533782959\n",
      "D grad l2-norm: 10.135260395265178, value max: 1.0688433647155762\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.011s / 5 iters, (0.002279)\n",
      "Loss_D = 0.84116268 (ave = 0.87436628)\n",
      "Loss_G = 1.58011496 (ave = 1.55298789)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.503338675939874, value max: 0.5864132642745972\n",
      "D grad l2-norm: 10.091561429417801, value max: 1.1146316528320312\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.014s / 5 iters, (0.002844)\n",
      "Loss_D = 1.00644445 (ave = 0.87147630)\n",
      "Loss_G = 1.64002728 (ave = 1.62149279)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.541388521168653, value max: 0.616150438785553\n",
      "D grad l2-norm: 10.40751471017201, value max: 1.1958565711975098\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001731)\n",
      "Loss_D = 0.86416888 (ave = 0.84296567)\n",
      "Loss_G = 1.65191591 (ave = 1.63980727)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.261734899414297, value max: 0.6441176533699036\n",
      "D grad l2-norm: 10.184102930027201, value max: 1.209086298942566\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.139s / 5 iters, (0.028)\tData load 0.017s / 5 iters, (0.003435)\n",
      "Loss_D = 0.99059111 (ave = 0.84801539)\n",
      "Loss_G = 1.68086755 (ave = 1.66646612)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.083720082085204, value max: 0.6648330092430115\n",
      "D grad l2-norm: 10.0682962808095, value max: 1.2147799730300903\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.015s / 5 iters, (0.002967)\n",
      "Loss_D = 0.83742136 (ave = 0.81910250)\n",
      "Loss_G = 1.66608226 (ave = 1.64398744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.808954981810194, value max: 0.6337839961051941\n",
      "D grad l2-norm: 9.733267371010959, value max: 1.179741621017456\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 0.76597244 (ave = 0.80286596)\n",
      "Loss_G = 1.63394403 (ave = 1.64057240)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.793782105802844, value max: 0.6674538254737854\n",
      "D grad l2-norm: 9.546585622087525, value max: 1.1388208866119385\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.203s / 5 iters, (0.041)\tData load 0.030s / 5 iters, (0.005937)\n",
      "Loss_D = 0.73667455 (ave = 0.79339236)\n",
      "Loss_G = 1.66026306 (ave = 1.64626532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.061319934949607, value max: 0.6822336316108704\n",
      "D grad l2-norm: 9.767065484615241, value max: 1.1566212177276611\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.016s / 5 iters, (0.003119)\n",
      "Loss_D = 0.95778763 (ave = 0.82494781)\n",
      "Loss_G = 1.60302913 (ave = 1.60760939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.015198439445216, value max: 0.6895768642425537\n",
      "D grad l2-norm: 9.377903289788472, value max: 1.0722064971923828\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003325)\n",
      "Loss_D = 0.91228688 (ave = 0.82877011)\n",
      "Loss_G = 1.56953311 (ave = 1.57669375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.86239354425957, value max: 0.6630072593688965\n",
      "D grad l2-norm: 9.31582003463575, value max: 1.0378847122192383\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.357s / 5 iters, (0.271)\tData load 1.304s / 5 iters, (0.260718)\n",
      "Loss_D = 0.91151690 (ave = 0.81882026)\n",
      "Loss_G = 1.59344041 (ave = 1.59361422)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.696351528756495, value max: 0.6125208735466003\n",
      "D grad l2-norm: 9.159638633841302, value max: 0.9946773648262024\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.027s / 5 iters, (0.005499)\n",
      "Loss_D = 0.79794389 (ave = 0.78837286)\n",
      "Loss_G = 1.56661999 (ave = 1.57965708)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.15452175883175, value max: 0.6324361562728882\n",
      "D grad l2-norm: 9.311179972728823, value max: 0.9477822780609131\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.182s / 5 iters, (0.036)\tData load 0.016s / 5 iters, (0.003187)\n",
      "Loss_D = 0.72259402 (ave = 0.77867496)\n",
      "Loss_G = 1.61228395 (ave = 1.60807295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.306411063901772, value max: 0.6462739109992981\n",
      "D grad l2-norm: 9.588448663384398, value max: 0.969190776348114\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.204s / 5 iters, (0.041)\tData load 0.018s / 5 iters, (0.003639)\n",
      "Loss_D = 0.89343178 (ave = 0.79075069)\n",
      "Loss_G = 1.63260937 (ave = 1.62219384)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.233407819612403, value max: 0.6032366752624512\n",
      "D grad l2-norm: 9.54966821071222, value max: 0.9635177254676819\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.206s / 5 iters, (0.041)\tData load 0.027s / 5 iters, (0.005389)\n",
      "Loss_D = 0.87809604 (ave = 0.77745055)\n",
      "Loss_G = 1.60305405 (ave = 1.61903744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.603991152368344, value max: 0.589404284954071\n",
      "D grad l2-norm: 9.492610477711027, value max: 0.9381056427955627\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.193s / 5 iters, (0.039)\tData load 0.006s / 5 iters, (0.001279)\n",
      "Loss_D = 0.63964725 (ave = 0.75818838)\n",
      "Loss_G = 1.59355140 (ave = 1.59726679)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.6445459587558, value max: 0.6339864730834961\n",
      "D grad l2-norm: 9.938157750570305, value max: 0.9442698955535889\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.195s / 5 iters, (0.039)\tData load 0.007s / 5 iters, (0.001315)\n",
      "Loss_D = 0.84715265 (ave = 0.79227399)\n",
      "Loss_G = 1.51375723 (ave = 1.55115178)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.84873170158687, value max: 0.7050763964653015\n",
      "D grad l2-norm: 9.841189559625002, value max: 0.9664598107337952\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 5 iters, (0.024)\tData load 0.022s / 5 iters, (0.004428)\n",
      "Loss_D = 0.79618144 (ave = 0.80120933)\n",
      "Loss_G = 1.49089313 (ave = 1.52510331)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.385265715311176, value max: 0.7236701846122742\n",
      "D grad l2-norm: 10.042081871527905, value max: 1.0212903022766113\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.164s / 5 iters, (0.033)\tData load 0.008s / 5 iters, (0.001522)\n",
      "Loss_D = 0.86473382 (ave = 0.82599505)\n",
      "Loss_G = 1.50338435 (ave = 1.49488113)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.23176576069571, value max: 0.6914709210395813\n",
      "D grad l2-norm: 10.119468775332761, value max: 1.0758421421051025\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.211s / 5 iters, (0.042)\tData load 0.048s / 5 iters, (0.009660)\n",
      "Loss_D = 0.69699919 (ave = 0.79269693)\n",
      "Loss_G = 1.58508348 (ave = 1.54183481)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.23474086524222, value max: 0.7014076709747314\n",
      "D grad l2-norm: 10.353974908253226, value max: 1.1393063068389893\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.722s / 5 iters, (0.344)\tData load 1.584s / 5 iters, (0.316827)\n",
      "Loss_D = 0.93932307 (ave = 0.81096621)\n",
      "Loss_G = 1.57933021 (ave = 1.59459484)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.579423201959763, value max: 0.7033039331436157\n",
      "D grad l2-norm: 10.711408175617391, value max: 1.1732299327850342\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.007s / 5 iters, (0.001423)\n",
      "Loss_D = 0.68408740 (ave = 0.76544080)\n",
      "Loss_G = 1.64364421 (ave = 1.62849596)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.12040366594364, value max: 0.7610167264938354\n",
      "D grad l2-norm: 11.295857923832664, value max: 1.2301127910614014\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.177s / 5 iters, (0.035)\tData load 0.035s / 5 iters, (0.007055)\n",
      "Loss_D = 0.63372278 (ave = 0.75280882)\n",
      "Loss_G = 1.70363235 (ave = 1.66071415)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.232406758249102, value max: 0.7755632996559143\n",
      "D grad l2-norm: 11.597789198462905, value max: 1.2618845701217651\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.144s / 5 iters, (0.029)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 0.76838052 (ave = 0.75925077)\n",
      "Loss_G = 1.74827158 (ave = 1.70625865)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.401314778834818, value max: 0.810411274433136\n",
      "D grad l2-norm: 12.054090468279334, value max: 1.347752332687378\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.154s / 5 iters, (0.031)\tData load 0.022s / 5 iters, (0.004390)\n",
      "Loss_D = 0.82124931 (ave = 0.75150019)\n",
      "Loss_G = 1.67732358 (ave = 1.70606894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.892177386451843, value max: 0.7069779634475708\n",
      "D grad l2-norm: 11.824199760429481, value max: 1.3652557134628296\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.016s / 5 iters, (0.003268)\n",
      "Loss_D = 0.59567750 (ave = 0.71619177)\n",
      "Loss_G = 1.75741553 (ave = 1.71111610)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.402130303966894, value max: 0.718427300453186\n",
      "D grad l2-norm: 11.914362188413843, value max: 1.4427722692489624\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.031s / 5 iters, (0.006207)\n",
      "Loss_D = 0.64517558 (ave = 0.70670127)\n",
      "Loss_G = 1.83901715 (ave = 1.81012111)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.30620899967606, value max: 0.6957454681396484\n",
      "D grad l2-norm: 12.178136815853943, value max: 1.5191841125488281\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.016s / 5 iters, (0.003102)\n",
      "Loss_D = 0.55092490 (ave = 0.67964114)\n",
      "Loss_G = 1.77672768 (ave = 1.78681433)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.584581256918426, value max: 0.7296181321144104\n",
      "D grad l2-norm: 12.30289948955879, value max: 1.534641981124878\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.016s / 5 iters, (0.003267)\n",
      "Loss_D = 0.70206201 (ave = 0.69764415)\n",
      "Loss_G = 1.76686561 (ave = 1.78034143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.057542167813285, value max: 0.7958956956863403\n",
      "D grad l2-norm: 12.392066934391607, value max: 1.550473690032959\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.023s / 5 iters, (0.004679)\n",
      "Loss_D = 0.66450202 (ave = 0.70893295)\n",
      "Loss_G = 1.71633697 (ave = 1.74749129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.535681341271982, value max: 0.670258641242981\n",
      "D grad l2-norm: 11.81717746196747, value max: 1.499248743057251\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.852s / 5 iters, (0.370)\tData load 1.756s / 5 iters, (0.351143)\n",
      "Loss_D = 0.76854634 (ave = 0.71262478)\n",
      "Loss_G = 1.71742761 (ave = 1.74085100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.409654894841253, value max: 0.6503621935844421\n",
      "D grad l2-norm: 11.625871987694302, value max: 1.484337568283081\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 5 iters, (0.023)\tData load 0.015s / 5 iters, (0.002955)\n",
      "Loss_D = 0.59988827 (ave = 0.69603649)\n",
      "Loss_G = 1.60792971 (ave = 1.66836193)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.83285515068759, value max: 0.6794065833091736\n",
      "D grad l2-norm: 11.522846815519905, value max: 1.4238619804382324\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.017s / 5 iters, (0.003424)\n",
      "Loss_D = 0.59902894 (ave = 0.71814504)\n",
      "Loss_G = 1.63372469 (ave = 1.61213245)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.860953365075392, value max: 0.6771753430366516\n",
      "D grad l2-norm: 11.415758417665664, value max: 1.4128680229187012\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.152s / 5 iters, (0.030)\tData load 0.050s / 5 iters, (0.010064)\n",
      "Loss_D = 0.68155622 (ave = 0.74878001)\n",
      "Loss_G = 1.56135964 (ave = 1.57447686)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.87638558057951, value max: 0.6906646490097046\n",
      "D grad l2-norm: 10.902199668401495, value max: 1.3023195266723633\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.016s / 5 iters, (0.003145)\n",
      "Loss_D = 0.79182112 (ave = 0.79823847)\n",
      "Loss_G = 1.43996644 (ave = 1.50922706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.182052391089218, value max: 0.6969468593597412\n",
      "D grad l2-norm: 10.627637182027959, value max: 1.1949716806411743\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.188s / 5 iters, (0.038)\tData load 0.019s / 5 iters, (0.003743)\n",
      "Loss_D = 1.02632236 (ave = 0.86255420)\n",
      "Loss_G = 1.37848389 (ave = 1.44486637)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.436508145765753, value max: 0.6539305448532104\n",
      "D grad l2-norm: 10.406153573969549, value max: 1.0950580835342407\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001638)\n",
      "Loss_D = 1.19108427 (ave = 0.93117682)\n",
      "Loss_G = 1.32731009 (ave = 1.36352558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.326654675487186, value max: 0.657866895198822\n",
      "D grad l2-norm: 10.18676715005269, value max: 0.9955775141716003\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001549)\n",
      "Loss_D = 1.11045182 (ave = 0.95310394)\n",
      "Loss_G = 1.29793239 (ave = 1.30290949)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.972404080304388, value max: 0.6038787961006165\n",
      "D grad l2-norm: 9.824706608764272, value max: 0.9691230058670044\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.020s / 5 iters, (0.004023)\n",
      "Loss_D = 1.20475090 (ave = 0.99340039)\n",
      "Loss_G = 1.27807963 (ave = 1.27281015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.108437109849087, value max: 0.6654654741287231\n",
      "D grad l2-norm: 9.861694690860807, value max: 0.9723772406578064\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.026s / 5 iters, (0.005195)\n",
      "Loss_D = 0.95750052 (ave = 0.98720932)\n",
      "Loss_G = 1.28731799 (ave = 1.26660740)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.555186638412804, value max: 0.7071183919906616\n",
      "D grad l2-norm: 9.572815306080754, value max: 0.9277945160865784\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.473s / 5 iters, (0.295)\tData load 1.413s / 5 iters, (0.282693)\n",
      "Loss_D = 0.85317159 (ave = 0.97112963)\n",
      "Loss_G = 1.30515087 (ave = 1.29748645)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.737763769807614, value max: 0.7380843758583069\n",
      "D grad l2-norm: 9.844502302735416, value max: 0.9442545175552368\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.190s / 5 iters, (0.038)\tData load 0.012s / 5 iters, (0.002428)\n",
      "Loss_D = 1.14712381 (ave = 1.01154578)\n",
      "Loss_G = 1.28772318 (ave = 1.29543045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.965608945735704, value max: 0.7162052392959595\n",
      "D grad l2-norm: 9.616166979657681, value max: 0.953039824962616\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.329s / 5 iters, (0.066)\tData load 0.048s / 5 iters, (0.009652)\n",
      "Loss_D = 0.88468748 (ave = 0.96724776)\n",
      "Loss_G = 1.37294364 (ave = 1.36426740)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.167723986962972, value max: 0.7473646998405457\n",
      "D grad l2-norm: 9.95555186788076, value max: 1.0275927782058716\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.175s / 5 iters, (0.035)\tData load 0.034s / 5 iters, (0.006834)\n",
      "Loss_D = 0.81218916 (ave = 0.94865321)\n",
      "Loss_G = 1.39161921 (ave = 1.39089444)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.890030794973015, value max: 0.728935718536377\n",
      "D grad l2-norm: 9.866426641452064, value max: 1.0492767095565796\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.196s / 5 iters, (0.039)\tData load 0.033s / 5 iters, (0.006556)\n",
      "Loss_D = 0.87997329 (ave = 0.94597462)\n",
      "Loss_G = 1.47915411 (ave = 1.43148615)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.89783496529677, value max: 0.7459647059440613\n",
      "D grad l2-norm: 10.2786835900683, value max: 1.1220676898956299\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.187s / 5 iters, (0.037)\tData load 0.041s / 5 iters, (0.008222)\n",
      "Loss_D = 0.87807971 (ave = 0.92778695)\n",
      "Loss_G = 1.50245619 (ave = 1.47321129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.849775887386294, value max: 0.7105773687362671\n",
      "D grad l2-norm: 10.485442338252422, value max: 1.1429606676101685\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.221s / 5 iters, (0.044)\tData load 0.021s / 5 iters, (0.004241)\n",
      "Loss_D = 0.69093168 (ave = 0.88385730)\n",
      "Loss_G = 1.51662362 (ave = 1.52101324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.35137850591978, value max: 0.6549485921859741\n",
      "D grad l2-norm: 10.556009036795533, value max: 1.1394838094711304\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.223s / 5 iters, (0.045)\tData load 0.028s / 5 iters, (0.005565)\n",
      "Loss_D = 0.86858332 (ave = 0.88233727)\n",
      "Loss_G = 1.61739254 (ave = 1.57818398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.10645884913135, value max: 0.6276546120643616\n",
      "D grad l2-norm: 10.900001270640734, value max: 1.1770238876342773\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.230s / 5 iters, (0.046)\tData load 0.023s / 5 iters, (0.004508)\n",
      "Loss_D = 0.96683329 (ave = 0.86297311)\n",
      "Loss_G = 1.72705913 (ave = 1.67704692)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.822065019889163, value max: 0.5937805771827698\n",
      "D grad l2-norm: 10.948210253190762, value max: 1.1821857690811157\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.139s / 5 iters, (0.028)\tData load 0.024s / 5 iters, (0.004813)\n",
      "Loss_D = 0.86403978 (ave = 0.81476128)\n",
      "Loss_G = 1.69540453 (ave = 1.71474299)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.977509978818157, value max: 0.5888227224349976\n",
      "D grad l2-norm: 11.146392024479582, value max: 1.152153491973877\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 2.204s / 5 iters, (0.441)\tData load 2.056s / 5 iters, (0.411197)\n",
      "Loss_D = 0.87828422 (ave = 0.79421375)\n",
      "Loss_G = 1.73492575 (ave = 1.71703405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.173126721196049, value max: 0.57867032289505\n",
      "D grad l2-norm: 11.35157772714054, value max: 1.1401779651641846\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.151s / 5 iters, (0.030)\tData load 0.015s / 5 iters, (0.002999)\n",
      "Loss_D = 0.80102539 (ave = 0.76166794)\n",
      "Loss_G = 1.73289764 (ave = 1.74731314)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.647529491165908, value max: 0.6628885865211487\n",
      "D grad l2-norm: 11.528316372759269, value max: 1.1128132343292236\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 0.72643054 (ave = 0.74522271)\n",
      "Loss_G = 1.73723185 (ave = 1.73735778)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.977514491436503, value max: 0.7402175068855286\n",
      "D grad l2-norm: 11.527520370255063, value max: 1.0682786703109741\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.013s / 5 iters, (0.002551)\n",
      "Loss_D = 0.67871511 (ave = 0.73273138)\n",
      "Loss_G = 1.67961645 (ave = 1.70304062)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.304201441090107, value max: 0.7839153409004211\n",
      "D grad l2-norm: 11.43403469747425, value max: 1.0015912055969238\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.015s / 5 iters, (0.002975)\n",
      "Loss_D = 0.72096193 (ave = 0.73600730)\n",
      "Loss_G = 1.68613958 (ave = 1.70724704)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.244044941906274, value max: 0.7860381603240967\n",
      "D grad l2-norm: 11.103107545257762, value max: 0.9455826878547668\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 0.92159474 (ave = 0.75629888)\n",
      "Loss_G = 1.67555726 (ave = 1.68532124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.460033132544194, value max: 0.8091887831687927\n",
      "D grad l2-norm: 11.27786912072884, value max: 0.9260218143463135\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.014s / 5 iters, (0.002702)\n",
      "Loss_D = 0.92435873 (ave = 0.75552958)\n",
      "Loss_G = 1.62891316 (ave = 1.65627732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.48467775258236, value max: 0.8144566416740417\n",
      "D grad l2-norm: 11.191054417719576, value max: 0.9564364552497864\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.220s / 5 iters, (0.044)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.69848347 (ave = 0.72681029)\n",
      "Loss_G = 1.63760352 (ave = 1.63422947)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.530385370333113, value max: 0.8347256183624268\n",
      "D grad l2-norm: 11.094617070124947, value max: 0.9887780547142029\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.209s / 5 iters, (0.042)\tData load 0.024s / 5 iters, (0.004876)\n",
      "Loss_D = 0.80927706 (ave = 0.74191108)\n",
      "Loss_G = 1.63844550 (ave = 1.62743452)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.715477960777989, value max: 0.7734900116920471\n",
      "D grad l2-norm: 11.222950487578018, value max: 1.0650800466537476\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.194s / 5 iters, (0.039)\tData load 0.016s / 5 iters, (0.003249)\n",
      "Loss_D = 0.75606608 (ave = 0.73601340)\n",
      "Loss_G = 1.64224362 (ave = 1.61983478)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.533515606535337, value max: 0.7292081117630005\n",
      "D grad l2-norm: 11.092200268635242, value max: 1.0928142070770264\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.798s / 5 iters, (0.360)\tData load 1.617s / 5 iters, (0.323315)\n",
      "Loss_D = 0.75602973 (ave = 0.73777961)\n",
      "Loss_G = 1.60115933 (ave = 1.61156666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.155462384265755, value max: 0.6879575848579407\n",
      "D grad l2-norm: 10.832574282692843, value max: 1.1064116954803467\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.016s / 5 iters, (0.003224)\n",
      "Loss_D = 0.54091674 (ave = 0.70215161)\n",
      "Loss_G = 1.56951678 (ave = 1.59074690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.888900335500852, value max: 0.6374490261077881\n",
      "D grad l2-norm: 10.548407434780199, value max: 1.095717191696167\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.024s / 5 iters, (0.004823)\n",
      "Loss_D = 0.79700238 (ave = 0.73407954)\n",
      "Loss_G = 1.62336612 (ave = 1.59236722)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.138009121055209, value max: 0.6862307190895081\n",
      "D grad l2-norm: 10.699656435663115, value max: 1.144102931022644\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.018s / 5 iters, (0.003658)\n",
      "Loss_D = 0.72341430 (ave = 0.72241850)\n",
      "Loss_G = 1.59010041 (ave = 1.56464064)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.065275277060714, value max: 0.6782805323600769\n",
      "D grad l2-norm: 10.39971378497181, value max: 1.1229079961776733\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.142s / 5 iters, (0.028)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 0.71148652 (ave = 0.73731807)\n",
      "Loss_G = 1.56365919 (ave = 1.57032032)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.383414556630877, value max: 0.7293114066123962\n",
      "D grad l2-norm: 10.499300227316109, value max: 1.1238712072372437\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 5 iters, (0.025)\tData load 0.016s / 5 iters, (0.003114)\n",
      "Loss_D = 0.76403964 (ave = 0.73665841)\n",
      "Loss_G = 1.52538955 (ave = 1.56132371)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.157996479754976, value max: 0.7587751150131226\n",
      "D grad l2-norm: 10.123402119988924, value max: 1.0703179836273193\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.181s / 5 iters, (0.036)\tData load 0.036s / 5 iters, (0.007183)\n",
      "Loss_D = 0.58356059 (ave = 0.71747614)\n",
      "Loss_G = 1.52489817 (ave = 1.54030423)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.126159583001476, value max: 0.7490141987800598\n",
      "D grad l2-norm: 10.022826479593506, value max: 1.0605469942092896\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.221s / 5 iters, (0.044)\tData load 0.037s / 5 iters, (0.007376)\n",
      "Loss_D = 0.72560179 (ave = 0.73547308)\n",
      "Loss_G = 1.52461481 (ave = 1.52006743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.877405238605485, value max: 0.748479962348938\n",
      "D grad l2-norm: 9.82821534896978, value max: 1.0311570167541504\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001528)\n",
      "Loss_D = 0.77160180 (ave = 0.73641926)\n",
      "Loss_G = 1.49509537 (ave = 1.51726317)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.916316389191683, value max: 0.746294379234314\n",
      "D grad l2-norm: 9.848747448792276, value max: 0.9880653023719788\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.017s / 5 iters, (0.003356)\n",
      "Loss_D = 0.78516191 (ave = 0.73218112)\n",
      "Loss_G = 1.49229550 (ave = 1.51113055)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.950126012888425, value max: 0.7789194583892822\n",
      "D grad l2-norm: 9.518915192053983, value max: 0.9202134609222412\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 1\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.147s / 5 iters, (0.029)\tData load 0.009s / 5 iters, (0.001875)\n",
      "Loss_D = 1.37065089 (ave = 1.37251027)\n",
      "Loss_G = 0.71140969 (ave = 0.71296521)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9671293693695023, value max: 0.0336315892636776\n",
      "D grad l2-norm: 0.7169404933674108, value max: 0.5090450048446655\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.852s / 5 iters, (0.170)\tData load 0.795s / 5 iters, (0.158920)\n",
      "Loss_D = 1.35256171 (ave = 1.35606728)\n",
      "Loss_G = 0.70823866 (ave = 0.70925714)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9690180898559313, value max: 0.02278381586074829\n",
      "D grad l2-norm: 0.7149401184654693, value max: 0.5074847340583801\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.815s / 5 iters, (0.163)\tData load 0.724s / 5 iters, (0.144773)\n",
      "Loss_D = 1.33926666 (ave = 1.34060071)\n",
      "Loss_G = 0.70483536 (ave = 0.70604796)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9647673969285058, value max: 0.025202065706253052\n",
      "D grad l2-norm: 0.7137361714644425, value max: 0.5058063864707947\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.975s / 5 iters, (0.195)\tData load 0.857s / 5 iters, (0.171333)\n",
      "Loss_D = 1.31831098 (ave = 1.32485242)\n",
      "Loss_G = 0.70250630 (ave = 0.70361139)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9697634716454564, value max: 0.024059932678937912\n",
      "D grad l2-norm: 0.7170176688402051, value max: 0.5046532154083252\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.072s / 5 iters, (0.214)\tData load 0.908s / 5 iters, (0.181631)\n",
      "Loss_D = 1.29556561 (ave = 1.30952535)\n",
      "Loss_G = 0.70001662 (ave = 0.70124648)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9689122069869436, value max: 0.02285161055624485\n",
      "D grad l2-norm: 0.718877089673068, value max: 0.5034180879592896\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.120s / 5 iters, (0.224)\tData load 1.020s / 5 iters, (0.204055)\n",
      "Loss_D = 1.28748798 (ave = 1.29675295)\n",
      "Loss_G = 0.69880837 (ave = 0.69941839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9701041407930856, value max: 0.02887623943388462\n",
      "D grad l2-norm: 0.7193987805075386, value max: 0.5028178095817566\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.873s / 5 iters, (0.175)\tData load 0.749s / 5 iters, (0.149818)\n",
      "Loss_D = 1.30263948 (ave = 1.28739035)\n",
      "Loss_G = 0.69753677 (ave = 0.69821690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9769265916218484, value max: 0.02921372652053833\n",
      "D grad l2-norm: 0.7230491837604144, value max: 0.5021847486495972\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.909s / 5 iters, (0.182)\tData load 0.680s / 5 iters, (0.136034)\n",
      "Loss_D = 1.27062702 (ave = 1.27193775)\n",
      "Loss_G = 0.69633186 (ave = 0.69635087)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9685521352407241, value max: 0.026241114363074303\n",
      "D grad l2-norm: 0.7285889451878892, value max: 0.5015845894813538\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.695s / 5 iters, (0.139)\tData load 0.573s / 5 iters, (0.114691)\n",
      "Loss_D = 1.27524853 (ave = 1.26180735)\n",
      "Loss_G = 0.69499242 (ave = 0.69545553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9712050215354633, value max: 0.024656496942043304\n",
      "D grad l2-norm: 0.7350618917580203, value max: 0.5009147524833679\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.293s / 5 iters, (0.259)\tData load 1.109s / 5 iters, (0.221809)\n",
      "Loss_D = 1.24106622 (ave = 1.24688668)\n",
      "Loss_G = 0.69472933 (ave = 0.69471315)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9696076735482803, value max: 0.029158586636185646\n",
      "D grad l2-norm: 0.7380670422957946, value max: 0.5007820129394531\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.658s / 5 iters, (0.132)\tData load 0.568s / 5 iters, (0.113535)\n",
      "Loss_D = 1.23394346 (ave = 1.23524323)\n",
      "Loss_G = 0.69360405 (ave = 0.69425251)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9726415333167653, value max: 0.03173020854592323\n",
      "D grad l2-norm: 0.7443917940812148, value max: 0.5002201795578003\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 1.21718431 (ave = 1.22309608)\n",
      "Loss_G = 0.69415998 (ave = 0.69418478)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9806830107519225, value max: 0.027349738404154778\n",
      "D grad l2-norm: 0.7525485826693877, value max: 0.5004986524581909\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 1.20856118 (ave = 1.21135578)\n",
      "Loss_G = 0.69561112 (ave = 0.69511279)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9786163418117887, value max: 0.030994780361652374\n",
      "D grad l2-norm: 0.7618466869563665, value max: 0.5012219548225403\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.19822121 (ave = 1.19961870)\n",
      "Loss_G = 0.69629282 (ave = 0.69581769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9751680026448288, value max: 0.03298762068152428\n",
      "D grad l2-norm: 0.7694254083871195, value max: 0.5015602707862854\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001566)\n",
      "Loss_D = 1.18010283 (ave = 1.18672030)\n",
      "Loss_G = 0.69821352 (ave = 0.69686085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9730777332253424, value max: 0.02636071667075157\n",
      "D grad l2-norm: 0.7788570536389136, value max: 0.5025156736373901\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.16935217 (ave = 1.17468140)\n",
      "Loss_G = 0.70015574 (ave = 0.69930786)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9744010119393633, value max: 0.027277324348688126\n",
      "D grad l2-norm: 0.7872449411800148, value max: 0.5034804940223694\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 1.15937102 (ave = 1.16270585)\n",
      "Loss_G = 0.70254660 (ave = 0.70131931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9742342452770686, value max: 0.02655063383281231\n",
      "D grad l2-norm: 0.7988970227287897, value max: 0.504666805267334\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 1.15554106 (ave = 1.15107210)\n",
      "Loss_G = 0.70507503 (ave = 0.70437814)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9706376309550991, value max: 0.027078088372945786\n",
      "D grad l2-norm: 0.8082368890045171, value max: 0.5059167146682739\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001766)\n",
      "Loss_D = 1.14305449 (ave = 1.13903999)\n",
      "Loss_G = 0.70860243 (ave = 0.70737188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974392615885457, value max: 0.03259856253862381\n",
      "D grad l2-norm: 0.821381067552427, value max: 0.5076554417610168\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.019s / 5 iters, (0.003742)\n",
      "Loss_D = 1.11695206 (ave = 1.12452810)\n",
      "Loss_G = 0.71330428 (ave = 0.71180065)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9710795410964939, value max: 0.031879253685474396\n",
      "D grad l2-norm: 0.8335348382394998, value max: 0.5099636912345886\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.815s / 5 iters, (0.163)\tData load 0.703s / 5 iters, (0.140558)\n",
      "Loss_D = 1.10335088 (ave = 1.11105773)\n",
      "Loss_G = 0.71705836 (ave = 0.71623851)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.974520805207674, value max: 0.036394283175468445\n",
      "D grad l2-norm: 0.8458291460156853, value max: 0.5117990970611572\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.017s / 5 iters, (0.003399)\n",
      "Loss_D = 1.11196411 (ave = 1.10090773)\n",
      "Loss_G = 0.72380662 (ave = 0.72160867)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9678028556629344, value max: 0.02968086302280426\n",
      "D grad l2-norm: 0.8597624943902666, value max: 0.5150821805000305\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.011s / 5 iters, (0.002163)\n",
      "Loss_D = 1.08257401 (ave = 1.08557332)\n",
      "Loss_G = 0.72915137 (ave = 0.72631227)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9762652143323384, value max: 0.03130093589425087\n",
      "D grad l2-norm: 0.8718215957496929, value max: 0.5176647901535034\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 1.06814337 (ave = 1.07244463)\n",
      "Loss_G = 0.73489404 (ave = 0.73225178)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9702974426198465, value max: 0.035334598273038864\n",
      "D grad l2-norm: 0.8891275971181776, value max: 0.5204301476478577\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001643)\n",
      "Loss_D = 1.04971969 (ave = 1.05772254)\n",
      "Loss_G = 0.74089950 (ave = 0.73885111)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9773219047774406, value max: 0.03285505250096321\n",
      "D grad l2-norm: 0.9002086855078338, value max: 0.5232937932014465\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001587)\n",
      "Loss_D = 1.04648626 (ave = 1.04565125)\n",
      "Loss_G = 0.74906689 (ave = 0.74536365)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976688755978193, value max: 0.031634021550416946\n",
      "D grad l2-norm: 0.9171445260203032, value max: 0.5271705389022827\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 1.04379487 (ave = 1.03375969)\n",
      "Loss_G = 0.75432408 (ave = 0.75122316)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9821833652661697, value max: 0.038638561964035034\n",
      "D grad l2-norm: 0.9353606208768439, value max: 0.5296501517295837\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.022s / 5 iters, (0.004495)\n",
      "Loss_D = 1.01053429 (ave = 1.01710238)\n",
      "Loss_G = 0.76212186 (ave = 0.75939647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9874370321755978, value max: 0.030375663191080093\n",
      "D grad l2-norm: 0.9550141147846612, value max: 0.533305823802948\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 0.98418570 (ave = 1.00211663)\n",
      "Loss_G = 0.76994026 (ave = 0.76649821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979962762402552, value max: 0.03613870590925217\n",
      "D grad l2-norm: 0.970191539594735, value max: 0.5369314551353455\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 0.97863412 (ave = 0.98879318)\n",
      "Loss_G = 0.77768952 (ave = 0.77418435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984438300947664, value max: 0.03808506950736046\n",
      "D grad l2-norm: 0.9897832644025599, value max: 0.5405066013336182\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.095s / 5 iters, (0.219)\tData load 1.045s / 5 iters, (0.209025)\n",
      "Loss_D = 0.96842813 (ave = 0.97633644)\n",
      "Loss_G = 0.78756160 (ave = 0.78290030)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9912635789436312, value max: 0.04094238951802254\n",
      "D grad l2-norm: 1.0052028626726608, value max: 0.5450232625007629\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 0.94869637 (ave = 0.96226996)\n",
      "Loss_G = 0.79201555 (ave = 0.79083846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9971439296435547, value max: 0.04121142625808716\n",
      "D grad l2-norm: 1.032263969484383, value max: 0.5470322370529175\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.94883358 (ave = 0.95070406)\n",
      "Loss_G = 0.80040354 (ave = 0.79879096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0025219521306545, value max: 0.0474703274667263\n",
      "D grad l2-norm: 1.0540747851833778, value max: 0.5508104562759399\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.010s / 5 iters, (0.001973)\n",
      "Loss_D = 0.92934597 (ave = 0.93861468)\n",
      "Loss_G = 0.80915779 (ave = 0.80683608)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0116397009803948, value max: 0.056090861558914185\n",
      "D grad l2-norm: 1.0716067119245696, value max: 0.5547251105308533\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.94253290 (ave = 0.92915200)\n",
      "Loss_G = 0.81621695 (ave = 0.81375309)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.026529787785738, value max: 0.06180945411324501\n",
      "D grad l2-norm: 1.09539768778697, value max: 0.5578469038009644\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.017s / 5 iters, (0.003395)\n",
      "Loss_D = 0.91667247 (ave = 0.91619905)\n",
      "Loss_G = 0.82184696 (ave = 0.82015582)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0362705336841536, value max: 0.0782279372215271\n",
      "D grad l2-norm: 1.1124090760191219, value max: 0.5603225231170654\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.014s / 5 iters, (0.002891)\n",
      "Loss_D = 0.88045150 (ave = 0.90337081)\n",
      "Loss_G = 0.82960868 (ave = 0.82689921)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0590148034973594, value max: 0.07307947427034378\n",
      "D grad l2-norm: 1.14077198522588, value max: 0.5637251138687134\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.016s / 5 iters, (0.003290)\n",
      "Loss_D = 0.90234435 (ave = 0.89795713)\n",
      "Loss_G = 0.83580136 (ave = 0.83258955)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0710518186619362, value max: 0.08405294269323349\n",
      "D grad l2-norm: 1.170146196378076, value max: 0.5664093494415283\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.015s / 5 iters, (0.003082)\n",
      "Loss_D = 0.88213110 (ave = 0.88814505)\n",
      "Loss_G = 0.84141570 (ave = 0.83813695)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0863822095593538, value max: 0.09256631135940552\n",
      "D grad l2-norm: 1.197297926557699, value max: 0.568810224533081\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001535)\n",
      "Loss_D = 0.86426437 (ave = 0.87765120)\n",
      "Loss_G = 0.84333187 (ave = 0.84261342)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1205883233053853, value max: 0.09709737449884415\n",
      "D grad l2-norm: 1.2519181449107304, value max: 0.5695973634719849\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.741s / 5 iters, (0.148)\tData load 0.686s / 5 iters, (0.137235)\n",
      "Loss_D = 0.87403554 (ave = 0.87330947)\n",
      "Loss_G = 0.85546726 (ave = 0.85051581)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.122161209229588, value max: 0.0946517288684845\n",
      "D grad l2-norm: 1.2740254160859499, value max: 0.5747957825660706\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001702)\n",
      "Loss_D = 0.85886586 (ave = 0.86491610)\n",
      "Loss_G = 0.85848111 (ave = 0.85424330)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1599011463742144, value max: 0.11168288439512253\n",
      "D grad l2-norm: 1.3385779334617254, value max: 0.575994610786438\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 0.86915147 (ave = 0.86047921)\n",
      "Loss_G = 0.86352015 (ave = 0.86139295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1773538817736247, value max: 0.11518654227256775\n",
      "D grad l2-norm: 1.3873902251035592, value max: 0.5781697630882263\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.81207705 (ave = 0.84448454)\n",
      "Loss_G = 0.87630230 (ave = 0.87165910)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1920061440963112, value max: 0.12574490904808044\n",
      "D grad l2-norm: 1.457701406876107, value max: 0.5834982991218567\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.009s / 5 iters, (0.001871)\n",
      "Loss_D = 0.83238459 (ave = 0.83764068)\n",
      "Loss_G = 0.89477599 (ave = 0.88737671)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1890003771205504, value max: 0.1252138316631317\n",
      "D grad l2-norm: 1.5251993909363635, value max: 0.5911458730697632\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002402)\n",
      "Loss_D = 0.80762857 (ave = 0.82156500)\n",
      "Loss_G = 0.91077501 (ave = 0.90199760)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1851601565751264, value max: 0.13059745728969574\n",
      "D grad l2-norm: 1.580129454959307, value max: 0.5976135730743408\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.016s / 5 iters, (0.003222)\n",
      "Loss_D = 0.81477976 (ave = 0.81086912)\n",
      "Loss_G = 0.93745679 (ave = 0.92758387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1954868462880097, value max: 0.1379414200782776\n",
      "D grad l2-norm: 1.661305310785595, value max: 0.6082180738449097\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.75754142 (ave = 0.78636965)\n",
      "Loss_G = 0.96131933 (ave = 0.95022775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1994012181268352, value max: 0.13798408210277557\n",
      "D grad l2-norm: 1.7418722468799466, value max: 0.6174640655517578\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.78325260 (ave = 0.77280374)\n",
      "Loss_G = 0.98968554 (ave = 0.97775211)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2132809308398438, value max: 0.12927232682704926\n",
      "D grad l2-norm: 1.8128731844416444, value max: 0.6282035708427429\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.69978070 (ave = 0.74703156)\n",
      "Loss_G = 1.01320136 (ave = 1.00153199)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:30:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2463373246809415, value max: 0.1300775557756424\n",
      "D grad l2-norm: 1.8945248506016665, value max: 0.636806845664978\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.926s / 5 iters, (0.185)\tData load 0.849s / 5 iters, (0.169737)\n",
      "Loss_D = 0.69901955 (ave = 0.73296503)\n",
      "Loss_G = 1.03524017 (ave = 1.02711706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.288126133008483, value max: 0.1183573454618454\n",
      "D grad l2-norm: 1.952576586322726, value max: 0.6447070240974426\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.001945)\n",
      "Loss_D = 0.73846042 (ave = 0.72584249)\n",
      "Loss_G = 1.05237937 (ave = 1.04649284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3385468118456931, value max: 0.12173755466938019\n",
      "D grad l2-norm: 2.0061217449568214, value max: 0.6507207155227661\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001816)\n",
      "Loss_D = 0.74037492 (ave = 0.71817074)\n",
      "Loss_G = 1.06538463 (ave = 1.06241534)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4045639488704935, value max: 0.12151440232992172\n",
      "D grad l2-norm: 2.0529958376246698, value max: 0.655242919921875\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 0.72661424 (ave = 0.70888541)\n",
      "Loss_G = 1.07040477 (ave = 1.06873565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.480539456239814, value max: 0.14395946264266968\n",
      "D grad l2-norm: 2.0956298699443257, value max: 0.6569533944129944\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001766)\n",
      "Loss_D = 0.64833826 (ave = 0.69649861)\n",
      "Loss_G = 1.06999898 (ave = 1.06756451)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5377854217811122, value max: 0.14768081903457642\n",
      "D grad l2-norm: 2.0909401842516515, value max: 0.6567845344543457\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001779)\n",
      "Loss_D = 0.76159793 (ave = 0.71208595)\n",
      "Loss_G = 1.05734408 (ave = 1.06672821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6469361835062022, value max: 0.1599852293729782\n",
      "D grad l2-norm: 2.12923078863664, value max: 0.6523447632789612\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.70627606 (ave = 0.70829954)\n",
      "Loss_G = 1.04276156 (ave = 1.04906375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.721546253787138, value max: 0.1727932244539261\n",
      "D grad l2-norm: 2.1191035277626655, value max: 0.6471413969993591\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001750)\n",
      "Loss_D = 0.68129802 (ave = 0.71172216)\n",
      "Loss_G = 1.03170896 (ave = 1.03892329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8144267278302586, value max: 0.17881886661052704\n",
      "D grad l2-norm: 2.1391368023057438, value max: 0.6431726217269897\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001733)\n",
      "Loss_D = 0.75465071 (ave = 0.73432473)\n",
      "Loss_G = 1.01656187 (ave = 1.01773276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9836146047003593, value max: 0.20455095171928406\n",
      "D grad l2-norm: 2.165755408207841, value max: 0.6374663710594177\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.73243546 (ave = 0.74802620)\n",
      "Loss_G = 0.97196043 (ave = 0.98005679)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1703204263799125, value max: 0.23573976755142212\n",
      "D grad l2-norm: 2.1434008817927093, value max: 0.6209423542022705\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.738s / 5 iters, (0.148)\tData load 0.650s / 5 iters, (0.130052)\n",
      "Loss_D = 0.74562478 (ave = 0.77973547)\n",
      "Loss_G = 0.91191041 (ave = 0.93676120)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.303868210633466, value max: 0.25966060161590576\n",
      "D grad l2-norm: 2.1018038318557375, value max: 0.5971026420593262\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 0.85972023 (ave = 0.83109334)\n",
      "Loss_G = 0.87113911 (ave = 0.89368088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3644802712675688, value max: 0.26796460151672363\n",
      "D grad l2-norm: 2.075812295232519, value max: 0.5802215337753296\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001702)\n",
      "Loss_D = 0.90212774 (ave = 0.86516293)\n",
      "Loss_G = 0.83945554 (ave = 0.85153624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.380536850007596, value max: 0.27800849080085754\n",
      "D grad l2-norm: 2.042120678627567, value max: 0.5666822195053101\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.89276695 (ave = 0.89786632)\n",
      "Loss_G = 0.82041144 (ave = 0.81607538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4144645323101734, value max: 0.2726755440235138\n",
      "D grad l2-norm: 2.066152251596779, value max: 0.5583491325378418\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 0.98066187 (ave = 0.93101624)\n",
      "Loss_G = 0.77386129 (ave = 0.79194739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.474558320894405, value max: 0.2617555558681488\n",
      "D grad l2-norm: 2.099310791742452, value max: 0.537229061126709\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.93074989 (ave = 0.94003525)\n",
      "Loss_G = 0.76946437 (ave = 0.77189136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4967404328112193, value max: 0.24641916155815125\n",
      "D grad l2-norm: 2.135158019242591, value max: 0.5351585745811462\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 1.01633644 (ave = 0.96218926)\n",
      "Loss_G = 0.75775945 (ave = 0.76755127)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.489912961277887, value max: 0.23458603024482727\n",
      "D grad l2-norm: 2.207435357751286, value max: 0.5292573571205139\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 0.80603123 (ave = 0.93427899)\n",
      "Loss_G = 0.77581453 (ave = 0.76568834)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.446645293174246, value max: 0.21664370596408844\n",
      "D grad l2-norm: 2.266823785890475, value max: 0.5381938219070435\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.009s / 5 iters, (0.001851)\n",
      "Loss_D = 0.97168630 (ave = 0.94692463)\n",
      "Loss_G = 0.78294069 (ave = 0.78237166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.487365557633125, value max: 0.22409303486347198\n",
      "D grad l2-norm: 2.3856008225595278, value max: 0.5415410995483398\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 5 iters, (0.024)\tData load 0.015s / 5 iters, (0.003087)\n",
      "Loss_D = 0.92007422 (ave = 0.93073040)\n",
      "Loss_G = 0.82239509 (ave = 0.80483587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.503560924687645, value max: 0.23642706871032715\n",
      "D grad l2-norm: 2.5167934081369867, value max: 0.5590448975563049\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.885s / 5 iters, (0.177)\tData load 0.831s / 5 iters, (0.166170)\n",
      "Loss_D = 0.90284204 (ave = 0.90249473)\n",
      "Loss_G = 0.85228437 (ave = 0.83856603)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.492868795668072, value max: 0.21563665568828583\n",
      "D grad l2-norm: 2.652435819815586, value max: 0.5721427202224731\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.79929060 (ave = 0.86021225)\n",
      "Loss_G = 0.90436840 (ave = 0.88426672)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.5421223010142335, value max: 0.20729990303516388\n",
      "D grad l2-norm: 2.8895554106434083, value max: 0.5940955877304077\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 0.79782665 (ave = 0.82672355)\n",
      "Loss_G = 0.96598887 (ave = 0.94300255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.57546493781635, value max: 0.21399138867855072\n",
      "D grad l2-norm: 3.033774788251761, value max: 0.6186220049858093\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 0.73255718 (ave = 0.78377366)\n",
      "Loss_G = 1.01691830 (ave = 0.99640189)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6659169569999333, value max: 0.207642063498497\n",
      "D grad l2-norm: 3.2698661389585455, value max: 0.6371362805366516\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.013s / 5 iters, (0.002666)\n",
      "Loss_D = 0.70928538 (ave = 0.75400946)\n",
      "Loss_G = 1.06319666 (ave = 1.04206684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.761857155147504, value max: 0.20932456851005554\n",
      "D grad l2-norm: 3.446954817727203, value max: 0.6536721587181091\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 0.67058039 (ave = 0.72347437)\n",
      "Loss_G = 1.11377501 (ave = 1.09468741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.858674191715401, value max: 0.22780722379684448\n",
      "D grad l2-norm: 3.625668899351705, value max: 0.67076575756073\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 0.69955146 (ave = 0.70456479)\n",
      "Loss_G = 1.15319872 (ave = 1.13683054)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1461019187485673, value max: 0.2790775001049042\n",
      "D grad l2-norm: 3.983442095280262, value max: 0.6835411787033081\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001694)\n",
      "Loss_D = 0.67669725 (ave = 0.68482525)\n",
      "Loss_G = 1.21347237 (ave = 1.17965219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1063511932882415, value max: 0.30743739008903503\n",
      "D grad l2-norm: 3.9982594075948477, value max: 0.7019829154014587\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 0.73490918 (ave = 0.67493205)\n",
      "Loss_G = 1.23746204 (ave = 1.21833291)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.369941776777211, value max: 0.3506884276866913\n",
      "D grad l2-norm: 4.299034759352263, value max: 0.7086686491966248\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.68178493 (ave = 0.65474199)\n",
      "Loss_G = 1.27496445 (ave = 1.26882954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.544500539844254, value max: 0.37613192200660706\n",
      "D grad l2-norm: 4.549278989449834, value max: 0.7196779251098633\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.701s / 5 iters, (0.140)\tData load 0.635s / 5 iters, (0.127038)\n",
      "Loss_D = 0.72762156 (ave = 0.64602188)\n",
      "Loss_G = 1.31816792 (ave = 1.29553397)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7051482383983565, value max: 0.3966436982154846\n",
      "D grad l2-norm: 4.700644123326946, value max: 0.7314232587814331\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.016s / 5 iters, (0.003213)\n",
      "Loss_D = 0.55947602 (ave = 0.61985977)\n",
      "Loss_G = 1.31926656 (ave = 1.31088569)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.988915115453427, value max: 0.42943134903907776\n",
      "D grad l2-norm: 4.939855940047708, value max: 0.7315709590911865\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 0.60616928 (ave = 0.62477602)\n",
      "Loss_G = 1.32139623 (ave = 1.32928581)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.192597131039179, value max: 0.4534436762332916\n",
      "D grad l2-norm: 5.063983437957033, value max: 0.7318959832191467\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 0.58055282 (ave = 0.62554533)\n",
      "Loss_G = 1.34301567 (ave = 1.33845932)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.261019041895435, value max: 0.4561499357223511\n",
      "D grad l2-norm: 5.16396906057132, value max: 0.7380459904670715\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 0.60030365 (ave = 0.63139452)\n",
      "Loss_G = 1.35017431 (ave = 1.35134060)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.344236025043466, value max: 0.4540814757347107\n",
      "D grad l2-norm: 5.221249955143439, value max: 0.7395868897438049\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 5 iters, (0.025)\tData load 0.019s / 5 iters, (0.003720)\n",
      "Loss_D = 0.69925606 (ave = 0.64392074)\n",
      "Loss_G = 1.35968912 (ave = 1.36440487)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.504307091254304, value max: 0.4411887228488922\n",
      "D grad l2-norm: 5.337894769027593, value max: 0.7420613169670105\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.023s / 5 iters, (0.004693)\n",
      "Loss_D = 0.74716544 (ave = 0.65866008)\n",
      "Loss_G = 1.36834323 (ave = 1.36829908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.584822035303708, value max: 0.42129507660865784\n",
      "D grad l2-norm: 5.359202320188432, value max: 0.7441778182983398\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 5 iters, (0.025)\tData load 0.014s / 5 iters, (0.002812)\n",
      "Loss_D = 0.63003445 (ave = 0.64944342)\n",
      "Loss_G = 1.35813105 (ave = 1.36493311)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.681092157290851, value max: 0.40705305337905884\n",
      "D grad l2-norm: 5.437332168014919, value max: 0.7414593696594238\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002449)\n",
      "Loss_D = 0.61989051 (ave = 0.65885650)\n",
      "Loss_G = 1.32852268 (ave = 1.35025260)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.8215651672396325, value max: 0.41109392046928406\n",
      "D grad l2-norm: 5.286152356357697, value max: 0.733487069606781\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.007s / 5 iters, (0.001432)\n",
      "Loss_D = 0.67821586 (ave = 0.68599708)\n",
      "Loss_G = 1.31094658 (ave = 1.31690419)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.245006837718223, value max: 0.4376925528049469\n",
      "D grad l2-norm: 5.445719451907483, value max: 0.7286275625228882\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.718s / 5 iters, (0.144)\tData load 0.671s / 5 iters, (0.134182)\n",
      "Loss_D = 0.75925159 (ave = 0.73738236)\n",
      "Loss_G = 1.21778107 (ave = 1.25318146)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.486566936117231, value max: 0.4470619559288025\n",
      "D grad l2-norm: 5.360783275042649, value max: 0.7008801102638245\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.86904573 (ave = 0.78657540)\n",
      "Loss_G = 1.19604456 (ave = 1.19342129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.324635508464651, value max: 0.4437147378921509\n",
      "D grad l2-norm: 5.319759350927159, value max: 0.6947422623634338\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.82626450 (ave = 0.79821581)\n",
      "Loss_G = 1.17839372 (ave = 1.18066103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.376985849258304, value max: 0.4497082531452179\n",
      "D grad l2-norm: 5.415528574153478, value max: 0.6886224746704102\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.78279400 (ave = 0.81071210)\n",
      "Loss_G = 1.20435619 (ave = 1.19577651)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.668754361362316, value max: 0.4714280962944031\n",
      "D grad l2-norm: 5.621446460029685, value max: 0.6967663168907166\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.013s / 5 iters, (0.002665)\n",
      "Loss_D = 0.90584552 (ave = 0.83106652)\n",
      "Loss_G = 1.18126142 (ave = 1.19322956)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.8721722935277185, value max: 0.4934656322002411\n",
      "D grad l2-norm: 5.76676735116858, value max: 0.689583420753479\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.83135152 (ave = 0.83112123)\n",
      "Loss_G = 1.22241437 (ave = 1.20939801)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.989890739119041, value max: 0.4662283658981323\n",
      "D grad l2-norm: 6.130002578894689, value max: 0.7000267505645752\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002275)\n",
      "Loss_D = 0.83451521 (ave = 0.83156031)\n",
      "Loss_G = 1.25252771 (ave = 1.23644013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.052487359526331, value max: 0.4697399437427521\n",
      "D grad l2-norm: 6.216581671201457, value max: 0.7087726593017578\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 0.84597206 (ave = 0.82793139)\n",
      "Loss_G = 1.27128744 (ave = 1.27319894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.541219699149711, value max: 0.4939947724342346\n",
      "D grad l2-norm: 6.622716391097035, value max: 0.7531413435935974\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.69883752 (ave = 0.83273277)\n",
      "Loss_G = 1.24948072 (ave = 1.27092087)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.892934008361176, value max: 0.509173572063446\n",
      "D grad l2-norm: 6.972734903566523, value max: 0.788369357585907\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001735)\n",
      "Loss_D = 0.88062078 (ave = 0.85511574)\n",
      "Loss_G = 1.26576948 (ave = 1.29292967)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.843427352278113, value max: 0.48315995931625366\n",
      "D grad l2-norm: 7.1295995281590665, value max: 0.8090049028396606\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.006s / 5 iters, (0.201)\tData load 0.948s / 5 iters, (0.189574)\n",
      "Loss_D = 0.92027593 (ave = 0.87233502)\n",
      "Loss_G = 1.32076478 (ave = 1.28872066)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.901908807680353, value max: 0.5266707539558411\n",
      "D grad l2-norm: 7.395695566857996, value max: 0.8522734045982361\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001771)\n",
      "Loss_D = 0.79239142 (ave = 0.85824370)\n",
      "Loss_G = 1.36422801 (ave = 1.33258867)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.332379649133683, value max: 0.5775174498558044\n",
      "D grad l2-norm: 8.006807567953022, value max: 0.9167031049728394\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 0.89049476 (ave = 0.85249223)\n",
      "Loss_G = 1.41717410 (ave = 1.38425958)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.495251344597571, value max: 0.6415287256240845\n",
      "D grad l2-norm: 8.266467498547447, value max: 0.9450360536575317\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.80426621 (ave = 0.84476191)\n",
      "Loss_G = 1.42359900 (ave = 1.41065485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.105034964623696, value max: 0.6432426571846008\n",
      "D grad l2-norm: 8.774215632754682, value max: 0.9813737273216248\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 0.93986416 (ave = 0.86264859)\n",
      "Loss_G = 1.41806662 (ave = 1.42434273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.052989177164266, value max: 0.6417289972305298\n",
      "D grad l2-norm: 8.674004794157131, value max: 0.9560827016830444\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 0.96121091 (ave = 0.88308105)\n",
      "Loss_G = 1.43895745 (ave = 1.43578629)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.450187382150403, value max: 0.616321861743927\n",
      "D grad l2-norm: 9.149933252111012, value max: 0.991765022277832\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.98922956 (ave = 0.89781008)\n",
      "Loss_G = 1.45064008 (ave = 1.44758656)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.370857197448306, value max: 0.5780463218688965\n",
      "D grad l2-norm: 9.474426986110716, value max: 1.0112338066101074\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001777)\n",
      "Loss_D = 0.83397323 (ave = 0.86517527)\n",
      "Loss_G = 1.48969924 (ave = 1.46825109)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.23374251776386, value max: 0.5329073667526245\n",
      "D grad l2-norm: 9.509816539791089, value max: 1.0022019147872925\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 0.76131356 (ave = 0.84762119)\n",
      "Loss_G = 1.51448894 (ave = 1.50747061)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.038040618815106, value max: 0.4793192148208618\n",
      "D grad l2-norm: 9.549112511013952, value max: 1.0347659587860107\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 1.10805988 (ave = 0.88488568)\n",
      "Loss_G = 1.57785583 (ave = 1.55362587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.8279913751430215, value max: 0.4770822525024414\n",
      "D grad l2-norm: 9.779779163215522, value max: 1.106265902519226\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.733s / 5 iters, (0.147)\tData load 0.679s / 5 iters, (0.135720)\n",
      "Loss_D = 0.63011944 (ave = 0.80276012)\n",
      "Loss_G = 1.62676179 (ave = 1.58357396)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.682333166210163, value max: 0.4605759084224701\n",
      "D grad l2-norm: 9.798673967651428, value max: 1.144380807876587\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 0.72677094 (ave = 0.80364528)\n",
      "Loss_G = 1.63605571 (ave = 1.62959187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.4986912880044105, value max: 0.4582585096359253\n",
      "D grad l2-norm: 9.70081049511619, value max: 1.145311951637268\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.90131301 (ave = 0.81046399)\n",
      "Loss_G = 1.67459643 (ave = 1.66109374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.2921424378432125, value max: 0.45188653469085693\n",
      "D grad l2-norm: 9.528103543152346, value max: 1.1522016525268555\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.009s / 5 iters, (0.001770)\n",
      "Loss_D = 0.70459765 (ave = 0.77368612)\n",
      "Loss_G = 1.66996574 (ave = 1.68524539)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.45061571151565, value max: 0.4711809754371643\n",
      "D grad l2-norm: 9.478578248390699, value max: 1.1412279605865479\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.017s / 5 iters, (0.003356)\n",
      "Loss_D = 0.78529119 (ave = 0.77632277)\n",
      "Loss_G = 1.64874935 (ave = 1.66330533)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.6513586006624, value max: 0.47292909026145935\n",
      "D grad l2-norm: 9.475070129491852, value max: 1.1194400787353516\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 0.78190446 (ave = 0.78158383)\n",
      "Loss_G = 1.62143779 (ave = 1.61940176)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.63923697146093, value max: 0.4577338397502899\n",
      "D grad l2-norm: 9.247452764324992, value max: 1.0586485862731934\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001675)\n",
      "Loss_D = 0.86009306 (ave = 0.79106470)\n",
      "Loss_G = 1.60410261 (ave = 1.61313457)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.716515628747058, value max: 0.41244667768478394\n",
      "D grad l2-norm: 9.346194796012638, value max: 1.0239341259002686\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.019s / 5 iters, (0.003897)\n",
      "Loss_D = 0.61391699 (ave = 0.75227869)\n",
      "Loss_G = 1.58539927 (ave = 1.60259042)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.758537375234336, value max: 0.42202913761138916\n",
      "D grad l2-norm: 9.07743744577279, value max: 0.9574024677276611\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.53752339 (ave = 0.74135600)\n",
      "Loss_G = 1.55316877 (ave = 1.58637319)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.013241956999494, value max: 0.44921958446502686\n",
      "D grad l2-norm: 8.890618785051595, value max: 0.8856514096260071\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002142)\n",
      "Loss_D = 0.92286700 (ave = 0.80366243)\n",
      "Loss_G = 1.55512786 (ave = 1.54956508)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.271496425299816, value max: 0.4297599196434021\n",
      "D grad l2-norm: 8.783896627911666, value max: 0.8638275265693665\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.723s / 5 iters, (0.145)\tData load 0.672s / 5 iters, (0.134493)\n",
      "Loss_D = 0.70542085 (ave = 0.78882531)\n",
      "Loss_G = 1.47226310 (ave = 1.47865059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.052685144170324, value max: 0.45285218954086304\n",
      "D grad l2-norm: 8.566583997346504, value max: 0.8154700398445129\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 0.81519622 (ave = 0.81281134)\n",
      "Loss_G = 1.48107815 (ave = 1.46625700)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.081809756422865, value max: 0.4613761007785797\n",
      "D grad l2-norm: 8.663998850731172, value max: 0.8185820579528809\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 0.91363943 (ave = 0.82312404)\n",
      "Loss_G = 1.45702672 (ave = 1.46736960)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.92608724819997, value max: 0.4493843913078308\n",
      "D grad l2-norm: 8.483299234003871, value max: 0.7848042249679565\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 0.74079454 (ave = 0.79813898)\n",
      "Loss_G = 1.47855783 (ave = 1.46421614)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.08879408694733, value max: 0.4537613093852997\n",
      "D grad l2-norm: 8.688859918291701, value max: 0.7773522734642029\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001754)\n",
      "Loss_D = 0.79788637 (ave = 0.80297050)\n",
      "Loss_G = 1.46738887 (ave = 1.47476387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.292958121938428, value max: 0.4859042763710022\n",
      "D grad l2-norm: 8.967382336391381, value max: 0.7712000608444214\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.036s / 5 iters, (0.007280)\n",
      "Loss_D = 0.84866488 (ave = 0.80759088)\n",
      "Loss_G = 1.48485827 (ave = 1.47330763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.424969309804737, value max: 0.5486171245574951\n",
      "D grad l2-norm: 9.142747865401397, value max: 0.769924521446228\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 0.87510169 (ave = 0.80595446)\n",
      "Loss_G = 1.48726141 (ave = 1.47634828)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.585801266475185, value max: 0.6188691854476929\n",
      "D grad l2-norm: 9.429303242754841, value max: 0.8033619523048401\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 0.63693583 (ave = 0.75703862)\n",
      "Loss_G = 1.52170491 (ave = 1.52313216)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.40362422479685, value max: 0.6686034202575684\n",
      "D grad l2-norm: 9.675690821049555, value max: 0.8549367189407349\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 0.69019562 (ave = 0.74382324)\n",
      "Loss_G = 1.63550842 (ave = 1.60889640)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.997625446605824, value max: 0.6755319833755493\n",
      "D grad l2-norm: 9.820781491307192, value max: 0.9103918075561523\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 0.66186804 (ave = 0.70900103)\n",
      "Loss_G = 1.74424195 (ave = 1.69322453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.993726287615681, value max: 0.7117340564727783\n",
      "D grad l2-norm: 10.207641280156935, value max: 0.9656040668487549\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.971s / 5 iters, (0.194)\tData load 0.917s / 5 iters, (0.183316)\n",
      "Loss_D = 0.78473067 (ave = 0.69711088)\n",
      "Loss_G = 1.73561275 (ave = 1.74523265)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.360899035243056, value max: 0.7514219880104065\n",
      "D grad l2-norm: 10.284476128956054, value max: 0.9530870318412781\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.018s / 5 iters, (0.003575)\n",
      "Loss_D = 0.56802911 (ave = 0.65428529)\n",
      "Loss_G = 1.81380272 (ave = 1.78210931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.623161459892156, value max: 0.7955235242843628\n",
      "D grad l2-norm: 10.801102320585239, value max: 1.0370360612869263\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001828)\n",
      "Loss_D = 0.59055740 (ave = 0.64151655)\n",
      "Loss_G = 1.84757280 (ave = 1.81541479)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.770043001979252, value max: 0.8050001859664917\n",
      "D grad l2-norm: 11.068938248594026, value max: 1.099109172821045\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001803)\n",
      "Loss_D = 0.64507598 (ave = 0.63561679)\n",
      "Loss_G = 1.84167314 (ave = 1.84503942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.061130122615303, value max: 0.7792742252349854\n",
      "D grad l2-norm: 11.305408794427747, value max: 1.140708088874817\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001787)\n",
      "Loss_D = 0.61137676 (ave = 0.62153713)\n",
      "Loss_G = 1.85091829 (ave = 1.84376180)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.30809230763758, value max: 0.7785969376564026\n",
      "D grad l2-norm: 11.508280998217893, value max: 1.1681691408157349\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001748)\n",
      "Loss_D = 0.51798558 (ave = 0.60189595)\n",
      "Loss_G = 1.89184320 (ave = 1.85307467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.597352364818637, value max: 0.780921220779419\n",
      "D grad l2-norm: 11.922605690659497, value max: 1.2151079177856445\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 0.52271008 (ave = 0.59921894)\n",
      "Loss_G = 1.88210797 (ave = 1.88946402)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.237660562517421, value max: 0.7220587730407715\n",
      "D grad l2-norm: 11.720021035280134, value max: 1.18584144115448\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001776)\n",
      "Loss_D = 0.48923981 (ave = 0.58622733)\n",
      "Loss_G = 1.88818407 (ave = 1.88713923)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.25243214365522, value max: 0.6935074925422668\n",
      "D grad l2-norm: 11.689730016605441, value max: 1.167527198791504\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.015s / 5 iters, (0.003017)\n",
      "Loss_D = 0.63461298 (ave = 0.60032189)\n",
      "Loss_G = 1.91482139 (ave = 1.90262184)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.55272769925205, value max: 0.7655035257339478\n",
      "D grad l2-norm: 11.905742398914748, value max: 1.1636133193969727\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001713)\n",
      "Loss_D = 0.50198889 (ave = 0.58115408)\n",
      "Loss_G = 1.91377974 (ave = 1.88472362)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.36803657657188, value max: 0.7526521682739258\n",
      "D grad l2-norm: 11.741378357464837, value max: 1.1311824321746826\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.795s / 5 iters, (0.159)\tData load 0.734s / 5 iters, (0.146800)\n",
      "Loss_D = 0.55707085 (ave = 0.59229660)\n",
      "Loss_G = 1.87138820 (ave = 1.89244580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.324802279449617, value max: 0.7606123089790344\n",
      "D grad l2-norm: 11.576488384964389, value max: 1.1107985973358154\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001780)\n",
      "Loss_D = 0.73097003 (ave = 0.61893870)\n",
      "Loss_G = 1.81732535 (ave = 1.87266443)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.592110406925752, value max: 0.7967127561569214\n",
      "D grad l2-norm: 11.550180945197729, value max: 1.0935426950454712\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001777)\n",
      "Loss_D = 0.59781182 (ave = 0.60896531)\n",
      "Loss_G = 1.82294595 (ave = 1.83334699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.515917231764842, value max: 0.7902857661247253\n",
      "D grad l2-norm: 11.415458155518417, value max: 1.0672721862792969\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.66126376 (ave = 0.62640337)\n",
      "Loss_G = 1.84422362 (ave = 1.82479355)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.863277410707138, value max: 0.7740949988365173\n",
      "D grad l2-norm: 11.812593466564692, value max: 1.0852653980255127\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.010s / 5 iters, (0.001986)\n",
      "Loss_D = 0.55114144 (ave = 0.62321554)\n",
      "Loss_G = 1.84266210 (ave = 1.82193844)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.472001636850292, value max: 0.7548863291740417\n",
      "D grad l2-norm: 11.438628885260085, value max: 1.0238564014434814\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.017s / 5 iters, (0.003323)\n",
      "Loss_D = 0.63138092 (ave = 0.62744032)\n",
      "Loss_G = 1.83442080 (ave = 1.83312895)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.680169351395055, value max: 0.7064622640609741\n",
      "D grad l2-norm: 11.490191905506878, value max: 0.9812273383140564\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.019s / 5 iters, (0.003826)\n",
      "Loss_D = 0.57025164 (ave = 0.63898526)\n",
      "Loss_G = 1.85030401 (ave = 1.81293833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.440099181291988, value max: 0.7721903324127197\n",
      "D grad l2-norm: 11.756575135265708, value max: 0.9320449233055115\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.015s / 5 iters, (0.002994)\n",
      "Loss_D = 0.77918631 (ave = 0.68633686)\n",
      "Loss_G = 1.69299448 (ave = 1.77981594)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.722926062763197, value max: 0.7984400391578674\n",
      "D grad l2-norm: 11.539097529331512, value max: 0.9116140007972717\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.010s / 5 iters, (0.001932)\n",
      "Loss_D = 0.60404921 (ave = 0.69800017)\n",
      "Loss_G = 1.69987118 (ave = 1.71689796)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.101648050894202, value max: 0.8896316289901733\n",
      "D grad l2-norm: 11.641148652613829, value max: 0.935024619102478\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.028s / 5 iters, (0.005668)\n",
      "Loss_D = 0.63957912 (ave = 0.71616263)\n",
      "Loss_G = 1.67860484 (ave = 1.70122278)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.04468232785074, value max: 0.8624674677848816\n",
      "D grad l2-norm: 11.388704491358276, value max: 0.9307863712310791\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.728s / 5 iters, (0.146)\tData load 0.678s / 5 iters, (0.135621)\n",
      "Loss_D = 0.80593628 (ave = 0.76749088)\n",
      "Loss_G = 1.68382120 (ave = 1.68541861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.009376629399332, value max: 0.8021734356880188\n",
      "D grad l2-norm: 11.300762211849333, value max: 0.9385309219360352\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001759)\n",
      "Loss_D = 0.96409190 (ave = 0.79535134)\n",
      "Loss_G = 1.66857100 (ave = 1.65221097)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.095058086413172, value max: 0.7944679260253906\n",
      "D grad l2-norm: 11.493294489462393, value max: 0.9437456130981445\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.69024622 (ave = 0.77428044)\n",
      "Loss_G = 1.68540394 (ave = 1.67506456)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.35355422115237, value max: 0.7000628113746643\n",
      "D grad l2-norm: 10.832296964688815, value max: 0.9006128907203674\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.81288981 (ave = 0.78446608)\n",
      "Loss_G = 1.70085025 (ave = 1.69937143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.346386149378308, value max: 0.7137357592582703\n",
      "D grad l2-norm: 11.84960780608812, value max: 0.9540458917617798\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 0.76332545 (ave = 0.78374611)\n",
      "Loss_G = 1.68457234 (ave = 1.67139413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.457082999521786, value max: 0.7736406922340393\n",
      "D grad l2-norm: 11.587091931722021, value max: 0.9132896661758423\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 0.88594496 (ave = 0.81627885)\n",
      "Loss_G = 1.65748227 (ave = 1.65005827)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.66943044914379, value max: 0.8533147573471069\n",
      "D grad l2-norm: 11.815044655249746, value max: 0.9244734644889832\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001741)\n",
      "Loss_D = 1.02313960 (ave = 0.83526874)\n",
      "Loss_G = 1.70872140 (ave = 1.70623069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.44897292325965, value max: 0.8136876821517944\n",
      "D grad l2-norm: 11.777298155861583, value max: 0.9350494742393494\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.011s / 5 iters, (0.002226)\n",
      "Loss_D = 0.58998978 (ave = 0.77447857)\n",
      "Loss_G = 1.66470075 (ave = 1.66582801)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.535353056199728, value max: 0.8459540009498596\n",
      "D grad l2-norm: 11.917198092622039, value max: 0.9357864260673523\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.016s / 5 iters, (0.003215)\n",
      "Loss_D = 0.77365363 (ave = 0.79503279)\n",
      "Loss_G = 1.69212556 (ave = 1.68474355)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.503722079690917, value max: 0.8392231464385986\n",
      "D grad l2-norm: 12.030312868922907, value max: 0.9356750845909119\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001638)\n",
      "Loss_D = 0.63118547 (ave = 0.76833042)\n",
      "Loss_G = 1.75244415 (ave = 1.73142927)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.618262805562509, value max: 0.8035562038421631\n",
      "D grad l2-norm: 12.272411303688667, value max: 0.960832953453064\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.425s / 5 iters, (0.285)\tData load 1.375s / 5 iters, (0.274927)\n",
      "Loss_D = 0.72137094 (ave = 0.76378026)\n",
      "Loss_G = 1.71444130 (ave = 1.74234204)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.573963785680965, value max: 0.801473081111908\n",
      "D grad l2-norm: 12.047289630095365, value max: 0.9676129221916199\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 0.86149955 (ave = 0.79173028)\n",
      "Loss_G = 1.69269443 (ave = 1.72658515)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.495121129045092, value max: 0.8015746474266052\n",
      "D grad l2-norm: 12.644264845865678, value max: 1.046440601348877\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001549)\n",
      "Loss_D = 0.66026676 (ave = 0.76801641)\n",
      "Loss_G = 1.68529248 (ave = 1.71497886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 12.624283113738882, value max: 0.8548136353492737\n",
      "D grad l2-norm: 12.500385582698671, value max: 1.0688167810440063\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 0.88296735 (ave = 0.80425463)\n",
      "Loss_G = 1.71163630 (ave = 1.69401023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.885770974533228, value max: 0.7438570857048035\n",
      "D grad l2-norm: 12.321586050722559, value max: 1.1005431413650513\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.72351992 (ave = 0.76982262)\n",
      "Loss_G = 1.74906123 (ave = 1.70972140)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.631893927075904, value max: 0.6889464259147644\n",
      "D grad l2-norm: 12.563375148365717, value max: 1.166551947593689\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 1.05330145 (ave = 0.78196315)\n",
      "Loss_G = 1.76446199 (ave = 1.76903589)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.7708326887607, value max: 0.6533815860748291\n",
      "D grad l2-norm: 11.839850066299611, value max: 1.1337867975234985\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.73577297 (ave = 0.72175802)\n",
      "Loss_G = 1.81283998 (ave = 1.79170184)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.475555344172351, value max: 0.6904087662696838\n",
      "D grad l2-norm: 12.173152317234598, value max: 1.1981732845306396\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 0.56789339 (ave = 0.68137634)\n",
      "Loss_G = 1.83493316 (ave = 1.82029707)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.512359681425684, value max: 0.7069553732872009\n",
      "D grad l2-norm: 12.14040427229623, value max: 1.2058756351470947\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001603)\n",
      "Loss_D = 0.42231423 (ave = 0.64476146)\n",
      "Loss_G = 1.82165265 (ave = 1.84017577)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.684718245427021, value max: 0.7771977782249451\n",
      "D grad l2-norm: 12.002151438394733, value max: 1.1796332597732544\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.49743634 (ave = 0.64919137)\n",
      "Loss_G = 1.83090782 (ave = 1.80879970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.993255238743073, value max: 0.8651071190834045\n",
      "D grad l2-norm: 12.038743054236125, value max: 1.166447639465332\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.786s / 5 iters, (0.157)\tData load 0.729s / 5 iters, (0.145829)\n",
      "Loss_D = 0.59676230 (ave = 0.65976309)\n",
      "Loss_G = 1.81951880 (ave = 1.81366529)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.730398819494024, value max: 0.8869198560714722\n",
      "D grad l2-norm: 11.80785883254115, value max: 1.1195073127746582\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.009s / 5 iters, (0.001813)\n",
      "Loss_D = 0.54787147 (ave = 0.64642770)\n",
      "Loss_G = 1.80281305 (ave = 1.80384552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.58185875950037, value max: 0.8303531408309937\n",
      "D grad l2-norm: 11.559972307866499, value max: 1.0601471662521362\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.141s / 5 iters, (0.028)\tData load 0.033s / 5 iters, (0.006569)\n",
      "Loss_D = 0.63590872 (ave = 0.64820683)\n",
      "Loss_G = 1.74080932 (ave = 1.79819293)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.567870282586513, value max: 0.8128595352172852\n",
      "D grad l2-norm: 11.232406370902781, value max: 0.9648044109344482\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.016s / 5 iters, (0.003234)\n",
      "Loss_D = 0.59436882 (ave = 0.64407159)\n",
      "Loss_G = 1.76885176 (ave = 1.78521459)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.516619234441405, value max: 0.8099550008773804\n",
      "D grad l2-norm: 11.269448755229334, value max: 0.948509931564331\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.016s / 5 iters, (0.003253)\n",
      "Loss_D = 0.84294975 (ave = 0.66611409)\n",
      "Loss_G = 1.79053831 (ave = 1.78695865)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.842901735854253, value max: 0.8457202315330505\n",
      "D grad l2-norm: 11.263046236167337, value max: 0.9334666728973389\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.027s / 5 iters, (0.005316)\n",
      "Loss_D = 0.52308691 (ave = 0.62568631)\n",
      "Loss_G = 1.68324685 (ave = 1.72049186)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.10522366672217, value max: 0.8606386184692383\n",
      "D grad l2-norm: 10.989186432185653, value max: 0.892117977142334\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 0.72121847 (ave = 0.65822921)\n",
      "Loss_G = 1.67160356 (ave = 1.69474902)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.582959935871873, value max: 0.8517829179763794\n",
      "D grad l2-norm: 10.632318608169907, value max: 0.8722749948501587\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.013s / 5 iters, (0.002677)\n",
      "Loss_D = 0.49010676 (ave = 0.62918967)\n",
      "Loss_G = 1.67562783 (ave = 1.68455837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.369142824538498, value max: 0.7981102466583252\n",
      "D grad l2-norm: 10.366511901991649, value max: 0.8767039179801941\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.019s / 5 iters, (0.003751)\n",
      "Loss_D = 0.59159851 (ave = 0.63727579)\n",
      "Loss_G = 1.68414915 (ave = 1.69991479)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.570801088778989, value max: 0.7854588031768799\n",
      "D grad l2-norm: 10.383517111429121, value max: 0.889827311038971\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.51238400 (ave = 0.63294185)\n",
      "Loss_G = 1.67097807 (ave = 1.66408155)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.178632647116569, value max: 0.7683517932891846\n",
      "D grad l2-norm: 10.779101210607621, value max: 0.9253811836242676\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.727s / 5 iters, (0.145)\tData load 0.675s / 5 iters, (0.135016)\n",
      "Loss_D = 0.80681199 (ave = 0.68394451)\n",
      "Loss_G = 1.59681320 (ave = 1.60587473)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.966931709298878, value max: 0.7677727937698364\n",
      "D grad l2-norm: 10.269965955347638, value max: 0.8727481365203857\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.79220289 (ave = 0.69634671)\n",
      "Loss_G = 1.54124260 (ave = 1.57811232)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.816847800577882, value max: 0.7620702981948853\n",
      "D grad l2-norm: 9.980654805211461, value max: 0.8364657759666443\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.010s / 5 iters, (0.002042)\n",
      "Loss_D = 0.57851124 (ave = 0.67028556)\n",
      "Loss_G = 1.54762125 (ave = 1.53821211)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.145370630275794, value max: 0.7717304825782776\n",
      "D grad l2-norm: 9.983887877364998, value max: 0.8466752171516418\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.019s / 5 iters, (0.003872)\n",
      "Loss_D = 0.61991191 (ave = 0.68505110)\n",
      "Loss_G = 1.53722000 (ave = 1.52805524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.643490105844647, value max: 0.802875816822052\n",
      "D grad l2-norm: 10.220484286236802, value max: 0.8732643723487854\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 0.72233123 (ave = 0.71479597)\n",
      "Loss_G = 1.50589943 (ave = 1.50857637)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.210879191409699, value max: 0.7843426465988159\n",
      "D grad l2-norm: 9.71670071542692, value max: 0.8319768905639648\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001700)\n",
      "Loss_D = 0.73089683 (ave = 0.72140213)\n",
      "Loss_G = 1.46790266 (ave = 1.47243738)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.877547801469772, value max: 0.8147204518318176\n",
      "D grad l2-norm: 9.570380901237323, value max: 0.8155251145362854\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.75411868 (ave = 0.73196790)\n",
      "Loss_G = 1.49830246 (ave = 1.46913931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.763213427978476, value max: 0.8014746904373169\n",
      "D grad l2-norm: 9.649941462864856, value max: 0.8170621395111084\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.012s / 5 iters, (0.002318)\n",
      "Loss_D = 0.79603696 (ave = 0.72683934)\n",
      "Loss_G = 1.47190809 (ave = 1.50067534)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.114372645718348, value max: 0.7635506987571716\n",
      "D grad l2-norm: 9.32524888991452, value max: 0.764092743396759\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 0.68771672 (ave = 0.69327147)\n",
      "Loss_G = 1.55877542 (ave = 1.53021929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.560901984479711, value max: 0.7076154351234436\n",
      "D grad l2-norm: 9.36449711747594, value max: 0.7836917042732239\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.51971930 (ave = 0.65554688)\n",
      "Loss_G = 1.59772563 (ave = 1.57295401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.41996491229915, value max: 0.7056604623794556\n",
      "D grad l2-norm: 9.49166219469093, value max: 0.7915200591087341\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.853s / 5 iters, (0.171)\tData load 0.801s / 5 iters, (0.160101)\n",
      "Loss_D = 0.66756058 (ave = 0.66417620)\n",
      "Loss_G = 1.59053767 (ave = 1.59990528)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.303713236423201, value max: 0.7086730599403381\n",
      "D grad l2-norm: 9.38168518045919, value max: 0.789374828338623\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.007s / 5 iters, (0.001495)\n",
      "Loss_D = 0.60376269 (ave = 0.64913408)\n",
      "Loss_G = 1.63187408 (ave = 1.63534117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.39539768646766, value max: 0.7456687688827515\n",
      "D grad l2-norm: 9.552663571174032, value max: 0.7987795472145081\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.74191147 (ave = 0.65825962)\n",
      "Loss_G = 1.64655328 (ave = 1.64300828)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.30972515096371, value max: 0.7555222511291504\n",
      "D grad l2-norm: 9.503221623608963, value max: 0.8010754585266113\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 0.49563855 (ave = 0.61942950)\n",
      "Loss_G = 1.69546437 (ave = 1.65057175)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.332809421739558, value max: 0.7754295468330383\n",
      "D grad l2-norm: 9.785441313589377, value max: 0.8350266814231873\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.68746686 (ave = 0.63447798)\n",
      "Loss_G = 1.71150327 (ave = 1.68738408)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.739605116582297, value max: 0.7171261310577393\n",
      "D grad l2-norm: 9.486923989140465, value max: 0.8446248769760132\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.56469536 (ave = 0.60639341)\n",
      "Loss_G = 1.72989631 (ave = 1.72642789)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.271194916694986, value max: 0.6678338050842285\n",
      "D grad l2-norm: 9.355579075687011, value max: 0.847984254360199\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 0.68829972 (ave = 0.60264995)\n",
      "Loss_G = 1.76181853 (ave = 1.76849546)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.68161005960596, value max: 0.6938909888267517\n",
      "D grad l2-norm: 9.625209618966796, value max: 0.8739319443702698\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 0.66285551 (ave = 0.59804895)\n",
      "Loss_G = 1.74098158 (ave = 1.74666541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.334698249868493, value max: 0.816016435623169\n",
      "D grad l2-norm: 9.841742695955771, value max: 0.8732664585113525\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.010s / 5 iters, (0.001965)\n",
      "Loss_D = 0.59443748 (ave = 0.59791318)\n",
      "Loss_G = 1.72077608 (ave = 1.71223767)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.614261494034427, value max: 0.8576377630233765\n",
      "D grad l2-norm: 9.711151782794856, value max: 0.8423016667366028\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 0.58060038 (ave = 0.60983882)\n",
      "Loss_G = 1.65702212 (ave = 1.65964775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.724584157952542, value max: 0.8986205458641052\n",
      "D grad l2-norm: 9.489587067134206, value max: 0.8022992610931396\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 2\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.006s / 5 iters, (0.001146)\n",
      "Loss_D = 1.36223555 (ave = 1.37355530)\n",
      "Loss_G = 0.71463627 (ave = 0.71632613)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9650855642119921, value max: 0.018278606235980988\n",
      "D grad l2-norm: 0.7065323916816278, value max: 0.5106271505355835\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.772s / 5 iters, (0.154)\tData load 0.651s / 5 iters, (0.130221)\n",
      "Loss_D = 1.35950124 (ave = 1.36048291)\n",
      "Loss_G = 0.71243751 (ave = 0.71347984)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968816242116772, value max: 0.01920885220170021\n",
      "D grad l2-norm: 0.7077643614351933, value max: 0.509550154209137\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.444s / 5 iters, (0.089)\tData load 0.385s / 5 iters, (0.077002)\n",
      "Loss_D = 1.34149587 (ave = 1.34568055)\n",
      "Loss_G = 0.70907843 (ave = 0.71030532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9628451814637019, value max: 0.017872080206871033\n",
      "D grad l2-norm: 0.7048463885057604, value max: 0.5079003572463989\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.454s / 5 iters, (0.091)\tData load 0.397s / 5 iters, (0.079454)\n",
      "Loss_D = 1.32785225 (ave = 1.33202732)\n",
      "Loss_G = 0.70752323 (ave = 0.70799114)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9631706627968268, value max: 0.021140486001968384\n",
      "D grad l2-norm: 0.7068103808945391, value max: 0.5071341395378113\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.492s / 5 iters, (0.098)\tData load 0.440s / 5 iters, (0.088094)\n",
      "Loss_D = 1.32691860 (ave = 1.32017853)\n",
      "Loss_G = 0.70593685 (ave = 0.70631071)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9697262891804947, value max: 0.027673264965415\n",
      "D grad l2-norm: 0.7042173118997608, value max: 0.506351888179779\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.440s / 5 iters, (0.088)\tData load 0.332s / 5 iters, (0.066318)\n",
      "Loss_D = 1.30737340 (ave = 1.30605385)\n",
      "Loss_G = 0.70327306 (ave = 0.70393790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.965191671463435, value max: 0.0188753604888916\n",
      "D grad l2-norm: 0.7050105021167958, value max: 0.5050349831581116\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.606s / 5 iters, (0.121)\tData load 0.497s / 5 iters, (0.099349)\n",
      "Loss_D = 1.27947879 (ave = 1.29138117)\n",
      "Loss_G = 0.70178246 (ave = 0.70255080)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9681623273069991, value max: 0.022372571751475334\n",
      "D grad l2-norm: 0.7068119628929369, value max: 0.504296600818634\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.450s / 5 iters, (0.090)\tData load 0.396s / 5 iters, (0.079232)\n",
      "Loss_D = 1.27493191 (ave = 1.27981491)\n",
      "Loss_G = 0.70055497 (ave = 0.70123502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9674808285545509, value max: 0.0267484150826931\n",
      "D grad l2-norm: 0.7087725466134029, value max: 0.5036873817443848\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.421s / 5 iters, (0.084)\tData load 0.372s / 5 iters, (0.074435)\n",
      "Loss_D = 1.27191424 (ave = 1.26868470)\n",
      "Loss_G = 0.69909757 (ave = 0.69980590)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9675038767519484, value max: 0.02633185312151909\n",
      "D grad l2-norm: 0.710438952146864, value max: 0.502963662147522\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.467s / 5 iters, (0.093)\tData load 0.412s / 5 iters, (0.082462)\n",
      "Loss_D = 1.24312377 (ave = 1.25443044)\n",
      "Loss_G = 0.69813120 (ave = 0.69861661)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9660374152166396, value max: 0.02504602074623108\n",
      "D grad l2-norm: 0.7138257109125936, value max: 0.5024830102920532\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.853s / 5 iters, (0.171)\tData load 0.750s / 5 iters, (0.149919)\n",
      "Loss_D = 1.24025226 (ave = 1.24361980)\n",
      "Loss_G = 0.69660485 (ave = 0.69730097)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9668275408267911, value max: 0.029856979846954346\n",
      "D grad l2-norm: 0.7170782522564961, value max: 0.5017222762107849\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.011s / 5 iters, (0.002190)\n",
      "Loss_D = 1.23676300 (ave = 1.23287721)\n",
      "Loss_G = 0.69714785 (ave = 0.69668601)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9709474064446706, value max: 0.027438009157776833\n",
      "D grad l2-norm: 0.7202972855201548, value max: 0.5019922852516174\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.019s / 5 iters, (0.003880)\n",
      "Loss_D = 1.21952963 (ave = 1.22016525)\n",
      "Loss_G = 0.69651711 (ave = 0.69612197)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9726598038117349, value max: 0.025425009429454803\n",
      "D grad l2-norm: 0.7230694700003929, value max: 0.5016778707504272\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 1.20032525 (ave = 1.20779817)\n",
      "Loss_G = 0.69550562 (ave = 0.69581120)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9652747491532044, value max: 0.031793802976608276\n",
      "D grad l2-norm: 0.7269086081497185, value max: 0.5011736750602722\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001542)\n",
      "Loss_D = 1.19704938 (ave = 1.19738531)\n",
      "Loss_G = 0.69526416 (ave = 0.69572856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9730548996003164, value max: 0.02763977274298668\n",
      "D grad l2-norm: 0.7309169580701446, value max: 0.5010511875152588\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.013s / 5 iters, (0.002681)\n",
      "Loss_D = 1.18407273 (ave = 1.18560498)\n",
      "Loss_G = 0.69539565 (ave = 0.69574014)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9674238567828668, value max: 0.028827004134655\n",
      "D grad l2-norm: 0.7374524716286197, value max: 0.5011165142059326\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001730)\n",
      "Loss_D = 1.14682269 (ave = 1.17120936)\n",
      "Loss_G = 0.69518334 (ave = 0.69578238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9785085275227747, value max: 0.03455066680908203\n",
      "D grad l2-norm: 0.7427591785531646, value max: 0.5010092258453369\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001747)\n",
      "Loss_D = 1.15707159 (ave = 1.16286428)\n",
      "Loss_G = 0.69637918 (ave = 0.69540192)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9774455480529223, value max: 0.027406595647335052\n",
      "D grad l2-norm: 0.7517013675024998, value max: 0.5016058683395386\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 1.13235664 (ave = 1.15050581)\n",
      "Loss_G = 0.69620508 (ave = 0.69517453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9778109394000108, value max: 0.03867971897125244\n",
      "D grad l2-norm: 0.757778523665107, value max: 0.5015153288841248\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001720)\n",
      "Loss_D = 1.13667083 (ave = 1.14272978)\n",
      "Loss_G = 0.69694835 (ave = 0.69595765)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9783137107600614, value max: 0.04682527855038643\n",
      "D grad l2-norm: 0.764529090304101, value max: 0.5018854737281799\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.663s / 5 iters, (0.133)\tData load 0.614s / 5 iters, (0.122741)\n",
      "Loss_D = 1.12995946 (ave = 1.13299985)\n",
      "Loss_G = 0.69595313 (ave = 0.69604751)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9866106852010152, value max: 0.04846625402569771\n",
      "D grad l2-norm: 0.7745520252661234, value max: 0.5013799667358398\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 5 iters, (0.027)\tData load 0.020s / 5 iters, (0.003901)\n",
      "Loss_D = 1.12147009 (ave = 1.12377217)\n",
      "Loss_G = 0.69707191 (ave = 0.69711910)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9917164688771943, value max: 0.05320998653769493\n",
      "D grad l2-norm: 0.7817612395737438, value max: 0.501940906047821\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.018s / 5 iters, (0.003610)\n",
      "Loss_D = 1.11757219 (ave = 1.11451437)\n",
      "Loss_G = 0.69744879 (ave = 0.69692302)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9910466575714897, value max: 0.05432423576712608\n",
      "D grad l2-norm: 0.7932248624641751, value max: 0.50212562084198\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 1.09443557 (ave = 1.10369861)\n",
      "Loss_G = 0.69854397 (ave = 0.69847205)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9877546872945312, value max: 0.053232673555612564\n",
      "D grad l2-norm: 0.8022475030934244, value max: 0.5026683807373047\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 1.10488868 (ave = 1.09682882)\n",
      "Loss_G = 0.69973797 (ave = 0.69929013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9948684563182257, value max: 0.05616828054189682\n",
      "D grad l2-norm: 0.8147031898831958, value max: 0.5032576322555542\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 1.06558073 (ave = 1.08291664)\n",
      "Loss_G = 0.70278001 (ave = 0.70032810)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9988209394842995, value max: 0.06165274605154991\n",
      "D grad l2-norm: 0.8275544138405563, value max: 0.5047613382339478\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 1.07486212 (ave = 1.07559581)\n",
      "Loss_G = 0.70182413 (ave = 0.70291659)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004991197206422, value max: 0.06611849367618561\n",
      "D grad l2-norm: 0.8430303204850742, value max: 0.5042737722396851\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001694)\n",
      "Loss_D = 1.06405723 (ave = 1.06500967)\n",
      "Loss_G = 0.70874351 (ave = 0.70665835)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0032544151991707, value max: 0.05983399599790573\n",
      "D grad l2-norm: 0.855011532336086, value max: 0.5076954960823059\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 1.05619121 (ave = 1.05492876)\n",
      "Loss_G = 0.71268028 (ave = 0.70951182)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0133088385019722, value max: 0.08019497990608215\n",
      "D grad l2-norm: 0.8711807493046202, value max: 0.5096314549446106\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.016s / 5 iters, (0.003276)\n",
      "Loss_D = 1.03328216 (ave = 1.04406710)\n",
      "Loss_G = 0.71645266 (ave = 0.71372898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.013079870790054, value max: 0.07039643824100494\n",
      "D grad l2-norm: 0.8881642852246339, value max: 0.5114668607711792\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.913s / 5 iters, (0.183)\tData load 0.832s / 5 iters, (0.166392)\n",
      "Loss_D = 1.04802644 (ave = 1.03655097)\n",
      "Loss_G = 0.72011763 (ave = 0.71842954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0184954196141751, value max: 0.07433636486530304\n",
      "D grad l2-norm: 0.9139102234296614, value max: 0.5132572054862976\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001704)\n",
      "Loss_D = 1.02249575 (ave = 1.02220590)\n",
      "Loss_G = 0.72600263 (ave = 0.72322894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0231365003212969, value max: 0.07426494359970093\n",
      "D grad l2-norm: 0.9345914073724705, value max: 0.5160932540893555\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.98350394 (ave = 1.00854082)\n",
      "Loss_G = 0.73090756 (ave = 0.72913916)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0245027173539638, value max: 0.07092569768428802\n",
      "D grad l2-norm: 0.9598677378567105, value max: 0.5184891223907471\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001656)\n",
      "Loss_D = 0.97515440 (ave = 0.99563904)\n",
      "Loss_G = 0.73952174 (ave = 0.73753525)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0237171255645385, value max: 0.07949388027191162\n",
      "D grad l2-norm: 0.9833652381109641, value max: 0.5225940942764282\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 0.96538746 (ave = 0.98201182)\n",
      "Loss_G = 0.75384849 (ave = 0.74860213)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0198988414267716, value max: 0.0754597932100296\n",
      "D grad l2-norm: 0.9944083330009825, value max: 0.5293858647346497\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001837)\n",
      "Loss_D = 0.95858347 (ave = 0.96862681)\n",
      "Loss_G = 0.75960505 (ave = 0.75619744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0298400655306095, value max: 0.0758785679936409\n",
      "D grad l2-norm: 1.036990033413711, value max: 0.5320928692817688\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.97661573 (ave = 0.95864654)\n",
      "Loss_G = 0.77248228 (ave = 0.76719556)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0344076931898216, value max: 0.07305643707513809\n",
      "D grad l2-norm: 1.06441831620281, value max: 0.5380794405937195\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.011s / 5 iters, (0.002165)\n",
      "Loss_D = 0.92639005 (ave = 0.93773845)\n",
      "Loss_G = 0.78101230 (ave = 0.77745008)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.044947301144139, value max: 0.08834177255630493\n",
      "D grad l2-norm: 1.0941557759485983, value max: 0.5420083999633789\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.013s / 5 iters, (0.002690)\n",
      "Loss_D = 0.90674043 (ave = 0.92359395)\n",
      "Loss_G = 0.79501677 (ave = 0.78998828)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0512577924150084, value max: 0.09187828004360199\n",
      "D grad l2-norm: 1.1256509063775246, value max: 0.5483835935592651\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 0.90764916 (ave = 0.91006832)\n",
      "Loss_G = 0.80492723 (ave = 0.80315547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0682020718787906, value max: 0.09277282655239105\n",
      "D grad l2-norm: 1.1600708610441566, value max: 0.5528315901756287\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.774s / 5 iters, (0.155)\tData load 0.715s / 5 iters, (0.143033)\n",
      "Loss_D = 0.87047625 (ave = 0.89326531)\n",
      "Loss_G = 0.82003433 (ave = 0.81413728)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0783201487741643, value max: 0.0955505520105362\n",
      "D grad l2-norm: 1.158503234082653, value max: 0.559536337852478\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001817)\n",
      "Loss_D = 0.86637437 (ave = 0.88173577)\n",
      "Loss_G = 0.82913721 (ave = 0.82527370)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0812986971343006, value max: 0.08727896958589554\n",
      "D grad l2-norm: 1.1788753998544415, value max: 0.5635215640068054\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001744)\n",
      "Loss_D = 0.87495190 (ave = 0.87144706)\n",
      "Loss_G = 0.83761638 (ave = 0.83337377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1113590385674477, value max: 0.10101952403783798\n",
      "D grad l2-norm: 1.2164519166711931, value max: 0.5672085881233215\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.014s / 5 iters, (0.002893)\n",
      "Loss_D = 0.86592251 (ave = 0.86096883)\n",
      "Loss_G = 0.84440655 (ave = 0.84178431)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1336198573574154, value max: 0.11129502952098846\n",
      "D grad l2-norm: 1.2605293383932215, value max: 0.5701254606246948\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003378)\n",
      "Loss_D = 0.85567993 (ave = 0.85213523)\n",
      "Loss_G = 0.85059142 (ave = 0.84736609)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.155125528909413, value max: 0.11441262066364288\n",
      "D grad l2-norm: 1.2907011619469686, value max: 0.5727837085723877\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 0.85971141 (ave = 0.84468660)\n",
      "Loss_G = 0.85520291 (ave = 0.85432420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1769033102161464, value max: 0.11387059092521667\n",
      "D grad l2-norm: 1.3105526790904896, value max: 0.5747329592704773\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001716)\n",
      "Loss_D = 0.86444271 (ave = 0.83924469)\n",
      "Loss_G = 0.86193937 (ave = 0.85894600)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1981478256687594, value max: 0.1187482699751854\n",
      "D grad l2-norm: 1.3334035584978023, value max: 0.5776005387306213\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.026s / 5 iters, (0.005125)\n",
      "Loss_D = 0.82013857 (ave = 0.82871386)\n",
      "Loss_G = 0.86228597 (ave = 0.86207120)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2308744049336655, value max: 0.1121317446231842\n",
      "D grad l2-norm: 1.3639528256754805, value max: 0.5777272582054138\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001754)\n",
      "Loss_D = 0.81887299 (ave = 0.82590934)\n",
      "Loss_G = 0.86308920 (ave = 0.86320660)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.260986782226498, value max: 0.11593589931726456\n",
      "D grad l2-norm: 1.3872176786048431, value max: 0.578044056892395\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.83731222 (ave = 0.82428139)\n",
      "Loss_G = 0.86640716 (ave = 0.86483297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2985631420422348, value max: 0.1208464652299881\n",
      "D grad l2-norm: 1.4264628061153937, value max: 0.5794438123703003\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.768s / 5 iters, (0.154)\tData load 0.699s / 5 iters, (0.139786)\n",
      "Loss_D = 0.84700406 (ave = 0.82538705)\n",
      "Loss_G = 0.86317933 (ave = 0.86099259)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3237013476172799, value max: 0.12569192051887512\n",
      "D grad l2-norm: 1.442970653114101, value max: 0.5780647993087769\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 0.74845964 (ave = 0.81247587)\n",
      "Loss_G = 0.86498910 (ave = 0.86562088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3526975867398072, value max: 0.12543459236621857\n",
      "D grad l2-norm: 1.4772197287351743, value max: 0.5788024067878723\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 0.84272313 (ave = 0.82225578)\n",
      "Loss_G = 0.86668479 (ave = 0.86625756)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3746175185461442, value max: 0.12028302997350693\n",
      "D grad l2-norm: 1.5207030663603507, value max: 0.5795197486877441\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 0.83295155 (ave = 0.81909436)\n",
      "Loss_G = 0.87587404 (ave = 0.87219056)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3971060745483563, value max: 0.12228165566921234\n",
      "D grad l2-norm: 1.5521872020892833, value max: 0.5833074450492859\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 0.81073117 (ave = 0.81171110)\n",
      "Loss_G = 0.88027799 (ave = 0.87879878)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4491621726020263, value max: 0.11983992159366608\n",
      "D grad l2-norm: 1.6069899327137012, value max: 0.5851551294326782\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 0.78075641 (ave = 0.80402815)\n",
      "Loss_G = 0.88778132 (ave = 0.88376874)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4514491256379203, value max: 0.13095331192016602\n",
      "D grad l2-norm: 1.6175091277434863, value max: 0.5882281064987183\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 0.77426422 (ave = 0.79851555)\n",
      "Loss_G = 0.89331603 (ave = 0.88762325)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4919587202892808, value max: 0.1378907412290573\n",
      "D grad l2-norm: 1.6510552453517888, value max: 0.5905083417892456\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001622)\n",
      "Loss_D = 0.80940449 (ave = 0.79771307)\n",
      "Loss_G = 0.89947629 (ave = 0.89609399)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5390494850107994, value max: 0.14976078271865845\n",
      "D grad l2-norm: 1.6808097202866896, value max: 0.5929813385009766\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.017s / 5 iters, (0.003380)\n",
      "Loss_D = 0.82541919 (ave = 0.79862537)\n",
      "Loss_G = 0.89720321 (ave = 0.89708296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6183230629849217, value max: 0.1793619692325592\n",
      "D grad l2-norm: 1.723473465632544, value max: 0.5919559001922607\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001578)\n",
      "Loss_D = 0.82101589 (ave = 0.79709300)\n",
      "Loss_G = 0.89363337 (ave = 0.89928868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7182961765089797, value max: 0.20150168240070343\n",
      "D grad l2-norm: 1.765269354751049, value max: 0.5904865860939026\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.771s / 5 iters, (0.154)\tData load 0.672s / 5 iters, (0.134487)\n",
      "Loss_D = 0.79212713 (ave = 0.79765526)\n",
      "Loss_G = 0.89147270 (ave = 0.89782368)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.762298181034828, value max: 0.22091737389564514\n",
      "D grad l2-norm: 1.7614006787247602, value max: 0.58953458070755\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.150s / 5 iters, (0.030)\tData load 0.023s / 5 iters, (0.004656)\n",
      "Loss_D = 0.75875497 (ave = 0.80125821)\n",
      "Loss_G = 0.89053392 (ave = 0.89136387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.816109801023772, value max: 0.24737435579299927\n",
      "D grad l2-norm: 1.7832418774592114, value max: 0.5892269611358643\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.034s / 5 iters, (0.006809)\n",
      "Loss_D = 0.83648676 (ave = 0.81432747)\n",
      "Loss_G = 0.88048220 (ave = 0.88560919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8606808172750664, value max: 0.26294541358947754\n",
      "D grad l2-norm: 1.8241078249011422, value max: 0.5850139260292053\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.022s / 5 iters, (0.004426)\n",
      "Loss_D = 0.87720609 (ave = 0.82380306)\n",
      "Loss_G = 0.88115120 (ave = 0.88625923)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.876162086538251, value max: 0.28328874707221985\n",
      "D grad l2-norm: 1.8316083929260778, value max: 0.5851600170135498\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001593)\n",
      "Loss_D = 0.84738797 (ave = 0.82157739)\n",
      "Loss_G = 0.88776517 (ave = 0.88300859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9350235424841815, value max: 0.289786696434021\n",
      "D grad l2-norm: 1.8742334786379995, value max: 0.5878826379776001\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.002005)\n",
      "Loss_D = 0.80166876 (ave = 0.81417346)\n",
      "Loss_G = 0.88981318 (ave = 0.88670700)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9902414943128521, value max: 0.3057192265987396\n",
      "D grad l2-norm: 1.9315161398346765, value max: 0.5887401103973389\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.81198227 (ave = 0.81141922)\n",
      "Loss_G = 0.90059924 (ave = 0.89039327)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.00310531978322, value max: 0.3121480643749237\n",
      "D grad l2-norm: 1.9559461117697048, value max: 0.5930655002593994\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.86024010 (ave = 0.81436338)\n",
      "Loss_G = 0.90860248 (ave = 0.89709569)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9976384650029482, value max: 0.3069004416465759\n",
      "D grad l2-norm: 2.02475118238892, value max: 0.5962857604026794\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.74104911 (ave = 0.78875551)\n",
      "Loss_G = 0.91985333 (ave = 0.91532080)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0305588385458075, value max: 0.2916857600212097\n",
      "D grad l2-norm: 2.0900585375229537, value max: 0.6009383201599121\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.79976821 (ave = 0.78454195)\n",
      "Loss_G = 0.94474995 (ave = 0.93334414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0500658756174763, value max: 0.29673317074775696\n",
      "D grad l2-norm: 2.122871955958123, value max: 0.6105983257293701\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.326s / 5 iters, (0.265)\tData load 1.221s / 5 iters, (0.244144)\n",
      "Loss_D = 0.76116323 (ave = 0.77285285)\n",
      "Loss_G = 0.94383544 (ave = 0.94647945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1674890556886104, value max: 0.29389578104019165\n",
      "D grad l2-norm: 2.2049471607491364, value max: 0.6102908849716187\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 0.82726002 (ave = 0.77503041)\n",
      "Loss_G = 0.95563561 (ave = 0.95869318)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.242903575863067, value max: 0.28294676542282104\n",
      "D grad l2-norm: 2.292794209870092, value max: 0.614902138710022\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001729)\n",
      "Loss_D = 0.80261624 (ave = 0.76947162)\n",
      "Loss_G = 0.96642679 (ave = 0.96446282)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.346844446667169, value max: 0.27928027510643005\n",
      "D grad l2-norm: 2.3598384450432937, value max: 0.6187130808830261\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 0.85755646 (ave = 0.77733591)\n",
      "Loss_G = 0.96923411 (ave = 0.96949029)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.461926641527863, value max: 0.25753459334373474\n",
      "D grad l2-norm: 2.456763390380915, value max: 0.6194915175437927\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 5 iters, (0.021)\tData load 0.017s / 5 iters, (0.003380)\n",
      "Loss_D = 0.85479575 (ave = 0.78345237)\n",
      "Loss_G = 0.94442415 (ave = 0.95406786)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6159787656632574, value max: 0.2458856850862503\n",
      "D grad l2-norm: 2.5293641066569648, value max: 0.6099866628646851\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.141s / 5 iters, (0.028)\tData load 0.009s / 5 iters, (0.001742)\n",
      "Loss_D = 0.72179615 (ave = 0.77499952)\n",
      "Loss_G = 0.95752305 (ave = 0.94760904)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6544994803624813, value max: 0.24940596520900726\n",
      "D grad l2-norm: 2.5802251758535792, value max: 0.614728569984436\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.011s / 5 iters, (0.002137)\n",
      "Loss_D = 0.77302748 (ave = 0.79373497)\n",
      "Loss_G = 0.93037438 (ave = 0.93578279)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8869470631606355, value max: 0.2534759044647217\n",
      "D grad l2-norm: 2.7588219173445347, value max: 0.6042435169219971\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.002056)\n",
      "Loss_D = 1.00393224 (ave = 0.83457910)\n",
      "Loss_G = 0.90955412 (ave = 0.92846396)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.05958441841658, value max: 0.2810414731502533\n",
      "D grad l2-norm: 2.837094211646435, value max: 0.5956118106842041\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.011s / 5 iters, (0.002235)\n",
      "Loss_D = 0.86680949 (ave = 0.84852090)\n",
      "Loss_G = 0.89855361 (ave = 0.89493366)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1450418305945114, value max: 0.2873861789703369\n",
      "D grad l2-norm: 2.8616924223425793, value max: 0.5909581780433655\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001693)\n",
      "Loss_D = 0.84565961 (ave = 0.86336125)\n",
      "Loss_G = 0.89148647 (ave = 0.88972399)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.21686792360063, value max: 0.2974163889884949\n",
      "D grad l2-norm: 3.014214477200151, value max: 0.5876166820526123\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.718s / 5 iters, (0.144)\tData load 0.661s / 5 iters, (0.132148)\n",
      "Loss_D = 0.76653206 (ave = 0.85875039)\n",
      "Loss_G = 0.92170990 (ave = 0.90110571)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.195399508902345, value max: 0.32739800214767456\n",
      "D grad l2-norm: 3.1633347172931137, value max: 0.6005352735519409\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001786)\n",
      "Loss_D = 0.96363705 (ave = 0.86442693)\n",
      "Loss_G = 0.96195704 (ave = 0.93485558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2161490024437467, value max: 0.34304770827293396\n",
      "D grad l2-norm: 3.379508191549378, value max: 0.6163376569747925\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.81308889 (ave = 0.82639143)\n",
      "Loss_G = 0.99987507 (ave = 0.98011719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.288074574398603, value max: 0.3505485951900482\n",
      "D grad l2-norm: 3.6017376825544343, value max: 0.63025963306427\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001530)\n",
      "Loss_D = 0.73196995 (ave = 0.79007243)\n",
      "Loss_G = 1.05859900 (ave = 1.04330301)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.485917839366703, value max: 0.39165186882019043\n",
      "D grad l2-norm: 3.8776396869639087, value max: 0.6518071293830872\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.010s / 5 iters, (0.001929)\n",
      "Loss_D = 0.73107529 (ave = 0.76481359)\n",
      "Loss_G = 1.10588527 (ave = 1.09191649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.691797668351963, value max: 0.41324344277381897\n",
      "D grad l2-norm: 4.0564207991984835, value max: 0.6670172214508057\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001704)\n",
      "Loss_D = 0.80719566 (ave = 0.77046472)\n",
      "Loss_G = 1.12461805 (ave = 1.11775148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9324580678496233, value max: 0.44131234288215637\n",
      "D grad l2-norm: 4.247054624406004, value max: 0.6735341548919678\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 0.72534639 (ave = 0.75771247)\n",
      "Loss_G = 1.15513039 (ave = 1.13486283)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.136354341723158, value max: 0.4229077696800232\n",
      "D grad l2-norm: 4.486544163462561, value max: 0.6829304695129395\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 0.85702443 (ave = 0.77732198)\n",
      "Loss_G = 1.15371227 (ave = 1.15262892)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.213607196208272, value max: 0.3940729796886444\n",
      "D grad l2-norm: 4.645554662714986, value max: 0.6829966306686401\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.85815847 (ave = 0.76789299)\n",
      "Loss_G = 1.18636894 (ave = 1.17954712)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.212724027786191, value max: 0.3734837472438812\n",
      "D grad l2-norm: 4.784107626120075, value max: 0.6931520700454712\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001623)\n",
      "Loss_D = 0.76498884 (ave = 0.74086833)\n",
      "Loss_G = 1.23853445 (ave = 1.21954710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.40244902381905, value max: 0.3449545204639435\n",
      "D grad l2-norm: 5.14413601026806, value max: 0.7085899114608765\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.037s / 5 iters, (0.207)\tData load 0.986s / 5 iters, (0.197118)\n",
      "Loss_D = 0.80589175 (ave = 0.73123542)\n",
      "Loss_G = 1.30028319 (ave = 1.27568188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.304015162997556, value max: 0.35957321524620056\n",
      "D grad l2-norm: 5.222744647638529, value max: 0.7261870503425598\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 0.58722937 (ave = 0.67935330)\n",
      "Loss_G = 1.35229158 (ave = 1.33748245)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.660217786987694, value max: 0.40332719683647156\n",
      "D grad l2-norm: 5.579118258668276, value max: 0.7400097250938416\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.74836040 (ave = 0.68764582)\n",
      "Loss_G = 1.37467909 (ave = 1.37159140)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.156346524595637, value max: 0.44795241951942444\n",
      "D grad l2-norm: 5.88120149107422, value max: 0.7458908557891846\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001622)\n",
      "Loss_D = 0.71476239 (ave = 0.68192550)\n",
      "Loss_G = 1.39547276 (ave = 1.40251296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.164509199468921, value max: 0.47006598114967346\n",
      "D grad l2-norm: 5.838753242147889, value max: 0.7509357333183289\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.67354047 (ave = 0.67624338)\n",
      "Loss_G = 1.39084792 (ave = 1.38673553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.4678712578052675, value max: 0.48288944363594055\n",
      "D grad l2-norm: 6.065501428281707, value max: 0.7494542598724365\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001587)\n",
      "Loss_D = 0.68006730 (ave = 0.68192384)\n",
      "Loss_G = 1.39530933 (ave = 1.40479755)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.387204399883508, value max: 0.49268367886543274\n",
      "D grad l2-norm: 5.945917686450519, value max: 0.7499980926513672\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001575)\n",
      "Loss_D = 0.71429646 (ave = 0.69025176)\n",
      "Loss_G = 1.38789010 (ave = 1.39795742)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.851951991258366, value max: 0.5047301650047302\n",
      "D grad l2-norm: 6.195655489560766, value max: 0.7478993535041809\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.75327349 (ave = 0.72250979)\n",
      "Loss_G = 1.35725904 (ave = 1.36123171)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.917297082227392, value max: 0.5115544199943542\n",
      "D grad l2-norm: 6.038600468998286, value max: 0.7400171160697937\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 0.87117887 (ave = 0.75775094)\n",
      "Loss_G = 1.33595061 (ave = 1.33946238)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.025684677738731, value max: 0.4871167242527008\n",
      "D grad l2-norm: 6.070550680181392, value max: 0.7335681915283203\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.82224280 (ave = 0.77151066)\n",
      "Loss_G = 1.29220581 (ave = 1.29792485)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.929946831243325, value max: 0.4554119110107422\n",
      "D grad l2-norm: 6.031376515939066, value max: 0.7221631407737732\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.722s / 5 iters, (0.144)\tData load 0.674s / 5 iters, (0.134792)\n",
      "Loss_D = 0.87122846 (ave = 0.78853066)\n",
      "Loss_G = 1.29879725 (ave = 1.28748918)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.7897586008085735, value max: 0.4640706777572632\n",
      "D grad l2-norm: 5.992030047724376, value max: 0.722852885723114\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 0.77029479 (ave = 0.78649262)\n",
      "Loss_G = 1.28527510 (ave = 1.28400762)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.069887951987242, value max: 0.4912567436695099\n",
      "D grad l2-norm: 6.126270295322341, value max: 0.7204005122184753\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001824)\n",
      "Loss_D = 0.85445631 (ave = 0.81597739)\n",
      "Loss_G = 1.25627184 (ave = 1.26537189)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.249483652651366, value max: 0.4970526099205017\n",
      "D grad l2-norm: 6.114503192852195, value max: 0.7102471590042114\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001883)\n",
      "Loss_D = 0.68587101 (ave = 0.81873468)\n",
      "Loss_G = 1.22129679 (ave = 1.23174710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.519902692964871, value max: 0.5296346545219421\n",
      "D grad l2-norm: 6.137048410612596, value max: 0.7008402347564697\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.018s / 5 iters, (0.003532)\n",
      "Loss_D = 0.99727494 (ave = 0.88953544)\n",
      "Loss_G = 1.21584320 (ave = 1.21004479)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.443858273113217, value max: 0.5314598083496094\n",
      "D grad l2-norm: 6.030335063482426, value max: 0.69770747423172\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.017s / 5 iters, (0.003367)\n",
      "Loss_D = 0.95721126 (ave = 0.91314521)\n",
      "Loss_G = 1.21495020 (ave = 1.19294586)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.494899672349543, value max: 0.5201086401939392\n",
      "D grad l2-norm: 6.231814277158614, value max: 0.6985124349594116\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.018s / 5 iters, (0.003691)\n",
      "Loss_D = 0.76975834 (ave = 0.88250480)\n",
      "Loss_G = 1.22711420 (ave = 1.22067609)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.57199530197623, value max: 0.5193191766738892\n",
      "D grad l2-norm: 6.511096032510902, value max: 0.7025871276855469\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.012s / 5 iters, (0.002437)\n",
      "Loss_D = 0.92425609 (ave = 0.87796271)\n",
      "Loss_G = 1.28801417 (ave = 1.26882277)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.652404161386296, value max: 0.5168778896331787\n",
      "D grad l2-norm: 6.812951746337162, value max: 0.7202290892601013\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.69781685 (ave = 0.83444803)\n",
      "Loss_G = 1.32579494 (ave = 1.31014712)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.654489290225415, value max: 0.5334545373916626\n",
      "D grad l2-norm: 6.969997338279629, value max: 0.730857253074646\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 0.66078198 (ave = 0.80658963)\n",
      "Loss_G = 1.37729335 (ave = 1.35769596)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.4173067036538445, value max: 0.5112484693527222\n",
      "D grad l2-norm: 7.119006731441259, value max: 0.745284914970398\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.696s / 5 iters, (0.139)\tData load 0.637s / 5 iters, (0.127498)\n",
      "Loss_D = 0.74477303 (ave = 0.78964058)\n",
      "Loss_G = 1.45726442 (ave = 1.42138150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.309006126920338, value max: 0.5084348320960999\n",
      "D grad l2-norm: 7.375151156931676, value max: 0.7653507590293884\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001889)\n",
      "Loss_D = 0.68499339 (ave = 0.74985807)\n",
      "Loss_G = 1.52489579 (ave = 1.49523425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.246114227303789, value max: 0.4960279166698456\n",
      "D grad l2-norm: 7.539460563303092, value max: 0.7936279773712158\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001831)\n",
      "Loss_D = 0.58507437 (ave = 0.70903039)\n",
      "Loss_G = 1.57126808 (ave = 1.53609772)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.980002519126062, value max: 0.46176692843437195\n",
      "D grad l2-norm: 7.428222039969928, value max: 0.7970850467681885\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.009s / 5 iters, (0.001838)\n",
      "Loss_D = 0.70440614 (ave = 0.69563869)\n",
      "Loss_G = 1.59237373 (ave = 1.59003315)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.2246791270887964, value max: 0.43402084708213806\n",
      "D grad l2-norm: 7.856531908872675, value max: 0.811640739440918\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.019s / 5 iters, (0.003719)\n",
      "Loss_D = 0.72985297 (ave = 0.68170422)\n",
      "Loss_G = 1.62505829 (ave = 1.62194104)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.108596760455985, value max: 0.39805087447166443\n",
      "D grad l2-norm: 7.733255013085427, value max: 0.8016448616981506\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.010s / 5 iters, (0.001934)\n",
      "Loss_D = 0.51827776 (ave = 0.63761684)\n",
      "Loss_G = 1.66248441 (ave = 1.64068820)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.246542790607247, value max: 0.4241846799850464\n",
      "D grad l2-norm: 7.8741341870148895, value max: 0.81349778175354\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.020s / 5 iters, (0.004048)\n",
      "Loss_D = 0.58453232 (ave = 0.63533336)\n",
      "Loss_G = 1.63914812 (ave = 1.63938160)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.240958507314889, value max: 0.45184576511383057\n",
      "D grad l2-norm: 7.50040245011105, value max: 0.8042357563972473\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.59445572 (ave = 0.63328000)\n",
      "Loss_G = 1.58747959 (ave = 1.60971723)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.762067526588985, value max: 0.4986512064933777\n",
      "D grad l2-norm: 7.726465614467685, value max: 0.7933990955352783\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.015s / 5 iters, (0.003009)\n",
      "Loss_D = 0.64890766 (ave = 0.64578743)\n",
      "Loss_G = 1.55948889 (ave = 1.57141852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.673196220244851, value max: 0.4987664818763733\n",
      "D grad l2-norm: 7.421628820871613, value max: 0.7878157496452332\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.68817616 (ave = 0.66050806)\n",
      "Loss_G = 1.51993036 (ave = 1.53214660)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.790220128344857, value max: 0.5112295746803284\n",
      "D grad l2-norm: 7.437851326932539, value max: 0.77850341796875\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.916s / 5 iters, (0.183)\tData load 0.778s / 5 iters, (0.155587)\n",
      "Loss_D = 0.75444275 (ave = 0.67729645)\n",
      "Loss_G = 1.47858226 (ave = 1.50383303)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.926937877967709, value max: 0.49822789430618286\n",
      "D grad l2-norm: 7.492203597410292, value max: 0.7886197566986084\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003389)\n",
      "Loss_D = 0.48498797 (ave = 0.64853282)\n",
      "Loss_G = 1.47491407 (ave = 1.46884074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.029409882073774, value max: 0.5205766558647156\n",
      "D grad l2-norm: 7.534687637786238, value max: 0.8117759823799133\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 0.63501918 (ave = 0.68288835)\n",
      "Loss_G = 1.42425299 (ave = 1.45684395)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.565084520450372, value max: 0.5521332621574402\n",
      "D grad l2-norm: 7.807035320838554, value max: 0.8462366461753845\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001743)\n",
      "Loss_D = 0.81560183 (ave = 0.72659154)\n",
      "Loss_G = 1.44913340 (ave = 1.45078082)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.944452518499495, value max: 0.5703950524330139\n",
      "D grad l2-norm: 8.219375609698858, value max: 0.9078649878501892\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 0.66427350 (ave = 0.71450520)\n",
      "Loss_G = 1.44242179 (ave = 1.43905096)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.931091208071006, value max: 0.5408561825752258\n",
      "D grad l2-norm: 8.42135991263498, value max: 0.9380192756652832\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001539)\n",
      "Loss_D = 0.63539016 (ave = 0.71104668)\n",
      "Loss_G = 1.48651433 (ave = 1.47167473)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.847447070756532, value max: 0.49796468019485474\n",
      "D grad l2-norm: 8.641261527234251, value max: 0.9933719635009766\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001741)\n",
      "Loss_D = 0.63500512 (ave = 0.70803699)\n",
      "Loss_G = 1.51771760 (ave = 1.50402372)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.757748165853501, value max: 0.5153406858444214\n",
      "D grad l2-norm: 8.71984104569054, value max: 1.0267033576965332\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 0.66501063 (ave = 0.70639402)\n",
      "Loss_G = 1.58687270 (ave = 1.55922141)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.736473673055381, value max: 0.5309773087501526\n",
      "D grad l2-norm: 8.955085583891487, value max: 1.08887779712677\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001721)\n",
      "Loss_D = 0.80395567 (ave = 0.71960678)\n",
      "Loss_G = 1.61968374 (ave = 1.58945973)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.858305204953818, value max: 0.566596269607544\n",
      "D grad l2-norm: 9.485551265725007, value max: 1.1567139625549316\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001806)\n",
      "Loss_D = 0.88813877 (ave = 0.72338146)\n",
      "Loss_G = 1.66993392 (ave = 1.64666069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.801667843818025, value max: 0.5360280275344849\n",
      "D grad l2-norm: 9.643016953751586, value max: 1.196410894393921\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.665s / 5 iters, (0.133)\tData load 0.614s / 5 iters, (0.122761)\n",
      "Loss_D = 0.68826950 (ave = 0.68348227)\n",
      "Loss_G = 1.73263359 (ave = 1.69227626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.626706795576282, value max: 0.487853080034256\n",
      "D grad l2-norm: 9.852471150949095, value max: 1.2423912286758423\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.023s / 5 iters, (0.004632)\n",
      "Loss_D = 0.75425828 (ave = 0.68213053)\n",
      "Loss_G = 1.74096191 (ave = 1.72156661)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.718104406632517, value max: 0.4950658082962036\n",
      "D grad l2-norm: 9.963926040007001, value max: 1.2584874629974365\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.020s / 5 iters, (0.004039)\n",
      "Loss_D = 0.64428270 (ave = 0.66341977)\n",
      "Loss_G = 1.75305843 (ave = 1.75090537)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.532277827656559, value max: 0.4723092019557953\n",
      "D grad l2-norm: 9.85826806253861, value max: 1.2353019714355469\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 0.57495797 (ave = 0.65243390)\n",
      "Loss_G = 1.75124598 (ave = 1.75010870)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.843793233526418, value max: 0.4689449071884155\n",
      "D grad l2-norm: 10.12177104134171, value max: 1.2296438217163086\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 0.57738984 (ave = 0.66288007)\n",
      "Loss_G = 1.72658753 (ave = 1.73985322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.52705695481835, value max: 0.4842745065689087\n",
      "D grad l2-norm: 10.245765606470188, value max: 1.1872106790542603\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.59354556 (ave = 0.68114209)\n",
      "Loss_G = 1.68761313 (ave = 1.71797924)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.029952078135832, value max: 0.5218613147735596\n",
      "D grad l2-norm: 10.317161516552822, value max: 1.1418269872665405\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001700)\n",
      "Loss_D = 0.56355238 (ave = 0.69338489)\n",
      "Loss_G = 1.69556165 (ave = 1.70837049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.094808445710836, value max: 0.5481466054916382\n",
      "D grad l2-norm: 10.267294088635374, value max: 1.095980167388916\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001749)\n",
      "Loss_D = 0.76746547 (ave = 0.72920356)\n",
      "Loss_G = 1.70085621 (ave = 1.69928341)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.397003280502608, value max: 0.5745987892150879\n",
      "D grad l2-norm: 10.357858118489023, value max: 1.0870047807693481\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.027s / 5 iters, (0.005369)\n",
      "Loss_D = 0.88730377 (ave = 0.75461535)\n",
      "Loss_G = 1.67970312 (ave = 1.67877958)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.498746123525532, value max: 0.6022322773933411\n",
      "D grad l2-norm: 10.325076520362243, value max: 1.0664273500442505\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.017s / 5 iters, (0.003442)\n",
      "Loss_D = 0.66195130 (ave = 0.73376020)\n",
      "Loss_G = 1.67998803 (ave = 1.65492024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.004976824772035, value max: 0.6627957820892334\n",
      "D grad l2-norm: 10.724471343566602, value max: 1.0949046611785889\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.923s / 5 iters, (0.185)\tData load 0.862s / 5 iters, (0.172370)\n",
      "Loss_D = 0.61477351 (ave = 0.73476335)\n",
      "Loss_G = 1.64830959 (ave = 1.66682537)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.729594796250163, value max: 0.665633499622345\n",
      "D grad l2-norm: 10.306857760561938, value max: 1.0579328536987305\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001693)\n",
      "Loss_D = 0.64264905 (ave = 0.74390210)\n",
      "Loss_G = 1.65609848 (ave = 1.64256837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.757612883839858, value max: 0.6966181397438049\n",
      "D grad l2-norm: 10.114563364437904, value max: 1.0388158559799194\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001684)\n",
      "Loss_D = 0.73238182 (ave = 0.76624213)\n",
      "Loss_G = 1.65252006 (ave = 1.64848089)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.821874946807768, value max: 0.730435311794281\n",
      "D grad l2-norm: 9.896359400004632, value max: 1.0194008350372314\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 0.70194745 (ave = 0.78868208)\n",
      "Loss_G = 1.60028708 (ave = 1.61109917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.509304039075056, value max: 0.6992394924163818\n",
      "D grad l2-norm: 10.18104418384235, value max: 1.0126680135726929\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001712)\n",
      "Loss_D = 0.83296645 (ave = 0.82902601)\n",
      "Loss_G = 1.48988676 (ave = 1.53214846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.891657138507465, value max: 0.6522683501243591\n",
      "D grad l2-norm: 10.156311799870217, value max: 0.9535333514213562\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.59336954 (ave = 0.82078074)\n",
      "Loss_G = 1.45758200 (ave = 1.48560698)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.638718413110107, value max: 0.5819082260131836\n",
      "D grad l2-norm: 9.93261189941974, value max: 0.909416675567627\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.013s / 5 iters, (0.002655)\n",
      "Loss_D = 0.75519073 (ave = 0.86338937)\n",
      "Loss_G = 1.47267497 (ave = 1.46398492)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.643409901480906, value max: 0.5641574263572693\n",
      "D grad l2-norm: 10.01791233233492, value max: 0.9322364330291748\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 0.95661306 (ave = 0.89861659)\n",
      "Loss_G = 1.43798304 (ave = 1.44267890)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.196325154249822, value max: 0.5585396885871887\n",
      "D grad l2-norm: 9.889574649411724, value max: 0.9393943548202515\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001656)\n",
      "Loss_D = 0.97077292 (ave = 0.89558449)\n",
      "Loss_G = 1.48742783 (ave = 1.48579741)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.699783510334269, value max: 0.6454020142555237\n",
      "D grad l2-norm: 9.864781884868554, value max: 0.9340016841888428\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 0.68279552 (ave = 0.83613504)\n",
      "Loss_G = 1.55059934 (ave = 1.50960059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.74786621120278, value max: 0.754908561706543\n",
      "D grad l2-norm: 10.277651029626464, value max: 0.9630603194236755\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.716s / 5 iters, (0.143)\tData load 0.666s / 5 iters, (0.133221)\n",
      "Loss_D = 0.87772298 (ave = 0.82851113)\n",
      "Loss_G = 1.61755335 (ave = 1.57959983)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.962947919568267, value max: 0.8423960208892822\n",
      "D grad l2-norm: 10.846407339967708, value max: 1.0319360494613647\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001824)\n",
      "Loss_D = 0.62796021 (ave = 0.77812852)\n",
      "Loss_G = 1.64244223 (ave = 1.61899300)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.307455167201033, value max: 0.8795746564865112\n",
      "D grad l2-norm: 11.099344135663163, value max: 1.0622636079788208\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.020s / 5 iters, (0.003902)\n",
      "Loss_D = 0.93993938 (ave = 0.80147928)\n",
      "Loss_G = 1.71468937 (ave = 1.68750098)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.582692303859984, value max: 0.8830892443656921\n",
      "D grad l2-norm: 11.233384483086537, value max: 1.0863316059112549\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 0.92373610 (ave = 0.79350538)\n",
      "Loss_G = 1.70393896 (ave = 1.68508842)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.922208118427035, value max: 0.8664068579673767\n",
      "D grad l2-norm: 11.659449728456082, value max: 1.1090307235717773\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 0.76986802 (ave = 0.75779020)\n",
      "Loss_G = 1.72060788 (ave = 1.70561845)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.990093201768776, value max: 0.867769181728363\n",
      "D grad l2-norm: 11.745636942974963, value max: 1.1583449840545654\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.015s / 5 iters, (0.002968)\n",
      "Loss_D = 0.88180906 (ave = 0.76299770)\n",
      "Loss_G = 1.75208688 (ave = 1.73176248)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.450026789247536, value max: 0.8831766247749329\n",
      "D grad l2-norm: 12.298676508464318, value max: 1.2717453241348267\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 0.87368095 (ave = 0.75958844)\n",
      "Loss_G = 1.76119161 (ave = 1.75244663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.0020644675624, value max: 0.8268848657608032\n",
      "D grad l2-norm: 11.86391144256468, value max: 1.2986267805099487\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.74745619 (ave = 0.73846575)\n",
      "Loss_G = 1.77232707 (ave = 1.76548135)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.997768509211745, value max: 0.8159619569778442\n",
      "D grad l2-norm: 11.758497974082683, value max: 1.3377771377563477\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.031s / 5 iters, (0.006213)\n",
      "Loss_D = 0.79168105 (ave = 0.74929925)\n",
      "Loss_G = 1.74300015 (ave = 1.75093188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.398423682801024, value max: 0.8683938980102539\n",
      "D grad l2-norm: 11.818336293646011, value max: 1.3615341186523438\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.018s / 5 iters, (0.003534)\n",
      "Loss_D = 0.91148371 (ave = 0.77044051)\n",
      "Loss_G = 1.70937598 (ave = 1.71321547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.68790853626715, value max: 0.9093798995018005\n",
      "D grad l2-norm: 12.053991080756834, value max: 1.385960340499878\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.741s / 5 iters, (0.148)\tData load 0.690s / 5 iters, (0.137937)\n",
      "Loss_D = 0.71844441 (ave = 0.76706003)\n",
      "Loss_G = 1.65266728 (ave = 1.66945963)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.1774844002881, value max: 0.8191685080528259\n",
      "D grad l2-norm: 11.51139125874757, value max: 1.3296984434127808\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 0.66169190 (ave = 0.76047988)\n",
      "Loss_G = 1.66562200 (ave = 1.67756591)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.746270103070335, value max: 0.744296669960022\n",
      "D grad l2-norm: 11.416716311077929, value max: 1.3433557748794556\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001603)\n",
      "Loss_D = 0.59260535 (ave = 0.74921089)\n",
      "Loss_G = 1.67266357 (ave = 1.66000566)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.25800269420951, value max: 0.6698655486106873\n",
      "D grad l2-norm: 11.26943739748961, value max: 1.3219726085662842\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.99975580 (ave = 0.79515668)\n",
      "Loss_G = 1.78115129 (ave = 1.69823673)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.17405168411207, value max: 0.639150083065033\n",
      "D grad l2-norm: 11.299027547886459, value max: 1.3394697904586792\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001557)\n",
      "Loss_D = 0.87589014 (ave = 0.77338170)\n",
      "Loss_G = 1.72661924 (ave = 1.71222377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.420998335792204, value max: 0.6198782324790955\n",
      "D grad l2-norm: 11.03369425309403, value max: 1.2646652460098267\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.007s / 5 iters, (0.001480)\n",
      "Loss_D = 0.67863679 (ave = 0.73364025)\n",
      "Loss_G = 1.72784388 (ave = 1.72659209)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.272888852026657, value max: 0.6051487326622009\n",
      "D grad l2-norm: 10.841992647833012, value max: 1.1917805671691895\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.014s / 5 iters, (0.002746)\n",
      "Loss_D = 0.62702048 (ave = 0.71524792)\n",
      "Loss_G = 1.76740956 (ave = 1.73900142)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.424914060493558, value max: 0.5821434259414673\n",
      "D grad l2-norm: 11.009226708371562, value max: 1.1643030643463135\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.010s / 5 iters, (0.001926)\n",
      "Loss_D = 0.49983764 (ave = 0.69454546)\n",
      "Loss_G = 1.73930395 (ave = 1.75614443)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.288826253683677, value max: 0.5994040369987488\n",
      "D grad l2-norm: 10.678378045806602, value max: 1.1374279260635376\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 0.94540846 (ave = 0.75416454)\n",
      "Loss_G = 1.70580959 (ave = 1.73329659)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.559682971284177, value max: 0.646062970161438\n",
      "D grad l2-norm: 10.772120952168269, value max: 1.1481404304504395\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.60509193 (ave = 0.71583307)\n",
      "Loss_G = 1.69527376 (ave = 1.71762447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.590614170912936, value max: 0.6493623852729797\n",
      "D grad l2-norm: 10.514853431844672, value max: 1.1129636764526367\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.922s / 5 iters, (0.184)\tData load 0.822s / 5 iters, (0.164448)\n",
      "Loss_D = 0.83108020 (ave = 0.73596413)\n",
      "Loss_G = 1.68363893 (ave = 1.70593503)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.687943835799523, value max: 0.684783399105072\n",
      "D grad l2-norm: 10.500633472158224, value max: 1.0997973680496216\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002326)\n",
      "Loss_D = 0.72112316 (ave = 0.73159022)\n",
      "Loss_G = 1.70308280 (ave = 1.71540964)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.76100520902324, value max: 0.6808151602745056\n",
      "D grad l2-norm: 10.593614591529727, value max: 1.1053160429000854\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.63448608 (ave = 0.70529320)\n",
      "Loss_G = 1.72206354 (ave = 1.70966933)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.989123292624932, value max: 0.7737083435058594\n",
      "D grad l2-norm: 10.830105226036686, value max: 1.1414004564285278\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.019s / 5 iters, (0.003705)\n",
      "Loss_D = 0.82423687 (ave = 0.72490978)\n",
      "Loss_G = 1.68633485 (ave = 1.70822976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.781173126265028, value max: 0.8167411088943481\n",
      "D grad l2-norm: 10.677151915015447, value max: 1.122441291809082\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001638)\n",
      "Loss_D = 0.67001432 (ave = 0.70024979)\n",
      "Loss_G = 1.77666736 (ave = 1.72661872)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.038387123133015, value max: 0.8089216947555542\n",
      "D grad l2-norm: 10.908646763142906, value max: 1.173105001449585\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001581)\n",
      "Loss_D = 0.73942792 (ave = 0.70028100)\n",
      "Loss_G = 1.71430540 (ave = 1.72878258)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.376594265962531, value max: 0.842418372631073\n",
      "D grad l2-norm: 10.641375067863473, value max: 1.1184337139129639\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.73220110 (ave = 0.70093342)\n",
      "Loss_G = 1.68462229 (ave = 1.69819016)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.863737570951669, value max: 0.8590500950813293\n",
      "D grad l2-norm: 10.70399365081834, value max: 1.1121958494186401\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 0.82816875 (ave = 0.72201281)\n",
      "Loss_G = 1.64644420 (ave = 1.65394547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.754112453655429, value max: 0.8045353889465332\n",
      "D grad l2-norm: 10.33275204530001, value max: 1.0631004571914673\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.74556005 (ave = 0.70751898)\n",
      "Loss_G = 1.61226475 (ave = 1.63533392)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.63450458275845, value max: 0.7924689054489136\n",
      "D grad l2-norm: 10.24165529952069, value max: 1.0441884994506836\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 0.51574808 (ave = 0.67943311)\n",
      "Loss_G = 1.59426618 (ave = 1.60665708)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.750015893168033, value max: 0.7769403457641602\n",
      "D grad l2-norm: 10.23340769625346, value max: 1.0122356414794922\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.770s / 5 iters, (0.154)\tData load 0.721s / 5 iters, (0.144279)\n",
      "Loss_D = 0.68941009 (ave = 0.69598458)\n",
      "Loss_G = 1.61851931 (ave = 1.61292326)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.671075865851146, value max: 0.7570636868476868\n",
      "D grad l2-norm: 10.254576491897089, value max: 0.9964121580123901\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001604)\n",
      "Loss_D = 0.70933783 (ave = 0.69931550)\n",
      "Loss_G = 1.63857913 (ave = 1.61259053)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.872372132348817, value max: 0.7382404804229736\n",
      "D grad l2-norm: 10.304265897356684, value max: 0.9780318737030029\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 0.58992368 (ave = 0.68004445)\n",
      "Loss_G = 1.55792093 (ave = 1.58101940)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.711978644495284, value max: 0.6913430094718933\n",
      "D grad l2-norm: 9.85690128467175, value max: 0.8955745697021484\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.61308134 (ave = 0.69354270)\n",
      "Loss_G = 1.55788779 (ave = 1.54654024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.007244280615089, value max: 0.6661222577095032\n",
      "D grad l2-norm: 9.861079536993882, value max: 0.8782164454460144\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.64094400 (ave = 0.71124494)\n",
      "Loss_G = 1.45748830 (ave = 1.47808721)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.408672462572143, value max: 0.7594752311706543\n",
      "D grad l2-norm: 9.915937758874797, value max: 0.8437919020652771\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 0.74543905 (ave = 0.74608821)\n",
      "Loss_G = 1.41957879 (ave = 1.42655332)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.070547455765992, value max: 0.7580598592758179\n",
      "D grad l2-norm: 9.654747698294498, value max: 0.8315139412879944\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 5 iters, (0.017)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 0.78384542 (ave = 0.76942053)\n",
      "Loss_G = 1.40243852 (ave = 1.41320150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 11.044695521794523, value max: 0.7753862142562866\n",
      "D grad l2-norm: 9.572823895980973, value max: 0.8495020270347595\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003452)\n",
      "Loss_D = 0.92804509 (ave = 0.79992042)\n",
      "Loss_G = 1.34065545 (ave = 1.40015097)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.830033552241114, value max: 0.753983199596405\n",
      "D grad l2-norm: 9.428684761330441, value max: 0.8473270535469055\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 5 iters, (0.025)\tData load 0.017s / 5 iters, (0.003323)\n",
      "Loss_D = 0.76979458 (ave = 0.79207168)\n",
      "Loss_G = 1.33644593 (ave = 1.35433607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.539563066802858, value max: 0.7186875343322754\n",
      "D grad l2-norm: 9.309073401265879, value max: 0.8464369773864746\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 1.07228744 (ave = 0.82762302)\n",
      "Loss_G = 1.38723040 (ave = 1.39018109)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.327451005206019, value max: 0.7013152241706848\n",
      "D grad l2-norm: 9.320745598120544, value max: 0.841791570186615\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.789s / 5 iters, (0.158)\tData load 0.740s / 5 iters, (0.147957)\n",
      "Loss_D = 1.04738414 (ave = 0.83580896)\n",
      "Loss_G = 1.42752922 (ave = 1.38032351)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.404166252830118, value max: 0.758246660232544\n",
      "D grad l2-norm: 9.565275026692373, value max: 0.8497322797775269\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001641)\n",
      "Loss_D = 1.01735711 (ave = 0.81991205)\n",
      "Loss_G = 1.43832445 (ave = 1.42300410)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.394833568279745, value max: 0.7612787485122681\n",
      "D grad l2-norm: 9.71738815325478, value max: 0.8325643539428711\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.69161415 (ave = 0.77179731)\n",
      "Loss_G = 1.44648051 (ave = 1.44461432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.45983050368522, value max: 0.7847298383712769\n",
      "D grad l2-norm: 9.90473349830895, value max: 0.8794282078742981\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 0.80316389 (ave = 0.77833935)\n",
      "Loss_G = 1.48785353 (ave = 1.47045751)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 10.1518148783742, value max: 0.7454724311828613\n",
      "D grad l2-norm: 9.965495715798927, value max: 0.9327964186668396\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 0.79287541 (ave = 0.76261226)\n",
      "Loss_G = 1.55981147 (ave = 1.53482242)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.597735014247267, value max: 0.7489656209945679\n",
      "D grad l2-norm: 10.139809667586254, value max: 0.9977633357048035\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.011s / 5 iters, (0.002219)\n",
      "Loss_D = 0.87218553 (ave = 0.74520706)\n",
      "Loss_G = 1.66357017 (ave = 1.59244018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.499442377752132, value max: 0.7652071118354797\n",
      "D grad l2-norm: 10.369534800950637, value max: 1.055903673171997\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.61431122 (ave = 0.69012717)\n",
      "Loss_G = 1.64164078 (ave = 1.63628271)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.238992618090812, value max: 0.7490135431289673\n",
      "D grad l2-norm: 10.254598355804852, value max: 1.0476776361465454\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.64192921 (ave = 0.68642448)\n",
      "Loss_G = 1.68364751 (ave = 1.66626315)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.57786723325932, value max: 0.7225494980812073\n",
      "D grad l2-norm: 10.659971416443618, value max: 1.0896838903427124\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.85007989 (ave = 0.70407350)\n",
      "Loss_G = 1.70358920 (ave = 1.69515209)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.591745608467381, value max: 0.7164720892906189\n",
      "D grad l2-norm: 10.656115452587622, value max: 1.0831639766693115\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 0.57203656 (ave = 0.66549624)\n",
      "Loss_G = 1.70822859 (ave = 1.70338156)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.29369346411734, value max: 0.7835018634796143\n",
      "D grad l2-norm: 10.350783918320907, value max: 1.0414745807647705\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 3\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.007s / 5 iters, (0.001330)\n",
      "Loss_D = 1.37002993 (ave = 1.37570527)\n",
      "Loss_G = 0.71842945 (ave = 0.71999557)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9616716899316503, value max: 0.033617712557315826\n",
      "D grad l2-norm: 0.7081690736442178, value max: 0.5124801397323608\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.498s / 5 iters, (0.100)\tData load 0.390s / 5 iters, (0.077997)\n",
      "Loss_D = 1.36501408 (ave = 1.36615894)\n",
      "Loss_G = 0.71687818 (ave = 0.71755568)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9597287789559795, value max: 0.020864980295300484\n",
      "D grad l2-norm: 0.7069060801725718, value max: 0.5117232203483582\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.477s / 5 iters, (0.095)\tData load 0.428s / 5 iters, (0.085524)\n",
      "Loss_D = 1.35356331 (ave = 1.35595200)\n",
      "Loss_G = 0.71439391 (ave = 0.71560054)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9690227541924312, value max: 0.02832862362265587\n",
      "D grad l2-norm: 0.7075127946996229, value max: 0.5105080008506775\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.436s / 5 iters, (0.087)\tData load 0.372s / 5 iters, (0.074401)\n",
      "Loss_D = 1.34478843 (ave = 1.34652400)\n",
      "Loss_G = 0.71296358 (ave = 0.71370921)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9668215488813893, value max: 0.025289243087172508\n",
      "D grad l2-norm: 0.7082353053617366, value max: 0.5098075270652771\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.388s / 5 iters, (0.078)\tData load 0.334s / 5 iters, (0.066870)\n",
      "Loss_D = 1.33963001 (ave = 1.33773618)\n",
      "Loss_G = 0.71141529 (ave = 0.71216195)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9671552960452637, value max: 0.020126348361372948\n",
      "D grad l2-norm: 0.7109026066776454, value max: 0.5090481638908386\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.454s / 5 iters, (0.091)\tData load 0.402s / 5 iters, (0.080416)\n",
      "Loss_D = 1.31549561 (ave = 1.32641969)\n",
      "Loss_G = 0.71042448 (ave = 0.71054869)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:31:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9670564546515998, value max: 0.022237708792090416\n",
      "D grad l2-norm: 0.711249414671416, value max: 0.5085608959197998\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.515s / 5 iters, (0.103)\tData load 0.406s / 5 iters, (0.081176)\n",
      "Loss_D = 1.30863655 (ave = 1.31815994)\n",
      "Loss_G = 0.71020842 (ave = 0.70987587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9725167829191637, value max: 0.025377707555890083\n",
      "D grad l2-norm: 0.7181809886940258, value max: 0.5084550976753235\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.557s / 5 iters, (0.111)\tData load 0.495s / 5 iters, (0.099001)\n",
      "Loss_D = 1.31942594 (ave = 1.31187377)\n",
      "Loss_G = 0.70866793 (ave = 0.70916713)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9721471812827939, value max: 0.02363394759595394\n",
      "D grad l2-norm: 0.7233073335163965, value max: 0.5076965093612671\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.434s / 5 iters, (0.087)\tData load 0.383s / 5 iters, (0.076596)\n",
      "Loss_D = 1.30117226 (ave = 1.30158939)\n",
      "Loss_G = 0.70832491 (ave = 0.70861868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9739453015988377, value max: 0.023673351854085922\n",
      "D grad l2-norm: 0.7238056757469937, value max: 0.5075271725654602\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.443s / 5 iters, (0.089)\tData load 0.390s / 5 iters, (0.078031)\n",
      "Loss_D = 1.29361594 (ave = 1.29306390)\n",
      "Loss_G = 0.70908397 (ave = 0.70846397)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9677158603913968, value max: 0.026303838938474655\n",
      "D grad l2-norm: 0.7303531554388367, value max: 0.507901132106781\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.686s / 5 iters, (0.337)\tData load 1.631s / 5 iters, (0.326117)\n",
      "Loss_D = 1.27052975 (ave = 1.28312862)\n",
      "Loss_G = 0.70741892 (ave = 0.70833972)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9669163986889081, value max: 0.03779244422912598\n",
      "D grad l2-norm: 0.7356833831268073, value max: 0.507079541683197\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001792)\n",
      "Loss_D = 1.26665974 (ave = 1.27510026)\n",
      "Loss_G = 0.70887947 (ave = 0.70849420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9672233725503897, value max: 0.03039552830159664\n",
      "D grad l2-norm: 0.739149262645767, value max: 0.5078000426292419\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001759)\n",
      "Loss_D = 1.26543319 (ave = 1.26799099)\n",
      "Loss_G = 0.70799476 (ave = 0.70851749)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9741508384335282, value max: 0.03208061680197716\n",
      "D grad l2-norm: 0.7458232608012201, value max: 0.5073632597923279\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001728)\n",
      "Loss_D = 1.24217033 (ave = 1.25768266)\n",
      "Loss_G = 0.70862919 (ave = 0.70844766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9694041908392702, value max: 0.03286486864089966\n",
      "D grad l2-norm: 0.7514538714618179, value max: 0.5076735615730286\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001885)\n",
      "Loss_D = 1.24794841 (ave = 1.25131357)\n",
      "Loss_G = 0.70949548 (ave = 0.70898750)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9718768280354696, value max: 0.03474722430109978\n",
      "D grad l2-norm: 0.757717773093672, value max: 0.5081020593643188\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.021s / 5 iters, (0.004264)\n",
      "Loss_D = 1.24386477 (ave = 1.24383135)\n",
      "Loss_G = 0.70885658 (ave = 0.70849440)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9738089297662975, value max: 0.03584812581539154\n",
      "D grad l2-norm: 0.7679419854608485, value max: 0.5077855587005615\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 1.22240043 (ave = 1.23394690)\n",
      "Loss_G = 0.71008092 (ave = 0.70932407)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9769350586033816, value max: 0.029788097366690636\n",
      "D grad l2-norm: 0.777054434744895, value max: 0.5083855390548706\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 1.22731733 (ave = 1.22744923)\n",
      "Loss_G = 0.71009940 (ave = 0.71012969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9783258956413288, value max: 0.036143407225608826\n",
      "D grad l2-norm: 0.7846948574860392, value max: 0.5083973407745361\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001725)\n",
      "Loss_D = 1.23291302 (ave = 1.22167227)\n",
      "Loss_G = 0.71196097 (ave = 0.71117630)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9792446412382385, value max: 0.03713775798678398\n",
      "D grad l2-norm: 0.792727954188488, value max: 0.5093073844909668\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001715)\n",
      "Loss_D = 1.20126820 (ave = 1.21021852)\n",
      "Loss_G = 0.71178406 (ave = 0.71210318)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9820483679033374, value max: 0.03913743793964386\n",
      "D grad l2-norm: 0.8041215031575184, value max: 0.5092216730117798\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.705s / 5 iters, (0.141)\tData load 0.652s / 5 iters, (0.130346)\n",
      "Loss_D = 1.19659662 (ave = 1.20280664)\n",
      "Loss_G = 0.71403116 (ave = 0.71314564)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9833682412763226, value max: 0.04678398743271828\n",
      "D grad l2-norm: 0.8170084751051431, value max: 0.5103223323822021\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.016s / 5 iters, (0.003195)\n",
      "Loss_D = 1.19794571 (ave = 1.19610105)\n",
      "Loss_G = 0.71644604 (ave = 0.71521703)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9799822928988471, value max: 0.039476439356803894\n",
      "D grad l2-norm: 0.8267395703234806, value max: 0.511500895023346\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.016s / 5 iters, (0.003211)\n",
      "Loss_D = 1.18433189 (ave = 1.18686616)\n",
      "Loss_G = 0.71746993 (ave = 0.71687882)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.988022254728877, value max: 0.04412214830517769\n",
      "D grad l2-norm: 0.839448209779139, value max: 0.5120039582252502\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004517)\n",
      "Loss_D = 1.17500687 (ave = 1.17881680)\n",
      "Loss_G = 0.72057253 (ave = 0.71976868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9807577650858182, value max: 0.044001176953315735\n",
      "D grad l2-norm: 0.8529168114580082, value max: 0.5135126709938049\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.034s / 5 iters, (0.006800)\n",
      "Loss_D = 1.17176652 (ave = 1.17027795)\n",
      "Loss_G = 0.72340256 (ave = 0.72289348)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9922601832877347, value max: 0.04339147359132767\n",
      "D grad l2-norm: 0.8662835882428087, value max: 0.5148837566375732\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 5 iters, (0.021)\tData load 0.017s / 5 iters, (0.003404)\n",
      "Loss_D = 1.16015375 (ave = 1.16026437)\n",
      "Loss_G = 0.72982818 (ave = 0.72702729)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9845584337354262, value max: 0.04485083371400833\n",
      "D grad l2-norm: 0.8755599594000187, value max: 0.5179932713508606\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 1.15195739 (ave = 1.15012858)\n",
      "Loss_G = 0.73389906 (ave = 0.73156917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9832606697330136, value max: 0.045659758150577545\n",
      "D grad l2-norm: 0.8894206461992031, value max: 0.5199511051177979\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.021s / 5 iters, (0.004140)\n",
      "Loss_D = 1.12637687 (ave = 1.13866968)\n",
      "Loss_G = 0.73665398 (ave = 0.73564198)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9897394769173045, value max: 0.04313402250409126\n",
      "D grad l2-norm: 0.9056521318149696, value max: 0.5212675333023071\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.12817442 (ave = 1.12998829)\n",
      "Loss_G = 0.74316406 (ave = 0.74082599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9949362365585559, value max: 0.04309137910604477\n",
      "D grad l2-norm: 0.918879337839568, value max: 0.5243757367134094\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.009s / 5 iters, (0.001840)\n",
      "Loss_D = 1.12279570 (ave = 1.12049003)\n",
      "Loss_G = 0.74803877 (ave = 0.74580970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9940054722738657, value max: 0.04563722386956215\n",
      "D grad l2-norm: 0.9268077230110369, value max: 0.5266889929771423\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.698s / 5 iters, (0.140)\tData load 0.643s / 5 iters, (0.128594)\n",
      "Loss_D = 1.09939694 (ave = 1.10891097)\n",
      "Loss_G = 0.75120491 (ave = 0.74955667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.005401457210924, value max: 0.052096787840127945\n",
      "D grad l2-norm: 0.9425822351379154, value max: 0.5281775593757629\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001721)\n",
      "Loss_D = 1.11388206 (ave = 1.10236304)\n",
      "Loss_G = 0.75628328 (ave = 0.75365978)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0131591743796104, value max: 0.044831402599811554\n",
      "D grad l2-norm: 0.953176376318349, value max: 0.5305640697479248\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.010s / 5 iters, (0.001937)\n",
      "Loss_D = 1.09662354 (ave = 1.09253705)\n",
      "Loss_G = 0.75711352 (ave = 0.75742824)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0157559757954184, value max: 0.05790185555815697\n",
      "D grad l2-norm: 0.9608176216708163, value max: 0.5309526920318604\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.012s / 5 iters, (0.002353)\n",
      "Loss_D = 1.11853874 (ave = 1.08916619)\n",
      "Loss_G = 0.75984883 (ave = 0.76063746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0202691381716797, value max: 0.060359735041856766\n",
      "D grad l2-norm: 0.9756341487805662, value max: 0.5322335958480835\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 5 iters, (0.017)\tData load 0.018s / 5 iters, (0.003697)\n",
      "Loss_D = 1.09289289 (ave = 1.07853334)\n",
      "Loss_G = 0.76458108 (ave = 0.76287771)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0333207056397746, value max: 0.06730713695287704\n",
      "D grad l2-norm: 0.9851331009958383, value max: 0.5344380736351013\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001868)\n",
      "Loss_D = 1.07230949 (ave = 1.06984591)\n",
      "Loss_G = 0.76593894 (ave = 0.76453906)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.045346133013936, value max: 0.07089851796627045\n",
      "D grad l2-norm: 1.005935811388769, value max: 0.5350598692893982\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 1.03631365 (ave = 1.05818975)\n",
      "Loss_G = 0.76717466 (ave = 0.76678770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0506488250796464, value max: 0.06932166963815689\n",
      "D grad l2-norm: 1.016992395841296, value max: 0.5356178879737854\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001716)\n",
      "Loss_D = 1.04945219 (ave = 1.05327752)\n",
      "Loss_G = 0.77165020 (ave = 0.76971157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0544652817774087, value max: 0.0696113258600235\n",
      "D grad l2-norm: 1.029482272188917, value max: 0.5377039909362793\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001729)\n",
      "Loss_D = 1.04501557 (ave = 1.04691715)\n",
      "Loss_G = 0.77657372 (ave = 0.77321515)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0621635167005081, value max: 0.07017775624990463\n",
      "D grad l2-norm: 1.0499119027335226, value max: 0.5399661660194397\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.04586685 (ave = 1.04176102)\n",
      "Loss_G = 0.77465451 (ave = 0.77449907)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0839419136455979, value max: 0.07588756829500198\n",
      "D grad l2-norm: 1.075150699038092, value max: 0.539063036441803\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.877s / 5 iters, (0.175)\tData load 0.820s / 5 iters, (0.163927)\n",
      "Loss_D = 1.05624485 (ave = 1.03842120)\n",
      "Loss_G = 0.77629000 (ave = 0.77559881)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1048266419078903, value max: 0.07394331693649292\n",
      "D grad l2-norm: 1.0954619956401972, value max: 0.5398242473602295\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 1.01738560 (ave = 1.02793751)\n",
      "Loss_G = 0.78041071 (ave = 0.77746603)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.109640877931363, value max: 0.07810032367706299\n",
      "D grad l2-norm: 1.1119980227031894, value max: 0.5417037010192871\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 1.00329030 (ave = 1.02166495)\n",
      "Loss_G = 0.78022057 (ave = 0.77804950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1235023224888876, value max: 0.08817414939403534\n",
      "D grad l2-norm: 1.1439009469526864, value max: 0.5415923595428467\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001492)\n",
      "Loss_D = 1.04398322 (ave = 1.02156963)\n",
      "Loss_G = 0.78605318 (ave = 0.78077114)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.135943336069259, value max: 0.09208077937364578\n",
      "D grad l2-norm: 1.1737706167057125, value max: 0.5442976355552673\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.007s / 5 iters, (0.001455)\n",
      "Loss_D = 0.99431288 (ave = 1.00850245)\n",
      "Loss_G = 0.78924298 (ave = 0.78575338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1435017851070235, value max: 0.09674403816461563\n",
      "D grad l2-norm: 1.2014224732064274, value max: 0.5457158088684082\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 1.00102413 (ave = 1.00395901)\n",
      "Loss_G = 0.79082340 (ave = 0.79007427)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.166966650863237, value max: 0.1058129221200943\n",
      "D grad l2-norm: 1.257441700669394, value max: 0.5464196801185608\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 0.99233484 (ave = 0.99392962)\n",
      "Loss_G = 0.80182457 (ave = 0.79745239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.158938197859616, value max: 0.11727361381053925\n",
      "D grad l2-norm: 1.2681188821409617, value max: 0.5514189600944519\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.97720885 (ave = 0.98425442)\n",
      "Loss_G = 0.81442428 (ave = 0.80678972)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1638556212227076, value max: 0.11332925409078598\n",
      "D grad l2-norm: 1.3024013977524278, value max: 0.5569989681243896\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 1.02010524 (ave = 0.97988793)\n",
      "Loss_G = 0.82139874 (ave = 0.81790801)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1838420564736147, value max: 0.11446802318096161\n",
      "D grad l2-norm: 1.3548214231533364, value max: 0.5600892901420593\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001742)\n",
      "Loss_D = 0.96085691 (ave = 0.96030583)\n",
      "Loss_G = 0.83334631 (ave = 0.83082871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.197933153398035, value max: 0.11960461735725403\n",
      "D grad l2-norm: 1.3912077759832011, value max: 0.5653247833251953\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.750s / 5 iters, (0.150)\tData load 0.658s / 5 iters, (0.131631)\n",
      "Loss_D = 0.91376460 (ave = 0.94310488)\n",
      "Loss_G = 0.84511483 (ave = 0.84215413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2089191772789376, value max: 0.12274371832609177\n",
      "D grad l2-norm: 1.4206858738237107, value max: 0.5703905820846558\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.96930754 (ave = 0.93684635)\n",
      "Loss_G = 0.85973984 (ave = 0.85712247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2224087358390168, value max: 0.1229107603430748\n",
      "D grad l2-norm: 1.4637769701819865, value max: 0.5766169428825378\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001566)\n",
      "Loss_D = 0.89853436 (ave = 0.91663957)\n",
      "Loss_G = 0.87540174 (ave = 0.86959685)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.222556901846483, value max: 0.12625478208065033\n",
      "D grad l2-norm: 1.4771291231444168, value max: 0.5832171440124512\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.84766400 (ave = 0.89759542)\n",
      "Loss_G = 0.89030159 (ave = 0.88248960)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.254690465579812, value max: 0.11972341686487198\n",
      "D grad l2-norm: 1.5212111380108557, value max: 0.5893510580062866\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.88373542 (ave = 0.89263932)\n",
      "Loss_G = 0.89792430 (ave = 0.89486152)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2957052273878142, value max: 0.12151724100112915\n",
      "D grad l2-norm: 1.5402783640759363, value max: 0.5924860239028931\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 0.87580454 (ave = 0.88339593)\n",
      "Loss_G = 0.90420246 (ave = 0.90244647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3530044869677564, value max: 0.1188167929649353\n",
      "D grad l2-norm: 1.5694944137044007, value max: 0.5950004458427429\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 0.85816574 (ave = 0.87757837)\n",
      "Loss_G = 0.90262473 (ave = 0.90239553)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.411374766113842, value max: 0.1460639089345932\n",
      "D grad l2-norm: 1.5761148756897296, value max: 0.5943464636802673\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001612)\n",
      "Loss_D = 0.86426163 (ave = 0.87787949)\n",
      "Loss_G = 0.89563429 (ave = 0.89900405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.499075141101717, value max: 0.15828090906143188\n",
      "D grad l2-norm: 1.5970726247388536, value max: 0.5914391875267029\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.014s / 5 iters, (0.002829)\n",
      "Loss_D = 0.91296136 (ave = 0.88674184)\n",
      "Loss_G = 0.88149375 (ave = 0.88705398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5782415154872047, value max: 0.18818818032741547\n",
      "D grad l2-norm: 1.6232288022570767, value max: 0.5855482816696167\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.013s / 5 iters, (0.002566)\n",
      "Loss_D = 0.90357029 (ave = 0.89459918)\n",
      "Loss_G = 0.86940134 (ave = 0.87708458)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6605505578725075, value max: 0.2067231386899948\n",
      "D grad l2-norm: 1.6549019481066842, value max: 0.5805089473724365\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.902s / 5 iters, (0.180)\tData load 0.855s / 5 iters, (0.170926)\n",
      "Loss_D = 0.90135169 (ave = 0.89980942)\n",
      "Loss_G = 0.85893613 (ave = 0.86252736)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7008269810841334, value max: 0.2313777357339859\n",
      "D grad l2-norm: 1.6731862669246005, value max: 0.5760170817375183\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.87914538 (ave = 0.90791196)\n",
      "Loss_G = 0.85314417 (ave = 0.85183759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7703363322627343, value max: 0.24105322360992432\n",
      "D grad l2-norm: 1.717871363848071, value max: 0.5735387206077576\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001612)\n",
      "Loss_D = 0.92547631 (ave = 0.91814057)\n",
      "Loss_G = 0.84875196 (ave = 0.84791663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.819417460889535, value max: 0.23946122825145721\n",
      "D grad l2-norm: 1.746290526650754, value max: 0.5715644359588623\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.92880559 (ave = 0.92487770)\n",
      "Loss_G = 0.84609377 (ave = 0.84484177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8420043021889543, value max: 0.2464320808649063\n",
      "D grad l2-norm: 1.7696105517128489, value max: 0.5703909993171692\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001638)\n",
      "Loss_D = 0.98673904 (ave = 0.93458054)\n",
      "Loss_G = 0.85567510 (ave = 0.84612125)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8777453981341548, value max: 0.24796098470687866\n",
      "D grad l2-norm: 1.8229269774813146, value max: 0.5745398998260498\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.94808364 (ave = 0.92643085)\n",
      "Loss_G = 0.85451901 (ave = 0.85083025)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9368851444563493, value max: 0.24450623989105225\n",
      "D grad l2-norm: 1.8730421035677303, value max: 0.5738662481307983\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.84874904 (ave = 0.91462212)\n",
      "Loss_G = 0.86517966 (ave = 0.85932664)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9662955413917158, value max: 0.24729228019714355\n",
      "D grad l2-norm: 1.9031573831257071, value max: 0.5783169269561768\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 0.91025364 (ave = 0.92151287)\n",
      "Loss_G = 0.86306840 (ave = 0.86374488)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.087939191100308, value max: 0.2548164129257202\n",
      "D grad l2-norm: 1.973592405883832, value max: 0.5773904323577881\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001753)\n",
      "Loss_D = 0.95278966 (ave = 0.92995872)\n",
      "Loss_G = 0.86253732 (ave = 0.86302638)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.21083096825492, value max: 0.25314754247665405\n",
      "D grad l2-norm: 2.0098094461404594, value max: 0.5770298838615417\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.95002389 (ave = 0.94057413)\n",
      "Loss_G = 0.83963096 (ave = 0.85128318)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3040751708011187, value max: 0.24333050847053528\n",
      "D grad l2-norm: 2.0749885214424872, value max: 0.5673055648803711\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.787s / 5 iters, (0.157)\tData load 0.736s / 5 iters, (0.147250)\n",
      "Loss_D = 0.95207298 (ave = 0.95822666)\n",
      "Loss_G = 0.82988507 (ave = 0.83774117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.368266278529214, value max: 0.2336505949497223\n",
      "D grad l2-norm: 2.1393383547299494, value max: 0.5630436539649963\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 1.05284035 (ave = 0.98292501)\n",
      "Loss_G = 0.81910539 (ave = 0.82830911)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.324320414135087, value max: 0.2113049030303955\n",
      "D grad l2-norm: 2.1568655342288703, value max: 0.5579964518547058\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.018s / 5 iters, (0.003662)\n",
      "Loss_D = 0.96671164 (ave = 0.98267872)\n",
      "Loss_G = 0.83106053 (ave = 0.82942537)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.338712932922657, value max: 0.20466840267181396\n",
      "D grad l2-norm: 2.264286042707134, value max: 0.5634475350379944\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.022s / 5 iters, (0.004460)\n",
      "Loss_D = 1.01346564 (ave = 0.98256737)\n",
      "Loss_G = 0.84084833 (ave = 0.83983208)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.290945720609001, value max: 0.1892477422952652\n",
      "D grad l2-norm: 2.338086248522921, value max: 0.5676167011260986\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.021s / 5 iters, (0.004127)\n",
      "Loss_D = 0.95989299 (ave = 0.97599738)\n",
      "Loss_G = 0.87976432 (ave = 0.85932209)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2538250988050166, value max: 0.1852823942899704\n",
      "D grad l2-norm: 2.3991582564220537, value max: 0.5841328501701355\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.019s / 5 iters, (0.003726)\n",
      "Loss_D = 0.88314736 (ave = 0.95020994)\n",
      "Loss_G = 0.88514102 (ave = 0.88358731)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3780018275595833, value max: 0.19484570622444153\n",
      "D grad l2-norm: 2.5509196316569813, value max: 0.5863960981369019\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002445)\n",
      "Loss_D = 0.97636747 (ave = 0.95413105)\n",
      "Loss_G = 0.90316176 (ave = 0.90471137)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.51420449795508, value max: 0.2223612666130066\n",
      "D grad l2-norm: 2.7033654507047693, value max: 0.5937535762786865\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.016s / 5 iters, (0.003206)\n",
      "Loss_D = 0.94275194 (ave = 0.94356627)\n",
      "Loss_G = 0.94079959 (ave = 0.92444500)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.625331265577603, value max: 0.2533191442489624\n",
      "D grad l2-norm: 2.819340106646227, value max: 0.6085983514785767\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001717)\n",
      "Loss_D = 0.92345214 (ave = 0.93383821)\n",
      "Loss_G = 0.94937003 (ave = 0.93864700)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.848407293034762, value max: 0.2827398180961609\n",
      "D grad l2-norm: 3.0305451678963244, value max: 0.6119359731674194\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001684)\n",
      "Loss_D = 1.06495297 (ave = 0.95500507)\n",
      "Loss_G = 0.96713871 (ave = 0.95440816)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.921905228659414, value max: 0.2855231761932373\n",
      "D grad l2-norm: 3.1426732963205013, value max: 0.6187772154808044\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.676s / 5 iters, (0.135)\tData load 0.625s / 5 iters, (0.125040)\n",
      "Loss_D = 0.83943355 (ave = 0.91552453)\n",
      "Loss_G = 0.99295014 (ave = 0.98353380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.964332005835211, value max: 0.3074339032173157\n",
      "D grad l2-norm: 3.221143320715458, value max: 0.6285486221313477\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 0.88058954 (ave = 0.90494123)\n",
      "Loss_G = 1.02199757 (ave = 1.00823516)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1637467512645006, value max: 0.3103412091732025\n",
      "D grad l2-norm: 3.489630385016466, value max: 0.6390786170959473\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.88978672 (ave = 0.89360573)\n",
      "Loss_G = 1.05053663 (ave = 1.03732915)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1495241638563134, value max: 0.3256026804447174\n",
      "D grad l2-norm: 3.49034277022992, value max: 0.6494762301445007\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001538)\n",
      "Loss_D = 0.90105772 (ave = 0.88538126)\n",
      "Loss_G = 1.09031200 (ave = 1.07210972)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2934617762914824, value max: 0.32094794511795044\n",
      "D grad l2-norm: 3.663630069584555, value max: 0.663040041923523\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 0.89616323 (ave = 0.87027127)\n",
      "Loss_G = 1.10909975 (ave = 1.10050395)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4143223939341865, value max: 0.35430607199668884\n",
      "D grad l2-norm: 3.772626886413953, value max: 0.6693145632743835\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 0.83339059 (ave = 0.85542672)\n",
      "Loss_G = 1.13011909 (ave = 1.12371359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6996195024741776, value max: 0.38482382893562317\n",
      "D grad l2-norm: 3.9555722004156557, value max: 0.675822377204895\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 0.85004508 (ave = 0.86248388)\n",
      "Loss_G = 1.12301874 (ave = 1.12035768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.957949929752496, value max: 0.4189481735229492\n",
      "D grad l2-norm: 3.989563871751368, value max: 0.6734048128128052\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.009s / 5 iters, (0.001739)\n",
      "Loss_D = 0.83391249 (ave = 0.87183336)\n",
      "Loss_G = 1.09957671 (ave = 1.10745242)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.167572026895011, value max: 0.4129808843135834\n",
      "D grad l2-norm: 4.022575165684652, value max: 0.6654580235481262\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001805)\n",
      "Loss_D = 0.85035825 (ave = 0.89403261)\n",
      "Loss_G = 1.08277571 (ave = 1.08357210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.362453635959965, value max: 0.42358869314193726\n",
      "D grad l2-norm: 4.0703549855159435, value max: 0.6600731611251831\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 0.88005435 (ave = 0.91776084)\n",
      "Loss_G = 1.04984391 (ave = 1.05805895)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.4993540110141055, value max: 0.40049949288368225\n",
      "D grad l2-norm: 4.100826998696329, value max: 0.6477866172790527\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.952s / 5 iters, (0.190)\tData load 0.882s / 5 iters, (0.176480)\n",
      "Loss_D = 0.85334104 (ave = 0.93723347)\n",
      "Loss_G = 1.04201579 (ave = 1.05191395)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.460378703883477, value max: 0.4156206250190735\n",
      "D grad l2-norm: 3.9945870911829604, value max: 0.6452240943908691\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 1.03815281 (ave = 0.97568949)\n",
      "Loss_G = 1.02510059 (ave = 1.03432591)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.56494544486407, value max: 0.40641266107559204\n",
      "D grad l2-norm: 4.049040496086172, value max: 0.6390553712844849\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.94491094 (ave = 0.97694790)\n",
      "Loss_G = 1.00698221 (ave = 1.01959791)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.634597506238086, value max: 0.4182690382003784\n",
      "D grad l2-norm: 4.0175020046824965, value max: 0.6328591704368591\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001679)\n",
      "Loss_D = 0.94269192 (ave = 0.99636805)\n",
      "Loss_G = 0.99404001 (ave = 1.00091631)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.4667147822805084, value max: 0.41392967104911804\n",
      "D grad l2-norm: 3.994954027106975, value max: 0.6278146505355835\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002470)\n",
      "Loss_D = 1.05139327 (ave = 1.01493678)\n",
      "Loss_G = 0.99158072 (ave = 0.99315835)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.563586166265324, value max: 0.4226461946964264\n",
      "D grad l2-norm: 4.077649698310501, value max: 0.6268013715744019\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001751)\n",
      "Loss_D = 1.10775709 (ave = 1.03365234)\n",
      "Loss_G = 0.98516166 (ave = 0.98817967)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.435661202200111, value max: 0.41732242703437805\n",
      "D grad l2-norm: 4.0692059372407074, value max: 0.6244931221008301\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 0.96790242 (ave = 1.02312803)\n",
      "Loss_G = 1.00343418 (ave = 0.98582239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.374989011059711, value max: 0.42299550771713257\n",
      "D grad l2-norm: 4.167861707423166, value max: 0.6316655874252319\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 1.04897296 (ave = 1.02956934)\n",
      "Loss_G = 1.00171626 (ave = 1.00020100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.505279947653596, value max: 0.42738643288612366\n",
      "D grad l2-norm: 4.240331722531185, value max: 0.6308767199516296\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.022s / 5 iters, (0.004320)\n",
      "Loss_D = 0.94665778 (ave = 1.01687107)\n",
      "Loss_G = 1.00492370 (ave = 0.99508897)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.602009382943953, value max: 0.4169655740261078\n",
      "D grad l2-norm: 4.3196555161209185, value max: 0.6306678056716919\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 1.13045049 (ave = 1.04244654)\n",
      "Loss_G = 1.00664186 (ave = 1.00520639)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.672316889391115, value max: 0.4324778914451599\n",
      "D grad l2-norm: 4.435222094122811, value max: 0.6323645710945129\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.738s / 5 iters, (0.148)\tData load 0.685s / 5 iters, (0.136978)\n",
      "Loss_D = 0.96562421 (ave = 1.02065259)\n",
      "Loss_G = 1.01088452 (ave = 1.00579667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.720481079147584, value max: 0.43023496866226196\n",
      "D grad l2-norm: 4.523654210590319, value max: 0.6337984204292297\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 1.01820755 (ave = 1.02337795)\n",
      "Loss_G = 1.03481483 (ave = 1.02537048)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.834644388535551, value max: 0.42888936400413513\n",
      "D grad l2-norm: 4.758393693820917, value max: 0.6418009996414185\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.96174228 (ave = 1.00214636)\n",
      "Loss_G = 1.08069348 (ave = 1.06125605)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.7577457782734225, value max: 0.4195692837238312\n",
      "D grad l2-norm: 4.786524233420701, value max: 0.6582686305046082\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.018s / 5 iters, (0.003669)\n",
      "Loss_D = 0.93417907 (ave = 0.98563541)\n",
      "Loss_G = 1.09821486 (ave = 1.07768533)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.085521753481124, value max: 0.40480607748031616\n",
      "D grad l2-norm: 5.168315854070312, value max: 0.6641867160797119\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.016s / 5 iters, (0.003206)\n",
      "Loss_D = 0.91874558 (ave = 0.97443241)\n",
      "Loss_G = 1.10143518 (ave = 1.11106689)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.2831655467134215, value max: 0.3822460174560547\n",
      "D grad l2-norm: 5.3874119504229165, value max: 0.6646865606307983\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.009s / 5 iters, (0.001823)\n",
      "Loss_D = 0.88232207 (ave = 0.95286297)\n",
      "Loss_G = 1.18055129 (ave = 1.15807836)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.261440747628292, value max: 0.38601699471473694\n",
      "D grad l2-norm: 5.63903449081935, value max: 0.6900689601898193\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.018s / 5 iters, (0.003574)\n",
      "Loss_D = 0.94426298 (ave = 0.93589115)\n",
      "Loss_G = 1.24592209 (ave = 1.21801128)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.175693918293657, value max: 0.44603976607322693\n",
      "D grad l2-norm: 5.781995220019958, value max: 0.7100263833999634\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.138s / 5 iters, (0.028)\tData load 0.025s / 5 iters, (0.005038)\n",
      "Loss_D = 0.92112827 (ave = 0.90265719)\n",
      "Loss_G = 1.27057016 (ave = 1.26033435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.819562339141965, value max: 0.5140071511268616\n",
      "D grad l2-norm: 6.335909359387505, value max: 0.7209405899047852\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.017s / 5 iters, (0.003399)\n",
      "Loss_D = 0.81179237 (ave = 0.87827516)\n",
      "Loss_G = 1.32597446 (ave = 1.30242484)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.0057624704475066, value max: 0.5821235775947571\n",
      "D grad l2-norm: 6.5719850108057045, value max: 0.7359500527381897\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001598)\n",
      "Loss_D = 0.83002782 (ave = 0.87590597)\n",
      "Loss_G = 1.34724569 (ave = 1.33308730)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.30316911469376, value max: 0.6419680714607239\n",
      "D grad l2-norm: 6.867000852883102, value max: 0.7416318655014038\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.687s / 5 iters, (0.137)\tData load 0.634s / 5 iters, (0.126772)\n",
      "Loss_D = 0.87647057 (ave = 0.86336228)\n",
      "Loss_G = 1.40164816 (ave = 1.39385991)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.619352411045271, value max: 0.6593801379203796\n",
      "D grad l2-norm: 7.411816804424123, value max: 0.8161309957504272\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.86983967 (ave = 0.84175005)\n",
      "Loss_G = 1.47422636 (ave = 1.43144650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.515820429666849, value max: 0.6489484906196594\n",
      "D grad l2-norm: 7.523749323504385, value max: 0.8669402003288269\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001555)\n",
      "Loss_D = 0.81236029 (ave = 0.81796118)\n",
      "Loss_G = 1.47523642 (ave = 1.46387775)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.659237350008588, value max: 0.6333099603652954\n",
      "D grad l2-norm: 7.669604806300236, value max: 0.892913281917572\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001886)\n",
      "Loss_D = 0.67215151 (ave = 0.78995315)\n",
      "Loss_G = 1.52618814 (ave = 1.50435276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.671270335537774, value max: 0.6535249948501587\n",
      "D grad l2-norm: 7.5684374995788595, value max: 0.9039382338523865\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001782)\n",
      "Loss_D = 0.83713913 (ave = 0.80738902)\n",
      "Loss_G = 1.51998591 (ave = 1.52627938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.955612160458615, value max: 0.6365054249763489\n",
      "D grad l2-norm: 7.6808674064844995, value max: 0.9224687218666077\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 0.88226557 (ave = 0.81997993)\n",
      "Loss_G = 1.46981907 (ave = 1.47621539)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.057296824060972, value max: 0.6238803267478943\n",
      "D grad l2-norm: 7.596088726149229, value max: 0.8917699456214905\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.011s / 5 iters, (0.002285)\n",
      "Loss_D = 0.93363392 (ave = 0.82978876)\n",
      "Loss_G = 1.44568932 (ave = 1.46902606)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.163464572740177, value max: 0.5946533679962158\n",
      "D grad l2-norm: 7.597912551404886, value max: 0.8770237565040588\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.024s / 5 iters, (0.004813)\n",
      "Loss_D = 0.81572849 (ave = 0.82624608)\n",
      "Loss_G = 1.45813084 (ave = 1.43739526)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.31237678224245, value max: 0.5686435103416443\n",
      "D grad l2-norm: 7.573087164287299, value max: 0.8761226534843445\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.79534125 (ave = 0.83075204)\n",
      "Loss_G = 1.40133810 (ave = 1.40360203)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.343460388827605, value max: 0.5497387647628784\n",
      "D grad l2-norm: 7.248734924447781, value max: 0.8005016446113586\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.87109518 (ave = 0.87158153)\n",
      "Loss_G = 1.33262253 (ave = 1.36937580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.860824195338135, value max: 0.5488107204437256\n",
      "D grad l2-norm: 7.210809124361211, value max: 0.7872313857078552\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.794s / 5 iters, (0.159)\tData load 0.738s / 5 iters, (0.147693)\n",
      "Loss_D = 0.88236827 (ave = 0.91757339)\n",
      "Loss_G = 1.24075532 (ave = 1.30002322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.8656386140000105, value max: 0.5040850043296814\n",
      "D grad l2-norm: 6.978384422141798, value max: 0.7569414973258972\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.139s / 5 iters, (0.028)\tData load 0.025s / 5 iters, (0.005077)\n",
      "Loss_D = 0.96001619 (ave = 0.96919389)\n",
      "Loss_G = 1.17991841 (ave = 1.21802866)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.95721905882648, value max: 0.4585321843624115\n",
      "D grad l2-norm: 6.633829287481725, value max: 0.7205458283424377\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.018s / 5 iters, (0.003654)\n",
      "Loss_D = 0.94259620 (ave = 1.02175479)\n",
      "Loss_G = 1.09544837 (ave = 1.12810583)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.050409356998768, value max: 0.42699670791625977\n",
      "D grad l2-norm: 6.589096484044074, value max: 0.7043882608413696\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 0.93091547 (ave = 1.06904335)\n",
      "Loss_G = 1.07158899 (ave = 1.08672545)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.182508220848133, value max: 0.47166547179222107\n",
      "D grad l2-norm: 6.7181351630380695, value max: 0.6987881064414978\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001477)\n",
      "Loss_D = 1.18093729 (ave = 1.13235400)\n",
      "Loss_G = 1.11099625 (ave = 1.08849266)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.163590382365362, value max: 0.5113406777381897\n",
      "D grad l2-norm: 6.939455596473543, value max: 0.7008849382400513\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001526)\n",
      "Loss_D = 1.21928072 (ave = 1.12632799)\n",
      "Loss_G = 1.15923071 (ave = 1.14642584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.991973610815054, value max: 0.5641009211540222\n",
      "D grad l2-norm: 7.293085314205257, value max: 0.7062768340110779\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.012s / 5 iters, (0.002348)\n",
      "Loss_D = 1.00046849 (ave = 1.06937737)\n",
      "Loss_G = 1.29170716 (ave = 1.24459791)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.013957296440601, value max: 0.6000030040740967\n",
      "D grad l2-norm: 7.673737218468722, value max: 0.7206834554672241\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 1.05988598 (ave = 1.03912618)\n",
      "Loss_G = 1.36141479 (ave = 1.33097007)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.090401260623546, value max: 0.6532411575317383\n",
      "D grad l2-norm: 7.927936664574636, value max: 0.7401149868965149\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001747)\n",
      "Loss_D = 1.18940389 (ave = 1.02542204)\n",
      "Loss_G = 1.43598640 (ave = 1.41113396)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.381011100007173, value max: 0.6867619156837463\n",
      "D grad l2-norm: 8.584787840209424, value max: 0.7591726779937744\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.92970663 (ave = 0.96674778)\n",
      "Loss_G = 1.49369526 (ave = 1.46923950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.37587602337433, value max: 0.6757490634918213\n",
      "D grad l2-norm: 8.795727501935485, value max: 0.7725323438644409\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.774s / 5 iters, (0.155)\tData load 0.709s / 5 iters, (0.141862)\n",
      "Loss_D = 0.98548746 (ave = 0.95046743)\n",
      "Loss_G = 1.53426921 (ave = 1.50964146)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.924463576010233, value max: 0.7760542035102844\n",
      "D grad l2-norm: 9.415706799176403, value max: 0.8238354921340942\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 0.74591315 (ave = 0.90816740)\n",
      "Loss_G = 1.52194786 (ave = 1.52986808)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.818821996506061, value max: 0.7783732414245605\n",
      "D grad l2-norm: 9.132073588568147, value max: 0.8442472219467163\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 0.78505719 (ave = 0.90786835)\n",
      "Loss_G = 1.54165816 (ave = 1.52639802)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.131160890199656, value max: 0.8527330160140991\n",
      "D grad l2-norm: 9.3641653034726, value max: 0.9154307842254639\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 1.03776741 (ave = 0.94172679)\n",
      "Loss_G = 1.48253727 (ave = 1.50898337)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.4720351838666, value max: 0.9065806269645691\n",
      "D grad l2-norm: 9.380068566895341, value max: 0.9569218754768372\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 0.83610094 (ave = 0.92643882)\n",
      "Loss_G = 1.48037696 (ave = 1.49238124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.90623999631134, value max: 0.8320722579956055\n",
      "D grad l2-norm: 8.888531620403437, value max: 0.9841549396514893\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.010s / 5 iters, (0.002005)\n",
      "Loss_D = 0.93484753 (ave = 0.93874701)\n",
      "Loss_G = 1.47010410 (ave = 1.47448165)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.162552911846976, value max: 0.8684426546096802\n",
      "D grad l2-norm: 8.933311931588822, value max: 1.0275920629501343\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.93304598 (ave = 0.94955204)\n",
      "Loss_G = 1.44619465 (ave = 1.43319438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.189656498759845, value max: 0.8120847940444946\n",
      "D grad l2-norm: 8.744367452578812, value max: 1.035601019859314\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001570)\n",
      "Loss_D = 1.01659083 (ave = 0.99090272)\n",
      "Loss_G = 1.37673044 (ave = 1.40250304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.385498965605306, value max: 0.8421452045440674\n",
      "D grad l2-norm: 8.597335590867445, value max: 1.014950156211853\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.013s / 5 iters, (0.002654)\n",
      "Loss_D = 0.86874020 (ave = 0.99465141)\n",
      "Loss_G = 1.31581926 (ave = 1.32927854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.298746882740476, value max: 0.7593867778778076\n",
      "D grad l2-norm: 8.272341894308664, value max: 0.9644666910171509\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 1.12454629 (ave = 1.07321072)\n",
      "Loss_G = 1.24430251 (ave = 1.25774732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.437232803785628, value max: 0.7099781632423401\n",
      "D grad l2-norm: 8.039551908062155, value max: 0.9136883616447449\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.885s / 5 iters, (0.177)\tData load 0.833s / 5 iters, (0.166568)\n",
      "Loss_D = 1.06633544 (ave = 1.11348913)\n",
      "Loss_G = 1.20639634 (ave = 1.20289898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.591449213630947, value max: 0.7431990504264832\n",
      "D grad l2-norm: 7.906415801411213, value max: 0.8720798492431641\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001739)\n",
      "Loss_D = 1.21317434 (ave = 1.19194167)\n",
      "Loss_G = 1.10558438 (ave = 1.14293537)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.336536925461914, value max: 0.7095566391944885\n",
      "D grad l2-norm: 7.5672463357902, value max: 0.7942079305648804\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.96329582 (ave = 1.19248631)\n",
      "Loss_G = 1.10221815 (ave = 1.12430975)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.444563072846211, value max: 0.6703774333000183\n",
      "D grad l2-norm: 7.175338116645178, value max: 0.7311057448387146\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 1.13951910 (ave = 1.20114088)\n",
      "Loss_G = 1.11030924 (ave = 1.12239213)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.221482857244498, value max: 0.662714421749115\n",
      "D grad l2-norm: 7.190207923976283, value max: 0.7007948756217957\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 1.27634621 (ave = 1.22709293)\n",
      "Loss_G = 1.17859054 (ave = 1.15999117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.11073103800619, value max: 0.6505780220031738\n",
      "D grad l2-norm: 7.350035204702279, value max: 0.7009045481681824\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001643)\n",
      "Loss_D = 1.08962297 (ave = 1.18279905)\n",
      "Loss_G = 1.20527089 (ave = 1.18631063)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.102546617916476, value max: 0.6367179155349731\n",
      "D grad l2-norm: 7.540523773808967, value max: 0.6949474811553955\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 1.02762449 (ave = 1.15828302)\n",
      "Loss_G = 1.21650577 (ave = 1.22896569)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.672363028539645, value max: 0.5838185548782349\n",
      "D grad l2-norm: 7.5486212468070075, value max: 0.7053179144859314\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 1.02836955 (ave = 1.12765689)\n",
      "Loss_G = 1.30274785 (ave = 1.27508447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.364079936041167, value max: 0.531755805015564\n",
      "D grad l2-norm: 7.718178659870192, value max: 0.7421026229858398\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002223)\n",
      "Loss_D = 1.02806818 (ave = 1.08910654)\n",
      "Loss_G = 1.39556313 (ave = 1.35879183)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.063422609923507, value max: 0.5006135702133179\n",
      "D grad l2-norm: 7.928916260435223, value max: 0.7820185422897339\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001579)\n",
      "Loss_D = 1.16477215 (ave = 1.05924863)\n",
      "Loss_G = 1.46043313 (ave = 1.44448555)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.025832019951021, value max: 0.4990384876728058\n",
      "D grad l2-norm: 8.187167417798427, value max: 0.8127599954605103\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.711s / 5 iters, (0.142)\tData load 0.659s / 5 iters, (0.131770)\n",
      "Loss_D = 0.91772920 (ave = 0.98719019)\n",
      "Loss_G = 1.50935245 (ave = 1.47891941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.841485499300739, value max: 0.4954887330532074\n",
      "D grad l2-norm: 8.2356128062804, value max: 0.8151645660400391\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 0.88304257 (ave = 0.95140144)\n",
      "Loss_G = 1.54972446 (ave = 1.53046734)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.665681143117709, value max: 0.48874473571777344\n",
      "D grad l2-norm: 8.316023958264228, value max: 0.8221749067306519\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.011s / 5 iters, (0.002194)\n",
      "Loss_D = 0.91839242 (ave = 0.91566951)\n",
      "Loss_G = 1.61704051 (ave = 1.58783367)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.298182105337732, value max: 0.47693267464637756\n",
      "D grad l2-norm: 8.102210037553458, value max: 0.8055514097213745\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003473)\n",
      "Loss_D = 0.92954719 (ave = 0.88411427)\n",
      "Loss_G = 1.63487554 (ave = 1.63147571)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.107197414078794, value max: 0.479837566614151\n",
      "D grad l2-norm: 8.09478915465562, value max: 0.8024850487709045\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001703)\n",
      "Loss_D = 0.66540533 (ave = 0.81518109)\n",
      "Loss_G = 1.69173169 (ave = 1.67694261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.1611462574026215, value max: 0.48843997716903687\n",
      "D grad l2-norm: 8.088630874012434, value max: 0.8138343095779419\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.017s / 5 iters, (0.003434)\n",
      "Loss_D = 0.76980853 (ave = 0.80168666)\n",
      "Loss_G = 1.67685604 (ave = 1.68756428)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.468833230233842, value max: 0.5075514316558838\n",
      "D grad l2-norm: 8.19571065174573, value max: 0.8104822039604187\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.017s / 5 iters, (0.003323)\n",
      "Loss_D = 0.75399220 (ave = 0.78121457)\n",
      "Loss_G = 1.68822408 (ave = 1.68831375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.912421312310744, value max: 0.5196289420127869\n",
      "D grad l2-norm: 8.396706229058926, value max: 0.8122504353523254\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.015s / 5 iters, (0.002966)\n",
      "Loss_D = 0.85468942 (ave = 0.78099622)\n",
      "Loss_G = 1.62306213 (ave = 1.65411282)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.8393897789112055, value max: 0.540810227394104\n",
      "D grad l2-norm: 8.034705224526835, value max: 0.7992838025093079\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.017s / 5 iters, (0.003424)\n",
      "Loss_D = 0.82922357 (ave = 0.77069429)\n",
      "Loss_G = 1.63499427 (ave = 1.62795134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.900112095769422, value max: 0.5296301245689392\n",
      "D grad l2-norm: 7.932483986056508, value max: 0.8019315004348755\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 0.83593798 (ave = 0.76647272)\n",
      "Loss_G = 1.57780671 (ave = 1.60213454)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.230149154655422, value max: 0.5273330211639404\n",
      "D grad l2-norm: 7.915951796200509, value max: 0.7906009554862976\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.733s / 5 iters, (0.147)\tData load 0.680s / 5 iters, (0.136066)\n",
      "Loss_D = 0.80474079 (ave = 0.76353222)\n",
      "Loss_G = 1.52868307 (ave = 1.54282727)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.356669013781016, value max: 0.5271966457366943\n",
      "D grad l2-norm: 7.723934672241474, value max: 0.7793284058570862\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001675)\n",
      "Loss_D = 0.83943319 (ave = 0.77790778)\n",
      "Loss_G = 1.47658563 (ave = 1.47789338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.106057983747533, value max: 0.5036336183547974\n",
      "D grad l2-norm: 7.354834398266218, value max: 0.7678070068359375\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001597)\n",
      "Loss_D = 0.83188164 (ave = 0.78806410)\n",
      "Loss_G = 1.44110417 (ave = 1.42956429)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.452251158074806, value max: 0.48756033182144165\n",
      "D grad l2-norm: 7.483588531187936, value max: 0.7599548697471619\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.79289144 (ave = 0.79351614)\n",
      "Loss_G = 1.36426115 (ave = 1.37326159)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.465465954607941, value max: 0.5290177464485168\n",
      "D grad l2-norm: 7.1152514900772585, value max: 0.7403465509414673\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002421)\n",
      "Loss_D = 0.91872764 (ave = 0.83423235)\n",
      "Loss_G = 1.29333484 (ave = 1.32203605)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.933492353016431, value max: 0.5999292135238647\n",
      "D grad l2-norm: 7.046609251219749, value max: 0.7214980125427246\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.73556077 (ave = 0.84637341)\n",
      "Loss_G = 1.17191613 (ave = 1.21665533)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.8283657323824825, value max: 0.6686014533042908\n",
      "D grad l2-norm: 6.562307838633586, value max: 0.6850182414054871\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 1.13357663 (ave = 0.94213806)\n",
      "Loss_G = 1.13099599 (ave = 1.16236117)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.832672082235051, value max: 0.6964695453643799\n",
      "D grad l2-norm: 6.352621131280021, value max: 0.6726189851760864\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002373)\n",
      "Loss_D = 1.09390092 (ave = 0.98018810)\n",
      "Loss_G = 1.06418896 (ave = 1.08638048)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.570245567870544, value max: 0.7655778527259827\n",
      "D grad l2-norm: 6.029881242807232, value max: 0.649281919002533\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.93888569 (ave = 0.99198387)\n",
      "Loss_G = 1.06349456 (ave = 1.05306149)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.4705652999610255, value max: 0.784285306930542\n",
      "D grad l2-norm: 5.954100787614419, value max: 0.6490575671195984\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001758)\n",
      "Loss_D = 1.06627679 (ave = 1.02650267)\n",
      "Loss_G = 1.02996039 (ave = 1.03030996)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.242946979712637, value max: 0.7796551585197449\n",
      "D grad l2-norm: 5.787085533547748, value max: 0.6379356980323792\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.910s / 5 iters, (0.182)\tData load 0.802s / 5 iters, (0.160400)\n",
      "Loss_D = 0.87695074 (ave = 1.01703928)\n",
      "Loss_G = 1.01835918 (ave = 1.00223635)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.922713692290908, value max: 0.8279826045036316\n",
      "D grad l2-norm: 5.694953365654799, value max: 0.6349071264266968\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.027s / 5 iters, (0.005367)\n",
      "Loss_D = 0.94879121 (ave = 1.02326130)\n",
      "Loss_G = 1.05347383 (ave = 1.03941760)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.996765050997928, value max: 0.82584148645401\n",
      "D grad l2-norm: 5.843865161654523, value max: 0.6468663811683655\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.90095639 (ave = 1.01422241)\n",
      "Loss_G = 1.07468700 (ave = 1.06434007)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.974077498072253, value max: 0.8309305310249329\n",
      "D grad l2-norm: 5.914580466310616, value max: 0.6548755764961243\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.030s / 5 iters, (0.005938)\n",
      "Loss_D = 1.03682327 (ave = 1.01709864)\n",
      "Loss_G = 1.07886577 (ave = 1.08677895)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.032366239163007, value max: 0.8349574208259583\n",
      "D grad l2-norm: 5.958376327867225, value max: 0.6562200784683228\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 1.10853410 (ave = 1.03057332)\n",
      "Loss_G = 1.11054492 (ave = 1.09681437)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.144802237932576, value max: 0.8414539098739624\n",
      "D grad l2-norm: 6.142457175472822, value max: 0.6673147678375244\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001580)\n",
      "Loss_D = 1.05027032 (ave = 1.01315147)\n",
      "Loss_G = 1.10759664 (ave = 1.10663636)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.255083060630006, value max: 0.8369783759117126\n",
      "D grad l2-norm: 6.228730405172477, value max: 0.6656150817871094\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 0.89920461 (ave = 0.98972123)\n",
      "Loss_G = 1.11216760 (ave = 1.11222551)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.426318446904042, value max: 0.810402512550354\n",
      "D grad l2-norm: 6.176908480484155, value max: 0.6670189499855042\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001575)\n",
      "Loss_D = 1.09863877 (ave = 1.01749523)\n",
      "Loss_G = 1.11762464 (ave = 1.11176960)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.639170888501912, value max: 0.7697283625602722\n",
      "D grad l2-norm: 6.306291850351107, value max: 0.6697362661361694\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 0.86968881 (ave = 0.99348767)\n",
      "Loss_G = 1.10623014 (ave = 1.10936499)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.654831398479237, value max: 0.6864233613014221\n",
      "D grad l2-norm: 6.295312363398866, value max: 0.6757689118385315\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 1.21114397 (ave = 1.04465816)\n",
      "Loss_G = 1.11927462 (ave = 1.11427822)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.476966507648407, value max: 0.6136031150817871\n",
      "D grad l2-norm: 6.251012608376649, value max: 0.7087682485580444\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.770s / 5 iters, (0.154)\tData load 0.719s / 5 iters, (0.143733)\n",
      "Loss_D = 0.96778059 (ave = 1.00981379)\n",
      "Loss_G = 1.11629248 (ave = 1.12389133)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.349540800159399, value max: 0.562526285648346\n",
      "D grad l2-norm: 6.271477230608178, value max: 0.7442659735679626\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001699)\n",
      "Loss_D = 1.09457231 (ave = 1.01719345)\n",
      "Loss_G = 1.14249074 (ave = 1.13997383)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.34124309236749, value max: 0.6320562362670898\n",
      "D grad l2-norm: 6.394737965416136, value max: 0.7788911461830139\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001626)\n",
      "Loss_D = 0.86128235 (ave = 0.97987251)\n",
      "Loss_G = 1.15950322 (ave = 1.15758338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.315664972739659, value max: 0.6839912533760071\n",
      "D grad l2-norm: 6.403657929705345, value max: 0.7972242832183838\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 1.04180741 (ave = 0.99380950)\n",
      "Loss_G = 1.20641804 (ave = 1.19930608)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.327430813354088, value max: 0.7596666216850281\n",
      "D grad l2-norm: 6.556746441950703, value max: 0.835192084312439\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 0.99478316 (ave = 0.97750363)\n",
      "Loss_G = 1.21149898 (ave = 1.20575392)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.388980425182184, value max: 0.776504635810852\n",
      "D grad l2-norm: 6.583943183684292, value max: 0.8462890982627869\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001754)\n",
      "Loss_D = 1.06609619 (ave = 0.98388575)\n",
      "Loss_G = 1.22158253 (ave = 1.22406733)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.47108461692463, value max: 0.8361591696739197\n",
      "D grad l2-norm: 6.636497476436184, value max: 0.8532633781433105\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 1.02594590 (ave = 0.97367601)\n",
      "Loss_G = 1.22626317 (ave = 1.22928617)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.2756059317485215, value max: 0.8335328102111816\n",
      "D grad l2-norm: 6.470825681287762, value max: 0.8368574380874634\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.018s / 5 iters, (0.003570)\n",
      "Loss_D = 1.07000124 (ave = 0.97968813)\n",
      "Loss_G = 1.21819925 (ave = 1.21908612)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.408841473434497, value max: 0.8346987962722778\n",
      "D grad l2-norm: 6.55530985141523, value max: 0.838422417640686\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 0.93459594 (ave = 0.96902989)\n",
      "Loss_G = 1.23445058 (ave = 1.20298991)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.3785899521594605, value max: 0.8770926594734192\n",
      "D grad l2-norm: 6.532573853832325, value max: 0.8338063359260559\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 1.06784844 (ave = 0.98404932)\n",
      "Loss_G = 1.24468493 (ave = 1.21624165)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.145185897633577, value max: 0.855458676815033\n",
      "D grad l2-norm: 6.359855981541645, value max: 0.8123050928115845\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.852s / 5 iters, (0.170)\tData load 0.801s / 5 iters, (0.160286)\n",
      "Loss_D = 0.95977253 (ave = 0.97582545)\n",
      "Loss_G = 1.19989419 (ave = 1.20494237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.838778404133303, value max: 0.8148829340934753\n",
      "D grad l2-norm: 6.109300540521622, value max: 0.77177894115448\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 0.96635532 (ave = 0.96658276)\n",
      "Loss_G = 1.22467113 (ave = 1.20840364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.77662537354421, value max: 0.7760927081108093\n",
      "D grad l2-norm: 6.128228050411627, value max: 0.7663902640342712\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 0.95992136 (ave = 0.96835082)\n",
      "Loss_G = 1.20604539 (ave = 1.19634304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.499240605567493, value max: 0.687063455581665\n",
      "D grad l2-norm: 5.8555277867820354, value max: 0.7271225452423096\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 0.89227772 (ave = 0.95865445)\n",
      "Loss_G = 1.20694137 (ave = 1.19413924)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.45851763962966, value max: 0.6371283531188965\n",
      "D grad l2-norm: 5.743278638476486, value max: 0.7131760120391846\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.019s / 5 iters, (0.003845)\n",
      "Loss_D = 1.01835680 (ave = 0.97719283)\n",
      "Loss_G = 1.16919827 (ave = 1.16956556)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.250203716686655, value max: 0.6110509634017944\n",
      "D grad l2-norm: 5.551589528664742, value max: 0.6849083304405212\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001597)\n",
      "Loss_D = 1.00493658 (ave = 0.98366086)\n",
      "Loss_G = 1.17737198 (ave = 1.17217538)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.237504746972372, value max: 0.6175658106803894\n",
      "D grad l2-norm: 5.569949585914634, value max: 0.6878566145896912\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.00125408 (ave = 0.98359774)\n",
      "Loss_G = 1.17118537 (ave = 1.14873860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.860128627864704, value max: 0.5609341859817505\n",
      "D grad l2-norm: 5.348736831955823, value max: 0.6863402724266052\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 1.14493680 (ave = 0.98602250)\n",
      "Loss_G = 1.19393253 (ave = 1.16293409)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.815131762573189, value max: 0.5561302304267883\n",
      "D grad l2-norm: 5.312563533180929, value max: 0.6926430463790894\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 1.05317402 (ave = 0.97021101)\n",
      "Loss_G = 1.16199744 (ave = 1.17935903)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.756012674364284, value max: 0.5337689518928528\n",
      "D grad l2-norm: 5.146151070459119, value max: 0.6832385063171387\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001697)\n",
      "Loss_D = 0.89968282 (ave = 0.95169270)\n",
      "Loss_G = 1.19178867 (ave = 1.17511129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.866079388685431, value max: 0.5479200482368469\n",
      "D grad l2-norm: 5.150099767118497, value max: 0.6923743486404419\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 4\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.006s / 5 iters, (0.001281)\n",
      "Loss_D = 1.39905143 (ave = 1.39842250)\n",
      "Loss_G = 0.75291920 (ave = 0.75380155)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9657083492378364, value max: 0.023859836161136627\n",
      "D grad l2-norm: 0.7126047638350137, value max: 0.5290079712867737\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.577s / 5 iters, (0.115)\tData load 0.477s / 5 iters, (0.095351)\n",
      "Loss_D = 1.39053822 (ave = 1.38624468)\n",
      "Loss_G = 0.74948484 (ave = 0.75052389)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9655345630616978, value max: 0.023212358355522156\n",
      "D grad l2-norm: 0.7113628562222838, value max: 0.527387261390686\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.422s / 5 iters, (0.084)\tData load 0.373s / 5 iters, (0.074610)\n",
      "Loss_D = 1.36709082 (ave = 1.37265139)\n",
      "Loss_G = 0.74662048 (ave = 0.74771839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.961398715693967, value max: 0.02605476789176464\n",
      "D grad l2-norm: 0.711364452695718, value max: 0.5260317325592041\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.394s / 5 iters, (0.079)\tData load 0.334s / 5 iters, (0.066751)\n",
      "Loss_D = 1.35282230 (ave = 1.36039913)\n",
      "Loss_G = 0.74375659 (ave = 0.74502144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9644194275957062, value max: 0.02578231878578663\n",
      "D grad l2-norm: 0.7119723280573398, value max: 0.5246716737747192\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.436s / 5 iters, (0.087)\tData load 0.342s / 5 iters, (0.068454)\n",
      "Loss_D = 1.34952295 (ave = 1.34994245)\n",
      "Loss_G = 0.74136651 (ave = 0.74257805)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9689941120399165, value max: 0.023966021835803986\n",
      "D grad l2-norm: 0.7124949601872114, value max: 0.5235346555709839\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.424s / 5 iters, (0.085)\tData load 0.369s / 5 iters, (0.073701)\n",
      "Loss_D = 1.34359002 (ave = 1.33963325)\n",
      "Loss_G = 0.73831606 (ave = 0.73990086)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.970406387860476, value max: 0.02741272747516632\n",
      "D grad l2-norm: 0.7131664184131632, value max: 0.5220784544944763\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.566s / 5 iters, (0.113)\tData load 0.481s / 5 iters, (0.096213)\n",
      "Loss_D = 1.31907690 (ave = 1.32759168)\n",
      "Loss_G = 0.73619819 (ave = 0.73730905)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9736861119298104, value max: 0.025982532650232315\n",
      "D grad l2-norm: 0.7164221608567364, value max: 0.5210641026496887\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.493s / 5 iters, (0.099)\tData load 0.422s / 5 iters, (0.084393)\n",
      "Loss_D = 1.32047141 (ave = 1.31878893)\n",
      "Loss_G = 0.73392206 (ave = 0.73492101)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9711474039244659, value max: 0.029910992830991745\n",
      "D grad l2-norm: 0.7229349770579478, value max: 0.5199713706970215\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.427s / 5 iters, (0.085)\tData load 0.348s / 5 iters, (0.069543)\n",
      "Loss_D = 1.29383278 (ave = 1.30686319)\n",
      "Loss_G = 0.73170418 (ave = 0.73275284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9687629124867438, value max: 0.02998456172645092\n",
      "D grad l2-norm: 0.7247685909679635, value max: 0.5189071297645569\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.249s / 5 iters, (0.250)\tData load 1.196s / 5 iters, (0.239135)\n",
      "Loss_D = 1.29021335 (ave = 1.29858890)\n",
      "Loss_G = 0.72908568 (ave = 0.73019267)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9730656338812852, value max: 0.03330455720424652\n",
      "D grad l2-norm: 0.7266852863186406, value max: 0.5176447629928589\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.898s / 5 iters, (0.180)\tData load 0.846s / 5 iters, (0.169282)\n",
      "Loss_D = 1.27087975 (ave = 1.28818853)\n",
      "Loss_G = 0.72704697 (ave = 0.72794143)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9745257739128261, value max: 0.03149713575839996\n",
      "D grad l2-norm: 0.7294373959076519, value max: 0.5166609883308411\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 1.27847195 (ave = 1.28152544)\n",
      "Loss_G = 0.72490257 (ave = 0.72587140)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9706931900469, value max: 0.038888800889253616\n",
      "D grad l2-norm: 0.7359758456876347, value max: 0.5156211256980896\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 1.27434826 (ave = 1.27384307)\n",
      "Loss_G = 0.72320020 (ave = 0.72390335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9778061450858944, value max: 0.0316077321767807\n",
      "D grad l2-norm: 0.7410573705429478, value max: 0.5147942900657654\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 1.25011408 (ave = 1.26330392)\n",
      "Loss_G = 0.72222078 (ave = 0.72230746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9788330185183336, value max: 0.03936753794550896\n",
      "D grad l2-norm: 0.7465351444364063, value max: 0.5143178105354309\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.016s / 5 iters, (0.003116)\n",
      "Loss_D = 1.24336505 (ave = 1.25590861)\n",
      "Loss_G = 0.71925914 (ave = 0.72040941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9820801303527851, value max: 0.03805705904960632\n",
      "D grad l2-norm: 0.7550056301658755, value max: 0.5128779411315918\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001731)\n",
      "Loss_D = 1.26009893 (ave = 1.25115983)\n",
      "Loss_G = 0.71892869 (ave = 0.71926477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9816244522549372, value max: 0.04036206007003784\n",
      "D grad l2-norm: 0.7613093212705158, value max: 0.5127125382423401\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.26318872 (ave = 1.24527636)\n",
      "Loss_G = 0.71580148 (ave = 0.71731795)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9867620076565974, value max: 0.04766889289021492\n",
      "D grad l2-norm: 0.7792438979552483, value max: 0.511184573173523\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 1.23892474 (ave = 1.23641028)\n",
      "Loss_G = 0.71585643 (ave = 0.71655766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9877039073734861, value max: 0.045570310205221176\n",
      "D grad l2-norm: 0.7846700421977452, value max: 0.5112074017524719\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 1.22288966 (ave = 1.22819352)\n",
      "Loss_G = 0.71449113 (ave = 0.71614769)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9906993023824344, value max: 0.04852084815502167\n",
      "D grad l2-norm: 0.7989225856746016, value max: 0.5105421543121338\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 1.22028172 (ave = 1.22203827)\n",
      "Loss_G = 0.71410477 (ave = 0.71471642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9969526172301436, value max: 0.04858367145061493\n",
      "D grad l2-norm: 0.8118862951237305, value max: 0.5103510618209839\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.749s / 5 iters, (0.150)\tData load 0.682s / 5 iters, (0.136328)\n",
      "Loss_D = 1.22076488 (ave = 1.21584783)\n",
      "Loss_G = 0.71504873 (ave = 0.71518264)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9927388851426838, value max: 0.05143769457936287\n",
      "D grad l2-norm: 0.8261136204472332, value max: 0.5108054280281067\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.015s / 5 iters, (0.003006)\n",
      "Loss_D = 1.20086002 (ave = 1.20849769)\n",
      "Loss_G = 0.71361357 (ave = 0.71474563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9987195056765065, value max: 0.04757697135210037\n",
      "D grad l2-norm: 0.842068518083978, value max: 0.510098934173584\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.024s / 5 iters, (0.004828)\n",
      "Loss_D = 1.21210408 (ave = 1.20427108)\n",
      "Loss_G = 0.71448004 (ave = 0.71510872)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0007153079540545, value max: 0.04854607582092285\n",
      "D grad l2-norm: 0.8583241398227154, value max: 0.5105247497558594\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.024s / 5 iters, (0.004778)\n",
      "Loss_D = 1.18979287 (ave = 1.19478793)\n",
      "Loss_G = 0.71810406 (ave = 0.71721382)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9967796061219808, value max: 0.048828139901161194\n",
      "D grad l2-norm: 0.8686719124326407, value max: 0.5122976899147034\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.019s / 5 iters, (0.003872)\n",
      "Loss_D = 1.18519855 (ave = 1.18701954)\n",
      "Loss_G = 0.72291386 (ave = 0.72028557)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9989948690106113, value max: 0.04633534327149391\n",
      "D grad l2-norm: 0.8861797532055088, value max: 0.5146269798278809\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003493)\n",
      "Loss_D = 1.16934299 (ave = 1.17740710)\n",
      "Loss_G = 0.72626185 (ave = 0.72464764)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0009213761828837, value max: 0.03912380337715149\n",
      "D grad l2-norm: 0.9132772514629076, value max: 0.5162613987922668\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.020s / 5 iters, (0.004092)\n",
      "Loss_D = 1.16304493 (ave = 1.16784160)\n",
      "Loss_G = 0.73233634 (ave = 0.72910239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0028670190609394, value max: 0.038807038217782974\n",
      "D grad l2-norm: 0.9296122792433998, value max: 0.519182562828064\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001501)\n",
      "Loss_D = 1.17786014 (ave = 1.16088834)\n",
      "Loss_G = 0.73759490 (ave = 0.73577471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9942896558670927, value max: 0.038432225584983826\n",
      "D grad l2-norm: 0.9513741435166574, value max: 0.5217028856277466\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 1.17619967 (ave = 1.15026443)\n",
      "Loss_G = 0.74731934 (ave = 0.74368805)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.997678746758024, value max: 0.03692211955785751\n",
      "D grad l2-norm: 0.9666348867587362, value max: 0.52634596824646\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001709)\n",
      "Loss_D = 1.12132955 (ave = 1.13287702)\n",
      "Loss_G = 0.75306684 (ave = 0.75078129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0007963938183595, value max: 0.0354955680668354\n",
      "D grad l2-norm: 0.9990629816233331, value max: 0.5290495157241821\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.696s / 5 iters, (0.139)\tData load 0.645s / 5 iters, (0.129032)\n",
      "Loss_D = 1.12893116 (ave = 1.12211077)\n",
      "Loss_G = 0.76409334 (ave = 0.76075481)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0046886583785655, value max: 0.03835003823041916\n",
      "D grad l2-norm: 1.0173572430719382, value max: 0.5342205166816711\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001749)\n",
      "Loss_D = 1.10543740 (ave = 1.10696266)\n",
      "Loss_G = 0.77307934 (ave = 0.77007650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9989846694323021, value max: 0.04309800639748573\n",
      "D grad l2-norm: 1.0374429291435328, value max: 0.5383908748626709\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 1.09119129 (ave = 1.09364874)\n",
      "Loss_G = 0.78476357 (ave = 0.77921233)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004516127904896, value max: 0.05069919303059578\n",
      "D grad l2-norm: 1.054751484246923, value max: 0.5437520742416382\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.012s / 5 iters, (0.002446)\n",
      "Loss_D = 1.10911870 (ave = 1.08351212)\n",
      "Loss_G = 0.79453981 (ave = 0.78960385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0047150901309272, value max: 0.05542746186256409\n",
      "D grad l2-norm: 1.0781199202908762, value max: 0.548189103603363\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.014s / 5 iters, (0.002866)\n",
      "Loss_D = 1.06330502 (ave = 1.06637444)\n",
      "Loss_G = 0.80301499 (ave = 0.79917374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0228862145008988, value max: 0.061220522969961166\n",
      "D grad l2-norm: 1.1096192524690571, value max: 0.5520017743110657\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 1.04379141 (ave = 1.05303099)\n",
      "Loss_G = 0.81203765 (ave = 0.80792896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.026683315915099, value max: 0.06676890701055527\n",
      "D grad l2-norm: 1.121483973664047, value max: 0.5560191869735718\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 1.03651369 (ave = 1.04157219)\n",
      "Loss_G = 0.81993920 (ave = 0.81598417)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0460546793973615, value max: 0.08205452561378479\n",
      "D grad l2-norm: 1.1335921052795865, value max: 0.5595149397850037\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 1.03653550 (ave = 1.03149717)\n",
      "Loss_G = 0.82694072 (ave = 0.82370796)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0553227343622784, value max: 0.08194353431463242\n",
      "D grad l2-norm: 1.1424456054705823, value max: 0.5625885725021362\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001712)\n",
      "Loss_D = 1.01420856 (ave = 1.01971006)\n",
      "Loss_G = 0.82890117 (ave = 0.82926846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0700870564394238, value max: 0.07943883538246155\n",
      "D grad l2-norm: 1.1567734634311326, value max: 0.5634355545043945\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 1.00487328 (ave = 1.01112528)\n",
      "Loss_G = 0.83463484 (ave = 0.83332247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0860035857641415, value max: 0.08885730057954788\n",
      "D grad l2-norm: 1.1742456467127689, value max: 0.5659214854240417\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.936s / 5 iters, (0.187)\tData load 0.888s / 5 iters, (0.177527)\n",
      "Loss_D = 1.02204061 (ave = 1.00529571)\n",
      "Loss_G = 0.83757824 (ave = 0.83675697)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1080214003423954, value max: 0.09335439652204514\n",
      "D grad l2-norm: 1.1862199712269668, value max: 0.5671992301940918\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001537)\n",
      "Loss_D = 1.04872620 (ave = 1.00214972)\n",
      "Loss_G = 0.84024888 (ave = 0.83921026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1148043266043084, value max: 0.08972515910863876\n",
      "D grad l2-norm: 1.188288229247273, value max: 0.5683319568634033\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.012s / 5 iters, (0.002335)\n",
      "Loss_D = 0.99330521 (ave = 0.98967720)\n",
      "Loss_G = 0.83863956 (ave = 0.83915024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1437782434322512, value max: 0.09905321151018143\n",
      "D grad l2-norm: 1.2015771902622, value max: 0.5676302313804626\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001737)\n",
      "Loss_D = 0.94815093 (ave = 0.97916187)\n",
      "Loss_G = 0.83661127 (ave = 0.83857483)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1845611763653852, value max: 0.10937980562448502\n",
      "D grad l2-norm: 1.211502562089591, value max: 0.5667431354522705\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 0.99328625 (ave = 0.98259393)\n",
      "Loss_G = 0.83071327 (ave = 0.83471631)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2158450637075433, value max: 0.12018786370754242\n",
      "D grad l2-norm: 1.2201595574668913, value max: 0.5641527771949768\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 0.99490499 (ave = 0.98310629)\n",
      "Loss_G = 0.82539439 (ave = 0.82831000)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2414475355063166, value max: 0.1255090981721878\n",
      "D grad l2-norm: 1.2168256000670221, value max: 0.5618185997009277\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.98246312 (ave = 0.98181646)\n",
      "Loss_G = 0.81958258 (ave = 0.82116905)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2704225188266607, value max: 0.14182697236537933\n",
      "D grad l2-norm: 1.2209199523768877, value max: 0.5592672824859619\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 0.97822082 (ave = 0.98472955)\n",
      "Loss_G = 0.80894625 (ave = 0.81096095)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2850271879061195, value max: 0.14074240624904633\n",
      "D grad l2-norm: 1.231925529028096, value max: 0.5544949769973755\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001697)\n",
      "Loss_D = 1.02743304 (ave = 0.99318933)\n",
      "Loss_G = 0.80079114 (ave = 0.80168477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3039752989718683, value max: 0.14676278829574585\n",
      "D grad l2-norm: 1.2491778684692936, value max: 0.5508666038513184\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 1.00809419 (ave = 0.99549487)\n",
      "Loss_G = 0.79344988 (ave = 0.79483737)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3258146705588956, value max: 0.15259939432144165\n",
      "D grad l2-norm: 1.2761299001086832, value max: 0.5474969148635864\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.800s / 5 iters, (0.160)\tData load 0.745s / 5 iters, (0.148977)\n",
      "Loss_D = 0.94458115 (ave = 0.98725679)\n",
      "Loss_G = 0.78771389 (ave = 0.78907626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3340956897743796, value max: 0.15241126716136932\n",
      "D grad l2-norm: 1.301177334576478, value max: 0.5449094772338867\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001731)\n",
      "Loss_D = 1.01779735 (ave = 0.99915600)\n",
      "Loss_G = 0.78562796 (ave = 0.78605905)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3406297676091892, value max: 0.14854229986667633\n",
      "D grad l2-norm: 1.3174302025914804, value max: 0.543908953666687\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 0.98565739 (ave = 0.99536241)\n",
      "Loss_G = 0.77489769 (ave = 0.78108870)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3763599478997275, value max: 0.14782766997814178\n",
      "D grad l2-norm: 1.3728447109324098, value max: 0.538928210735321\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001702)\n",
      "Loss_D = 0.97775185 (ave = 0.99760618)\n",
      "Loss_G = 0.77900076 (ave = 0.78228730)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3923164410745756, value max: 0.15706683695316315\n",
      "D grad l2-norm: 1.3977340487963126, value max: 0.5408427715301514\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 5 iters, (0.024)\tData load 0.009s / 5 iters, (0.001700)\n",
      "Loss_D = 0.99018669 (ave = 0.99990396)\n",
      "Loss_G = 0.78788674 (ave = 0.78154305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4108342827720817, value max: 0.15482720732688904\n",
      "D grad l2-norm: 1.4162614988489954, value max: 0.5448763966560364\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.015s / 5 iters, (0.003052)\n",
      "Loss_D = 1.04480326 (ave = 1.00817263)\n",
      "Loss_G = 0.78329247 (ave = 0.78050843)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4433158396317276, value max: 0.15253782272338867\n",
      "D grad l2-norm: 1.4540724915440206, value max: 0.5427441000938416\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 0.94262183 (ave = 0.99446619)\n",
      "Loss_G = 0.78197408 (ave = 0.77675377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4908292659949387, value max: 0.15584918856620789\n",
      "D grad l2-norm: 1.5230974296852358, value max: 0.5420966148376465\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.015s / 5 iters, (0.003053)\n",
      "Loss_D = 1.02276635 (ave = 1.00351236)\n",
      "Loss_G = 0.79448617 (ave = 0.78976079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4911135954522194, value max: 0.15914250910282135\n",
      "D grad l2-norm: 1.5582689893653612, value max: 0.5477840900421143\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.018s / 5 iters, (0.003676)\n",
      "Loss_D = 1.00106072 (ave = 0.99589396)\n",
      "Loss_G = 0.80340463 (ave = 0.79744655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4941182974803564, value max: 0.1599927842617035\n",
      "D grad l2-norm: 1.602597372488005, value max: 0.5517917275428772\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.140s / 5 iters, (0.028)\tData load 0.024s / 5 iters, (0.004774)\n",
      "Loss_D = 0.95768702 (ave = 0.98097947)\n",
      "Loss_G = 0.82704127 (ave = 0.81416482)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5015279512930984, value max: 0.1552531123161316\n",
      "D grad l2-norm: 1.6763263417650591, value max: 0.5621896982192993\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.794s / 5 iters, (0.159)\tData load 0.745s / 5 iters, (0.148927)\n",
      "Loss_D = 0.87938654 (ave = 0.95676007)\n",
      "Loss_G = 0.83700234 (ave = 0.82576665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5375691890567618, value max: 0.16214323043823242\n",
      "D grad l2-norm: 1.7410268742394066, value max: 0.5665341019630432\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 0.98923683 (ave = 0.95620756)\n",
      "Loss_G = 0.86300313 (ave = 0.85249792)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5603270198059556, value max: 0.16897453367710114\n",
      "D grad l2-norm: 1.81449309365128, value max: 0.5777010917663574\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 0.95345354 (ave = 0.93867713)\n",
      "Loss_G = 0.88325649 (ave = 0.86986722)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.612136375803898, value max: 0.17735637724399567\n",
      "D grad l2-norm: 1.8588444371715016, value max: 0.5861148238182068\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001706)\n",
      "Loss_D = 0.89548624 (ave = 0.91923963)\n",
      "Loss_G = 0.89823836 (ave = 0.89058087)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.713250663036585, value max: 0.19062326848506927\n",
      "D grad l2-norm: 1.9444526001122115, value max: 0.5922635793685913\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001746)\n",
      "Loss_D = 0.93227851 (ave = 0.91235323)\n",
      "Loss_G = 0.91193831 (ave = 0.90829686)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8169347263832876, value max: 0.18987494707107544\n",
      "D grad l2-norm: 2.0264261586540737, value max: 0.5977667570114136\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 0.91169631 (ave = 0.90532256)\n",
      "Loss_G = 0.91539371 (ave = 0.91180905)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9385114376887043, value max: 0.18833385407924652\n",
      "D grad l2-norm: 2.125479318750204, value max: 0.5990260243415833\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.90602243 (ave = 0.90550412)\n",
      "Loss_G = 0.90883762 (ave = 0.91543651)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.011222562511465, value max: 0.204250767827034\n",
      "D grad l2-norm: 2.161372574801072, value max: 0.5963423848152161\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.015s / 5 iters, (0.002938)\n",
      "Loss_D = 0.93433547 (ave = 0.90805885)\n",
      "Loss_G = 0.92769891 (ave = 0.92304037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0597167569776684, value max: 0.21732011437416077\n",
      "D grad l2-norm: 2.2321952501808755, value max: 0.6038597822189331\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.011s / 5 iters, (0.002271)\n",
      "Loss_D = 0.84146261 (ave = 0.89468753)\n",
      "Loss_G = 0.91699225 (ave = 0.91901468)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1542460790774114, value max: 0.21745124459266663\n",
      "D grad l2-norm: 2.289614187860587, value max: 0.5994999408721924\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.93885106 (ave = 0.91253281)\n",
      "Loss_G = 0.92263877 (ave = 0.92224579)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2767717334173607, value max: 0.2430214136838913\n",
      "D grad l2-norm: 2.3309036007545427, value max: 0.6018417477607727\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.768s / 5 iters, (0.154)\tData load 0.716s / 5 iters, (0.143247)\n",
      "Loss_D = 0.88313860 (ave = 0.91094915)\n",
      "Loss_G = 0.90304798 (ave = 0.90983601)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3440068569202803, value max: 0.2415652722120285\n",
      "D grad l2-norm: 2.38752064699585, value max: 0.5937989950180054\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001799)\n",
      "Loss_D = 0.89318961 (ave = 0.92077487)\n",
      "Loss_G = 0.90179890 (ave = 0.90286651)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.277017229736535, value max: 0.23082305490970612\n",
      "D grad l2-norm: 2.4019191874556824, value max: 0.5933253765106201\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 0.95073557 (ave = 0.93093077)\n",
      "Loss_G = 0.90971208 (ave = 0.90307518)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3076189527568998, value max: 0.23520870506763458\n",
      "D grad l2-norm: 2.501858455644569, value max: 0.5967166423797607\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 5 iters, (0.022)\tData load 0.032s / 5 iters, (0.006383)\n",
      "Loss_D = 0.94772196 (ave = 0.92912771)\n",
      "Loss_G = 0.92220783 (ave = 0.91181426)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2558766368182352, value max: 0.23447242379188538\n",
      "D grad l2-norm: 2.5292817777552803, value max: 0.6016969680786133\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001716)\n",
      "Loss_D = 0.89712226 (ave = 0.91003653)\n",
      "Loss_G = 0.93010873 (ave = 0.92892851)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3338050056643964, value max: 0.22289834916591644\n",
      "D grad l2-norm: 2.6757583366864757, value max: 0.6048434972763062\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 0.95537645 (ave = 0.90705081)\n",
      "Loss_G = 0.96386272 (ave = 0.94960431)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.337089437038664, value max: 0.22672103345394135\n",
      "D grad l2-norm: 2.7174444987670494, value max: 0.6179095506668091\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001843)\n",
      "Loss_D = 0.84008944 (ave = 0.87459655)\n",
      "Loss_G = 0.98194081 (ave = 0.97261500)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.456100394870019, value max: 0.24175681173801422\n",
      "D grad l2-norm: 2.9098185078436027, value max: 0.6248456835746765\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001729)\n",
      "Loss_D = 0.96941102 (ave = 0.87844615)\n",
      "Loss_G = 1.02348161 (ave = 1.00123749)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.477702300769054, value max: 0.2578828036785126\n",
      "D grad l2-norm: 3.0429274296407622, value max: 0.6400606036186218\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 0.82806712 (ave = 0.84382418)\n",
      "Loss_G = 1.05065370 (ave = 1.03498459)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.5755665860870085, value max: 0.2689303159713745\n",
      "D grad l2-norm: 3.2017290174620903, value max: 0.6498492360115051\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 0.76431835 (ave = 0.81266103)\n",
      "Loss_G = 1.09198081 (ave = 1.07788806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6763319005751494, value max: 0.2876953184604645\n",
      "D grad l2-norm: 3.3535212951119067, value max: 0.6637586355209351\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.681s / 5 iters, (0.136)\tData load 0.631s / 5 iters, (0.126192)\n",
      "Loss_D = 0.81246924 (ave = 0.79812922)\n",
      "Loss_G = 1.13452375 (ave = 1.12101119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8688911604340857, value max: 0.3050999045372009\n",
      "D grad l2-norm: 3.5740702686966053, value max: 0.6778289675712585\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001723)\n",
      "Loss_D = 0.85151213 (ave = 0.79236943)\n",
      "Loss_G = 1.17129028 (ave = 1.15522401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.9400194543628237, value max: 0.3098977208137512\n",
      "D grad l2-norm: 3.618410131433896, value max: 0.6893213987350464\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.010s / 5 iters, (0.002027)\n",
      "Loss_D = 0.69884825 (ave = 0.75942937)\n",
      "Loss_G = 1.18882108 (ave = 1.18181770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.286255194245926, value max: 0.33496421575546265\n",
      "D grad l2-norm: 3.86050618238394, value max: 0.6945134401321411\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.021s / 5 iters, (0.004102)\n",
      "Loss_D = 0.83025420 (ave = 0.77339579)\n",
      "Loss_G = 1.19191194 (ave = 1.18596313)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4568152914887817, value max: 0.3711410164833069\n",
      "D grad l2-norm: 3.902784269819042, value max: 0.6951358318328857\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.90368015 (ave = 0.78341663)\n",
      "Loss_G = 1.18266916 (ave = 1.19076333)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.642722164267765, value max: 0.39572176337242126\n",
      "D grad l2-norm: 3.949480189702388, value max: 0.691989541053772\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 0.76678693 (ave = 0.77014704)\n",
      "Loss_G = 1.19090080 (ave = 1.18311441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.8380090394192123, value max: 0.41713792085647583\n",
      "D grad l2-norm: 4.022279522075655, value max: 0.6942651867866516\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001709)\n",
      "Loss_D = 0.83296192 (ave = 0.79271901)\n",
      "Loss_G = 1.16569984 (ave = 1.16880777)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.8988348507344255, value max: 0.4349355697631836\n",
      "D grad l2-norm: 3.9658115794496136, value max: 0.6866066455841064\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002376)\n",
      "Loss_D = 0.89290082 (ave = 0.80956136)\n",
      "Loss_G = 1.11658311 (ave = 1.14114971)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9809212167012955, value max: 0.46077555418014526\n",
      "D grad l2-norm: 3.8646685056078685, value max: 0.6705365777015686\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001734)\n",
      "Loss_D = 0.88942862 (ave = 0.82853959)\n",
      "Loss_G = 1.12476301 (ave = 1.12611067)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.109229706759235, value max: 0.4738672375679016\n",
      "D grad l2-norm: 3.9022563277950466, value max: 0.672643780708313\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 0.89350319 (ave = 0.84861534)\n",
      "Loss_G = 1.05823398 (ave = 1.09351335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.395415084794357, value max: 0.4843488931655884\n",
      "D grad l2-norm: 3.9408874653611696, value max: 0.6499958038330078\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.926s / 5 iters, (0.185)\tData load 0.862s / 5 iters, (0.172393)\n",
      "Loss_D = 0.90929627 (ave = 0.87719014)\n",
      "Loss_G = 1.03076410 (ave = 1.05663331)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.327794204716557, value max: 0.46824824810028076\n",
      "D grad l2-norm: 3.817597841096911, value max: 0.6399567723274231\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.018s / 5 iters, (0.003569)\n",
      "Loss_D = 0.98664016 (ave = 0.91943413)\n",
      "Loss_G = 1.01362419 (ave = 1.01031253)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.31247390294336, value max: 0.4465242028236389\n",
      "D grad l2-norm: 3.823196418881663, value max: 0.6346349120140076\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 0.87326729 (ave = 0.91817498)\n",
      "Loss_G = 0.96677613 (ave = 0.97253088)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.167900784915193, value max: 0.3961099684238434\n",
      "D grad l2-norm: 3.7448414294897927, value max: 0.6170806884765625\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001730)\n",
      "Loss_D = 0.84618759 (ave = 0.93447461)\n",
      "Loss_G = 0.97622770 (ave = 0.96830746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.13061727767912, value max: 0.3674241006374359\n",
      "D grad l2-norm: 3.7406794446182747, value max: 0.6204302310943604\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 0.86953688 (ave = 0.94236329)\n",
      "Loss_G = 0.97824621 (ave = 0.97134343)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.176543466290227, value max: 0.38637784123420715\n",
      "D grad l2-norm: 3.81015484221429, value max: 0.6213181614875793\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 1.01587534 (ave = 0.96618298)\n",
      "Loss_G = 0.95021528 (ave = 0.96491752)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.186401990139971, value max: 0.3626445233821869\n",
      "D grad l2-norm: 3.8103795510450715, value max: 0.610700249671936\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001700)\n",
      "Loss_D = 0.88934958 (ave = 0.95589402)\n",
      "Loss_G = 0.97405547 (ave = 0.97008666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.298284849672498, value max: 0.3641054332256317\n",
      "D grad l2-norm: 3.947580539499703, value max: 0.6203436255455017\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.009s / 5 iters, (0.001784)\n",
      "Loss_D = 0.92233407 (ave = 0.96798267)\n",
      "Loss_G = 0.97883081 (ave = 0.97140896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.270289287525063, value max: 0.3320755660533905\n",
      "D grad l2-norm: 3.9925527670298413, value max: 0.6212342977523804\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.020s / 5 iters, (0.003975)\n",
      "Loss_D = 1.13113236 (ave = 0.99820124)\n",
      "Loss_G = 0.98072380 (ave = 0.97617123)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.6127095727974385, value max: 0.34783118963241577\n",
      "D grad l2-norm: 4.209993286878464, value max: 0.6221083998680115\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 0.95087409 (ave = 0.98136584)\n",
      "Loss_G = 0.98785222 (ave = 0.98120620)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.676259286895049, value max: 0.3821521997451782\n",
      "D grad l2-norm: 4.306867458357196, value max: 0.6246652007102966\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.764s / 5 iters, (0.153)\tData load 0.713s / 5 iters, (0.142638)\n",
      "Loss_D = 0.97547603 (ave = 0.99227208)\n",
      "Loss_G = 0.97708583 (ave = 0.99089705)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.870444949536169, value max: 0.40306898951530457\n",
      "D grad l2-norm: 4.629112455077209, value max: 0.6209490299224854\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 1.03304660 (ave = 1.00445104)\n",
      "Loss_G = 1.03955650 (ave = 1.02675226)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.802075747494252, value max: 0.40421634912490845\n",
      "D grad l2-norm: 4.846359350939784, value max: 0.6437264084815979\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 0.96159768 (ave = 0.97021395)\n",
      "Loss_G = 1.11012065 (ave = 1.08005397)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.811500110371976, value max: 0.4022443890571594\n",
      "D grad l2-norm: 5.244558307036279, value max: 0.6682041883468628\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.016s / 5 iters, (0.003292)\n",
      "Loss_D = 0.92189544 (ave = 0.94253802)\n",
      "Loss_G = 1.21259725 (ave = 1.16421938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.013978793031716, value max: 0.411973237991333\n",
      "D grad l2-norm: 5.678277376682995, value max: 0.7007752060890198\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.018s / 5 iters, (0.003573)\n",
      "Loss_D = 0.96945530 (ave = 0.93091618)\n",
      "Loss_G = 1.26861405 (ave = 1.23844793)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.183881102294695, value max: 0.4056967496871948\n",
      "D grad l2-norm: 5.971404524240141, value max: 0.7170516848564148\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 0.74733829 (ave = 0.89529861)\n",
      "Loss_G = 1.26687813 (ave = 1.25472956)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.453817431160943, value max: 0.39984560012817383\n",
      "D grad l2-norm: 6.33180988684811, value max: 0.7163233757019043\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.009s / 5 iters, (0.001775)\n",
      "Loss_D = 1.01539338 (ave = 0.92470379)\n",
      "Loss_G = 1.29951274 (ave = 1.30443420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.432249637391841, value max: 0.39110463857650757\n",
      "D grad l2-norm: 6.454999868749642, value max: 0.7254375219345093\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.020s / 5 iters, (0.004001)\n",
      "Loss_D = 0.92314470 (ave = 0.91169577)\n",
      "Loss_G = 1.35455215 (ave = 1.33422706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.535628498684717, value max: 0.3753214478492737\n",
      "D grad l2-norm: 6.692730395733594, value max: 0.7410529851913452\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.92635286 (ave = 0.90827119)\n",
      "Loss_G = 1.36017203 (ave = 1.36930366)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.744529191035791, value max: 0.3686394989490509\n",
      "D grad l2-norm: 6.871684025354991, value max: 0.8069185614585876\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001566)\n",
      "Loss_D = 0.82106566 (ave = 0.89615587)\n",
      "Loss_G = 1.40281093 (ave = 1.38634107)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.81737523303677, value max: 0.4252071976661682\n",
      "D grad l2-norm: 6.997171682543574, value max: 0.8607158064842224\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.712s / 5 iters, (0.142)\tData load 0.659s / 5 iters, (0.131703)\n",
      "Loss_D = 0.98348629 (ave = 0.91833930)\n",
      "Loss_G = 1.43077970 (ave = 1.41488056)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.041107355574526, value max: 0.46046876907348633\n",
      "D grad l2-norm: 7.159572425876691, value max: 0.90629643201828\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001709)\n",
      "Loss_D = 0.80693555 (ave = 0.89256227)\n",
      "Loss_G = 1.44051313 (ave = 1.44327493)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.196416878993475, value max: 0.4753129482269287\n",
      "D grad l2-norm: 7.145804419213087, value max: 0.9228845834732056\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.81007129 (ave = 0.89594254)\n",
      "Loss_G = 1.40770662 (ave = 1.42290094)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.66579615102195, value max: 0.48459601402282715\n",
      "D grad l2-norm: 7.209437476399485, value max: 0.9288524389266968\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 0.85310209 (ave = 0.91751856)\n",
      "Loss_G = 1.39154530 (ave = 1.40549226)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.840510921078437, value max: 0.5053915977478027\n",
      "D grad l2-norm: 7.171758618904361, value max: 0.9271734952926636\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 0.94409943 (ave = 0.94006382)\n",
      "Loss_G = 1.38719428 (ave = 1.38443754)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.832422594090973, value max: 0.5148233771324158\n",
      "D grad l2-norm: 7.109058861684622, value max: 0.9142748713493347\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001589)\n",
      "Loss_D = 0.95924747 (ave = 0.95155472)\n",
      "Loss_G = 1.36043680 (ave = 1.36561661)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.826219142042435, value max: 0.5120449662208557\n",
      "D grad l2-norm: 7.0022614080531, value max: 0.8962715864181519\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001684)\n",
      "Loss_D = 1.05788958 (ave = 0.96490524)\n",
      "Loss_G = 1.37369561 (ave = 1.36004283)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.783722462844555, value max: 0.5078599452972412\n",
      "D grad l2-norm: 6.822408149597095, value max: 0.8758395910263062\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.013s / 5 iters, (0.002504)\n",
      "Loss_D = 0.89778936 (ave = 0.95402529)\n",
      "Loss_G = 1.30601192 (ave = 1.33553655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.035998839291152, value max: 0.4983105957508087\n",
      "D grad l2-norm: 6.864967615161922, value max: 0.8478839993476868\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 0.97356188 (ave = 0.96696486)\n",
      "Loss_G = 1.27284348 (ave = 1.29655421)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.960479293360926, value max: 0.49016815423965454\n",
      "D grad l2-norm: 6.73779222953833, value max: 0.7977850437164307\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002313)\n",
      "Loss_D = 0.76925552 (ave = 0.95214710)\n",
      "Loss_G = 1.28891265 (ave = 1.28966224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.007395909190379, value max: 0.48285216093063354\n",
      "D grad l2-norm: 6.773241457159803, value max: 0.7702808976173401\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.678s / 5 iters, (0.136)\tData load 0.614s / 5 iters, (0.122745)\n",
      "Loss_D = 0.88950193 (ave = 0.96821401)\n",
      "Loss_G = 1.26525414 (ave = 1.27373626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.080888935784832, value max: 0.5074284672737122\n",
      "D grad l2-norm: 6.814294828015343, value max: 0.7125884294509888\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001703)\n",
      "Loss_D = 0.99747813 (ave = 0.97135751)\n",
      "Loss_G = 1.29261184 (ave = 1.29897246)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.219864460572066, value max: 0.5274002552032471\n",
      "D grad l2-norm: 6.871988332978132, value max: 0.7211827635765076\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 0.89544249 (ave = 0.96020455)\n",
      "Loss_G = 1.28480089 (ave = 1.29375587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.223847955106477, value max: 0.5615904927253723\n",
      "D grad l2-norm: 6.894328619603502, value max: 0.7218417525291443\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 1.04671001 (ave = 0.96892585)\n",
      "Loss_G = 1.24453783 (ave = 1.26992104)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.104002216357281, value max: 0.5721153020858765\n",
      "D grad l2-norm: 6.840519806016792, value max: 0.7077693939208984\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.89608479 (ave = 0.93697603)\n",
      "Loss_G = 1.29776812 (ave = 1.28740876)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.137552494464741, value max: 0.5972743034362793\n",
      "D grad l2-norm: 7.06028037156075, value max: 0.7341814041137695\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.80212671 (ave = 0.91135120)\n",
      "Loss_G = 1.32265115 (ave = 1.30982575)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.9877127831272166, value max: 0.57900071144104\n",
      "D grad l2-norm: 7.087753296819735, value max: 0.7301928400993347\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 0.74678743 (ave = 0.88294563)\n",
      "Loss_G = 1.32651401 (ave = 1.33563414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.155598105845077, value max: 0.6237884163856506\n",
      "D grad l2-norm: 7.271353516150996, value max: 0.7315850853919983\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001578)\n",
      "Loss_D = 0.88877362 (ave = 0.89498821)\n",
      "Loss_G = 1.34110475 (ave = 1.35169127)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.196094044570229, value max: 0.6684587597846985\n",
      "D grad l2-norm: 7.349017192895708, value max: 0.7349255084991455\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.017s / 5 iters, (0.003429)\n",
      "Loss_D = 0.93499476 (ave = 0.89310434)\n",
      "Loss_G = 1.36702657 (ave = 1.35077000)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.127792320148233, value max: 0.6649411916732788\n",
      "D grad l2-norm: 7.430202806662655, value max: 0.7416208982467651\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001575)\n",
      "Loss_D = 0.88003039 (ave = 0.87919339)\n",
      "Loss_G = 1.37551272 (ave = 1.35320287)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.051115627831793, value max: 0.6450625061988831\n",
      "D grad l2-norm: 7.527994887302745, value max: 0.7443986535072327\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.883s / 5 iters, (0.177)\tData load 0.828s / 5 iters, (0.165612)\n",
      "Loss_D = 0.88046104 (ave = 0.86542261)\n",
      "Loss_G = 1.36860013 (ave = 1.36847284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.728195353546314, value max: 0.5728043913841248\n",
      "D grad l2-norm: 7.278525133277276, value max: 0.7434412240982056\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001718)\n",
      "Loss_D = 0.96214437 (ave = 0.86542068)\n",
      "Loss_G = 1.40854895 (ave = 1.39639134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.9680920406923645, value max: 0.5485777258872986\n",
      "D grad l2-norm: 7.545283163455399, value max: 0.7789275646209717\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001598)\n",
      "Loss_D = 0.81200874 (ave = 0.83480235)\n",
      "Loss_G = 1.40588367 (ave = 1.39308276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.734841569765402, value max: 0.4873735010623932\n",
      "D grad l2-norm: 7.429240910868431, value max: 0.7748492956161499\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 0.86359847 (ave = 0.83699162)\n",
      "Loss_G = 1.44553018 (ave = 1.40817497)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.164505460614779, value max: 0.44633859395980835\n",
      "D grad l2-norm: 7.812287937808689, value max: 0.8179863095283508\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.82584953 (ave = 0.83108881)\n",
      "Loss_G = 1.41040921 (ave = 1.40603542)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.183913574995795, value max: 0.4366671144962311\n",
      "D grad l2-norm: 7.6151180803562335, value max: 0.7846911549568176\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.023s / 5 iters, (0.004521)\n",
      "Loss_D = 0.73247528 (ave = 0.82661524)\n",
      "Loss_G = 1.33693814 (ave = 1.38274975)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.556766396780206, value max: 0.44431397318840027\n",
      "D grad l2-norm: 7.62529127604535, value max: 0.7559521794319153\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 1.02123690 (ave = 0.88474072)\n",
      "Loss_G = 1.30503798 (ave = 1.32733693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.679840180292875, value max: 0.4644647240638733\n",
      "D grad l2-norm: 7.42727059614544, value max: 0.7338116765022278\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001609)\n",
      "Loss_D = 0.80734611 (ave = 0.88610648)\n",
      "Loss_G = 1.25573611 (ave = 1.27190304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.501637099940365, value max: 0.47223982214927673\n",
      "D grad l2-norm: 7.209135101763964, value max: 0.711802065372467\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.88368261 (ave = 0.90640908)\n",
      "Loss_G = 1.26185632 (ave = 1.25040069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.318727746110644, value max: 0.4216374158859253\n",
      "D grad l2-norm: 7.1186065795845685, value max: 0.7125577926635742\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001703)\n",
      "Loss_D = 0.81231225 (ave = 0.90607886)\n",
      "Loss_G = 1.22462606 (ave = 1.23595574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.562094705736105, value max: 0.40583285689353943\n",
      "D grad l2-norm: 7.193080850870681, value max: 0.7018911838531494\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.694s / 5 iters, (0.139)\tData load 0.639s / 5 iters, (0.127798)\n",
      "Loss_D = 1.02212906 (ave = 0.94958634)\n",
      "Loss_G = 1.23317766 (ave = 1.23290210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.624204540144353, value max: 0.4217906594276428\n",
      "D grad l2-norm: 7.2331187947715705, value max: 0.713280200958252\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001723)\n",
      "Loss_D = 0.93123937 (ave = 0.94996210)\n",
      "Loss_G = 1.20262837 (ave = 1.20544841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.612984033088672, value max: 0.429206907749176\n",
      "D grad l2-norm: 7.247276942625901, value max: 0.7163534760475159\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 5 iters, (0.024)\tData load 0.028s / 5 iters, (0.005619)\n",
      "Loss_D = 1.06322122 (ave = 0.97310305)\n",
      "Loss_G = 1.23330283 (ave = 1.20548255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.825712039011384, value max: 0.49279558658599854\n",
      "D grad l2-norm: 7.505082973092595, value max: 0.7575312852859497\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 0.89585078 (ave = 0.95281948)\n",
      "Loss_G = 1.23624206 (ave = 1.23730075)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.104097919004234, value max: 0.5356972217559814\n",
      "D grad l2-norm: 7.687809284500274, value max: 0.7687502503395081\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001693)\n",
      "Loss_D = 0.99419206 (ave = 0.97052598)\n",
      "Loss_G = 1.23237395 (ave = 1.24585555)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.354111289248307, value max: 0.567878007888794\n",
      "D grad l2-norm: 7.8658419235048855, value max: 0.7541338801383972\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.027s / 5 iters, (0.005394)\n",
      "Loss_D = 0.88410842 (ave = 0.95830833)\n",
      "Loss_G = 1.28756881 (ave = 1.25514350)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.422967538099213, value max: 0.5919303894042969\n",
      "D grad l2-norm: 8.19399083207166, value max: 0.7654433250427246\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.79933763 (ave = 0.93310268)\n",
      "Loss_G = 1.32401538 (ave = 1.29637880)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.37928403900427, value max: 0.6201198101043701\n",
      "D grad l2-norm: 8.428450385340717, value max: 0.7565887570381165\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.89750290 (ave = 0.93699062)\n",
      "Loss_G = 1.39106297 (ave = 1.37463832)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.57981789584021, value max: 0.6328158378601074\n",
      "D grad l2-norm: 8.86901521137015, value max: 0.8044309616088867\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.143s / 5 iters, (0.029)\tData load 0.033s / 5 iters, (0.006670)\n",
      "Loss_D = 0.90837121 (ave = 0.91769786)\n",
      "Loss_G = 1.44707298 (ave = 1.44345286)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.731850853141276, value max: 0.6761341691017151\n",
      "D grad l2-norm: 9.212999437522909, value max: 0.8437969088554382\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.018s / 5 iters, (0.003591)\n",
      "Loss_D = 0.86856860 (ave = 0.89145401)\n",
      "Loss_G = 1.58667231 (ave = 1.53341939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.928590635780244, value max: 0.6956878304481506\n",
      "D grad l2-norm: 9.959962185105612, value max: 0.9243781566619873\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.733s / 5 iters, (0.147)\tData load 0.684s / 5 iters, (0.136746)\n",
      "Loss_D = 0.81474459 (ave = 0.85750626)\n",
      "Loss_G = 1.63490450 (ave = 1.61415904)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.620068303512992, value max: 0.6877321600914001\n",
      "D grad l2-norm: 9.787297956385112, value max: 0.9195659756660461\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.75055492 (ave = 0.83078725)\n",
      "Loss_G = 1.67158592 (ave = 1.64893706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.89592875404539, value max: 0.6997053623199463\n",
      "D grad l2-norm: 10.170134611435198, value max: 0.9511959552764893\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001537)\n",
      "Loss_D = 0.80059558 (ave = 0.83123424)\n",
      "Loss_G = 1.65379369 (ave = 1.66314399)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.072821734781572, value max: 0.7337662577629089\n",
      "D grad l2-norm: 10.409696337391564, value max: 0.9568905830383301\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.84359121 (ave = 0.82354378)\n",
      "Loss_G = 1.73140168 (ave = 1.71389012)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.913254596860156, value max: 0.7757883667945862\n",
      "D grad l2-norm: 10.533650265408884, value max: 0.9831905364990234\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001604)\n",
      "Loss_D = 0.85052037 (ave = 0.82020923)\n",
      "Loss_G = 1.73229134 (ave = 1.72050595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.69876369572774, value max: 0.7400528192520142\n",
      "D grad l2-norm: 10.50359827549619, value max: 1.0018869638442993\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001638)\n",
      "Loss_D = 0.82418883 (ave = 0.80022538)\n",
      "Loss_G = 1.69947338 (ave = 1.71653020)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.110454179652693, value max: 0.7070407271385193\n",
      "D grad l2-norm: 10.14729722021024, value max: 0.9989778399467468\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.84195924 (ave = 0.80013537)\n",
      "Loss_G = 1.77031636 (ave = 1.74251370)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.98805607332765, value max: 0.6641725897789001\n",
      "D grad l2-norm: 10.278991406244195, value max: 1.0417145490646362\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.018s / 5 iters, (0.003683)\n",
      "Loss_D = 0.98627681 (ave = 0.81555239)\n",
      "Loss_G = 1.73058236 (ave = 1.73199301)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.266059971362736, value max: 0.6510807871818542\n",
      "D grad l2-norm: 10.034661764611501, value max: 1.033348560333252\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 0.82093918 (ave = 0.79783895)\n",
      "Loss_G = 1.66452777 (ave = 1.70133364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.622864724720255, value max: 0.6819643974304199\n",
      "D grad l2-norm: 9.951205104866299, value max: 1.0185503959655762\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 0.76015687 (ave = 0.81155924)\n",
      "Loss_G = 1.59849334 (ave = 1.62379260)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.891215076893815, value max: 0.7052990198135376\n",
      "D grad l2-norm: 9.596820708259141, value max: 0.9916262030601501\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.793s / 5 iters, (0.159)\tData load 0.742s / 5 iters, (0.148305)\n",
      "Loss_D = 0.88043427 (ave = 0.85951264)\n",
      "Loss_G = 1.55325639 (ave = 1.55968723)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.812095008080625, value max: 0.6836453676223755\n",
      "D grad l2-norm: 9.238696654977023, value max: 0.9683673977851868\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.017s / 5 iters, (0.003438)\n",
      "Loss_D = 0.63801825 (ave = 0.85212066)\n",
      "Loss_G = 1.51259303 (ave = 1.50602424)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.826357906382551, value max: 0.638266921043396\n",
      "D grad l2-norm: 9.052109125521216, value max: 0.9591369032859802\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.89986634 (ave = 0.91026239)\n",
      "Loss_G = 1.42701817 (ave = 1.45725877)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.801424185868726, value max: 0.5767930746078491\n",
      "D grad l2-norm: 8.670627704033233, value max: 0.9075502157211304\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 1.06646061 (ave = 0.96883739)\n",
      "Loss_G = 1.36239195 (ave = 1.38828447)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.841042305390014, value max: 0.5928241014480591\n",
      "D grad l2-norm: 8.641549030753664, value max: 0.8808555006980896\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.95439374 (ave = 0.97879510)\n",
      "Loss_G = 1.35482955 (ave = 1.36699739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.451728052118192, value max: 0.59329754114151\n",
      "D grad l2-norm: 8.354017350331006, value max: 0.8436833620071411\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001583)\n",
      "Loss_D = 1.05818152 (ave = 1.00607435)\n",
      "Loss_G = 1.34644496 (ave = 1.35383635)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.309884984292587, value max: 0.5904926061630249\n",
      "D grad l2-norm: 8.232633882518751, value max: 0.8149436712265015\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001766)\n",
      "Loss_D = 0.81854022 (ave = 0.98140846)\n",
      "Loss_G = 1.35227287 (ave = 1.32948294)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.242628349212701, value max: 0.5973851084709167\n",
      "D grad l2-norm: 8.062426652185646, value max: 0.8080116510391235\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.99492002 (ave = 1.00998701)\n",
      "Loss_G = 1.32320797 (ave = 1.33847675)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.447949390195681, value max: 0.6051614284515381\n",
      "D grad l2-norm: 7.994224941815875, value max: 0.8366881608963013\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 1.03870714 (ave = 1.03341178)\n",
      "Loss_G = 1.29804492 (ave = 1.30600646)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.278486088059028, value max: 0.6291695237159729\n",
      "D grad l2-norm: 7.820061440260766, value max: 0.8434795141220093\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 1.07722878 (ave = 1.04215717)\n",
      "Loss_G = 1.30347478 (ave = 1.30504856)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.443685750120578, value max: 0.6674280166625977\n",
      "D grad l2-norm: 8.10186869243583, value max: 0.8980312347412109\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.691s / 5 iters, (0.138)\tData load 0.635s / 5 iters, (0.126988)\n",
      "Loss_D = 0.89268947 (ave = 1.01018150)\n",
      "Loss_G = 1.30167270 (ave = 1.30941644)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.03779445071079, value max: 0.64872807264328\n",
      "D grad l2-norm: 7.948311089850249, value max: 0.8964828848838806\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 0.88749772 (ave = 0.99155596)\n",
      "Loss_G = 1.34268796 (ave = 1.33848343)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.331844659267063, value max: 0.6495302319526672\n",
      "D grad l2-norm: 8.179931997302079, value max: 0.9326616525650024\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.009s / 5 iters, (0.001767)\n",
      "Loss_D = 1.01134694 (ave = 0.99758110)\n",
      "Loss_G = 1.37253368 (ave = 1.35180545)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.346726045148714, value max: 0.6397532224655151\n",
      "D grad l2-norm: 8.175581975411934, value max: 0.9477261304855347\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001721)\n",
      "Loss_D = 0.76337516 (ave = 0.95119649)\n",
      "Loss_G = 1.32513964 (ave = 1.34176977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.133205050626637, value max: 0.6875507831573486\n",
      "D grad l2-norm: 8.026243082993654, value max: 0.9236273765563965\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001741)\n",
      "Loss_D = 0.91351664 (ave = 0.96165285)\n",
      "Loss_G = 1.37459719 (ave = 1.37271762)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.03253046018612, value max: 0.7439095377922058\n",
      "D grad l2-norm: 8.12381735862803, value max: 0.9396824240684509\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 0.88631481 (ave = 0.93708305)\n",
      "Loss_G = 1.38140810 (ave = 1.38098624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.80966664064931, value max: 0.7691375613212585\n",
      "D grad l2-norm: 7.839643496869094, value max: 0.9126260280609131\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001777)\n",
      "Loss_D = 0.79371738 (ave = 0.90939410)\n",
      "Loss_G = 1.35715413 (ave = 1.38298652)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.59343629441023, value max: 0.7644245624542236\n",
      "D grad l2-norm: 7.472624893832826, value max: 0.8597806096076965\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001762)\n",
      "Loss_D = 0.85283649 (ave = 0.89526701)\n",
      "Loss_G = 1.40922570 (ave = 1.38988523)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.016425750806286, value max: 0.8159044981002808\n",
      "D grad l2-norm: 7.8279365553526326, value max: 0.9065456390380859\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001761)\n",
      "Loss_D = 0.95652032 (ave = 0.89431392)\n",
      "Loss_G = 1.35510004 (ave = 1.37003520)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.809899734356391, value max: 0.7767606973648071\n",
      "D grad l2-norm: 7.52997184076276, value max: 0.8466224074363708\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001713)\n",
      "Loss_D = 0.98612881 (ave = 0.89111460)\n",
      "Loss_G = 1.36698306 (ave = 1.34934301)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:32:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.9073802121974435, value max: 0.8129716515541077\n",
      "D grad l2-norm: 7.498090269449285, value max: 0.8360192179679871\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.000s / 5 iters, (0.200)\tData load 0.947s / 5 iters, (0.189318)\n",
      "Loss_D = 0.75340962 (ave = 0.85700823)\n",
      "Loss_G = 1.35609150 (ave = 1.34294162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.687480577011488, value max: 0.8142171502113342\n",
      "D grad l2-norm: 7.198783888471968, value max: 0.784186601638794\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001780)\n",
      "Loss_D = 0.83422565 (ave = 0.85459574)\n",
      "Loss_G = 1.30458033 (ave = 1.33485258)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.8695515105710605, value max: 0.801146924495697\n",
      "D grad l2-norm: 7.024041102594774, value max: 0.7310300469398499\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 0.79310369 (ave = 0.85537088)\n",
      "Loss_G = 1.28605998 (ave = 1.29634886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.811748460775389, value max: 0.7562248706817627\n",
      "D grad l2-norm: 6.7188309515542155, value max: 0.717302143573761\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 0.87993211 (ave = 0.87006242)\n",
      "Loss_G = 1.22083068 (ave = 1.23618906)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.535098502788335, value max: 0.6978645324707031\n",
      "D grad l2-norm: 6.387360852818141, value max: 0.6997519731521606\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.75013161 (ave = 0.86175060)\n",
      "Loss_G = 1.18505383 (ave = 1.19468727)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.205278504594867, value max: 0.6298391819000244\n",
      "D grad l2-norm: 6.139971794076476, value max: 0.6894960999488831\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.82865363 (ave = 0.86465058)\n",
      "Loss_G = 1.21697903 (ave = 1.18770010)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.872935179593659, value max: 0.5805288553237915\n",
      "D grad l2-norm: 5.925940175980484, value max: 0.69898521900177\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.72317749 (ave = 0.84452952)\n",
      "Loss_G = 1.23482597 (ave = 1.20321224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.7240443904850835, value max: 0.5147184729576111\n",
      "D grad l2-norm: 5.931154346935543, value max: 0.7050716280937195\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.020s / 5 iters, (0.003995)\n",
      "Loss_D = 0.72788048 (ave = 0.82865802)\n",
      "Loss_G = 1.16442657 (ave = 1.20357134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.228482592692347, value max: 0.4643450081348419\n",
      "D grad l2-norm: 5.533730860502043, value max: 0.6826984286308289\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001804)\n",
      "Loss_D = 0.60040182 (ave = 0.80559977)\n",
      "Loss_G = 1.23537195 (ave = 1.21962669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.073326650250239, value max: 0.43583980202674866\n",
      "D grad l2-norm: 5.554848956530636, value max: 0.7044788002967834\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001739)\n",
      "Loss_D = 0.81084108 (ave = 0.80812244)\n",
      "Loss_G = 1.23393607 (ave = 1.22702935)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.650177368015592, value max: 0.4167467951774597\n",
      "D grad l2-norm: 5.308358277197728, value max: 0.7048795223236084\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.759s / 5 iters, (0.152)\tData load 0.710s / 5 iters, (0.141980)\n",
      "Loss_D = 0.75615680 (ave = 0.78387386)\n",
      "Loss_G = 1.24965835 (ave = 1.24142423)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.635509947645217, value max: 0.37860462069511414\n",
      "D grad l2-norm: 5.416988964494168, value max: 0.7094525694847107\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.75164586 (ave = 0.76613166)\n",
      "Loss_G = 1.27327120 (ave = 1.27154489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.3933884049990475, value max: 0.39897945523262024\n",
      "D grad l2-norm: 5.239377334566097, value max: 0.7160614132881165\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.010s / 5 iters, (0.001953)\n",
      "Loss_D = 0.71914238 (ave = 0.74303895)\n",
      "Loss_G = 1.29195845 (ave = 1.27480922)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.21903616565821, value max: 0.45066535472869873\n",
      "D grad l2-norm: 5.265089517230899, value max: 0.7227849960327148\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 5 iters, (0.026)\tData load 0.027s / 5 iters, (0.005477)\n",
      "Loss_D = 0.70322257 (ave = 0.71868683)\n",
      "Loss_G = 1.31188488 (ave = 1.31477451)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.95812171911587, value max: 0.49419811367988586\n",
      "D grad l2-norm: 5.105236958737548, value max: 0.7282664775848389\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.016s / 5 iters, (0.003287)\n",
      "Loss_D = 0.59696323 (ave = 0.68111707)\n",
      "Loss_G = 1.35757542 (ave = 1.34020936)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.966812088595184, value max: 0.5232731699943542\n",
      "D grad l2-norm: 5.241831564088879, value max: 0.7401894330978394\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.026s / 5 iters, (0.005197)\n",
      "Loss_D = 0.60817420 (ave = 0.66648823)\n",
      "Loss_G = 1.36665666 (ave = 1.35739393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.762950363750588, value max: 0.5158429741859436\n",
      "D grad l2-norm: 5.012612157146981, value max: 0.7423144578933716\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.020s / 5 iters, (0.003916)\n",
      "Loss_D = 0.64347869 (ave = 0.65771319)\n",
      "Loss_G = 1.40154195 (ave = 1.37557390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.078597535257635, value max: 0.600422739982605\n",
      "D grad l2-norm: 5.185189792692265, value max: 0.7518128156661987\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.015s / 5 iters, (0.002962)\n",
      "Loss_D = 0.70090288 (ave = 0.65698491)\n",
      "Loss_G = 1.36996257 (ave = 1.37283208)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.315930719169572, value max: 0.6203991770744324\n",
      "D grad l2-norm: 5.125411916484733, value max: 0.7436708211898804\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.006s / 5 iters, (0.001283)\n",
      "Loss_D = 0.75388992 (ave = 0.66193007)\n",
      "Loss_G = 1.36217976 (ave = 1.36039879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.682196815489272, value max: 0.6962153911590576\n",
      "D grad l2-norm: 5.1214741567004705, value max: 0.7408022284507751\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.010s / 5 iters, (0.001913)\n",
      "Loss_D = 0.78357166 (ave = 0.67218055)\n",
      "Loss_G = 1.27836645 (ave = 1.30847423)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.803941101957636, value max: 0.6876952052116394\n",
      "D grad l2-norm: 5.0134208045298925, value max: 0.7182227373123169\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 5\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.006s / 5 iters, (0.001165)\n",
      "Loss_D = 1.37977982 (ave = 1.39123614)\n",
      "Loss_G = 0.67100239 (ave = 0.67157131)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9598839192982281, value max: 0.018906859681010246\n",
      "D grad l2-norm: 0.6532208804221928, value max: 0.48880261182785034\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.479s / 5 iters, (0.096)\tData load 0.422s / 5 iters, (0.084422)\n",
      "Loss_D = 1.37755919 (ave = 1.38283200)\n",
      "Loss_G = 0.67050666 (ave = 0.67093022)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9624972813274747, value max: 0.02018156833946705\n",
      "D grad l2-norm: 0.6543578124132737, value max: 0.48854851722717285\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.490s / 5 iters, (0.098)\tData load 0.400s / 5 iters, (0.079927)\n",
      "Loss_D = 1.37558186 (ave = 1.37504492)\n",
      "Loss_G = 0.66989267 (ave = 0.67018191)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9617946116511387, value max: 0.019247611984610558\n",
      "D grad l2-norm: 0.655131022218944, value max: 0.48823487758636475\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.521s / 5 iters, (0.104)\tData load 0.455s / 5 iters, (0.090990)\n",
      "Loss_D = 1.36067879 (ave = 1.36540501)\n",
      "Loss_G = 0.66889948 (ave = 0.66950432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9704137780261202, value max: 0.02435426414012909\n",
      "D grad l2-norm: 0.6577131663698241, value max: 0.4877259433269501\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.455s / 5 iters, (0.091)\tData load 0.397s / 5 iters, (0.079321)\n",
      "Loss_D = 1.34496641 (ave = 1.35613477)\n",
      "Loss_G = 0.66891134 (ave = 0.66907299)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9660922056393381, value max: 0.01779433898627758\n",
      "D grad l2-norm: 0.6585031536471322, value max: 0.4877324104309082\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.445s / 5 iters, (0.089)\tData load 0.391s / 5 iters, (0.078218)\n",
      "Loss_D = 1.34265518 (ave = 1.34832282)\n",
      "Loss_G = 0.66879427 (ave = 0.66901461)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9632304444433991, value max: 0.021172810345888138\n",
      "D grad l2-norm: 0.6610001762720207, value max: 0.48767149448394775\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.480s / 5 iters, (0.096)\tData load 0.422s / 5 iters, (0.084326)\n",
      "Loss_D = 1.32823741 (ave = 1.33921871)\n",
      "Loss_G = 0.66918772 (ave = 0.66888884)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9630664822384176, value max: 0.019943855702877045\n",
      "D grad l2-norm: 0.6629998374260803, value max: 0.487872838973999\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.466s / 5 iters, (0.093)\tData load 0.382s / 5 iters, (0.076354)\n",
      "Loss_D = 1.33170867 (ave = 1.33233953)\n",
      "Loss_G = 0.66897732 (ave = 0.66907603)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9710534286639468, value max: 0.01771174930036068\n",
      "D grad l2-norm: 0.6668589106591813, value max: 0.487764835357666\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.663s / 5 iters, (0.133)\tData load 0.612s / 5 iters, (0.122333)\n",
      "Loss_D = 1.31612492 (ave = 1.32334518)\n",
      "Loss_G = 0.66980445 (ave = 0.66964744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9693212250426606, value max: 0.018747126683592796\n",
      "D grad l2-norm: 0.6712600992402031, value max: 0.4881890118122101\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.463s / 5 iters, (0.093)\tData load 0.414s / 5 iters, (0.082717)\n",
      "Loss_D = 1.31526065 (ave = 1.31588480)\n",
      "Loss_G = 0.67097473 (ave = 0.67035580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962835337200938, value max: 0.023349881172180176\n",
      "D grad l2-norm: 0.6752094487015978, value max: 0.488786906003952\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.749s / 5 iters, (0.150)\tData load 0.694s / 5 iters, (0.138740)\n",
      "Loss_D = 1.30229640 (ave = 1.30699096)\n",
      "Loss_G = 0.67065585 (ave = 0.67064304)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9636878151747331, value max: 0.02260591834783554\n",
      "D grad l2-norm: 0.6765210637672566, value max: 0.48862361907958984\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001715)\n",
      "Loss_D = 1.29583824 (ave = 1.29912241)\n",
      "Loss_G = 0.67156488 (ave = 0.67125980)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9656135077944115, value max: 0.024659644812345505\n",
      "D grad l2-norm: 0.6809395759027346, value max: 0.4890883266925812\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 1.29006934 (ave = 1.29106467)\n",
      "Loss_G = 0.67258370 (ave = 0.67224000)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9710447511833971, value max: 0.01954491436481476\n",
      "D grad l2-norm: 0.6838688041020474, value max: 0.48960810899734497\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 1.28598225 (ave = 1.28346663)\n",
      "Loss_G = 0.67281127 (ave = 0.67266653)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9651455269021916, value max: 0.027377251535654068\n",
      "D grad l2-norm: 0.6889045353419551, value max: 0.4897235929965973\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 1.26581240 (ave = 1.27387168)\n",
      "Loss_G = 0.67415744 (ave = 0.67372049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9741429701037547, value max: 0.019856318831443787\n",
      "D grad l2-norm: 0.694476609381143, value max: 0.49040916562080383\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 1.27308011 (ave = 1.26740663)\n",
      "Loss_G = 0.67546868 (ave = 0.67496746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.966500232914873, value max: 0.024749020114541054\n",
      "D grad l2-norm: 0.6999388218136181, value max: 0.4910786747932434\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 1.23498523 (ave = 1.25517931)\n",
      "Loss_G = 0.67739964 (ave = 0.67661040)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9725424366597546, value max: 0.019699182361364365\n",
      "D grad l2-norm: 0.70529273573388, value max: 0.49205827713012695\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.029s / 5 iters, (0.005878)\n",
      "Loss_D = 1.23286223 (ave = 1.24779909)\n",
      "Loss_G = 0.67746353 (ave = 0.67728561)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9633916373099195, value max: 0.025108374655246735\n",
      "D grad l2-norm: 0.709672813217442, value max: 0.4920896887779236\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.017s / 5 iters, (0.003323)\n",
      "Loss_D = 1.24890995 (ave = 1.24235699)\n",
      "Loss_G = 0.67942107 (ave = 0.67866133)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9743772265377564, value max: 0.024728970602154732\n",
      "D grad l2-norm: 0.7175238170969174, value max: 0.49308323860168457\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001697)\n",
      "Loss_D = 1.22024989 (ave = 1.23165021)\n",
      "Loss_G = 0.68075818 (ave = 0.67997029)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9754552093269879, value max: 0.027322808280587196\n",
      "D grad l2-norm: 0.7250180037224354, value max: 0.493760883808136\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.839s / 5 iters, (0.168)\tData load 0.785s / 5 iters, (0.156958)\n",
      "Loss_D = 1.22990191 (ave = 1.22640469)\n",
      "Loss_G = 0.68214005 (ave = 0.68138777)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.972310213864, value max: 0.02657950110733509\n",
      "D grad l2-norm: 0.7336795454060302, value max: 0.4944571852684021\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001713)\n",
      "Loss_D = 1.22440934 (ave = 1.21851923)\n",
      "Loss_G = 0.68347549 (ave = 0.68248272)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9745305699229332, value max: 0.034065525978803635\n",
      "D grad l2-norm: 0.739780383945873, value max: 0.49513161182403564\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 1.22228348 (ave = 1.21293674)\n",
      "Loss_G = 0.68436611 (ave = 0.68315053)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9825840303570649, value max: 0.03591243550181389\n",
      "D grad l2-norm: 0.7470943636789983, value max: 0.49557775259017944\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.010s / 5 iters, (0.001929)\n",
      "Loss_D = 1.21046114 (ave = 1.20508952)\n",
      "Loss_G = 0.68516099 (ave = 0.68521681)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9834529471336272, value max: 0.04350120946764946\n",
      "D grad l2-norm: 0.75450276602402, value max: 0.4959729015827179\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 1.21270514 (ave = 1.19938612)\n",
      "Loss_G = 0.68842530 (ave = 0.68704332)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9819968926079282, value max: 0.0463179349899292\n",
      "D grad l2-norm: 0.7628299587420315, value max: 0.49762076139450073\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001728)\n",
      "Loss_D = 1.17585123 (ave = 1.18950140)\n",
      "Loss_G = 0.68707395 (ave = 0.68746128)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9866150286567332, value max: 0.046269625425338745\n",
      "D grad l2-norm: 0.771606297141859, value max: 0.4969303607940674\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001777)\n",
      "Loss_D = 1.18637276 (ave = 1.18521318)\n",
      "Loss_G = 0.68867218 (ave = 0.68827176)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9964570685446903, value max: 0.05521916225552559\n",
      "D grad l2-norm: 0.7801974372852133, value max: 0.4977380931377411\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001776)\n",
      "Loss_D = 1.19801641 (ave = 1.18074570)\n",
      "Loss_G = 0.68851268 (ave = 0.68890837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0041660998664592, value max: 0.05697430297732353\n",
      "D grad l2-norm: 0.791203911781125, value max: 0.49764835834503174\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.002019)\n",
      "Loss_D = 1.16917038 (ave = 1.17259269)\n",
      "Loss_G = 0.69087136 (ave = 0.68942255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.004249903838702, value max: 0.05204523354768753\n",
      "D grad l2-norm: 0.7985402097182716, value max: 0.49882975220680237\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001794)\n",
      "Loss_D = 1.14831686 (ave = 1.16653082)\n",
      "Loss_G = 0.69152999 (ave = 0.69098377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0096372325446286, value max: 0.05069389194250107\n",
      "D grad l2-norm: 0.8049600659832526, value max: 0.4991663992404938\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.775s / 5 iters, (0.155)\tData load 0.706s / 5 iters, (0.141284)\n",
      "Loss_D = 1.16122568 (ave = 1.16280262)\n",
      "Loss_G = 0.69030148 (ave = 0.69167293)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0143799475424848, value max: 0.05869829282164574\n",
      "D grad l2-norm: 0.8188421225328575, value max: 0.49853450059890747\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.009s / 5 iters, (0.001780)\n",
      "Loss_D = 1.16356838 (ave = 1.15828979)\n",
      "Loss_G = 0.69340914 (ave = 0.69169468)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0174608338579547, value max: 0.06191866844892502\n",
      "D grad l2-norm: 0.8290431483811235, value max: 0.5000951290130615\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.015s / 5 iters, (0.003092)\n",
      "Loss_D = 1.13674700 (ave = 1.14975636)\n",
      "Loss_G = 0.69351232 (ave = 0.69406078)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.021672907051799, value max: 0.0546780489385128\n",
      "D grad l2-norm: 0.8393818284461446, value max: 0.5001410245895386\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.009s / 5 iters, (0.001811)\n",
      "Loss_D = 1.13520801 (ave = 1.14436057)\n",
      "Loss_G = 0.69609028 (ave = 0.69479890)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.016542344905203, value max: 0.05677797645330429\n",
      "D grad l2-norm: 0.8531931811471405, value max: 0.5014333724975586\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.016s / 5 iters, (0.003242)\n",
      "Loss_D = 1.12866294 (ave = 1.13817928)\n",
      "Loss_G = 0.70115542 (ave = 0.69808121)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0140175918687029, value max: 0.04437378793954849\n",
      "D grad l2-norm: 0.8656000039777135, value max: 0.5039481520652771\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 1.11924660 (ave = 1.12940404)\n",
      "Loss_G = 0.70464218 (ave = 0.70349411)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.014956375939913, value max: 0.04998885095119476\n",
      "D grad l2-norm: 0.8815235087246114, value max: 0.5056750178337097\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.018s / 5 iters, (0.003606)\n",
      "Loss_D = 1.13426113 (ave = 1.12292368)\n",
      "Loss_G = 0.71030998 (ave = 0.70776163)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0123524187019433, value max: 0.05204155296087265\n",
      "D grad l2-norm: 0.8964649258230187, value max: 0.5084846615791321\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001856)\n",
      "Loss_D = 1.11010373 (ave = 1.11145194)\n",
      "Loss_G = 0.71836650 (ave = 0.71440884)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.011252949763228, value max: 0.0481719933450222\n",
      "D grad l2-norm: 0.9102837810701196, value max: 0.5124173760414124\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 1.08537948 (ave = 1.09673181)\n",
      "Loss_G = 0.72476608 (ave = 0.72072519)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0107050372202815, value max: 0.05289096757769585\n",
      "D grad l2-norm: 0.9253746810223327, value max: 0.515526294708252\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.009s / 5 iters, (0.001780)\n",
      "Loss_D = 1.08668590 (ave = 1.08631835)\n",
      "Loss_G = 0.73291767 (ave = 0.72946558)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0145367525593425, value max: 0.054885897785425186\n",
      "D grad l2-norm: 0.9474889023461746, value max: 0.5194679498672485\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.734s / 5 iters, (0.147)\tData load 0.670s / 5 iters, (0.133904)\n",
      "Loss_D = 1.06644821 (ave = 1.07223299)\n",
      "Loss_G = 0.74101782 (ave = 0.73680664)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.005950902623893, value max: 0.056833185255527496\n",
      "D grad l2-norm: 0.9678777948676287, value max: 0.5233451724052429\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 1.03357363 (ave = 1.05744603)\n",
      "Loss_G = 0.74929816 (ave = 0.74566234)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0106753736047909, value max: 0.060412462800741196\n",
      "D grad l2-norm: 0.9847801769803206, value max: 0.5272800922393799\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001679)\n",
      "Loss_D = 1.05723131 (ave = 1.04801712)\n",
      "Loss_G = 0.76010811 (ave = 0.75599744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.017104904996245, value max: 0.05639775097370148\n",
      "D grad l2-norm: 1.0001623084585054, value max: 0.5323570370674133\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.014s / 5 iters, (0.002765)\n",
      "Loss_D = 1.00692832 (ave = 1.02942994)\n",
      "Loss_G = 0.76965618 (ave = 0.76425338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.025138999658506, value max: 0.06141745299100876\n",
      "D grad l2-norm: 1.0135340911182003, value max: 0.5368061661720276\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.024s / 5 iters, (0.004827)\n",
      "Loss_D = 1.02186704 (ave = 1.01934049)\n",
      "Loss_G = 0.77812898 (ave = 0.77405747)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0289005503840905, value max: 0.06520338356494904\n",
      "D grad l2-norm: 1.0289646034371165, value max: 0.5407115817070007\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002104)\n",
      "Loss_D = 0.96774358 (ave = 1.00119191)\n",
      "Loss_G = 0.78659350 (ave = 0.78244325)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0344074878839926, value max: 0.0683845803141594\n",
      "D grad l2-norm: 1.0465838083404038, value max: 0.5445768237113953\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001725)\n",
      "Loss_D = 1.00909626 (ave = 0.99549252)\n",
      "Loss_G = 0.79528648 (ave = 0.79184449)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.046031097972068, value max: 0.06159742921590805\n",
      "D grad l2-norm: 1.065598058818974, value max: 0.548520565032959\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001734)\n",
      "Loss_D = 1.00516176 (ave = 0.98412906)\n",
      "Loss_G = 0.80056447 (ave = 0.79813026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.070782470526553, value max: 0.06781630963087082\n",
      "D grad l2-norm: 1.0742430597864843, value max: 0.5508870482444763\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.99065655 (ave = 0.97430848)\n",
      "Loss_G = 0.80283743 (ave = 0.80196848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0777246644815424, value max: 0.07942645251750946\n",
      "D grad l2-norm: 1.088283858934078, value max: 0.5518963932991028\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.96029878 (ave = 0.96382734)\n",
      "Loss_G = 0.80490595 (ave = 0.80348859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1107907461692423, value max: 0.0886833444237709\n",
      "D grad l2-norm: 1.1038742735431084, value max: 0.5528011918067932\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.969s / 5 iters, (0.194)\tData load 0.883s / 5 iters, (0.176531)\n",
      "Loss_D = 0.93945682 (ave = 0.95532850)\n",
      "Loss_G = 0.80480701 (ave = 0.80449413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1443460279132092, value max: 0.09969937056303024\n",
      "D grad l2-norm: 1.1212926768218137, value max: 0.5527676343917847\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001702)\n",
      "Loss_D = 0.90681708 (ave = 0.95008670)\n",
      "Loss_G = 0.79583001 (ave = 0.79995034)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.19790936325824, value max: 0.10904410481452942\n",
      "D grad l2-norm: 1.133719506397916, value max: 0.5487180352210999\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 0.95941150 (ave = 0.95938567)\n",
      "Loss_G = 0.79392707 (ave = 0.79478465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2109846397448656, value max: 0.11030133813619614\n",
      "D grad l2-norm: 1.1400038523045994, value max: 0.5478362441062927\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 0.95404840 (ave = 0.96141502)\n",
      "Loss_G = 0.78234047 (ave = 0.78578393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2467466447534674, value max: 0.12933246791362762\n",
      "D grad l2-norm: 1.1530745777289981, value max: 0.5425631403923035\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.95109892 (ave = 0.96589384)\n",
      "Loss_G = 0.77601647 (ave = 0.77717217)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2582871860867684, value max: 0.13774295151233673\n",
      "D grad l2-norm: 1.1639086120883395, value max: 0.5396291613578796\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.98027468 (ave = 0.97536561)\n",
      "Loss_G = 0.76781189 (ave = 0.76907617)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2967403267651039, value max: 0.12983693182468414\n",
      "D grad l2-norm: 1.1832942353109022, value max: 0.5358248353004456\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.97112006 (ave = 0.97742950)\n",
      "Loss_G = 0.75859833 (ave = 0.75920831)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.309235162021362, value max: 0.14638526737689972\n",
      "D grad l2-norm: 1.1945130872882406, value max: 0.531471848487854\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.96474111 (ave = 0.98387384)\n",
      "Loss_G = 0.75267130 (ave = 0.75468105)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3491855030412891, value max: 0.1477181315422058\n",
      "D grad l2-norm: 1.2090507348421953, value max: 0.5286842584609985\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001748)\n",
      "Loss_D = 1.04032075 (ave = 0.99677970)\n",
      "Loss_G = 0.74193287 (ave = 0.74597220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3924943251882025, value max: 0.1582319140434265\n",
      "D grad l2-norm: 1.239040091952313, value max: 0.5235541462898254\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001626)\n",
      "Loss_D = 1.02025497 (ave = 1.00458035)\n",
      "Loss_G = 0.73041230 (ave = 0.73200501)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.433903435825351, value max: 0.14915116131305695\n",
      "D grad l2-norm: 1.261894662256491, value max: 0.5179964303970337\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 2.003s / 5 iters, (0.401)\tData load 1.951s / 5 iters, (0.390106)\n",
      "Loss_D = 1.01074445 (ave = 1.01133859)\n",
      "Loss_G = 0.72996449 (ave = 0.72809609)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4306021474486807, value max: 0.14632871747016907\n",
      "D grad l2-norm: 1.2802255535050275, value max: 0.5177834033966064\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 1.01645792 (ave = 1.01816370)\n",
      "Loss_G = 0.72000337 (ave = 0.71825047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4430513344934999, value max: 0.1431249976158142\n",
      "D grad l2-norm: 1.3142307364037613, value max: 0.5128765106201172\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001766)\n",
      "Loss_D = 0.98659825 (ave = 1.01838002)\n",
      "Loss_G = 0.72704840 (ave = 0.71638325)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4314191542858017, value max: 0.12291663140058517\n",
      "D grad l2-norm: 1.3505500873733198, value max: 0.5162510871887207\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001883)\n",
      "Loss_D = 1.04621685 (ave = 1.02192993)\n",
      "Loss_G = 0.72866929 (ave = 0.72238522)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4076972523000362, value max: 0.10690794140100479\n",
      "D grad l2-norm: 1.4021640340638948, value max: 0.5171433091163635\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001824)\n",
      "Loss_D = 1.01868308 (ave = 1.00712109)\n",
      "Loss_G = 0.74389189 (ave = 0.73752927)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3872236073068163, value max: 0.11987239122390747\n",
      "D grad l2-norm: 1.4495981961445863, value max: 0.5244311094284058\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001746)\n",
      "Loss_D = 0.99242759 (ave = 0.98498139)\n",
      "Loss_G = 0.76294428 (ave = 0.75804564)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4097161907538234, value max: 0.1315813511610031\n",
      "D grad l2-norm: 1.5254835591333287, value max: 0.5333575010299683\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 0.96898782 (ave = 0.96589464)\n",
      "Loss_G = 0.78894293 (ave = 0.78127916)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.412411010421884, value max: 0.1467350572347641\n",
      "D grad l2-norm: 1.5884131403177275, value max: 0.5453099012374878\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001656)\n",
      "Loss_D = 0.89710653 (ave = 0.93916519)\n",
      "Loss_G = 0.82007253 (ave = 0.80733314)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4228396600183308, value max: 0.14848090708255768\n",
      "D grad l2-norm: 1.633259080659794, value max: 0.5593047738075256\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001723)\n",
      "Loss_D = 0.95264494 (ave = 0.92515270)\n",
      "Loss_G = 0.85117924 (ave = 0.83784976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4313366165826695, value max: 0.16730234026908875\n",
      "D grad l2-norm: 1.7187048423186349, value max: 0.5728946328163147\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 0.89235687 (ave = 0.89401911)\n",
      "Loss_G = 0.87891614 (ave = 0.86604151)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4583588529743372, value max: 0.1762702912092209\n",
      "D grad l2-norm: 1.7734778196774326, value max: 0.5845489501953125\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.864s / 5 iters, (0.173)\tData load 0.759s / 5 iters, (0.151783)\n",
      "Loss_D = 0.90706074 (ave = 0.87766287)\n",
      "Loss_G = 0.90503931 (ave = 0.89282601)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.517354785654318, value max: 0.18216387927532196\n",
      "D grad l2-norm: 1.8829069944054846, value max: 0.5952982902526855\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.138s / 5 iters, (0.028)\tData load 0.021s / 5 iters, (0.004195)\n",
      "Loss_D = 0.83996856 (ave = 0.84934486)\n",
      "Loss_G = 0.92343295 (ave = 0.91803393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6005431816478175, value max: 0.17915134131908417\n",
      "D grad l2-norm: 2.002539059529992, value max: 0.6026368141174316\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.009s / 5 iters, (0.001805)\n",
      "Loss_D = 0.83800530 (ave = 0.83317609)\n",
      "Loss_G = 0.95616758 (ave = 0.94547161)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6332243321746613, value max: 0.1970118135213852\n",
      "D grad l2-norm: 2.0635084460482847, value max: 0.6154608726501465\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.141s / 5 iters, (0.028)\tData load 0.009s / 5 iters, (0.001713)\n",
      "Loss_D = 0.80143708 (ave = 0.81275922)\n",
      "Loss_G = 0.97797060 (ave = 0.96756028)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7018958344492887, value max: 0.19653218984603882\n",
      "D grad l2-norm: 2.1503438699292348, value max: 0.6236432194709778\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.016s / 5 iters, (0.003251)\n",
      "Loss_D = 0.81154907 (ave = 0.80141237)\n",
      "Loss_G = 0.99647403 (ave = 0.99171755)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7721037081747086, value max: 0.22149072587490082\n",
      "D grad l2-norm: 2.221518273638356, value max: 0.6305821537971497\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.021s / 5 iters, (0.004172)\n",
      "Loss_D = 0.80859685 (ave = 0.78877165)\n",
      "Loss_G = 1.01067519 (ave = 1.00863364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9515879797684463, value max: 0.2446189671754837\n",
      "D grad l2-norm: 2.373373440019622, value max: 0.6357768774032593\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.81837833 (ave = 0.78652523)\n",
      "Loss_G = 1.01602626 (ave = 1.01652272)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.074336269017723, value max: 0.26028284430503845\n",
      "D grad l2-norm: 2.4019009589199, value max: 0.6374492049217224\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 0.80771023 (ave = 0.78682885)\n",
      "Loss_G = 1.00005257 (ave = 1.01146858)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.365818824935505, value max: 0.2989020347595215\n",
      "D grad l2-norm: 2.5488912367075174, value max: 0.6316591501235962\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 0.76933825 (ave = 0.79577696)\n",
      "Loss_G = 0.98683387 (ave = 0.99971913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4446653065376585, value max: 0.3033115267753601\n",
      "D grad l2-norm: 2.5929384646105467, value max: 0.6266953349113464\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 0.83068764 (ave = 0.81688901)\n",
      "Loss_G = 0.97809827 (ave = 0.98473094)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6000207772465984, value max: 0.3204101622104645\n",
      "D grad l2-norm: 2.642260068003221, value max: 0.6233412027359009\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.766s / 5 iters, (0.153)\tData load 0.704s / 5 iters, (0.140786)\n",
      "Loss_D = 0.78660238 (ave = 0.82916923)\n",
      "Loss_G = 0.94927394 (ave = 0.96633047)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.795762164328013, value max: 0.3383464813232422\n",
      "D grad l2-norm: 2.6802718903481235, value max: 0.6119316816329956\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.018s / 5 iters, (0.003611)\n",
      "Loss_D = 0.93791270 (ave = 0.87052425)\n",
      "Loss_G = 0.93389821 (ave = 0.94389518)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8510658341014548, value max: 0.3406219780445099\n",
      "D grad l2-norm: 2.7135206281922697, value max: 0.6060214042663574\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 0.84567320 (ave = 0.88088508)\n",
      "Loss_G = 0.91342127 (ave = 0.91635385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8851917290027806, value max: 0.33016514778137207\n",
      "D grad l2-norm: 2.7151640404690323, value max: 0.5976125597953796\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 0.84857649 (ave = 0.89781908)\n",
      "Loss_G = 0.89862627 (ave = 0.89856914)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.9079435623588683, value max: 0.338815301656723\n",
      "D grad l2-norm: 2.74405996258694, value max: 0.5909860730171204\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 0.92301732 (ave = 0.92540332)\n",
      "Loss_G = 0.89127225 (ave = 0.88855038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.988058179841707, value max: 0.3593221604824066\n",
      "D grad l2-norm: 2.856651229859254, value max: 0.5882934927940369\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001622)\n",
      "Loss_D = 1.00141835 (ave = 0.94527595)\n",
      "Loss_G = 0.88739032 (ave = 0.89706417)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.115377843231938, value max: 0.3764352798461914\n",
      "D grad l2-norm: 2.9137749371756545, value max: 0.5863379836082458\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001612)\n",
      "Loss_D = 1.04492772 (ave = 0.96221111)\n",
      "Loss_G = 0.90051836 (ave = 0.89923332)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2967949053861387, value max: 0.39820733666419983\n",
      "D grad l2-norm: 2.9610921025915005, value max: 0.5918928980827332\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001568)\n",
      "Loss_D = 0.98083377 (ave = 0.97270999)\n",
      "Loss_G = 0.88366687 (ave = 0.88008246)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4976932833865777, value max: 0.3830632269382477\n",
      "D grad l2-norm: 3.06901353380261, value max: 0.5846964120864868\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 1.02522063 (ave = 1.00827703)\n",
      "Loss_G = 0.85584748 (ave = 0.86107045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.5728724910773653, value max: 0.34351828694343567\n",
      "D grad l2-norm: 3.100815477511373, value max: 0.5729014277458191\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.018s / 5 iters, (0.003547)\n",
      "Loss_D = 1.12646532 (ave = 1.04276755)\n",
      "Loss_G = 0.85102028 (ave = 0.85468839)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.453577653019747, value max: 0.34364110231399536\n",
      "D grad l2-norm: 3.1237820625515207, value max: 0.5707124471664429\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.853s / 5 iters, (0.171)\tData load 0.783s / 5 iters, (0.156504)\n",
      "Loss_D = 0.95934439 (ave = 1.02247679)\n",
      "Loss_G = 0.88138813 (ave = 0.86092668)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.374007605527893, value max: 0.35904228687286377\n",
      "D grad l2-norm: 3.1823206413621548, value max: 0.5838356018066406\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.99976170 (ave = 1.01730433)\n",
      "Loss_G = 0.88286531 (ave = 0.88079543)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.519533121056847, value max: 0.3767547607421875\n",
      "D grad l2-norm: 3.3210666307218775, value max: 0.584503173828125\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.98938608 (ave = 1.02123345)\n",
      "Loss_G = 0.89516503 (ave = 0.88994910)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6219863264541075, value max: 0.37567004561424255\n",
      "D grad l2-norm: 3.4850711930173346, value max: 0.5895837545394897\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 0.91194212 (ave = 1.00330268)\n",
      "Loss_G = 0.93008018 (ave = 0.91664470)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.646740991722088, value max: 0.3708360195159912\n",
      "D grad l2-norm: 3.623915148710773, value max: 0.6040511727333069\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001585)\n",
      "Loss_D = 1.04478526 (ave = 1.00771998)\n",
      "Loss_G = 0.94394600 (ave = 0.93833383)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7118166314663554, value max: 0.35871466994285583\n",
      "D grad l2-norm: 3.7188047084403673, value max: 0.6092438697814941\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 0.96556413 (ave = 0.99072077)\n",
      "Loss_G = 0.97535217 (ave = 0.96245705)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.856059035727675, value max: 0.35701173543930054\n",
      "D grad l2-norm: 3.903608564419209, value max: 0.6213896870613098\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 1.04892993 (ave = 0.98599745)\n",
      "Loss_G = 1.00274706 (ave = 0.99745383)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.007296362195938, value max: 0.3309210538864136\n",
      "D grad l2-norm: 4.03837071855109, value max: 0.6313998103141785\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001545)\n",
      "Loss_D = 1.10358882 (ave = 0.98716955)\n",
      "Loss_G = 1.01339948 (ave = 1.00794871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.247634278547941, value max: 0.3319162428379059\n",
      "D grad l2-norm: 4.263063477615525, value max: 0.6351186633110046\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001867)\n",
      "Loss_D = 0.90839666 (ave = 0.95924872)\n",
      "Loss_G = 1.04670751 (ave = 1.03355658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.247580912505934, value max: 0.32652905583381653\n",
      "D grad l2-norm: 4.424856672673485, value max: 0.6467999219894409\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 0.94603390 (ave = 0.94556311)\n",
      "Loss_G = 1.09491777 (ave = 1.07266474)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.31512969645526, value max: 0.33696454763412476\n",
      "D grad l2-norm: 4.64368775981874, value max: 0.663462221622467\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.758s / 5 iters, (0.152)\tData load 0.704s / 5 iters, (0.140865)\n",
      "Loss_D = 0.89811254 (ave = 0.92072579)\n",
      "Loss_G = 1.10682631 (ave = 1.10581787)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.432910043145052, value max: 0.35812294483184814\n",
      "D grad l2-norm: 4.729945034795469, value max: 0.6673446297645569\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001693)\n",
      "Loss_D = 0.92763209 (ave = 0.91519107)\n",
      "Loss_G = 1.14997256 (ave = 1.12457881)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.650137872796973, value max: 0.36063089966773987\n",
      "D grad l2-norm: 4.881376128730225, value max: 0.6816086769104004\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.96038783 (ave = 0.92052134)\n",
      "Loss_G = 1.13302886 (ave = 1.14476843)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.814213921962505, value max: 0.3773571252822876\n",
      "D grad l2-norm: 4.9359920127744745, value max: 0.6759105324745178\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.024s / 5 iters, (0.004781)\n",
      "Loss_D = 0.90580189 (ave = 0.90835305)\n",
      "Loss_G = 1.16772616 (ave = 1.15644567)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.832208809753586, value max: 0.3590272068977356\n",
      "D grad l2-norm: 5.068245615066112, value max: 0.686612606048584\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001779)\n",
      "Loss_D = 0.77686095 (ave = 0.89076252)\n",
      "Loss_G = 1.18972898 (ave = 1.17370770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.923304658125245, value max: 0.353902667760849\n",
      "D grad l2-norm: 5.137680233532142, value max: 0.6930922269821167\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.009s / 5 iters, (0.001748)\n",
      "Loss_D = 0.83774996 (ave = 0.89359697)\n",
      "Loss_G = 1.19300580 (ave = 1.18497109)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.079748793918513, value max: 0.346714049577713\n",
      "D grad l2-norm: 5.305475560588447, value max: 0.6942323446273804\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.012s / 5 iters, (0.002381)\n",
      "Loss_D = 0.79697436 (ave = 0.88620740)\n",
      "Loss_G = 1.21102273 (ave = 1.20302792)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.015136599014577, value max: 0.36694958806037903\n",
      "D grad l2-norm: 5.2874196662578665, value max: 0.6996784210205078\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001761)\n",
      "Loss_D = 0.84104145 (ave = 0.88287460)\n",
      "Loss_G = 1.23944259 (ave = 1.22386489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.955575325268556, value max: 0.4152364730834961\n",
      "D grad l2-norm: 5.144289053670014, value max: 0.7081317901611328\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001807)\n",
      "Loss_D = 0.83132750 (ave = 0.87726951)\n",
      "Loss_G = 1.23093081 (ave = 1.22880647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.117354454279873, value max: 0.4494219720363617\n",
      "D grad l2-norm: 5.148406000762101, value max: 0.7055574059486389\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 0.88536674 (ave = 0.89436350)\n",
      "Loss_G = 1.23343170 (ave = 1.22993650)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.205058026605691, value max: 0.4589524269104004\n",
      "D grad l2-norm: 5.076556471473109, value max: 0.7062376141548157\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.770s / 5 iters, (0.154)\tData load 0.717s / 5 iters, (0.143471)\n",
      "Loss_D = 0.96338516 (ave = 0.91474451)\n",
      "Loss_G = 1.18810463 (ave = 1.20682359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.461778773628698, value max: 0.4817928969860077\n",
      "D grad l2-norm: 5.14901741038151, value max: 0.6923003792762756\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001768)\n",
      "Loss_D = 0.94782305 (ave = 0.93152584)\n",
      "Loss_G = 1.14994621 (ave = 1.16251788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.795979617051396, value max: 0.481920450925827\n",
      "D grad l2-norm: 5.228439894947252, value max: 0.6803464889526367\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.95675743 (ave = 0.97018034)\n",
      "Loss_G = 1.07836175 (ave = 1.10143008)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.9656650596598775, value max: 0.47668159008026123\n",
      "D grad l2-norm: 5.09047575659343, value max: 0.6563855409622192\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 1.20657253 (ave = 1.05233923)\n",
      "Loss_G = 1.05068660 (ave = 1.06317606)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.88177408773619, value max: 0.4830440878868103\n",
      "D grad l2-norm: 5.115419596251597, value max: 0.6467865109443665\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 1.07472301 (ave = 1.04141862)\n",
      "Loss_G = 1.05231845 (ave = 1.05918341)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.010215226062314, value max: 0.44979435205459595\n",
      "D grad l2-norm: 5.275765026580021, value max: 0.648179292678833\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001707)\n",
      "Loss_D = 1.08454299 (ave = 1.04345673)\n",
      "Loss_G = 1.06615210 (ave = 1.06301706)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.781379772638186, value max: 0.4191896617412567\n",
      "D grad l2-norm: 5.277868159253527, value max: 0.6525439620018005\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001581)\n",
      "Loss_D = 0.96944523 (ave = 1.03746765)\n",
      "Loss_G = 1.09460092 (ave = 1.08106258)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.726404469683323, value max: 0.4551689028739929\n",
      "D grad l2-norm: 5.299709691019249, value max: 0.6631253361701965\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.019s / 5 iters, (0.003757)\n",
      "Loss_D = 0.98286390 (ave = 1.03040633)\n",
      "Loss_G = 1.11590755 (ave = 1.11105883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.0707604061710025, value max: 0.4793623089790344\n",
      "D grad l2-norm: 5.5937627002705, value max: 0.669020414352417\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 1.10027862 (ave = 1.05773523)\n",
      "Loss_G = 1.12255752 (ave = 1.12221618)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.48642812352048, value max: 0.5150136947631836\n",
      "D grad l2-norm: 5.889498257113691, value max: 0.6716324090957642\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.07527721 (ave = 1.06323755)\n",
      "Loss_G = 1.13589239 (ave = 1.11545525)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.298566958954514, value max: 0.49707311391830444\n",
      "D grad l2-norm: 5.915358178112997, value max: 0.6763988733291626\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.896s / 5 iters, (0.179)\tData load 0.770s / 5 iters, (0.154044)\n",
      "Loss_D = 1.01370990 (ave = 1.05043597)\n",
      "Loss_G = 1.13501978 (ave = 1.13557432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.3071193527812754, value max: 0.48436176776885986\n",
      "D grad l2-norm: 6.098246453529582, value max: 0.6899734139442444\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.91461051 (ave = 1.03256276)\n",
      "Loss_G = 1.19217014 (ave = 1.17065260)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.515443198001942, value max: 0.45641013979911804\n",
      "D grad l2-norm: 6.449051508642293, value max: 0.7612646222114563\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001549)\n",
      "Loss_D = 0.91086286 (ave = 1.02421585)\n",
      "Loss_G = 1.20061064 (ave = 1.19259989)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.696128212239963, value max: 0.4542222023010254\n",
      "D grad l2-norm: 6.658113209067873, value max: 0.7985819578170776\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001536)\n",
      "Loss_D = 1.10005987 (ave = 1.04556273)\n",
      "Loss_G = 1.22216773 (ave = 1.22174420)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.923577965850736, value max: 0.4845551550388336\n",
      "D grad l2-norm: 6.957776623855777, value max: 0.8476226925849915\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.023s / 5 iters, (0.004521)\n",
      "Loss_D = 1.08182526 (ave = 1.03986218)\n",
      "Loss_G = 1.25815058 (ave = 1.23487790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.880959882899939, value max: 0.5269808173179626\n",
      "D grad l2-norm: 6.989553605601511, value max: 0.862727165222168\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 1.01176345 (ave = 1.02584505)\n",
      "Loss_G = 1.27365267 (ave = 1.27873514)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.421916398018602, value max: 0.5433536767959595\n",
      "D grad l2-norm: 6.825056703811065, value max: 0.8658493757247925\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 1.15835857 (ave = 1.03026680)\n",
      "Loss_G = 1.36750197 (ave = 1.33659768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.511918444180283, value max: 0.5792415142059326\n",
      "D grad l2-norm: 7.215522473071037, value max: 0.9621448516845703\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 1.00747943 (ave = 0.98638283)\n",
      "Loss_G = 1.37991405 (ave = 1.36320324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.630033193281767, value max: 0.6262915730476379\n",
      "D grad l2-norm: 7.386496896028647, value max: 0.9917290806770325\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001714)\n",
      "Loss_D = 0.98327839 (ave = 0.96654024)\n",
      "Loss_G = 1.41431427 (ave = 1.39161541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.584372461687402, value max: 0.6462226510047913\n",
      "D grad l2-norm: 7.371955357249659, value max: 0.9994012713432312\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.87569058 (ave = 0.94591668)\n",
      "Loss_G = 1.46785438 (ave = 1.44094222)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.651945992167619, value max: 0.6338611245155334\n",
      "D grad l2-norm: 7.517010179129892, value max: 1.0397250652313232\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.704s / 5 iters, (0.141)\tData load 0.640s / 5 iters, (0.128057)\n",
      "Loss_D = 0.80871975 (ave = 0.92791871)\n",
      "Loss_G = 1.43368196 (ave = 1.44941816)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.233028799400051, value max: 0.6550588011741638\n",
      "D grad l2-norm: 7.613860126777997, value max: 1.0248782634735107\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.024s / 5 iters, (0.004858)\n",
      "Loss_D = 0.92692649 (ave = 0.96220917)\n",
      "Loss_G = 1.39195478 (ave = 1.41559024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.233495960331824, value max: 0.6323286890983582\n",
      "D grad l2-norm: 7.329427699582681, value max: 0.9691253304481506\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 1.05365813 (ave = 0.99096400)\n",
      "Loss_G = 1.37101555 (ave = 1.38519521)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.178224732305571, value max: 0.5875402688980103\n",
      "D grad l2-norm: 7.25687176219409, value max: 0.9485144019126892\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001722)\n",
      "Loss_D = 1.02703905 (ave = 0.99353323)\n",
      "Loss_G = 1.37656689 (ave = 1.35678539)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.928124603949527, value max: 0.5325154066085815\n",
      "D grad l2-norm: 7.211818235613585, value max: 0.9307736754417419\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 1.00392151 (ave = 0.99750317)\n",
      "Loss_G = 1.33160067 (ave = 1.35143163)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.775902543325465, value max: 0.5088663101196289\n",
      "D grad l2-norm: 7.016499560945298, value max: 0.8852497935295105\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 1.11172283 (ave = 1.00547733)\n",
      "Loss_G = 1.33622253 (ave = 1.35389020)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.87127649570365, value max: 0.48174524307250977\n",
      "D grad l2-norm: 6.8886636225487505, value max: 0.8526356220245361\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 1.08175218 (ave = 1.01474764)\n",
      "Loss_G = 1.30384660 (ave = 1.33148630)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.044927341295752, value max: 0.5165342092514038\n",
      "D grad l2-norm: 6.869753571067124, value max: 0.8398723602294922\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001581)\n",
      "Loss_D = 1.07070994 (ave = 1.04048905)\n",
      "Loss_G = 1.24489641 (ave = 1.28786037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.306216677853318, value max: 0.5738707780838013\n",
      "D grad l2-norm: 6.758795543118265, value max: 0.8264170289039612\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.023s / 5 iters, (0.004537)\n",
      "Loss_D = 1.06439674 (ave = 1.05893991)\n",
      "Loss_G = 1.19687510 (ave = 1.24363539)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.653409914563185, value max: 0.5889319777488708\n",
      "D grad l2-norm: 6.74318401840854, value max: 0.8171426057815552\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.134s / 5 iters, (0.027)\tData load 0.026s / 5 iters, (0.005177)\n",
      "Loss_D = 1.01435304 (ave = 1.09117107)\n",
      "Loss_G = 1.17849553 (ave = 1.19270835)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.67697858890228, value max: 0.5681507587432861\n",
      "D grad l2-norm: 6.652299893727753, value max: 0.8157459497451782\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.892s / 5 iters, (0.178)\tData load 0.838s / 5 iters, (0.167631)\n",
      "Loss_D = 1.22863245 (ave = 1.15303886)\n",
      "Loss_G = 1.17736280 (ave = 1.16290410)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.558431190554696, value max: 0.5200085043907166\n",
      "D grad l2-norm: 6.600057812109286, value max: 0.8121873736381531\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001794)\n",
      "Loss_D = 1.21123278 (ave = 1.15812695)\n",
      "Loss_G = 1.13423276 (ave = 1.15724010)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.305604621461961, value max: 0.46176594495773315\n",
      "D grad l2-norm: 6.581332029800612, value max: 0.7791749835014343\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 1.09362268 (ave = 1.14823642)\n",
      "Loss_G = 1.17544603 (ave = 1.15444524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.004953096505765, value max: 0.41347458958625793\n",
      "D grad l2-norm: 6.721822597892458, value max: 0.7869133949279785\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001768)\n",
      "Loss_D = 1.07458103 (ave = 1.12218866)\n",
      "Loss_G = 1.21194851 (ave = 1.19957552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.774216024024106, value max: 0.3667633831501007\n",
      "D grad l2-norm: 6.813970527137388, value max: 0.7773529291152954\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 1.17080116 (ave = 1.11069543)\n",
      "Loss_G = 1.26765180 (ave = 1.23717544)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.492296382039485, value max: 0.40099263191223145\n",
      "D grad l2-norm: 6.944818692134513, value max: 0.7863739728927612\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 1.11649549 (ave = 1.06342423)\n",
      "Loss_G = 1.34351194 (ave = 1.30735464)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.31857262918971, value max: 0.4272446632385254\n",
      "D grad l2-norm: 7.088810685753061, value max: 0.789594829082489\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 1.08305097 (ave = 1.02394840)\n",
      "Loss_G = 1.39730787 (ave = 1.37099977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.647302231693362, value max: 0.4831407070159912\n",
      "D grad l2-norm: 7.493565532369386, value max: 0.8135734796524048\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.009s / 5 iters, (0.001784)\n",
      "Loss_D = 0.95342165 (ave = 0.98245317)\n",
      "Loss_G = 1.38606286 (ave = 1.38607888)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.440002327862566, value max: 0.5043488144874573\n",
      "D grad l2-norm: 7.2592310771605115, value max: 0.7465950846672058\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001769)\n",
      "Loss_D = 0.98661435 (ave = 0.96871469)\n",
      "Loss_G = 1.43824053 (ave = 1.42205858)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.71820545478625, value max: 0.5560376644134521\n",
      "D grad l2-norm: 7.588952891531043, value max: 0.7599749565124512\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.92291296 (ave = 0.94273899)\n",
      "Loss_G = 1.43847394 (ave = 1.44623580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.887002827535811, value max: 0.5814987421035767\n",
      "D grad l2-norm: 7.680146967640928, value max: 0.7587693929672241\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.819s / 5 iters, (0.164)\tData load 0.730s / 5 iters, (0.146001)\n",
      "Loss_D = 0.89429772 (ave = 0.92587190)\n",
      "Loss_G = 1.49217892 (ave = 1.47575634)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.000143676183163, value max: 0.6292788982391357\n",
      "D grad l2-norm: 7.660786255451955, value max: 0.772121012210846\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.142s / 5 iters, (0.028)\tData load 0.019s / 5 iters, (0.003858)\n",
      "Loss_D = 0.87408841 (ave = 0.90883397)\n",
      "Loss_G = 1.47024024 (ave = 1.45302210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.15985115603415, value max: 0.6498017907142639\n",
      "D grad l2-norm: 7.727524287443561, value max: 0.7667984962463379\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.026s / 5 iters, (0.005148)\n",
      "Loss_D = 0.93307245 (ave = 0.90726804)\n",
      "Loss_G = 1.47526431 (ave = 1.46555309)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.808526473126139, value max: 0.6164827942848206\n",
      "D grad l2-norm: 7.54047575325205, value max: 0.7683879733085632\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.145s / 5 iters, (0.029)\tData load 0.028s / 5 iters, (0.005541)\n",
      "Loss_D = 0.90949154 (ave = 0.88313580)\n",
      "Loss_G = 1.48928750 (ave = 1.48498437)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.585030913453107, value max: 0.6023297309875488\n",
      "D grad l2-norm: 7.479650686664206, value max: 0.7716234922409058\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.022s / 5 iters, (0.004325)\n",
      "Loss_D = 0.83562207 (ave = 0.85187595)\n",
      "Loss_G = 1.54533911 (ave = 1.52791932)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.611303050057764, value max: 0.5775869488716125\n",
      "D grad l2-norm: 7.530801806931941, value max: 0.7847234010696411\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.040s / 5 iters, (0.007940)\n",
      "Loss_D = 0.88958728 (ave = 0.83928238)\n",
      "Loss_G = 1.54521906 (ave = 1.54127719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.7884709913420345, value max: 0.5797756314277649\n",
      "D grad l2-norm: 7.537309866970747, value max: 0.7838701009750366\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 0.97867310 (ave = 0.84634473)\n",
      "Loss_G = 1.50262880 (ave = 1.50364616)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.729639492694497, value max: 0.5480135679244995\n",
      "D grad l2-norm: 7.221940094739553, value max: 0.7745622992515564\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001713)\n",
      "Loss_D = 0.80193603 (ave = 0.83095222)\n",
      "Loss_G = 1.45202696 (ave = 1.46754100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.1064432613387085, value max: 0.5503701567649841\n",
      "D grad l2-norm: 7.357320298758971, value max: 0.762383222579956\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.015s / 5 iters, (0.002965)\n",
      "Loss_D = 0.89613116 (ave = 0.83987486)\n",
      "Loss_G = 1.41242123 (ave = 1.42824414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.1814072524697155, value max: 0.529525876045227\n",
      "D grad l2-norm: 7.101788247314236, value max: 0.7518576979637146\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001742)\n",
      "Loss_D = 0.73204219 (ave = 0.83538001)\n",
      "Loss_G = 1.34173536 (ave = 1.37422833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.3342881505922985, value max: 0.5378838777542114\n",
      "D grad l2-norm: 6.856636885791314, value max: 0.7336934804916382\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.807s / 5 iters, (0.161)\tData load 0.740s / 5 iters, (0.147912)\n",
      "Loss_D = 0.82811952 (ave = 0.87008793)\n",
      "Loss_G = 1.30948162 (ave = 1.30857532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.3425645258873535, value max: 0.5441439151763916\n",
      "D grad l2-norm: 6.7397439752050845, value max: 0.7245688438415527\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 0.86193967 (ave = 0.88425055)\n",
      "Loss_G = 1.25356007 (ave = 1.26825569)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.1227775500063695, value max: 0.5360275506973267\n",
      "D grad l2-norm: 6.472936340403737, value max: 0.7095020413398743\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.015s / 5 iters, (0.003013)\n",
      "Loss_D = 0.94294983 (ave = 0.91941410)\n",
      "Loss_G = 1.23543060 (ave = 1.23937368)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.320175399828016, value max: 0.5531887412071228\n",
      "D grad l2-norm: 6.562981738506592, value max: 0.703730583190918\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 0.96447867 (ave = 0.92657131)\n",
      "Loss_G = 1.19484901 (ave = 1.22146108)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.027467071086415, value max: 0.5218295454978943\n",
      "D grad l2-norm: 6.130612474618412, value max: 0.6919713616371155\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001706)\n",
      "Loss_D = 1.08826113 (ave = 0.95963601)\n",
      "Loss_G = 1.16589403 (ave = 1.17584758)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.09992082711849, value max: 0.49797067046165466\n",
      "D grad l2-norm: 6.160236680466068, value max: 0.6829266548156738\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001730)\n",
      "Loss_D = 0.83646166 (ave = 0.93544626)\n",
      "Loss_G = 1.15762150 (ave = 1.17629898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.693194178804379, value max: 0.4716217815876007\n",
      "D grad l2-norm: 5.923544971170034, value max: 0.6814128756523132\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 1.06039989 (ave = 0.96407721)\n",
      "Loss_G = 1.17613769 (ave = 1.16341484)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.560907293268185, value max: 0.47572752833366394\n",
      "D grad l2-norm: 5.979793840177238, value max: 0.6871347427368164\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.020s / 5 iters, (0.003927)\n",
      "Loss_D = 0.85374928 (ave = 0.92730339)\n",
      "Loss_G = 1.20348036 (ave = 1.19531467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.487610753477759, value max: 0.4467865228652954\n",
      "D grad l2-norm: 6.001914302125813, value max: 0.6965209245681763\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001700)\n",
      "Loss_D = 1.07739747 (ave = 0.94663706)\n",
      "Loss_G = 1.18431461 (ave = 1.19386404)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.466611480793495, value max: 0.4166014492511749\n",
      "D grad l2-norm: 5.820691894855724, value max: 0.6901726722717285\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.025s / 5 iters, (0.004974)\n",
      "Loss_D = 0.96349990 (ave = 0.94561268)\n",
      "Loss_G = 1.17798626 (ave = 1.18263361)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.7411755986719575, value max: 0.46000340580940247\n",
      "D grad l2-norm: 5.95594876814644, value max: 0.6887087225914001\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.854s / 5 iters, (0.171)\tData load 0.803s / 5 iters, (0.160608)\n",
      "Loss_D = 0.84981990 (ave = 0.92773248)\n",
      "Loss_G = 1.16695261 (ave = 1.16145983)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.745374406073016, value max: 0.46704569458961487\n",
      "D grad l2-norm: 5.908650519261918, value max: 0.6848975419998169\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 0.87744725 (ave = 0.93940643)\n",
      "Loss_G = 1.16401839 (ave = 1.15572751)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.689663207964789, value max: 0.48810097575187683\n",
      "D grad l2-norm: 5.859532944997361, value max: 0.6835997700691223\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 0.99606806 (ave = 0.95485190)\n",
      "Loss_G = 1.17750871 (ave = 1.14763055)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.442208326801432, value max: 0.4705336093902588\n",
      "D grad l2-norm: 5.799610505044126, value max: 0.6889791488647461\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.010s / 5 iters, (0.001936)\n",
      "Loss_D = 1.05722117 (ave = 0.95259130)\n",
      "Loss_G = 1.18211043 (ave = 1.15570514)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.279527101718791, value max: 0.46122580766677856\n",
      "D grad l2-norm: 5.726449515293899, value max: 0.6901369094848633\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002287)\n",
      "Loss_D = 0.86879563 (ave = 0.92015967)\n",
      "Loss_G = 1.17232323 (ave = 1.17276323)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.3558500193891945, value max: 0.46065959334373474\n",
      "D grad l2-norm: 5.8816989831670785, value max: 0.6869899034500122\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001587)\n",
      "Loss_D = 1.03710783 (ave = 0.93452640)\n",
      "Loss_G = 1.23677075 (ave = 1.19695339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.151555626972327, value max: 0.44733303785324097\n",
      "D grad l2-norm: 6.003830014145127, value max: 0.7066318392753601\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001577)\n",
      "Loss_D = 0.94475865 (ave = 0.89267373)\n",
      "Loss_G = 1.24629354 (ave = 1.24819701)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.683142187535911, value max: 0.4258888065814972\n",
      "D grad l2-norm: 5.890003455154173, value max: 0.7098169922828674\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001560)\n",
      "Loss_D = 0.88164347 (ave = 0.85787238)\n",
      "Loss_G = 1.31361520 (ave = 1.29976406)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.783815200380686, value max: 0.4175804555416107\n",
      "D grad l2-norm: 6.10904829719885, value max: 0.7284733057022095\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 0.86992145 (ave = 0.83370634)\n",
      "Loss_G = 1.30835617 (ave = 1.31578157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.85197236795162, value max: 0.433870792388916\n",
      "D grad l2-norm: 5.998859488144724, value max: 0.7268040180206299\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002133)\n",
      "Loss_D = 0.80776691 (ave = 0.81774170)\n",
      "Loss_G = 1.34428334 (ave = 1.33239684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.13023348782321, value max: 0.4636838734149933\n",
      "D grad l2-norm: 6.147631426666558, value max: 0.7351402044296265\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.835s / 5 iters, (0.167)\tData load 0.723s / 5 iters, (0.144690)\n",
      "Loss_D = 0.75323403 (ave = 0.80196439)\n",
      "Loss_G = 1.31617141 (ave = 1.30711343)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.183433775347595, value max: 0.48764774203300476\n",
      "D grad l2-norm: 6.060060188190516, value max: 0.7282975912094116\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001752)\n",
      "Loss_D = 0.79326177 (ave = 0.80865713)\n",
      "Loss_G = 1.27986073 (ave = 1.29663734)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.791450573366267, value max: 0.4809357225894928\n",
      "D grad l2-norm: 5.650228382401689, value max: 0.7181885838508606\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.025s / 5 iters, (0.004933)\n",
      "Loss_D = 0.78192198 (ave = 0.80614101)\n",
      "Loss_G = 1.29124939 (ave = 1.30894239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.735847035923859, value max: 0.4865076243877411\n",
      "D grad l2-norm: 5.629709557656533, value max: 0.7212731838226318\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.152s / 5 iters, (0.030)\tData load 0.025s / 5 iters, (0.005010)\n",
      "Loss_D = 0.89939904 (ave = 0.81139934)\n",
      "Loss_G = 1.27520251 (ave = 1.30437744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.676444167273774, value max: 0.5397212505340576\n",
      "D grad l2-norm: 5.485452871831889, value max: 0.7172710299491882\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 0.73754990 (ave = 0.79155427)\n",
      "Loss_G = 1.33506870 (ave = 1.31437638)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.959908466548095, value max: 0.5748937726020813\n",
      "D grad l2-norm: 5.623858930114068, value max: 0.7335362434387207\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.024s / 5 iters, (0.004898)\n",
      "Loss_D = 0.91737336 (ave = 0.81805660)\n",
      "Loss_G = 1.30440676 (ave = 1.28954155)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.004176195914419, value max: 0.6086172461509705\n",
      "D grad l2-norm: 5.501242097411481, value max: 0.7240617275238037\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.74932599 (ave = 0.80184674)\n",
      "Loss_G = 1.21886730 (ave = 1.24190927)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.896009145218349, value max: 0.652418315410614\n",
      "D grad l2-norm: 5.238631447422901, value max: 0.6996998190879822\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 0.82799470 (ave = 0.81175530)\n",
      "Loss_G = 1.24720275 (ave = 1.24204967)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.814863234025669, value max: 0.6499423384666443\n",
      "D grad l2-norm: 5.179790533162716, value max: 0.708464503288269\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 0.80184960 (ave = 0.81725932)\n",
      "Loss_G = 1.21311200 (ave = 1.21179562)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.664428677444518, value max: 0.6587547063827515\n",
      "D grad l2-norm: 4.94173575252694, value max: 0.6989642381668091\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 0.85884929 (ave = 0.82711002)\n",
      "Loss_G = 1.19624627 (ave = 1.20466833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.820511104871665, value max: 0.641276478767395\n",
      "D grad l2-norm: 5.011372214367906, value max: 0.6932987570762634\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.714s / 5 iters, (0.143)\tData load 0.660s / 5 iters, (0.131951)\n",
      "Loss_D = 0.92118430 (ave = 0.84463574)\n",
      "Loss_G = 1.15240276 (ave = 1.15677123)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.752677984108209, value max: 0.6356026530265808\n",
      "D grad l2-norm: 4.834365461048173, value max: 0.679726243019104\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 0.90346456 (ave = 0.86438932)\n",
      "Loss_G = 1.15057456 (ave = 1.13318076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.972040790890956, value max: 0.6470502614974976\n",
      "D grad l2-norm: 4.876962701420549, value max: 0.6778370141983032\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.023s / 5 iters, (0.004536)\n",
      "Loss_D = 1.05691934 (ave = 0.90023086)\n",
      "Loss_G = 1.05213702 (ave = 1.08360026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.914735886992746, value max: 0.6420701146125793\n",
      "D grad l2-norm: 4.596186526838502, value max: 0.6458654999732971\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.015s / 5 iters, (0.002996)\n",
      "Loss_D = 0.93875241 (ave = 0.91321591)\n",
      "Loss_G = 1.02291465 (ave = 1.04075186)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.000265392688175, value max: 0.6257957220077515\n",
      "D grad l2-norm: 4.498311682208006, value max: 0.6346760988235474\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.98143947 (ave = 0.95914633)\n",
      "Loss_G = 0.95629162 (ave = 0.98845253)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.730024986410191, value max: 0.6081433892250061\n",
      "D grad l2-norm: 4.1298444301872195, value max: 0.6102393865585327\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001551)\n",
      "Loss_D = 1.04923916 (ave = 1.00601255)\n",
      "Loss_G = 0.93071580 (ave = 0.94233164)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.760259915857143, value max: 0.6034879684448242\n",
      "D grad l2-norm: 4.075635044998341, value max: 0.6012977361679077\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.07380462 (ave = 1.03895690)\n",
      "Loss_G = 0.90052450 (ave = 0.90549158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.602302607793193, value max: 0.5711881518363953\n",
      "D grad l2-norm: 3.9204046919549556, value max: 0.5893958806991577\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 1.00889146 (ave = 1.06960764)\n",
      "Loss_G = 0.85939431 (ave = 0.86963938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.492348864227988, value max: 0.5182127952575684\n",
      "D grad l2-norm: 3.795034795768973, value max: 0.5727071762084961\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 1.04494500 (ave = 1.09958987)\n",
      "Loss_G = 0.82469380 (ave = 0.83868868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.404210091205598, value max: 0.470598042011261\n",
      "D grad l2-norm: 3.801624914611863, value max: 0.5567236542701721\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.09238815 (ave = 1.11490793)\n",
      "Loss_G = 0.83605790 (ave = 0.83833959)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.041013980373656, value max: 0.43358343839645386\n",
      "D grad l2-norm: 3.6692765348355136, value max: 0.5630373954772949\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 6\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.006s / 5 iters, (0.001150)\n",
      "Loss_D = 1.38194466 (ave = 1.39585094)\n",
      "Loss_G = 0.75602454 (ave = 0.75783885)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9663553714778584, value max: 0.022273648530244827\n",
      "D grad l2-norm: 0.7682817807761328, value max: 0.530467689037323\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.409s / 5 iters, (0.082)\tData load 0.344s / 5 iters, (0.068796)\n",
      "Loss_D = 1.36886668 (ave = 1.37988269)\n",
      "Loss_G = 0.75123966 (ave = 0.75326498)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9720620663401759, value max: 0.018622668460011482\n",
      "D grad l2-norm: 0.7634105414391102, value max: 0.5282156467437744\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.418s / 5 iters, (0.084)\tData load 0.370s / 5 iters, (0.074055)\n",
      "Loss_D = 1.35929942 (ave = 1.36415031)\n",
      "Loss_G = 0.74722868 (ave = 0.74853051)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9678494773318737, value max: 0.023691220209002495\n",
      "D grad l2-norm: 0.7598247204047259, value max: 0.5263198018074036\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.443s / 5 iters, (0.089)\tData load 0.392s / 5 iters, (0.078350)\n",
      "Loss_D = 1.34106040 (ave = 1.34825654)\n",
      "Loss_G = 0.74277276 (ave = 0.74475898)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.97097716923571, value max: 0.0262126624584198\n",
      "D grad l2-norm: 0.7585382789042501, value max: 0.5242047309875488\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.492s / 5 iters, (0.098)\tData load 0.383s / 5 iters, (0.076520)\n",
      "Loss_D = 1.32643342 (ave = 1.33344197)\n",
      "Loss_G = 0.73986781 (ave = 0.74100482)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9630205199169463, value max: 0.036105621606111526\n",
      "D grad l2-norm: 0.7561642639123172, value max: 0.5228205323219299\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.620s / 5 iters, (0.124)\tData load 0.565s / 5 iters, (0.113082)\n",
      "Loss_D = 1.30884659 (ave = 1.31831326)\n",
      "Loss_G = 0.73658645 (ave = 0.73783349)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9685602070764768, value max: 0.02978598326444626\n",
      "D grad l2-norm: 0.755641477992685, value max: 0.5212515592575073\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.377s / 5 iters, (0.075)\tData load 0.328s / 5 iters, (0.065560)\n",
      "Loss_D = 1.30322695 (ave = 1.30548236)\n",
      "Loss_G = 0.73417568 (ave = 0.73500129)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9708088664109343, value max: 0.024919304996728897\n",
      "D grad l2-norm: 0.7590158715278666, value max: 0.5200958847999573\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.443s / 5 iters, (0.089)\tData load 0.389s / 5 iters, (0.077800)\n",
      "Loss_D = 1.30454707 (ave = 1.29355693)\n",
      "Loss_G = 0.73173815 (ave = 0.73253913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9667494361653685, value max: 0.026244789361953735\n",
      "D grad l2-norm: 0.7605214463158461, value max: 0.5189246535301208\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.435s / 5 iters, (0.087)\tData load 0.381s / 5 iters, (0.076184)\n",
      "Loss_D = 1.28332305 (ave = 1.27906561)\n",
      "Loss_G = 0.73035115 (ave = 0.73066549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.96160467542767, value max: 0.03105565905570984\n",
      "D grad l2-norm: 0.7631396418670519, value max: 0.5182558298110962\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.439s / 5 iters, (0.088)\tData load 0.379s / 5 iters, (0.075833)\n",
      "Loss_D = 1.27520537 (ave = 1.26701815)\n",
      "Loss_G = 0.72858226 (ave = 0.72919483)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9679669233034176, value max: 0.025805698707699776\n",
      "D grad l2-norm: 0.7683330358196927, value max: 0.517402172088623\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.854s / 5 iters, (0.171)\tData load 0.805s / 5 iters, (0.161069)\n",
      "Loss_D = 1.24677181 (ave = 1.25243297)\n",
      "Loss_G = 0.72783357 (ave = 0.72779841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9649844966438333, value max: 0.029273545369505882\n",
      "D grad l2-norm: 0.7703425433419899, value max: 0.517041027545929\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 1.23733962 (ave = 1.24026594)\n",
      "Loss_G = 0.72609842 (ave = 0.72617012)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9671384208276604, value max: 0.02535843849182129\n",
      "D grad l2-norm: 0.7751806969928315, value max: 0.5162004828453064\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 1.22206199 (ave = 1.22773242)\n",
      "Loss_G = 0.72559500 (ave = 0.72557596)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9709203000595601, value max: 0.0277851652354002\n",
      "D grad l2-norm: 0.7838509524331243, value max: 0.5159573554992676\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001739)\n",
      "Loss_D = 1.20304561 (ave = 1.21513102)\n",
      "Loss_G = 0.72486162 (ave = 0.72484144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9728516096509165, value max: 0.038064345717430115\n",
      "D grad l2-norm: 0.7910255470103437, value max: 0.5156007409095764\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001714)\n",
      "Loss_D = 1.19353950 (ave = 1.20371213)\n",
      "Loss_G = 0.72469771 (ave = 0.72468855)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9817093951499756, value max: 0.02890583500266075\n",
      "D grad l2-norm: 0.7969061012432735, value max: 0.5155212879180908\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.19381070 (ave = 1.19402945)\n",
      "Loss_G = 0.72428167 (ave = 0.72380818)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9778534853297033, value max: 0.035123419016599655\n",
      "D grad l2-norm: 0.8071844450262933, value max: 0.5153167843818665\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.017s / 5 iters, (0.003303)\n",
      "Loss_D = 1.15918040 (ave = 1.17981248)\n",
      "Loss_G = 0.72406012 (ave = 0.72451837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9822745250174786, value max: 0.04120329022407532\n",
      "D grad l2-norm: 0.8169588952772996, value max: 0.5152036547660828\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 1.18732071 (ave = 1.17363200)\n",
      "Loss_G = 0.72600174 (ave = 0.72522997)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9801760137306368, value max: 0.04230482503771782\n",
      "D grad l2-norm: 0.8244356556203688, value max: 0.5161486864089966\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 1.17707264 (ave = 1.16338427)\n",
      "Loss_G = 0.72608340 (ave = 0.72573200)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9790235875483138, value max: 0.03987843170762062\n",
      "D grad l2-norm: 0.8347302361909978, value max: 0.5161828398704529\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 1.15531826 (ave = 1.15096545)\n",
      "Loss_G = 0.72826314 (ave = 0.72743579)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9834956698433647, value max: 0.041300613433122635\n",
      "D grad l2-norm: 0.8465514059896461, value max: 0.5172340869903564\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.689s / 5 iters, (0.138)\tData load 0.641s / 5 iters, (0.128237)\n",
      "Loss_D = 1.17299652 (ave = 1.14362338)\n",
      "Loss_G = 0.72837144 (ave = 0.72806798)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9911558710447176, value max: 0.055122632533311844\n",
      "D grad l2-norm: 0.8593004458299456, value max: 0.5172829627990723\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 1.12714696 (ave = 1.12940228)\n",
      "Loss_G = 0.73092210 (ave = 0.72965677)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9916402448666737, value max: 0.052525024861097336\n",
      "D grad l2-norm: 0.8728685260550767, value max: 0.5185114145278931\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.10016441 (ave = 1.11828632)\n",
      "Loss_G = 0.73218846 (ave = 0.73121797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0055451553650854, value max: 0.052507393062114716\n",
      "D grad l2-norm: 0.8869406930417858, value max: 0.5191091299057007\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.022s / 5 iters, (0.004319)\n",
      "Loss_D = 1.09782755 (ave = 1.11009002)\n",
      "Loss_G = 0.73406178 (ave = 0.73388747)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.009205217058638, value max: 0.05903270095586777\n",
      "D grad l2-norm: 0.9073613593638183, value max: 0.5200097560882568\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.025s / 5 iters, (0.004919)\n",
      "Loss_D = 1.10953116 (ave = 1.10412633)\n",
      "Loss_G = 0.73769730 (ave = 0.73541247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0134890178717189, value max: 0.06593263149261475\n",
      "D grad l2-norm: 0.9231873384979937, value max: 0.5217438340187073\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.017s / 5 iters, (0.003331)\n",
      "Loss_D = 1.10590696 (ave = 1.09648597)\n",
      "Loss_G = 0.73993802 (ave = 0.73865077)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0189043831423577, value max: 0.06020445004105568\n",
      "D grad l2-norm: 0.9425057671212671, value max: 0.5228078365325928\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001728)\n",
      "Loss_D = 1.09164333 (ave = 1.08593688)\n",
      "Loss_G = 0.74593306 (ave = 0.74230617)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.028117450356441, value max: 0.06011548265814781\n",
      "D grad l2-norm: 0.9602911611363549, value max: 0.5256584882736206\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 1.06678867 (ave = 1.07610166)\n",
      "Loss_G = 0.74943805 (ave = 0.74588375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0288738654724465, value max: 0.05855154991149902\n",
      "D grad l2-norm: 0.9880482392951052, value max: 0.5273115038871765\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.025s / 5 iters, (0.005099)\n",
      "Loss_D = 1.07992983 (ave = 1.06931050)\n",
      "Loss_G = 0.75384736 (ave = 0.75155103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0314608242191639, value max: 0.059165723621845245\n",
      "D grad l2-norm: 1.013353000381148, value max: 0.5293631553649902\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 1.02394497 (ave = 1.05359068)\n",
      "Loss_G = 0.76193607 (ave = 0.75798346)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0247388536976545, value max: 0.05796514451503754\n",
      "D grad l2-norm: 1.040383327786524, value max: 0.5331864953041077\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.826s / 5 iters, (0.165)\tData load 0.772s / 5 iters, (0.154489)\n",
      "Loss_D = 1.06176102 (ave = 1.04814248)\n",
      "Loss_G = 0.77109504 (ave = 0.76636214)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.027823594075573, value max: 0.06762388348579407\n",
      "D grad l2-norm: 1.063727337221452, value max: 0.5374146699905396\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001744)\n",
      "Loss_D = 1.01313651 (ave = 1.03049536)\n",
      "Loss_G = 0.78276050 (ave = 0.77728375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0304800356508557, value max: 0.06541772931814194\n",
      "D grad l2-norm: 1.0895569616270355, value max: 0.5428088903427124\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001879)\n",
      "Loss_D = 1.03737056 (ave = 1.02030306)\n",
      "Loss_G = 0.79555488 (ave = 0.78926702)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.016926377386195, value max: 0.06790613383054733\n",
      "D grad l2-norm: 1.124157105184228, value max: 0.548628032207489\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001704)\n",
      "Loss_D = 0.96947241 (ave = 0.99930124)\n",
      "Loss_G = 0.80850112 (ave = 0.80273846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0148625937650226, value max: 0.0693398267030716\n",
      "D grad l2-norm: 1.1545165924085463, value max: 0.5544344782829285\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 0.99336064 (ave = 0.98660685)\n",
      "Loss_G = 0.82451898 (ave = 0.81784530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0199683815683331, value max: 0.06753477454185486\n",
      "D grad l2-norm: 1.1963293187195208, value max: 0.5615255236625671\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 0.95460308 (ave = 0.96638426)\n",
      "Loss_G = 0.84037161 (ave = 0.83388481)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0151622785376575, value max: 0.06579652428627014\n",
      "D grad l2-norm: 1.233374944811633, value max: 0.5684276819229126\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001876)\n",
      "Loss_D = 0.93020093 (ave = 0.94698454)\n",
      "Loss_G = 0.85840702 (ave = 0.85017246)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0177759030759141, value max: 0.06342890113592148\n",
      "D grad l2-norm: 1.2407650912739054, value max: 0.5761374235153198\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.011s / 5 iters, (0.002244)\n",
      "Loss_D = 0.90799034 (ave = 0.92860564)\n",
      "Loss_G = 0.87278640 (ave = 0.86618757)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0173248314047196, value max: 0.07039757072925568\n",
      "D grad l2-norm: 1.2730607464488342, value max: 0.5821873545646667\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.018s / 5 iters, (0.003513)\n",
      "Loss_D = 0.91779178 (ave = 0.91406614)\n",
      "Loss_G = 0.88903219 (ave = 0.88272491)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0332991630218265, value max: 0.06514757871627808\n",
      "D grad l2-norm: 1.2898956862669542, value max: 0.5889226198196411\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001752)\n",
      "Loss_D = 0.87457466 (ave = 0.89442205)\n",
      "Loss_G = 0.90040416 (ave = 0.89508685)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0487506590841582, value max: 0.06563964486122131\n",
      "D grad l2-norm: 1.3036833108514496, value max: 0.5935669541358948\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.845s / 5 iters, (0.169)\tData load 0.791s / 5 iters, (0.158198)\n",
      "Loss_D = 0.86971295 (ave = 0.88113033)\n",
      "Loss_G = 0.90783006 (ave = 0.90582896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.073685066706373, value max: 0.08119062334299088\n",
      "D grad l2-norm: 1.3041968841717126, value max: 0.5965569019317627\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.009s / 5 iters, (0.001825)\n",
      "Loss_D = 0.88049543 (ave = 0.87325704)\n",
      "Loss_G = 0.91233343 (ave = 0.91293713)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1016611557854918, value max: 0.0953960120677948\n",
      "D grad l2-norm: 1.3038974050328145, value max: 0.5983665585517883\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.025s / 5 iters, (0.004979)\n",
      "Loss_D = 0.86680913 (ave = 0.86309410)\n",
      "Loss_G = 0.91603792 (ave = 0.91430379)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1397709945132104, value max: 0.10800539702177048\n",
      "D grad l2-norm: 1.3188977347533664, value max: 0.5998358130455017\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001697)\n",
      "Loss_D = 0.80242932 (ave = 0.85066667)\n",
      "Loss_G = 0.91029263 (ave = 0.91189090)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1817502818351187, value max: 0.12528762221336365\n",
      "D grad l2-norm: 1.2940144448113478, value max: 0.5975034832954407\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001736)\n",
      "Loss_D = 0.86918992 (ave = 0.85855415)\n",
      "Loss_G = 0.90284216 (ave = 0.90343040)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2503787051526705, value max: 0.1279909610748291\n",
      "D grad l2-norm: 1.3059777343707106, value max: 0.5944907665252686\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001840)\n",
      "Loss_D = 0.86667824 (ave = 0.86311834)\n",
      "Loss_G = 0.87918657 (ave = 0.88660825)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2974928132346533, value max: 0.15022467076778412\n",
      "D grad l2-norm: 1.2846203056273469, value max: 0.5847102999687195\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001714)\n",
      "Loss_D = 0.85598516 (ave = 0.87137517)\n",
      "Loss_G = 0.85778749 (ave = 0.86670083)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.366098168759625, value max: 0.1631910651922226\n",
      "D grad l2-norm: 1.2896465544155118, value max: 0.5757476091384888\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.91793501 (ave = 0.89023179)\n",
      "Loss_G = 0.83594304 (ave = 0.84468797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4131999606451555, value max: 0.17307768762111664\n",
      "D grad l2-norm: 1.2795787391028788, value max: 0.566382110118866\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.93356788 (ave = 0.90969408)\n",
      "Loss_G = 0.80587935 (ave = 0.81573218)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.456670307693886, value max: 0.1633889079093933\n",
      "D grad l2-norm: 1.2801266159329063, value max: 0.5530582070350647\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 0.92393076 (ave = 0.92655722)\n",
      "Loss_G = 0.77459472 (ave = 0.78763642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4773873765154082, value max: 0.1667691171169281\n",
      "D grad l2-norm: 1.2893167341017449, value max: 0.5387899279594421\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.737s / 5 iters, (0.147)\tData load 0.683s / 5 iters, (0.136518)\n",
      "Loss_D = 0.91216493 (ave = 0.93929461)\n",
      "Loss_G = 0.75391948 (ave = 0.76637702)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5071762601419256, value max: 0.16668701171875\n",
      "D grad l2-norm: 1.3123941915067578, value max: 0.529152512550354\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.93568075 (ave = 0.96068602)\n",
      "Loss_G = 0.73628730 (ave = 0.74932662)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.521806972387574, value max: 0.1614730805158615\n",
      "D grad l2-norm: 1.3276521462159323, value max: 0.5206011533737183\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.96279597 (ave = 0.97124561)\n",
      "Loss_G = 0.73941320 (ave = 0.74043710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5250351298382419, value max: 0.17051571607589722\n",
      "D grad l2-norm: 1.364321556367463, value max: 0.5221743583679199\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001564)\n",
      "Loss_D = 1.02075052 (ave = 0.99026759)\n",
      "Loss_G = 0.73464060 (ave = 0.73284011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5376838519777694, value max: 0.16102604568004608\n",
      "D grad l2-norm: 1.4061872026274385, value max: 0.5199132561683655\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002238)\n",
      "Loss_D = 1.03208923 (ave = 0.98656237)\n",
      "Loss_G = 0.74232525 (ave = 0.73660480)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5132235038916482, value max: 0.15837359428405762\n",
      "D grad l2-norm: 1.4308010109086655, value max: 0.5235335230827332\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.02140880 (ave = 0.98516692)\n",
      "Loss_G = 0.74613214 (ave = 0.74345661)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5290812686097919, value max: 0.1694960594177246\n",
      "D grad l2-norm: 1.491502468050127, value max: 0.525287926197052\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.97026885 (ave = 0.96530167)\n",
      "Loss_G = 0.75405228 (ave = 0.75660859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5455649073055415, value max: 0.17728863656520844\n",
      "D grad l2-norm: 1.5615809524729434, value max: 0.528841495513916\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.96562111 (ave = 0.95070134)\n",
      "Loss_G = 0.78355956 (ave = 0.77745359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5432566595998913, value max: 0.18871736526489258\n",
      "D grad l2-norm: 1.6191642324562563, value max: 0.5427578687667847\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.99160588 (ave = 0.93925232)\n",
      "Loss_G = 0.80584121 (ave = 0.79847114)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5573541204859054, value max: 0.19044122099876404\n",
      "D grad l2-norm: 1.6755168848350779, value max: 0.5529359579086304\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.82544500 (ave = 0.89943573)\n",
      "Loss_G = 0.82788026 (ave = 0.82219517)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5985919347141304, value max: 0.17678608000278473\n",
      "D grad l2-norm: 1.7614693332823883, value max: 0.5625478625297546\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.802s / 5 iters, (0.160)\tData load 0.756s / 5 iters, (0.151295)\n",
      "Loss_D = 0.90795588 (ave = 0.89378574)\n",
      "Loss_G = 0.86287123 (ave = 0.84891201)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6205544764647892, value max: 0.1821175068616867\n",
      "D grad l2-norm: 1.8115758648292797, value max: 0.5776183605194092\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.007s / 5 iters, (0.001484)\n",
      "Loss_D = 0.83052796 (ave = 0.86638150)\n",
      "Loss_G = 0.88141286 (ave = 0.86424152)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6727975587624915, value max: 0.17380455136299133\n",
      "D grad l2-norm: 1.8896187955352615, value max: 0.5853741765022278\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001702)\n",
      "Loss_D = 0.90415990 (ave = 0.86653507)\n",
      "Loss_G = 0.88870370 (ave = 0.88738623)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7837920760019865, value max: 0.18814821541309357\n",
      "D grad l2-norm: 1.9857600861302613, value max: 0.5884240865707397\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001582)\n",
      "Loss_D = 0.87595367 (ave = 0.85241787)\n",
      "Loss_G = 0.90862352 (ave = 0.90008711)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8488986674686372, value max: 0.19041886925697327\n",
      "D grad l2-norm: 2.046016881410324, value max: 0.5964440703392029\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.90536177 (ave = 0.84781320)\n",
      "Loss_G = 0.90958697 (ave = 0.91017928)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.028901787527877, value max: 0.207593634724617\n",
      "D grad l2-norm: 2.162677170314987, value max: 0.5965585708618164\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 0.89277929 (ave = 0.85515312)\n",
      "Loss_G = 0.89778137 (ave = 0.90496401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1797361373232134, value max: 0.22158078849315643\n",
      "D grad l2-norm: 2.237725644148256, value max: 0.5917738676071167\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.82389623 (ave = 0.85533327)\n",
      "Loss_G = 0.88665944 (ave = 0.89261703)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.282064200489961, value max: 0.21252964437007904\n",
      "D grad l2-norm: 2.3343444964127507, value max: 0.5869948267936707\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.79629213 (ave = 0.85349362)\n",
      "Loss_G = 0.89535874 (ave = 0.89582694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3137293936789542, value max: 0.21275952458381653\n",
      "D grad l2-norm: 2.4164980518557626, value max: 0.5904865264892578\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001575)\n",
      "Loss_D = 0.84317088 (ave = 0.85839242)\n",
      "Loss_G = 0.92462897 (ave = 0.91296774)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.358170227946587, value max: 0.2143782377243042\n",
      "D grad l2-norm: 2.558509187929002, value max: 0.6024455428123474\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 0.84556186 (ave = 0.84797291)\n",
      "Loss_G = 0.96068674 (ave = 0.94334989)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3652050164767506, value max: 0.2357267290353775\n",
      "D grad l2-norm: 2.698537744882598, value max: 0.6167010068893433\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.720s / 5 iters, (0.144)\tData load 0.668s / 5 iters, (0.133547)\n",
      "Loss_D = 0.82525313 (ave = 0.82812986)\n",
      "Loss_G = 0.99845749 (ave = 0.97743018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4104824138210397, value max: 0.2678450345993042\n",
      "D grad l2-norm: 2.817787390315387, value max: 0.6308932900428772\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001759)\n",
      "Loss_D = 0.82352281 (ave = 0.81120408)\n",
      "Loss_G = 1.01514602 (ave = 1.00916908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.621466068680676, value max: 0.305783212184906\n",
      "D grad l2-norm: 3.0290008407620617, value max: 0.6368325352668762\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.75693190 (ave = 0.79485786)\n",
      "Loss_G = 1.05339670 (ave = 1.03526416)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6625310669700193, value max: 0.34314998984336853\n",
      "D grad l2-norm: 3.125740641565344, value max: 0.6505171060562134\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.80769265 (ave = 0.79111104)\n",
      "Loss_G = 1.06536114 (ave = 1.06098051)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.73194495012374, value max: 0.37155240774154663\n",
      "D grad l2-norm: 3.246251379659586, value max: 0.6546117067337036\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.77705276 (ave = 0.77788340)\n",
      "Loss_G = 1.10262597 (ave = 1.09395673)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.744580001716857, value max: 0.3819314241409302\n",
      "D grad l2-norm: 3.3533993606235777, value max: 0.6669473648071289\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.024s / 5 iters, (0.004854)\n",
      "Loss_D = 0.81298459 (ave = 0.76991736)\n",
      "Loss_G = 1.13475478 (ave = 1.12153466)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.883849842057851, value max: 0.3998908996582031\n",
      "D grad l2-norm: 3.5560089540090214, value max: 0.6776078939437866\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001694)\n",
      "Loss_D = 0.71480870 (ave = 0.75522900)\n",
      "Loss_G = 1.15805781 (ave = 1.14409559)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.051180887629929, value max: 0.4166598320007324\n",
      "D grad l2-norm: 3.6457057066424565, value max: 0.6849597096443176\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.012s / 5 iters, (0.002411)\n",
      "Loss_D = 0.77538198 (ave = 0.75957443)\n",
      "Loss_G = 1.17111206 (ave = 1.16294363)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2409878690276583, value max: 0.4341069757938385\n",
      "D grad l2-norm: 3.706174893871912, value max: 0.6887622475624084\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.018s / 5 iters, (0.003652)\n",
      "Loss_D = 0.73090100 (ave = 0.76896579)\n",
      "Loss_G = 1.14273465 (ave = 1.14567084)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.524669038399266, value max: 0.4440686106681824\n",
      "D grad l2-norm: 3.8297453203821523, value max: 0.6796847581863403\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 0.82275569 (ave = 0.79369850)\n",
      "Loss_G = 1.12871182 (ave = 1.12949073)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.5864932162231535, value max: 0.4353727400302887\n",
      "D grad l2-norm: 3.817082887042153, value max: 0.6749392747879028\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.741s / 5 iters, (0.148)\tData load 0.692s / 5 iters, (0.138360)\n",
      "Loss_D = 0.71323180 (ave = 0.80012619)\n",
      "Loss_G = 1.09750342 (ave = 1.11078324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.917835086694524, value max: 0.4467184245586395\n",
      "D grad l2-norm: 3.904338930654266, value max: 0.664434552192688\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 0.88351977 (ave = 0.85206110)\n",
      "Loss_G = 1.07970834 (ave = 1.07685382)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9626443250974757, value max: 0.4214033782482147\n",
      "D grad l2-norm: 3.9085902546986904, value max: 0.6585320830345154\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 0.84802151 (ave = 0.87056613)\n",
      "Loss_G = 1.07334876 (ave = 1.06248543)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.868658792462956, value max: 0.38826802372932434\n",
      "D grad l2-norm: 3.9133973430477087, value max: 0.6559166312217712\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.90035594 (ave = 0.88752222)\n",
      "Loss_G = 1.05400491 (ave = 1.04455290)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9449662828708125, value max: 0.3446641266345978\n",
      "D grad l2-norm: 4.002417563482163, value max: 0.6487370729446411\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001899)\n",
      "Loss_D = 0.94013119 (ave = 0.90466498)\n",
      "Loss_G = 1.04854310 (ave = 1.05111797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.028363172907995, value max: 0.3133199214935303\n",
      "D grad l2-norm: 4.024277306365664, value max: 0.6468755602836609\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001727)\n",
      "Loss_D = 0.80958247 (ave = 0.90015732)\n",
      "Loss_G = 1.05190003 (ave = 1.05181878)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.374176137206279, value max: 0.33101406693458557\n",
      "D grad l2-norm: 4.134637908534217, value max: 0.6474531888961792\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001718)\n",
      "Loss_D = 0.99275136 (ave = 0.94498514)\n",
      "Loss_G = 1.01923168 (ave = 1.02856262)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.574107710004477, value max: 0.3421960473060608\n",
      "D grad l2-norm: 4.1341017270968745, value max: 0.6325570344924927\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 1.06859636 (ave = 0.99416834)\n",
      "Loss_G = 0.96679133 (ave = 0.97791560)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.757330973619858, value max: 0.34987616539001465\n",
      "D grad l2-norm: 4.260928924469323, value max: 0.6143367290496826\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.97335398 (ave = 1.02096844)\n",
      "Loss_G = 0.95399916 (ave = 0.96656011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.744108186133364, value max: 0.3393753468990326\n",
      "D grad l2-norm: 4.284151132886685, value max: 0.6097095012664795\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001736)\n",
      "Loss_D = 0.94391918 (ave = 1.03190379)\n",
      "Loss_G = 0.96233273 (ave = 0.96930844)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.014541909692804, value max: 0.34756970405578613\n",
      "D grad l2-norm: 4.558020063397018, value max: 0.6140566468238831\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.726s / 5 iters, (0.145)\tData load 0.672s / 5 iters, (0.134443)\n",
      "Loss_D = 1.10690117 (ave = 1.07114632)\n",
      "Loss_G = 0.96975768 (ave = 0.97370358)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.993075197745224, value max: 0.3575417101383209\n",
      "D grad l2-norm: 4.690904516182622, value max: 0.6173804402351379\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.010s / 5 iters, (0.001979)\n",
      "Loss_D = 0.93146908 (ave = 1.04995904)\n",
      "Loss_G = 0.98891425 (ave = 0.98428251)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.013223708406438, value max: 0.3599644899368286\n",
      "D grad l2-norm: 4.900860419489949, value max: 0.6237567067146301\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002126)\n",
      "Loss_D = 1.09376073 (ave = 1.06215131)\n",
      "Loss_G = 1.03120804 (ave = 1.02004297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.025992052614836, value max: 0.363837331533432\n",
      "D grad l2-norm: 5.107284358156556, value max: 0.6395682096481323\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 1.05321300 (ave = 1.03961887)\n",
      "Loss_G = 1.08150625 (ave = 1.07360365)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.057578601732485, value max: 0.3828902244567871\n",
      "D grad l2-norm: 5.457912808480036, value max: 0.7125555276870728\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.012s / 5 iters, (0.002354)\n",
      "Loss_D = 0.94331002 (ave = 0.99581473)\n",
      "Loss_G = 1.14299548 (ave = 1.12378273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.980617173327464, value max: 0.3886471390724182\n",
      "D grad l2-norm: 5.659879796427246, value max: 0.7765048742294312\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.017s / 5 iters, (0.003398)\n",
      "Loss_D = 0.94731086 (ave = 0.97210113)\n",
      "Loss_G = 1.21655440 (ave = 1.20148878)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.055990259789921, value max: 0.4042874872684479\n",
      "D grad l2-norm: 5.899012865078086, value max: 0.8413625359535217\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003313)\n",
      "Loss_D = 0.83902717 (ave = 0.93120058)\n",
      "Loss_G = 1.29671204 (ave = 1.27115481)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.22826979319011, value max: 0.4147575795650482\n",
      "D grad l2-norm: 6.275260427477199, value max: 0.9269828796386719\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003366)\n",
      "Loss_D = 0.97778827 (ave = 0.92014201)\n",
      "Loss_G = 1.35061121 (ave = 1.32943070)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.192910560919776, value max: 0.4357525706291199\n",
      "D grad l2-norm: 6.377226735460745, value max: 0.9726588726043701\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 1.01337671 (ave = 0.90481392)\n",
      "Loss_G = 1.39302564 (ave = 1.36974809)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.22311223808662, value max: 0.45360067486763\n",
      "D grad l2-norm: 6.492026536294846, value max: 1.0049301385879517\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 0.95515978 (ave = 0.87564321)\n",
      "Loss_G = 1.42064178 (ave = 1.41058712)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.332591854427439, value max: 0.4648860991001129\n",
      "D grad l2-norm: 6.568910169539186, value max: 1.0198416709899902\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.715s / 5 iters, (0.143)\tData load 0.659s / 5 iters, (0.131787)\n",
      "Loss_D = 0.80085373 (ave = 0.83919547)\n",
      "Loss_G = 1.43641567 (ave = 1.43828118)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.597426781054431, value max: 0.4726092517375946\n",
      "D grad l2-norm: 6.831401369339039, value max: 1.046389102935791\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001768)\n",
      "Loss_D = 0.81171131 (ave = 0.83307287)\n",
      "Loss_G = 1.46292901 (ave = 1.44792273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.513789930105173, value max: 0.4595802426338196\n",
      "D grad l2-norm: 6.699658556529224, value max: 1.0185256004333496\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 0.78426719 (ave = 0.81680299)\n",
      "Loss_G = 1.46713543 (ave = 1.47344294)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.635462341847742, value max: 0.4495445489883423\n",
      "D grad l2-norm: 6.8297706572716885, value max: 1.0087000131607056\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.76738381 (ave = 0.80400525)\n",
      "Loss_G = 1.50394785 (ave = 1.49214249)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.4089891082697426, value max: 0.4205314815044403\n",
      "D grad l2-norm: 6.792945350902515, value max: 0.988336980342865\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.90059602 (ave = 0.80176805)\n",
      "Loss_G = 1.51865768 (ave = 1.52445934)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.553431667107403, value max: 0.4559568762779236\n",
      "D grad l2-norm: 6.851582139870406, value max: 0.9446606040000916\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 0.75970513 (ave = 0.76991605)\n",
      "Loss_G = 1.53326881 (ave = 1.53187950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.708660179989454, value max: 0.4771876335144043\n",
      "D grad l2-norm: 6.818255757844222, value max: 0.891638994216919\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 0.69604540 (ave = 0.76336045)\n",
      "Loss_G = 1.47635269 (ave = 1.50555739)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.789937420689093, value max: 0.523985743522644\n",
      "D grad l2-norm: 6.594301015982589, value max: 0.7833207845687866\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.026s / 5 iters, (0.005194)\n",
      "Loss_D = 0.74539524 (ave = 0.77552238)\n",
      "Loss_G = 1.47335792 (ave = 1.48769896)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.100350327694037, value max: 0.5463951230049133\n",
      "D grad l2-norm: 6.735752476748699, value max: 0.7681781053543091\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001745)\n",
      "Loss_D = 0.79903311 (ave = 0.79924536)\n",
      "Loss_G = 1.41403842 (ave = 1.43809426)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.239006918314516, value max: 0.55902498960495\n",
      "D grad l2-norm: 6.624565471674872, value max: 0.7527869343757629\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 0.75711250 (ave = 0.81419407)\n",
      "Loss_G = 1.36571026 (ave = 1.39269917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.396898775323065, value max: 0.5531297326087952\n",
      "D grad l2-norm: 6.531138877577897, value max: 0.7397273182868958\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.867s / 5 iters, (0.173)\tData load 0.782s / 5 iters, (0.156342)\n",
      "Loss_D = 0.97690099 (ave = 0.86901261)\n",
      "Loss_G = 1.31011868 (ave = 1.34359426)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.6985861605691, value max: 0.5551943182945251\n",
      "D grad l2-norm: 6.573401860133043, value max: 0.7247593402862549\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.009s / 5 iters, (0.001765)\n",
      "Loss_D = 0.82818568 (ave = 0.87470678)\n",
      "Loss_G = 1.27532971 (ave = 1.29002619)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.758482742749916, value max: 0.5431932210922241\n",
      "D grad l2-norm: 6.465809591532298, value max: 0.7146792411804199\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001564)\n",
      "Loss_D = 0.85967171 (ave = 0.91056327)\n",
      "Loss_G = 1.23325527 (ave = 1.25192361)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.990839304244953, value max: 0.5854175090789795\n",
      "D grad l2-norm: 6.527209036599575, value max: 0.7013941407203674\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001697)\n",
      "Loss_D = 0.99809861 (ave = 0.97997406)\n",
      "Loss_G = 1.18379152 (ave = 1.19877710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.850328828859246, value max: 0.5421611666679382\n",
      "D grad l2-norm: 6.287106599096411, value max: 0.6874068379402161\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.017s / 5 iters, (0.003348)\n",
      "Loss_D = 0.87679207 (ave = 0.99676945)\n",
      "Loss_G = 1.16380596 (ave = 1.16424110)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.57282745962281, value max: 0.4905155301094055\n",
      "D grad l2-norm: 6.121491285876459, value max: 0.6809899210929871\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 1.06245983 (ave = 1.02931277)\n",
      "Loss_G = 1.14193892 (ave = 1.12247379)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.521224839389272, value max: 0.44282251596450806\n",
      "D grad l2-norm: 6.214709868637398, value max: 0.674835205078125\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 1.05176365 (ave = 1.04633710)\n",
      "Loss_G = 1.11136103 (ave = 1.12728331)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.32661596399265, value max: 0.4555736184120178\n",
      "D grad l2-norm: 6.064696166532405, value max: 0.6645041704177856\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 1.01533973 (ave = 1.04663136)\n",
      "Loss_G = 1.14340985 (ave = 1.13076189)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.3901534221008855, value max: 0.4940362572669983\n",
      "D grad l2-norm: 6.191052165315633, value max: 0.6735808849334717\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001626)\n",
      "Loss_D = 1.17292774 (ave = 1.07498651)\n",
      "Loss_G = 1.14602935 (ave = 1.13304930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.533452558049758, value max: 0.5375878214836121\n",
      "D grad l2-norm: 6.383734764386204, value max: 0.6754521727561951\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.00719404 (ave = 1.04347465)\n",
      "Loss_G = 1.13531637 (ave = 1.14623480)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.689219909493306, value max: 0.5380336046218872\n",
      "D grad l2-norm: 6.629452615326844, value max: 0.6781396269798279\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.752s / 5 iters, (0.150)\tData load 0.702s / 5 iters, (0.140384)\n",
      "Loss_D = 1.04724097 (ave = 1.04217477)\n",
      "Loss_G = 1.18438244 (ave = 1.17670932)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.483006661520697, value max: 0.5415393114089966\n",
      "D grad l2-norm: 6.728525190773261, value max: 0.7288234829902649\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 1.09499562 (ave = 1.02094936)\n",
      "Loss_G = 1.25778103 (ave = 1.23684893)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.4663785397608855, value max: 0.5461645126342773\n",
      "D grad l2-norm: 6.96323697652229, value max: 0.7937116622924805\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001580)\n",
      "Loss_D = 1.16576457 (ave = 0.99749470)\n",
      "Loss_G = 1.29257488 (ave = 1.28556085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.427796049672836, value max: 0.5246413946151733\n",
      "D grad l2-norm: 7.320624205298541, value max: 0.8505171537399292\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 1.11695135 (ave = 0.95331498)\n",
      "Loss_G = 1.39872265 (ave = 1.36476986)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.229916709119382, value max: 0.5019160509109497\n",
      "D grad l2-norm: 7.527419791991271, value max: 0.9129884243011475\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001562)\n",
      "Loss_D = 0.86473870 (ave = 0.88156476)\n",
      "Loss_G = 1.45713222 (ave = 1.43522134)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.404384702903904, value max: 0.485930860042572\n",
      "D grad l2-norm: 8.00211794327233, value max: 0.9621071815490723\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001572)\n",
      "Loss_D = 0.84891373 (ave = 0.84645917)\n",
      "Loss_G = 1.52467883 (ave = 1.50193970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.333020921334505, value max: 0.45295658707618713\n",
      "D grad l2-norm: 8.14611610946874, value max: 0.9842339158058167\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001574)\n",
      "Loss_D = 0.71614885 (ave = 0.80536654)\n",
      "Loss_G = 1.58206534 (ave = 1.56418929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.47660180061836, value max: 0.46135231852531433\n",
      "D grad l2-norm: 8.458992213368932, value max: 1.0093166828155518\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.013s / 5 iters, (0.002582)\n",
      "Loss_D = 0.83710027 (ave = 0.79274814)\n",
      "Loss_G = 1.61306334 (ave = 1.58988502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.575474224918671, value max: 0.48075243830680847\n",
      "D grad l2-norm: 8.49220655820084, value max: 0.992724597454071\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 0.63048923 (ave = 0.75094225)\n",
      "Loss_G = 1.59427571 (ave = 1.60183587)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.9947563305964495, value max: 0.5225330591201782\n",
      "D grad l2-norm: 8.736490739055014, value max: 0.9667705297470093\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 0.78744411 (ave = 0.75771742)\n",
      "Loss_G = 1.62157393 (ave = 1.60439432)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:33:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.154789155936549, value max: 0.5421603322029114\n",
      "D grad l2-norm: 8.850390350704334, value max: 0.9843321442604065\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.937s / 5 iters, (0.187)\tData load 0.884s / 5 iters, (0.176845)\n",
      "Loss_D = 0.78865194 (ave = 0.74715739)\n",
      "Loss_G = 1.64346266 (ave = 1.62696595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.1305016327470385, value max: 0.5600919127464294\n",
      "D grad l2-norm: 8.893286976727223, value max: 1.0136967897415161\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 0.73430550 (ave = 0.71894416)\n",
      "Loss_G = 1.60940933 (ave = 1.63011160)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.260186263481873, value max: 0.5645011067390442\n",
      "D grad l2-norm: 8.899783905282067, value max: 1.009782314300537\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.018s / 5 iters, (0.003632)\n",
      "Loss_D = 0.76470637 (ave = 0.71359448)\n",
      "Loss_G = 1.64193177 (ave = 1.63736684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.286058850056128, value max: 0.5566563010215759\n",
      "D grad l2-norm: 8.70413103729458, value max: 1.0103563070297241\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001664)\n",
      "Loss_D = 0.91103888 (ave = 0.72120119)\n",
      "Loss_G = 1.58512521 (ave = 1.63072178)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.578308761710033, value max: 0.5461789965629578\n",
      "D grad l2-norm: 8.704806266950456, value max: 0.9988158345222473\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 0.81775331 (ave = 0.71093149)\n",
      "Loss_G = 1.59669304 (ave = 1.58482909)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.472394929848987, value max: 0.5271296501159668\n",
      "D grad l2-norm: 8.435304931401767, value max: 0.9870495200157166\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 0.71632600 (ave = 0.69729322)\n",
      "Loss_G = 1.56650531 (ave = 1.55875468)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.829919968435225, value max: 0.5204322934150696\n",
      "D grad l2-norm: 8.447226876035725, value max: 0.9671981334686279\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.73918736 (ave = 0.70004901)\n",
      "Loss_G = 1.51018560 (ave = 1.53465009)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.913769206658157, value max: 0.5043664574623108\n",
      "D grad l2-norm: 8.12758189941466, value max: 0.8912792801856995\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.001930)\n",
      "Loss_D = 0.69181895 (ave = 0.70915741)\n",
      "Loss_G = 1.50065005 (ave = 1.48869357)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.774396480953903, value max: 0.5425238013267517\n",
      "D grad l2-norm: 7.911412372827409, value max: 0.8481712937355042\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001598)\n",
      "Loss_D = 0.77410430 (ave = 0.72060931)\n",
      "Loss_G = 1.44531441 (ave = 1.45870144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.504849198044151, value max: 0.5361816883087158\n",
      "D grad l2-norm: 7.614298578705929, value max: 0.7786783576011658\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 0.74183834 (ave = 0.72101747)\n",
      "Loss_G = 1.41385126 (ave = 1.42913926)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.652993406629015, value max: 0.5704129934310913\n",
      "D grad l2-norm: 7.433486114949805, value max: 0.7523735761642456\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.795s / 5 iters, (0.159)\tData load 0.701s / 5 iters, (0.140121)\n",
      "Loss_D = 0.89879739 (ave = 0.76020081)\n",
      "Loss_G = 1.35001707 (ave = 1.37763336)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.829862433955641, value max: 0.6253551244735718\n",
      "D grad l2-norm: 7.279807302722759, value max: 0.735883355140686\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 0.84763312 (ave = 0.76768348)\n",
      "Loss_G = 1.32930732 (ave = 1.33586771)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.924883947780239, value max: 0.633470892906189\n",
      "D grad l2-norm: 7.0825539808351685, value max: 0.7291740775108337\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.88534421 (ave = 0.80012482)\n",
      "Loss_G = 1.29115009 (ave = 1.29226768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.699076776537424, value max: 0.6661762595176697\n",
      "D grad l2-norm: 6.79150723194043, value max: 0.7196592092514038\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.036s / 5 iters, (0.007272)\n",
      "Loss_D = 0.66175354 (ave = 0.78664762)\n",
      "Loss_G = 1.25145304 (ave = 1.27590580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.357521868914825, value max: 0.6121233105659485\n",
      "D grad l2-norm: 6.603726434430385, value max: 0.7085473537445068\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 1.03074241 (ave = 0.82956830)\n",
      "Loss_G = 1.30042481 (ave = 1.27892649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.262864389951364, value max: 0.6118696331977844\n",
      "D grad l2-norm: 6.790741212151329, value max: 0.7238178849220276\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.010s / 5 iters, (0.001969)\n",
      "Loss_D = 0.71796799 (ave = 0.77738677)\n",
      "Loss_G = 1.28128064 (ave = 1.27503941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.699999523504403, value max: 0.5974231362342834\n",
      "D grad l2-norm: 6.579649812224842, value max: 0.7184021472930908\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.72781324 (ave = 0.75658283)\n",
      "Loss_G = 1.37378633 (ave = 1.34213879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.568478989490589, value max: 0.5545377135276794\n",
      "D grad l2-norm: 6.884339834751406, value max: 0.7426624298095703\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.021s / 5 iters, (0.004120)\n",
      "Loss_D = 0.70316517 (ave = 0.73608170)\n",
      "Loss_G = 1.41235757 (ave = 1.39095206)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.279708678220878, value max: 0.507570207118988\n",
      "D grad l2-norm: 6.813767616289809, value max: 0.7536973357200623\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.86481285 (ave = 0.73356832)\n",
      "Loss_G = 1.41209948 (ave = 1.41890945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.145137046395542, value max: 0.47612252831459045\n",
      "D grad l2-norm: 6.70516335249453, value max: 0.7531619668006897\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.68054795 (ave = 0.70046316)\n",
      "Loss_G = 1.46453059 (ave = 1.44177060)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.668336531954624, value max: 0.5025951862335205\n",
      "D grad l2-norm: 7.170301122252051, value max: 0.765093207359314\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.703s / 5 iters, (0.141)\tData load 0.653s / 5 iters, (0.130661)\n",
      "Loss_D = 0.64595747 (ave = 0.69296067)\n",
      "Loss_G = 1.44052613 (ave = 1.44598532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.892123957199843, value max: 0.5091082453727722\n",
      "D grad l2-norm: 7.10831993225118, value max: 0.7592536807060242\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 0.67588067 (ave = 0.70323627)\n",
      "Loss_G = 1.45150495 (ave = 1.44503770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.926228495288033, value max: 0.48918357491493225\n",
      "D grad l2-norm: 7.224868115729322, value max: 0.7619668245315552\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.009s / 5 iters, (0.001855)\n",
      "Loss_D = 0.57579017 (ave = 0.69235168)\n",
      "Loss_G = 1.45433629 (ave = 1.43056719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.861485923864717, value max: 0.472040593624115\n",
      "D grad l2-norm: 7.404273726229887, value max: 0.7623271346092224\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.013s / 5 iters, (0.002674)\n",
      "Loss_D = 0.72697043 (ave = 0.69926161)\n",
      "Loss_G = 1.48174012 (ave = 1.45272551)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.643008467295138, value max: 0.47899046540260315\n",
      "D grad l2-norm: 7.26577869310372, value max: 0.7687928676605225\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001761)\n",
      "Loss_D = 0.74001831 (ave = 0.69675248)\n",
      "Loss_G = 1.49478734 (ave = 1.46595159)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.0089322293732925, value max: 0.5403107404708862\n",
      "D grad l2-norm: 7.535683673901806, value max: 0.770902693271637\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001737)\n",
      "Loss_D = 0.67617577 (ave = 0.68610891)\n",
      "Loss_G = 1.45237553 (ave = 1.47547817)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.082304087283926, value max: 0.5311318039894104\n",
      "D grad l2-norm: 7.427781291244381, value max: 0.7600709199905396\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.71162999 (ave = 0.70103225)\n",
      "Loss_G = 1.45483518 (ave = 1.45642340)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.406801249156226, value max: 0.574684202671051\n",
      "D grad l2-norm: 7.438631683668518, value max: 0.7688383460044861\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002347)\n",
      "Loss_D = 0.64389074 (ave = 0.71298306)\n",
      "Loss_G = 1.39942598 (ave = 1.43038011)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.709436743493901, value max: 0.5853605270385742\n",
      "D grad l2-norm: 7.413724440081899, value max: 0.7609769701957703\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001680)\n",
      "Loss_D = 0.72692358 (ave = 0.74257828)\n",
      "Loss_G = 1.36626148 (ave = 1.38726985)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.89211101211386, value max: 0.5633593201637268\n",
      "D grad l2-norm: 7.449043005799976, value max: 0.7613258957862854\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.78591037 (ave = 0.77295341)\n",
      "Loss_G = 1.34916461 (ave = 1.35650527)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.960948559215173, value max: 0.5570670962333679\n",
      "D grad l2-norm: 7.417578393098503, value max: 0.7553514838218689\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.942s / 5 iters, (0.188)\tData load 0.852s / 5 iters, (0.170318)\n",
      "Loss_D = 0.81758678 (ave = 0.80392120)\n",
      "Loss_G = 1.36113679 (ave = 1.32384720)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.172445915296437, value max: 0.5844749212265015\n",
      "D grad l2-norm: 7.544629824257235, value max: 0.761343777179718\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.72236651 (ave = 0.81291379)\n",
      "Loss_G = 1.27502704 (ave = 1.30399003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.125274578522996, value max: 0.6079529523849487\n",
      "D grad l2-norm: 7.56130718787656, value max: 0.7672592997550964\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001641)\n",
      "Loss_D = 0.75817847 (ave = 0.83829792)\n",
      "Loss_G = 1.30306482 (ave = 1.27991886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.465267620059453, value max: 0.632218062877655\n",
      "D grad l2-norm: 7.915749482244019, value max: 0.8286113142967224\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 0.88038462 (ave = 0.88051428)\n",
      "Loss_G = 1.25404358 (ave = 1.28698711)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.352740663945537, value max: 0.6107490658760071\n",
      "D grad l2-norm: 7.707880088440387, value max: 0.8131179809570312\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001720)\n",
      "Loss_D = 1.10104287 (ave = 0.93084146)\n",
      "Loss_G = 1.30499077 (ave = 1.29497786)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.417058850554755, value max: 0.6622989177703857\n",
      "D grad l2-norm: 7.969486375611025, value max: 0.8592914938926697\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001718)\n",
      "Loss_D = 0.91122115 (ave = 0.91875072)\n",
      "Loss_G = 1.30015576 (ave = 1.28667953)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.361958084775674, value max: 0.6611375212669373\n",
      "D grad l2-norm: 8.029988612361514, value max: 0.8865514397621155\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 1.08345151 (ave = 0.94515833)\n",
      "Loss_G = 1.32084465 (ave = 1.30160694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.294429293697236, value max: 0.6601240634918213\n",
      "D grad l2-norm: 8.081688171640566, value max: 0.9317100048065186\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.91174471 (ave = 0.92998006)\n",
      "Loss_G = 1.31847858 (ave = 1.33587563)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.488128276937847, value max: 0.6617665886878967\n",
      "D grad l2-norm: 8.510090556763354, value max: 1.0009832382202148\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.013s / 5 iters, (0.002672)\n",
      "Loss_D = 0.88536572 (ave = 0.91641455)\n",
      "Loss_G = 1.38369131 (ave = 1.36934810)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.168973826344446, value max: 0.6522109508514404\n",
      "D grad l2-norm: 8.30769771463449, value max: 1.0181077718734741\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.94380260 (ave = 0.92871020)\n",
      "Loss_G = 1.39368010 (ave = 1.37992985)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.989693270699917, value max: 0.6142950654029846\n",
      "D grad l2-norm: 8.320834670924022, value max: 1.0362557172775269\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.756s / 5 iters, (0.151)\tData load 0.704s / 5 iters, (0.140879)\n",
      "Loss_D = 0.80094337 (ave = 0.90085498)\n",
      "Loss_G = 1.41227877 (ave = 1.41923811)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.93322034809234, value max: 0.5799972414970398\n",
      "D grad l2-norm: 8.328810956814992, value max: 1.040140151977539\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 0.84853452 (ave = 0.89330279)\n",
      "Loss_G = 1.40442777 (ave = 1.42998562)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.169185504709118, value max: 0.6496279239654541\n",
      "D grad l2-norm: 8.447285296730161, value max: 1.039332628250122\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.015s / 5 iters, (0.002981)\n",
      "Loss_D = 0.82510579 (ave = 0.89398150)\n",
      "Loss_G = 1.45260274 (ave = 1.43232646)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.979502269242162, value max: 0.681638240814209\n",
      "D grad l2-norm: 8.401768040340729, value max: 1.0376921892166138\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.009s / 5 iters, (0.001888)\n",
      "Loss_D = 0.93952870 (ave = 0.89776360)\n",
      "Loss_G = 1.45365179 (ave = 1.44908783)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.876755988199885, value max: 0.697482168674469\n",
      "D grad l2-norm: 8.17421850722315, value max: 0.9922422170639038\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.017s / 5 iters, (0.003403)\n",
      "Loss_D = 0.85096884 (ave = 0.88808981)\n",
      "Loss_G = 1.44700432 (ave = 1.43123312)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.145072853031756, value max: 0.7316679358482361\n",
      "D grad l2-norm: 8.222778295820165, value max: 0.957227885723114\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.143s / 5 iters, (0.029)\tData load 0.018s / 5 iters, (0.003511)\n",
      "Loss_D = 0.84464359 (ave = 0.88480434)\n",
      "Loss_G = 1.37581551 (ave = 1.41454833)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.089610854751012, value max: 0.7397540807723999\n",
      "D grad l2-norm: 7.967990996358972, value max: 0.872222900390625\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004550)\n",
      "Loss_D = 0.86743385 (ave = 0.89354250)\n",
      "Loss_G = 1.39617276 (ave = 1.40712340)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.05899451409692, value max: 0.7465760111808777\n",
      "D grad l2-norm: 7.778674191019078, value max: 0.8235303163528442\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.015s / 5 iters, (0.002925)\n",
      "Loss_D = 1.11020970 (ave = 0.93858951)\n",
      "Loss_G = 1.37406707 (ave = 1.38395300)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.592179249151473, value max: 0.7735260725021362\n",
      "D grad l2-norm: 8.021725469021089, value max: 0.7819176912307739\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001384)\n",
      "Loss_D = 1.06068087 (ave = 0.93908899)\n",
      "Loss_G = 1.31812108 (ave = 1.34346721)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.598527169524386, value max: 0.7409238815307617\n",
      "D grad l2-norm: 7.852137528804814, value max: 0.7269889712333679\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 0.87206042 (ave = 0.93029854)\n",
      "Loss_G = 1.32232261 (ave = 1.30918550)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.452490938138382, value max: 0.6951974630355835\n",
      "D grad l2-norm: 7.7743903336458855, value max: 0.7280529737472534\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 2.318s / 5 iters, (0.464)\tData load 2.266s / 5 iters, (0.453275)\n",
      "Loss_D = 0.79003453 (ave = 0.92557003)\n",
      "Loss_G = 1.26021099 (ave = 1.30214467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.495723135308602, value max: 0.630353569984436\n",
      "D grad l2-norm: 7.692503586596606, value max: 0.7081024050712585\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 1.09838176 (ave = 0.97807283)\n",
      "Loss_G = 1.26840973 (ave = 1.27841985)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.549124327217488, value max: 0.6365129351615906\n",
      "D grad l2-norm: 7.65927226828079, value max: 0.7122012376785278\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.93999553 (ave = 0.96736549)\n",
      "Loss_G = 1.25631726 (ave = 1.25893111)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.318375559024563, value max: 0.6341642141342163\n",
      "D grad l2-norm: 7.3588564910943335, value max: 0.7075811624526978\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001597)\n",
      "Loss_D = 0.83640426 (ave = 0.96374696)\n",
      "Loss_G = 1.26723647 (ave = 1.25048780)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.13204594023669, value max: 0.6494776606559753\n",
      "D grad l2-norm: 7.139714792162251, value max: 0.7111533284187317\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 1.02527153 (ave = 1.00198631)\n",
      "Loss_G = 1.23820257 (ave = 1.23736756)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.41480264718958, value max: 0.670006275177002\n",
      "D grad l2-norm: 7.367639870144171, value max: 0.7029778957366943\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 1.18221927 (ave = 1.02620139)\n",
      "Loss_G = 1.22570503 (ave = 1.24430737)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.336915634224678, value max: 0.6701229214668274\n",
      "D grad l2-norm: 7.375771510461053, value max: 0.6982815861701965\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001598)\n",
      "Loss_D = 1.12404740 (ave = 1.01313356)\n",
      "Loss_G = 1.19573951 (ave = 1.22231665)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.104944962372906, value max: 0.6554073095321655\n",
      "D grad l2-norm: 7.228333511401632, value max: 0.6896237730979919\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001891)\n",
      "Loss_D = 0.95045829 (ave = 0.98241165)\n",
      "Loss_G = 1.25099802 (ave = 1.25017345)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.66210286725597, value max: 0.6180998682975769\n",
      "D grad l2-norm: 7.0750900259444025, value max: 0.7082636952400208\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001583)\n",
      "Loss_D = 0.79101920 (ave = 0.93729974)\n",
      "Loss_G = 1.31198895 (ave = 1.29297724)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.842752704598581, value max: 0.5897427797317505\n",
      "D grad l2-norm: 7.4196077297386065, value max: 0.7259674072265625\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001557)\n",
      "Loss_D = 0.84105468 (ave = 0.92305399)\n",
      "Loss_G = 1.32543468 (ave = 1.31113162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.618227865662623, value max: 0.5347126722335815\n",
      "D grad l2-norm: 7.361658385672305, value max: 0.7289379239082336\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.722s / 5 iters, (0.144)\tData load 0.671s / 5 iters, (0.134200)\n",
      "Loss_D = 0.91459167 (ave = 0.90640405)\n",
      "Loss_G = 1.31572080 (ave = 1.34790144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.513876178006313, value max: 0.5641268491744995\n",
      "D grad l2-norm: 7.429308114174629, value max: 0.7264814972877502\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.87693298 (ave = 0.88147802)\n",
      "Loss_G = 1.36174333 (ave = 1.35403442)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.401529001666062, value max: 0.6312308311462402\n",
      "D grad l2-norm: 7.2871797102522, value max: 0.7382649183273315\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 1.01113057 (ave = 0.87243991)\n",
      "Loss_G = 1.37060571 (ave = 1.36683214)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.487900035253516, value max: 0.6648962497711182\n",
      "D grad l2-norm: 7.417958965937683, value max: 0.7398398518562317\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.001915)\n",
      "Loss_D = 0.92786229 (ave = 0.84160278)\n",
      "Loss_G = 1.34129965 (ave = 1.37580984)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.105908128923076, value max: 0.6762315034866333\n",
      "D grad l2-norm: 7.101241223717896, value max: 0.7337210178375244\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.013s / 5 iters, (0.002503)\n",
      "Loss_D = 0.79311264 (ave = 0.80746111)\n",
      "Loss_G = 1.39648271 (ave = 1.39084990)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.862899381803203, value max: 0.6817564368247986\n",
      "D grad l2-norm: 7.01028856569749, value max: 0.74891197681427\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.018s / 5 iters, (0.003559)\n",
      "Loss_D = 0.71918964 (ave = 0.77462960)\n",
      "Loss_G = 1.42355454 (ave = 1.42228870)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.934069723267952, value max: 0.6825555562973022\n",
      "D grad l2-norm: 6.90256533749093, value max: 0.7549818754196167\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.70604944 (ave = 0.75668976)\n",
      "Loss_G = 1.40280855 (ave = 1.43490422)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.1818041975924, value max: 0.698860228061676\n",
      "D grad l2-norm: 6.778645389191235, value max: 0.7487552762031555\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.008s / 5 iters, (0.001675)\n",
      "Loss_D = 0.64676708 (ave = 0.74841106)\n",
      "Loss_G = 1.31257582 (ave = 1.38025794)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.271037910648002, value max: 0.691866397857666\n",
      "D grad l2-norm: 6.48583989401029, value max: 0.724897027015686\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.024s / 5 iters, (0.004736)\n",
      "Loss_D = 0.57599598 (ave = 0.74282959)\n",
      "Loss_G = 1.31836963 (ave = 1.34198163)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.676690959118462, value max: 0.6943274140357971\n",
      "D grad l2-norm: 6.597254259348238, value max: 0.7273642420768738\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.042s / 5 iters, (0.008317)\n",
      "Loss_D = 0.89501560 (ave = 0.80490191)\n",
      "Loss_G = 1.23661947 (ave = 1.27477503)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.6988754894213836, value max: 0.6797196269035339\n",
      "D grad l2-norm: 6.20654547526015, value max: 0.7033951878547668\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 7\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.006s / 5 iters, (0.001123)\n",
      "Loss_D = 1.40048778 (ave = 1.40979538)\n",
      "Loss_G = 0.66519666 (ave = 0.66553940)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9646167540057177, value max: 0.020626084879040718\n",
      "D grad l2-norm: 0.6627325643829324, value max: 0.4858255088329315\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.448s / 5 iters, (0.090)\tData load 0.374s / 5 iters, (0.074859)\n",
      "Loss_D = 1.39905810 (ave = 1.40001004)\n",
      "Loss_G = 0.66322720 (ave = 0.66387280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9725910735883677, value max: 0.018815066665410995\n",
      "D grad l2-norm: 0.6580904398153573, value max: 0.4848111569881439\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.389s / 5 iters, (0.078)\tData load 0.337s / 5 iters, (0.067440)\n",
      "Loss_D = 1.38769913 (ave = 1.38885157)\n",
      "Loss_G = 0.66216201 (ave = 0.66252958)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9626411228397064, value max: 0.019359556958079338\n",
      "D grad l2-norm: 0.6568793853222717, value max: 0.4842623770236969\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.586s / 5 iters, (0.117)\tData load 0.506s / 5 iters, (0.101276)\n",
      "Loss_D = 1.38233066 (ave = 1.37877097)\n",
      "Loss_G = 0.66118014 (ave = 0.66155272)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9627055170141415, value max: 0.018601329997181892\n",
      "D grad l2-norm: 0.6563841683206384, value max: 0.48375555872917175\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.479s / 5 iters, (0.096)\tData load 0.430s / 5 iters, (0.085907)\n",
      "Loss_D = 1.36708105 (ave = 1.36789198)\n",
      "Loss_G = 0.66007638 (ave = 0.66052210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9598868656234487, value max: 0.01982339285314083\n",
      "D grad l2-norm: 0.654958460732073, value max: 0.4831855297088623\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.451s / 5 iters, (0.090)\tData load 0.403s / 5 iters, (0.080660)\n",
      "Loss_D = 1.36234486 (ave = 1.35834429)\n",
      "Loss_G = 0.65946394 (ave = 0.65965085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9691178479780259, value max: 0.019423620775341988\n",
      "D grad l2-norm: 0.6547047462719136, value max: 0.48286905884742737\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.463s / 5 iters, (0.093)\tData load 0.348s / 5 iters, (0.069587)\n",
      "Loss_D = 1.33850217 (ave = 1.34660206)\n",
      "Loss_G = 0.65881145 (ave = 0.65903376)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9654287555234939, value max: 0.020511837676167488\n",
      "D grad l2-norm: 0.6563116579597228, value max: 0.4825313091278076\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.392s / 5 iters, (0.078)\tData load 0.333s / 5 iters, (0.066579)\n",
      "Loss_D = 1.33909941 (ave = 1.33816130)\n",
      "Loss_G = 0.65836859 (ave = 0.65855693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9685596300897007, value max: 0.021293718367815018\n",
      "D grad l2-norm: 0.6566719238539549, value max: 0.4823020398616791\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.539s / 5 iters, (0.108)\tData load 0.485s / 5 iters, (0.097019)\n",
      "Loss_D = 1.33033204 (ave = 1.32871308)\n",
      "Loss_G = 0.65892327 (ave = 0.65837988)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9629969374415687, value max: 0.0252557210624218\n",
      "D grad l2-norm: 0.6574707122374508, value max: 0.48258885741233826\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.519s / 5 iters, (0.104)\tData load 0.468s / 5 iters, (0.093560)\n",
      "Loss_D = 1.32655442 (ave = 1.32008758)\n",
      "Loss_G = 0.65808922 (ave = 0.65815068)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9650581717643535, value max: 0.02929268404841423\n",
      "D grad l2-norm: 0.6591131146334895, value max: 0.4821576476097107\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.671s / 5 iters, (0.134)\tData load 0.618s / 5 iters, (0.123574)\n",
      "Loss_D = 1.30778646 (ave = 1.30952437)\n",
      "Loss_G = 0.65825009 (ave = 0.65824479)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9653915173493324, value max: 0.02655625529587269\n",
      "D grad l2-norm: 0.6598429290484706, value max: 0.48224031925201416\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001579)\n",
      "Loss_D = 1.30601931 (ave = 1.30142546)\n",
      "Loss_G = 0.65778255 (ave = 0.65789241)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9632205333347105, value max: 0.02613893896341324\n",
      "D grad l2-norm: 0.6638519096066683, value max: 0.4819970726966858\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001572)\n",
      "Loss_D = 1.27763629 (ave = 1.28983612)\n",
      "Loss_G = 0.65834183 (ave = 0.65843345)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9681636095361594, value max: 0.02725149318575859\n",
      "D grad l2-norm: 0.6656995379715462, value max: 0.4822872281074524\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.011s / 5 iters, (0.002176)\n",
      "Loss_D = 1.29465175 (ave = 1.28388774)\n",
      "Loss_G = 0.65834576 (ave = 0.65835377)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9690130384835709, value max: 0.023157119750976562\n",
      "D grad l2-norm: 0.6675503814508671, value max: 0.4822886884212494\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.010s / 5 iters, (0.002084)\n",
      "Loss_D = 1.26361644 (ave = 1.27209752)\n",
      "Loss_G = 0.65856516 (ave = 0.65889411)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9681994620591924, value max: 0.024487163871526718\n",
      "D grad l2-norm: 0.6733309432925039, value max: 0.4824015498161316\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 1.26619744 (ave = 1.26457846)\n",
      "Loss_G = 0.65966964 (ave = 0.65940186)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9672172702173741, value max: 0.02322671376168728\n",
      "D grad l2-norm: 0.6749010773448487, value max: 0.4829727113246918\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001570)\n",
      "Loss_D = 1.25651491 (ave = 1.25601168)\n",
      "Loss_G = 0.66015059 (ave = 0.65986798)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9678681679472936, value max: 0.02779919095337391\n",
      "D grad l2-norm: 0.679036338229458, value max: 0.48321956396102905\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 1.25589001 (ave = 1.24810178)\n",
      "Loss_G = 0.66074216 (ave = 0.66041570)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9654141712869658, value max: 0.03204016759991646\n",
      "D grad l2-norm: 0.6846147158918634, value max: 0.48352640867233276\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 1.21663189 (ave = 1.23553221)\n",
      "Loss_G = 0.66278595 (ave = 0.66160519)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9654248930952867, value max: 0.028257226571440697\n",
      "D grad l2-norm: 0.6891641806068612, value max: 0.4845789074897766\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001710)\n",
      "Loss_D = 1.23209906 (ave = 1.22935052)\n",
      "Loss_G = 0.66306221 (ave = 0.66255876)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9742681404858476, value max: 0.029839469119906425\n",
      "D grad l2-norm: 0.6979577293904408, value max: 0.48472175002098083\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.859s / 5 iters, (0.172)\tData load 0.814s / 5 iters, (0.162879)\n",
      "Loss_D = 1.24039412 (ave = 1.22320845)\n",
      "Loss_G = 0.66533136 (ave = 0.66406586)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9644293530677974, value max: 0.031284913420677185\n",
      "D grad l2-norm: 0.7034277953362228, value max: 0.48589035868644714\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.016s / 5 iters, (0.003230)\n",
      "Loss_D = 1.19881928 (ave = 1.20994754)\n",
      "Loss_G = 0.66578627 (ave = 0.66533817)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9755124828285681, value max: 0.027434376999735832\n",
      "D grad l2-norm: 0.7084720995792843, value max: 0.4861218333244324\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.018s / 5 iters, (0.003606)\n",
      "Loss_D = 1.18768108 (ave = 1.20126297)\n",
      "Loss_G = 0.66783440 (ave = 0.66685823)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9713085510022994, value max: 0.03339070454239845\n",
      "D grad l2-norm: 0.7179913091081519, value max: 0.4871736466884613\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 1.21204817 (ave = 1.19732780)\n",
      "Loss_G = 0.66936249 (ave = 0.66888436)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9767113475251098, value max: 0.03797546774148941\n",
      "D grad l2-norm: 0.7254010036852927, value max: 0.4879547655582428\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 1.16142404 (ave = 1.18260918)\n",
      "Loss_G = 0.67202830 (ave = 0.67057227)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9780540230590977, value max: 0.035547707229852676\n",
      "D grad l2-norm: 0.7348313804263279, value max: 0.4893186092376709\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 1.15924597 (ave = 1.17546837)\n",
      "Loss_G = 0.67324281 (ave = 0.67266281)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9798251963873765, value max: 0.04146406054496765\n",
      "D grad l2-norm: 0.7450235984277966, value max: 0.4899336099624634\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.19330645 (ave = 1.17207322)\n",
      "Loss_G = 0.67666215 (ave = 0.67583866)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9795548965935471, value max: 0.03934001922607422\n",
      "D grad l2-norm: 0.7522799795425968, value max: 0.4916734993457794\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001622)\n",
      "Loss_D = 1.15216970 (ave = 1.15959833)\n",
      "Loss_G = 0.67885321 (ave = 0.67739929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9875899969116104, value max: 0.03805305063724518\n",
      "D grad l2-norm: 0.7672516408385661, value max: 0.49278774857521057\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 1.15415931 (ave = 1.15278752)\n",
      "Loss_G = 0.68183833 (ave = 0.68065505)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9843456198952705, value max: 0.03792617842555046\n",
      "D grad l2-norm: 0.7778999446663123, value max: 0.4942976236343384\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001560)\n",
      "Loss_D = 1.14924276 (ave = 1.14464090)\n",
      "Loss_G = 0.68550158 (ave = 0.68400159)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9891871147548559, value max: 0.04293201118707657\n",
      "D grad l2-norm: 0.7904501216974769, value max: 0.49614617228507996\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.748s / 5 iters, (0.150)\tData load 0.699s / 5 iters, (0.139781)\n",
      "Loss_D = 1.16854370 (ave = 1.13920348)\n",
      "Loss_G = 0.68959033 (ave = 0.68797991)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9910186685727755, value max: 0.04314146935939789\n",
      "D grad l2-norm: 0.8031538680718948, value max: 0.49819785356521606\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 1.10186982 (ave = 1.12343514)\n",
      "Loss_G = 0.69268686 (ave = 0.69143785)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.991560355626637, value max: 0.05816064029932022\n",
      "D grad l2-norm: 0.8245019373904179, value max: 0.49974870681762695\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 1.11091769 (ave = 1.11687574)\n",
      "Loss_G = 0.69717103 (ave = 0.69586174)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9944799115964676, value max: 0.05134473741054535\n",
      "D grad l2-norm: 0.8418182086737256, value max: 0.501979649066925\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 1.12403274 (ave = 1.11031561)\n",
      "Loss_G = 0.70279050 (ave = 0.70021476)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9950322569473563, value max: 0.04906165227293968\n",
      "D grad l2-norm: 0.8608819772886535, value max: 0.5047734975814819\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 1.08277035 (ave = 1.09649820)\n",
      "Loss_G = 0.70842820 (ave = 0.70675251)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9993507293551701, value max: 0.04817216098308563\n",
      "D grad l2-norm: 0.8796054967964865, value max: 0.5075570344924927\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 1.08081877 (ave = 1.08754678)\n",
      "Loss_G = 0.71587384 (ave = 0.71260424)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.993502742601968, value max: 0.055576685816049576\n",
      "D grad l2-norm: 0.896584068187062, value max: 0.5112067461013794\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 1.09121919 (ave = 1.08011925)\n",
      "Loss_G = 0.72226840 (ave = 0.71969116)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9990508240843898, value max: 0.05823232978582382\n",
      "D grad l2-norm: 0.9231147980061997, value max: 0.5143158435821533\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.012s / 5 iters, (0.002303)\n",
      "Loss_D = 1.08025897 (ave = 1.06924388)\n",
      "Loss_G = 0.73159564 (ave = 0.72746637)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0004651166158027, value max: 0.05661643296480179\n",
      "D grad l2-norm: 0.9389082302886428, value max: 0.5188327431678772\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 1.07080841 (ave = 1.05775783)\n",
      "Loss_G = 0.73681605 (ave = 0.73423669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.01705083574398, value max: 0.05563705414533615\n",
      "D grad l2-norm: 0.9757307557236199, value max: 0.5213330984115601\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 1.01594043 (ave = 1.04180272)\n",
      "Loss_G = 0.74504137 (ave = 0.74233977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.019542183385264, value max: 0.06329742074012756\n",
      "D grad l2-norm: 0.9980843279179091, value max: 0.5252468585968018\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.841s / 5 iters, (0.168)\tData load 0.793s / 5 iters, (0.158534)\n",
      "Loss_D = 1.03835273 (ave = 1.03416667)\n",
      "Loss_G = 0.75369263 (ave = 0.75091326)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0293248959481118, value max: 0.05907362326979637\n",
      "D grad l2-norm: 1.0322117915361761, value max: 0.5293407440185547\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.014s / 5 iters, (0.002791)\n",
      "Loss_D = 1.05000913 (ave = 1.02870057)\n",
      "Loss_G = 0.76263654 (ave = 0.75864985)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0297578598994679, value max: 0.06184167414903641\n",
      "D grad l2-norm: 1.0535240526402316, value max: 0.5335237979888916\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.96481490 (ave = 1.00985045)\n",
      "Loss_G = 0.76984662 (ave = 0.76588471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0468210898682373, value max: 0.06873533129692078\n",
      "D grad l2-norm: 1.0833156036588818, value max: 0.5368624925613403\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.016s / 5 iters, (0.003174)\n",
      "Loss_D = 0.96572673 (ave = 1.00202000)\n",
      "Loss_G = 0.77500308 (ave = 0.77318252)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.06645924604329, value max: 0.0727711021900177\n",
      "D grad l2-norm: 1.117528414204299, value max: 0.5392352342605591\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 0.99987113 (ave = 1.00024672)\n",
      "Loss_G = 0.78310800 (ave = 0.78079947)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.078209316198346, value max: 0.07432028651237488\n",
      "D grad l2-norm: 1.138753128470461, value max: 0.5429328680038452\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 1.02230871 (ave = 0.99733083)\n",
      "Loss_G = 0.79085469 (ave = 0.78645939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0898221502954966, value max: 0.08198115229606628\n",
      "D grad l2-norm: 1.1673229741778821, value max: 0.5464593768119812\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 0.94009095 (ave = 0.98208154)\n",
      "Loss_G = 0.79270989 (ave = 0.79031883)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.111237776354133, value max: 0.08902174979448318\n",
      "D grad l2-norm: 1.1925582716852214, value max: 0.5473060011863708\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 0.96261317 (ave = 0.98128872)\n",
      "Loss_G = 0.79959947 (ave = 0.79763653)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.121688801104366, value max: 0.09472683817148209\n",
      "D grad l2-norm: 1.2240338142510874, value max: 0.5503942966461182\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 0.96635735 (ave = 0.97613170)\n",
      "Loss_G = 0.80105269 (ave = 0.80065595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1383010878702187, value max: 0.09830282628536224\n",
      "D grad l2-norm: 1.2492853325551858, value max: 0.5510247945785522\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001715)\n",
      "Loss_D = 0.98098099 (ave = 0.97615496)\n",
      "Loss_G = 0.80224645 (ave = 0.80250695)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1773736617952537, value max: 0.10380946099758148\n",
      "D grad l2-norm: 1.2905209389325045, value max: 0.5515474081039429\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.824s / 5 iters, (0.165)\tData load 0.734s / 5 iters, (0.146766)\n",
      "Loss_D = 0.94746691 (ave = 0.96862481)\n",
      "Loss_G = 0.80755585 (ave = 0.80642158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2019270269446574, value max: 0.10741404443979263\n",
      "D grad l2-norm: 1.3117828118618156, value max: 0.5539076328277588\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.017s / 5 iters, (0.003373)\n",
      "Loss_D = 0.97427547 (ave = 0.96887716)\n",
      "Loss_G = 0.81011343 (ave = 0.80843658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2387904195739183, value max: 0.1269216239452362\n",
      "D grad l2-norm: 1.3478131871246197, value max: 0.5549986958503723\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.025s / 5 iters, (0.004917)\n",
      "Loss_D = 0.98375952 (ave = 0.97383467)\n",
      "Loss_G = 0.80857867 (ave = 0.80610003)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3060569962662623, value max: 0.1316247582435608\n",
      "D grad l2-norm: 1.3674629321849554, value max: 0.55433189868927\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.017s / 5 iters, (0.003337)\n",
      "Loss_D = 0.95382899 (ave = 0.97312772)\n",
      "Loss_G = 0.79524297 (ave = 0.80065995)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3668273396880928, value max: 0.13692082464694977\n",
      "D grad l2-norm: 1.4034826283314146, value max: 0.5481799840927124\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003368)\n",
      "Loss_D = 0.97156227 (ave = 0.98591701)\n",
      "Loss_G = 0.78814107 (ave = 0.79312264)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3930691731730862, value max: 0.15517657995224\n",
      "D grad l2-norm: 1.4247347215179897, value max: 0.5450232028961182\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001722)\n",
      "Loss_D = 1.01634634 (ave = 0.99383626)\n",
      "Loss_G = 0.78213179 (ave = 0.78564203)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4314916660343613, value max: 0.15400151908397675\n",
      "D grad l2-norm: 1.4588070508107687, value max: 0.5421848297119141\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.018s / 5 iters, (0.003516)\n",
      "Loss_D = 1.01109993 (ave = 0.99861379)\n",
      "Loss_G = 0.78739035 (ave = 0.78754719)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4242735950295498, value max: 0.15144047141075134\n",
      "D grad l2-norm: 1.492307725917437, value max: 0.5446598529815674\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 1.01584888 (ave = 0.99535806)\n",
      "Loss_G = 0.78760099 (ave = 0.78739179)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4338422991923538, value max: 0.16675306856632233\n",
      "D grad l2-norm: 1.533097519222468, value max: 0.5447893738746643\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001576)\n",
      "Loss_D = 0.98569191 (ave = 0.98725492)\n",
      "Loss_G = 0.79819846 (ave = 0.79794605)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4157162618738879, value max: 0.1823520064353943\n",
      "D grad l2-norm: 1.5880590360209457, value max: 0.5495670437812805\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.016s / 5 iters, (0.003270)\n",
      "Loss_D = 0.96221352 (ave = 0.97400707)\n",
      "Loss_G = 0.81738287 (ave = 0.81154079)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3905078871389378, value max: 0.18273237347602844\n",
      "D grad l2-norm: 1.6327300402290728, value max: 0.5581330060958862\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.706s / 5 iters, (0.141)\tData load 0.654s / 5 iters, (0.130750)\n",
      "Loss_D = 0.95374668 (ave = 0.95615572)\n",
      "Loss_G = 0.84471065 (ave = 0.83296999)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3780866771578537, value max: 0.18403300642967224\n",
      "D grad l2-norm: 1.6917376893749756, value max: 0.5700788497924805\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001811)\n",
      "Loss_D = 0.89387131 (ave = 0.93075458)\n",
      "Loss_G = 0.86721480 (ave = 0.85601158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.401366692113126, value max: 0.19382135570049286\n",
      "D grad l2-norm: 1.7647783358747848, value max: 0.5796269178390503\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.88511729 (ave = 0.90925822)\n",
      "Loss_G = 0.89487469 (ave = 0.88481934)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3964492656314664, value max: 0.19695180654525757\n",
      "D grad l2-norm: 1.8107096493695392, value max: 0.5911393165588379\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001700)\n",
      "Loss_D = 0.88408011 (ave = 0.89196156)\n",
      "Loss_G = 0.91783905 (ave = 0.90726684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.40801707106207, value max: 0.19865483045578003\n",
      "D grad l2-norm: 1.8451559763295324, value max: 0.6004398465156555\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.011s / 5 iters, (0.002227)\n",
      "Loss_D = 0.84191620 (ave = 0.87103801)\n",
      "Loss_G = 0.93672264 (ave = 0.92908453)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.456330245287814, value max: 0.20389346778392792\n",
      "D grad l2-norm: 1.9003823573142609, value max: 0.6079181432723999\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.017s / 5 iters, (0.003462)\n",
      "Loss_D = 0.85119259 (ave = 0.85747895)\n",
      "Loss_G = 0.95002162 (ave = 0.94642328)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5161011196809437, value max: 0.21602168679237366\n",
      "D grad l2-norm: 1.9442045365722809, value max: 0.6130650639533997\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 0.88834345 (ave = 0.85000557)\n",
      "Loss_G = 0.96662343 (ave = 0.95797783)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.525941872827596, value max: 0.21533428132534027\n",
      "D grad l2-norm: 1.9205998329404972, value max: 0.6194263696670532\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001778)\n",
      "Loss_D = 0.82429481 (ave = 0.83545197)\n",
      "Loss_G = 0.96725082 (ave = 0.96770631)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6113344283523567, value max: 0.21845297515392303\n",
      "D grad l2-norm: 1.9830228169756012, value max: 0.6195484399795532\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 0.82670242 (ave = 0.82725194)\n",
      "Loss_G = 0.97257793 (ave = 0.97001884)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.622511663546716, value max: 0.21457616984844208\n",
      "D grad l2-norm: 1.9358559238868798, value max: 0.6216419339179993\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 0.81188130 (ave = 0.82106655)\n",
      "Loss_G = 0.96841389 (ave = 0.97248210)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6995185775767025, value max: 0.21489229798316956\n",
      "D grad l2-norm: 1.9708513747409835, value max: 0.6199291348457336\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.948s / 5 iters, (0.190)\tData load 0.863s / 5 iters, (0.172689)\n",
      "Loss_D = 0.78055567 (ave = 0.81609664)\n",
      "Loss_G = 0.96181917 (ave = 0.96497247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7936595389046053, value max: 0.21917875111103058\n",
      "D grad l2-norm: 1.9912920116885853, value max: 0.6174527406692505\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001732)\n",
      "Loss_D = 0.85122323 (ave = 0.82741610)\n",
      "Loss_G = 0.94282436 (ave = 0.95417042)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8448548829439435, value max: 0.21949604153633118\n",
      "D grad l2-norm: 1.94834368535873, value max: 0.6100983619689941\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001769)\n",
      "Loss_D = 0.87944031 (ave = 0.83884904)\n",
      "Loss_G = 0.92685854 (ave = 0.93674384)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9196846743286158, value max: 0.22688908874988556\n",
      "D grad l2-norm: 1.9504685313025711, value max: 0.603651762008667\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001704)\n",
      "Loss_D = 0.87223184 (ave = 0.85268357)\n",
      "Loss_G = 0.90764898 (ave = 0.91275761)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.951790796331616, value max: 0.2126597762107849\n",
      "D grad l2-norm: 1.909100523804237, value max: 0.5958333611488342\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 0.87495875 (ave = 0.86619403)\n",
      "Loss_G = 0.88266957 (ave = 0.89323115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.026528727277072, value max: 0.19659650325775146\n",
      "D grad l2-norm: 1.9153831836857909, value max: 0.5856219530105591\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 0.86633909 (ave = 0.87574230)\n",
      "Loss_G = 0.85463119 (ave = 0.86811951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.082210434492045, value max: 0.19864819943904877\n",
      "D grad l2-norm: 1.9372517639109594, value max: 0.5737884640693665\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001616)\n",
      "Loss_D = 0.82429761 (ave = 0.89180797)\n",
      "Loss_G = 0.84209037 (ave = 0.84593261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.115296879335037, value max: 0.21642203629016876\n",
      "D grad l2-norm: 1.9751693761602263, value max: 0.5679988265037537\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001585)\n",
      "Loss_D = 0.88265097 (ave = 0.90466719)\n",
      "Loss_G = 0.83256143 (ave = 0.83965124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1251361493034766, value max: 0.22762323915958405\n",
      "D grad l2-norm: 2.023099583979635, value max: 0.5640171766281128\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 0.94701743 (ave = 0.91813340)\n",
      "Loss_G = 0.84347862 (ave = 0.84165173)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.138242185987778, value max: 0.21898841857910156\n",
      "D grad l2-norm: 2.0742287422255656, value max: 0.5689727663993835\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.90823746 (ave = 0.90476767)\n",
      "Loss_G = 0.85936469 (ave = 0.84793372)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.127743088404197, value max: 0.22710072994232178\n",
      "D grad l2-norm: 2.1653808999240094, value max: 0.5755262970924377\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.746s / 5 iters, (0.149)\tData load 0.699s / 5 iters, (0.139782)\n",
      "Loss_D = 0.89960408 (ave = 0.89316294)\n",
      "Loss_G = 0.88994968 (ave = 0.87365181)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1269014837484734, value max: 0.20922106504440308\n",
      "D grad l2-norm: 2.294118175918398, value max: 0.5885928869247437\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.81497228 (ave = 0.86133944)\n",
      "Loss_G = 0.92936641 (ave = 0.91089369)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1569606853746865, value max: 0.20144017040729523\n",
      "D grad l2-norm: 2.460157236507239, value max: 0.6042922139167786\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 0.82519728 (ave = 0.83564599)\n",
      "Loss_G = 0.98742336 (ave = 0.95967488)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1820634386274813, value max: 0.1988546997308731\n",
      "D grad l2-norm: 2.676592492726927, value max: 0.6267130374908447\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001643)\n",
      "Loss_D = 0.70232970 (ave = 0.78569700)\n",
      "Loss_G = 1.04689884 (ave = 1.01482778)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2534631205995477, value max: 0.1930055022239685\n",
      "D grad l2-norm: 2.8914521881893, value max: 0.6481930613517761\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001689)\n",
      "Loss_D = 0.87706101 (ave = 0.78073472)\n",
      "Loss_G = 1.09493732 (ave = 1.07711711)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2978753999549975, value max: 0.1916123628616333\n",
      "D grad l2-norm: 3.039544021968933, value max: 0.664777934551239\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001561)\n",
      "Loss_D = 0.73980063 (ave = 0.73935453)\n",
      "Loss_G = 1.13564420 (ave = 1.12113326)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.5657286823713443, value max: 0.20112086832523346\n",
      "D grad l2-norm: 3.348887855194524, value max: 0.6780370473861694\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.025s / 5 iters, (0.004933)\n",
      "Loss_D = 0.76526439 (ave = 0.72226144)\n",
      "Loss_G = 1.17759728 (ave = 1.17197487)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.7221699575449, value max: 0.23761685192584991\n",
      "D grad l2-norm: 3.3858825744789294, value max: 0.6910477876663208\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.78761935 (ave = 0.72336116)\n",
      "Loss_G = 1.18981266 (ave = 1.18311846)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.0848027153482818, value max: 0.30847111344337463\n",
      "D grad l2-norm: 3.4836632846446025, value max: 0.6941320896148682\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001656)\n",
      "Loss_D = 0.69958460 (ave = 0.72893062)\n",
      "Loss_G = 1.11126614 (ave = 1.14659131)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6732818966654412, value max: 0.39055585861206055\n",
      "D grad l2-norm: 3.5305733440988845, value max: 0.6689781546592712\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 0.85351765 (ave = 0.79603143)\n",
      "Loss_G = 1.04472375 (ave = 1.07775090)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.120425391335108, value max: 0.4521712362766266\n",
      "D grad l2-norm: 3.56707701137769, value max: 0.6444603204727173\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.888s / 5 iters, (0.178)\tData load 0.832s / 5 iters, (0.166401)\n",
      "Loss_D = 0.95776248 (ave = 0.87677937)\n",
      "Loss_G = 0.96406835 (ave = 0.97853528)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.457786377134011, value max: 0.49757441878318787\n",
      "D grad l2-norm: 3.6392750256556092, value max: 0.6139405369758606\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001730)\n",
      "Loss_D = 0.96408188 (ave = 0.93053856)\n",
      "Loss_G = 0.90883934 (ave = 0.91660234)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.549537799843893, value max: 0.5246042013168335\n",
      "D grad l2-norm: 3.6494147050661403, value max: 0.5923968553543091\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001623)\n",
      "Loss_D = 1.03439713 (ave = 1.00407686)\n",
      "Loss_G = 0.90718901 (ave = 0.89704401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.597790186827433, value max: 0.5409265756607056\n",
      "D grad l2-norm: 3.711977062210767, value max: 0.592145562171936\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 0.99426341 (ave = 1.01136395)\n",
      "Loss_G = 0.90895277 (ave = 0.89323869)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.8893292571666755, value max: 0.5464617609977722\n",
      "D grad l2-norm: 3.978828145894471, value max: 0.5926610231399536\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.012s / 5 iters, (0.002368)\n",
      "Loss_D = 1.09273481 (ave = 1.03402712)\n",
      "Loss_G = 0.90036738 (ave = 0.91085074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.925960775448666, value max: 0.5403592586517334\n",
      "D grad l2-norm: 4.058817813045621, value max: 0.5886551737785339\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.021s / 5 iters, (0.004146)\n",
      "Loss_D = 1.01448572 (ave = 1.02974885)\n",
      "Loss_G = 0.95453769 (ave = 0.93456978)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.008500811881451, value max: 0.5560835003852844\n",
      "D grad l2-norm: 4.256477528944916, value max: 0.6105952858924866\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001641)\n",
      "Loss_D = 1.01818824 (ave = 1.02133142)\n",
      "Loss_G = 0.95333081 (ave = 0.94984871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.050853712754116, value max: 0.5350191593170166\n",
      "D grad l2-norm: 4.346981434879003, value max: 0.6110559105873108\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001551)\n",
      "Loss_D = 1.00404584 (ave = 1.02588623)\n",
      "Loss_G = 0.97263116 (ave = 0.97960951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.201686928954124, value max: 0.5319665670394897\n",
      "D grad l2-norm: 4.462194102105337, value max: 0.6189433336257935\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.94112092 (ave = 1.02945598)\n",
      "Loss_G = 0.99007571 (ave = 0.97606022)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.35150126701733, value max: 0.5010027885437012\n",
      "D grad l2-norm: 4.676994691382021, value max: 0.6260203719139099\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 1.21046817 (ave = 1.07337854)\n",
      "Loss_G = 0.99958956 (ave = 0.98210312)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.3676318871415, value max: 0.4842294752597809\n",
      "D grad l2-norm: 4.706312264959874, value max: 0.6291738748550415\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.754s / 5 iters, (0.151)\tData load 0.707s / 5 iters, (0.141308)\n",
      "Loss_D = 1.06016576 (ave = 1.07444134)\n",
      "Loss_G = 0.96409851 (ave = 0.97216525)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.447972435431438, value max: 0.44555220007896423\n",
      "D grad l2-norm: 4.8377303442794375, value max: 0.6157506704330444\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 5 iters, (0.023)\tData load 0.017s / 5 iters, (0.003315)\n",
      "Loss_D = 1.06807983 (ave = 1.09126315)\n",
      "Loss_G = 0.99611348 (ave = 0.99132458)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.453430273590942, value max: 0.4363645017147064\n",
      "D grad l2-norm: 4.9423000324705555, value max: 0.6281038522720337\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 5 iters, (0.025)\tData load 0.031s / 5 iters, (0.006226)\n",
      "Loss_D = 1.03633404 (ave = 1.08546975)\n",
      "Loss_G = 1.01921952 (ave = 1.00563642)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.405881533081556, value max: 0.4419170916080475\n",
      "D grad l2-norm: 5.220992259948894, value max: 0.6365205645561218\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.113s / 5 iters, (0.023)\tData load 0.018s / 5 iters, (0.003605)\n",
      "Loss_D = 1.01656687 (ave = 1.06855540)\n",
      "Loss_G = 1.05999541 (ave = 1.05907645)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.586117959935999, value max: 0.45355933904647827\n",
      "D grad l2-norm: 5.466849312789782, value max: 0.6507805585861206\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.014s / 5 iters, (0.002883)\n",
      "Loss_D = 0.96613431 (ave = 1.05990443)\n",
      "Loss_G = 1.08445942 (ave = 1.07758138)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.774676688892592, value max: 0.4556194543838501\n",
      "D grad l2-norm: 5.684876358209846, value max: 0.6588106155395508\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.022s / 5 iters, (0.004427)\n",
      "Loss_D = 1.10793924 (ave = 1.08121567)\n",
      "Loss_G = 1.13337779 (ave = 1.11654253)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.966288719893276, value max: 0.46899721026420593\n",
      "D grad l2-norm: 5.921989468988097, value max: 0.673884391784668\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001560)\n",
      "Loss_D = 1.10207438 (ave = 1.09037941)\n",
      "Loss_G = 1.13462555 (ave = 1.11876912)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.147446600277189, value max: 0.45224085450172424\n",
      "D grad l2-norm: 6.172119652947442, value max: 0.6744801998138428\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.015s / 5 iters, (0.002946)\n",
      "Loss_D = 0.97789168 (ave = 1.08360934)\n",
      "Loss_G = 1.12194681 (ave = 1.12923696)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.325715921974577, value max: 0.42849597334861755\n",
      "D grad l2-norm: 6.379050211378443, value max: 0.6690129637718201\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001643)\n",
      "Loss_D = 1.03998756 (ave = 1.10065169)\n",
      "Loss_G = 1.15998960 (ave = 1.14089270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.419769129908867, value max: 0.4587920308113098\n",
      "D grad l2-norm: 6.478048521412415, value max: 0.6821364164352417\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001785)\n",
      "Loss_D = 1.47695208 (ave = 1.17598650)\n",
      "Loss_G = 1.14764512 (ave = 1.14430921)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.481409527594225, value max: 0.4822918176651001\n",
      "D grad l2-norm: 6.442482346504038, value max: 0.6782852411270142\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.657s / 5 iters, (0.131)\tData load 0.608s / 5 iters, (0.121507)\n",
      "Loss_D = 1.22768140 (ave = 1.16025572)\n",
      "Loss_G = 1.15226364 (ave = 1.14280999)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.389386963098468, value max: 0.47439447045326233\n",
      "D grad l2-norm: 6.48384702097293, value max: 0.6786719560623169\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001553)\n",
      "Loss_D = 1.12385821 (ave = 1.16175215)\n",
      "Loss_G = 1.19707894 (ave = 1.15613015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.539950896656691, value max: 0.4680420458316803\n",
      "D grad l2-norm: 6.727236389499961, value max: 0.6935099959373474\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001715)\n",
      "Loss_D = 1.15775776 (ave = 1.16834559)\n",
      "Loss_G = 1.18247056 (ave = 1.18355057)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.541695058038884, value max: 0.49362099170684814\n",
      "D grad l2-norm: 6.827714753392946, value max: 0.6889930963516235\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001787)\n",
      "Loss_D = 1.17129171 (ave = 1.17023678)\n",
      "Loss_G = 1.25654840 (ave = 1.22447526)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.576221873682668, value max: 0.48277390003204346\n",
      "D grad l2-norm: 7.206334408908217, value max: 0.7108285427093506\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.015s / 5 iters, (0.002961)\n",
      "Loss_D = 0.99461347 (ave = 1.13579491)\n",
      "Loss_G = 1.31272900 (ave = 1.27527106)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.619000162186601, value max: 0.4897235929965973\n",
      "D grad l2-norm: 7.446069316706947, value max: 0.7276807427406311\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001720)\n",
      "Loss_D = 1.16002309 (ave = 1.13103831)\n",
      "Loss_G = 1.34955990 (ave = 1.32364018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.640661494603667, value max: 0.5061743259429932\n",
      "D grad l2-norm: 7.498351792797368, value max: 0.7368332147598267\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 1.09612572 (ave = 1.10924804)\n",
      "Loss_G = 1.36675143 (ave = 1.35386214)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.782253055600619, value max: 0.5033367872238159\n",
      "D grad l2-norm: 7.685778491786865, value max: 0.7560778260231018\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 1.23076022 (ave = 1.11825068)\n",
      "Loss_G = 1.39489007 (ave = 1.37525039)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.919466223037044, value max: 0.4814600944519043\n",
      "D grad l2-norm: 7.890369961421685, value max: 0.7778698801994324\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001616)\n",
      "Loss_D = 0.91693521 (ave = 1.06324182)\n",
      "Loss_G = 1.41603327 (ave = 1.40315194)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.1230030100341155, value max: 0.5021587610244751\n",
      "D grad l2-norm: 7.981680180819683, value max: 0.7800880074501038\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 0.93111819 (ave = 1.06301697)\n",
      "Loss_G = 1.42076325 (ave = 1.41421525)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.9907281092307665, value max: 0.47650107741355896\n",
      "D grad l2-norm: 7.899676530497321, value max: 0.7741478085517883\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.923s / 5 iters, (0.185)\tData load 0.866s / 5 iters, (0.173144)\n",
      "Loss_D = 0.92788243 (ave = 1.05796385)\n",
      "Loss_G = 1.43742478 (ave = 1.41975276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.719256670943869, value max: 0.4583015739917755\n",
      "D grad l2-norm: 7.726376902137143, value max: 0.7609886527061462\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.014s / 5 iters, (0.002785)\n",
      "Loss_D = 1.11112535 (ave = 1.06136968)\n",
      "Loss_G = 1.40523052 (ave = 1.42115028)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.81838439261705, value max: 0.46149948239326477\n",
      "D grad l2-norm: 7.7176733551051635, value max: 0.7511289715766907\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.98254752 (ave = 1.04755878)\n",
      "Loss_G = 1.40298307 (ave = 1.41125517)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.037443717695348, value max: 0.4396798312664032\n",
      "D grad l2-norm: 7.740876849838589, value max: 0.750457763671875\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 0.84536099 (ave = 1.02420943)\n",
      "Loss_G = 1.39308059 (ave = 1.40956738)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.6262655799056, value max: 0.4074290692806244\n",
      "D grad l2-norm: 7.322556255368666, value max: 0.7481633424758911\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002119)\n",
      "Loss_D = 1.05080545 (ave = 1.04727504)\n",
      "Loss_G = 1.36940551 (ave = 1.37635136)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.805360292963042, value max: 0.44484543800354004\n",
      "D grad l2-norm: 7.268291609213277, value max: 0.7422299385070801\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 1.19571733 (ave = 1.07185950)\n",
      "Loss_G = 1.34516418 (ave = 1.36085837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.893888243410246, value max: 0.4736931025981903\n",
      "D grad l2-norm: 7.297879585325252, value max: 0.7362096309661865\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 0.94949424 (ave = 1.04177887)\n",
      "Loss_G = 1.32289875 (ave = 1.34194744)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.898424370799067, value max: 0.5054885745048523\n",
      "D grad l2-norm: 7.218266259069627, value max: 0.7301392555236816\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001641)\n",
      "Loss_D = 1.17436194 (ave = 1.06712370)\n",
      "Loss_G = 1.32505023 (ave = 1.32313709)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.790854251223182, value max: 0.5288037061691284\n",
      "D grad l2-norm: 6.989362956987356, value max: 0.7305864691734314\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.012s / 5 iters, (0.002479)\n",
      "Loss_D = 1.08533049 (ave = 1.04709105)\n",
      "Loss_G = 1.34287441 (ave = 1.32625468)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.727816664423434, value max: 0.5463016629219055\n",
      "D grad l2-norm: 6.980787483312418, value max: 0.7679221630096436\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 5 iters, (0.017)\tData load 0.009s / 5 iters, (0.001738)\n",
      "Loss_D = 0.98164731 (ave = 1.02257137)\n",
      "Loss_G = 1.32218754 (ave = 1.31265464)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.86372484176751, value max: 0.5457030534744263\n",
      "D grad l2-norm: 7.203505227738333, value max: 0.8053460717201233\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.832s / 5 iters, (0.166)\tData load 0.749s / 5 iters, (0.149870)\n",
      "Loss_D = 1.04793608 (ave = 1.01404641)\n",
      "Loss_G = 1.35695159 (ave = 1.34296460)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.362314602960028, value max: 0.5249197483062744\n",
      "D grad l2-norm: 6.9760386702264165, value max: 0.8028644323348999\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.016s / 5 iters, (0.003125)\n",
      "Loss_D = 0.91570669 (ave = 0.96706632)\n",
      "Loss_G = 1.40147996 (ave = 1.37858276)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.189988925613906, value max: 0.5032371282577515\n",
      "D grad l2-norm: 6.932702947336416, value max: 0.8107437491416931\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 0.84242940 (ave = 0.92919451)\n",
      "Loss_G = 1.45945346 (ave = 1.44228222)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.6194999249685464, value max: 0.5311968326568604\n",
      "D grad l2-norm: 7.40278418407197, value max: 0.8706293702125549\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.010s / 5 iters, (0.001902)\n",
      "Loss_D = 0.76476705 (ave = 0.89404706)\n",
      "Loss_G = 1.44992363 (ave = 1.44670205)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.7873033983785325, value max: 0.5552597045898438\n",
      "D grad l2-norm: 7.4675194426053535, value max: 0.8586300015449524\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.010s / 5 iters, (0.001974)\n",
      "Loss_D = 1.04166603 (ave = 0.91855489)\n",
      "Loss_G = 1.43804944 (ave = 1.45433862)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.23684818714452, value max: 0.582483172416687\n",
      "D grad l2-norm: 7.542910614930565, value max: 0.8630027174949646\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 0.94428384 (ave = 0.89899948)\n",
      "Loss_G = 1.40265620 (ave = 1.42182848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.469929890818184, value max: 0.5617365837097168\n",
      "D grad l2-norm: 7.667889659439282, value max: 0.8611400127410889\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.009s / 5 iters, (0.001744)\n",
      "Loss_D = 0.90699863 (ave = 0.89014636)\n",
      "Loss_G = 1.43009567 (ave = 1.41952908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.34897771123643, value max: 0.5222675800323486\n",
      "D grad l2-norm: 7.66036315767201, value max: 0.8771417140960693\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001714)\n",
      "Loss_D = 0.85399663 (ave = 0.86277285)\n",
      "Loss_G = 1.43482566 (ave = 1.43475239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.362089373620802, value max: 0.49081164598464966\n",
      "D grad l2-norm: 7.885594627594716, value max: 0.8968797326087952\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001684)\n",
      "Loss_D = 0.85453576 (ave = 0.84744719)\n",
      "Loss_G = 1.47366762 (ave = 1.44929318)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.3837810275889195, value max: 0.4710691571235657\n",
      "D grad l2-norm: 7.9515241788650135, value max: 0.9086281061172485\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.009s / 5 iters, (0.001726)\n",
      "Loss_D = 0.97242808 (ave = 0.84384727)\n",
      "Loss_G = 1.47737372 (ave = 1.48534150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.7742359814550595, value max: 0.4915204346179962\n",
      "D grad l2-norm: 8.304785557255157, value max: 0.9256938099861145\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.717s / 5 iters, (0.143)\tData load 0.665s / 5 iters, (0.132966)\n",
      "Loss_D = 0.76941526 (ave = 0.80793096)\n",
      "Loss_G = 1.50719976 (ave = 1.48064716)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.58886355030009, value max: 0.4844514727592468\n",
      "D grad l2-norm: 7.970478624003767, value max: 0.8870872259140015\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001722)\n",
      "Loss_D = 0.84150374 (ave = 0.81134459)\n",
      "Loss_G = 1.41647863 (ave = 1.47081423)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.236354629983266, value max: 0.5067153573036194\n",
      "D grad l2-norm: 8.172398576465412, value max: 0.850969135761261\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001684)\n",
      "Loss_D = 0.82439876 (ave = 0.81986353)\n",
      "Loss_G = 1.42316532 (ave = 1.43196435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.380351662553313, value max: 0.49939200282096863\n",
      "D grad l2-norm: 8.139087795742602, value max: 0.8570048809051514\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.76649046 (ave = 0.82424073)\n",
      "Loss_G = 1.40359783 (ave = 1.39552119)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.418990386574707, value max: 0.5035361647605896\n",
      "D grad l2-norm: 8.015206707996256, value max: 0.8473431468009949\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.93087357 (ave = 0.85320081)\n",
      "Loss_G = 1.37615407 (ave = 1.37588797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.522862272361131, value max: 0.5477936267852783\n",
      "D grad l2-norm: 7.98595420821844, value max: 0.8363450169563293\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 0.83602083 (ave = 0.84805690)\n",
      "Loss_G = 1.35371149 (ave = 1.35265393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.47921335043693, value max: 0.5756199359893799\n",
      "D grad l2-norm: 7.953338959688619, value max: 0.8331612944602966\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001723)\n",
      "Loss_D = 0.84196103 (ave = 0.85021658)\n",
      "Loss_G = 1.32038224 (ave = 1.32608137)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.040938688511478, value max: 0.5744842886924744\n",
      "D grad l2-norm: 7.6712844628941355, value max: 0.800126314163208\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001723)\n",
      "Loss_D = 0.89021897 (ave = 0.85554287)\n",
      "Loss_G = 1.37582445 (ave = 1.33792968)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.02946409113457, value max: 0.6112454533576965\n",
      "D grad l2-norm: 7.819800392222938, value max: 0.8265520930290222\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001733)\n",
      "Loss_D = 0.88836205 (ave = 0.84202003)\n",
      "Loss_G = 1.36042356 (ave = 1.35351443)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.581331881297271, value max: 0.613743782043457\n",
      "D grad l2-norm: 7.541930755934217, value max: 0.787676215171814\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.84119248 (ave = 0.82775450)\n",
      "Loss_G = 1.36299622 (ave = 1.37614536)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.569196257660966, value max: 0.623881459236145\n",
      "D grad l2-norm: 7.448177573104159, value max: 0.7720636129379272\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.905s / 5 iters, (0.181)\tData load 0.800s / 5 iters, (0.160077)\n",
      "Loss_D = 0.68363786 (ave = 0.80993452)\n",
      "Loss_G = 1.40864754 (ave = 1.38174148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.626185309601849, value max: 0.6411163210868835\n",
      "D grad l2-norm: 7.707063426101683, value max: 0.7961750030517578\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 0.68620759 (ave = 0.79522558)\n",
      "Loss_G = 1.42203712 (ave = 1.39181015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.196091165727533, value max: 0.6315216422080994\n",
      "D grad l2-norm: 7.607912403464143, value max: 0.7736535668373108\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004500)\n",
      "Loss_D = 0.71637988 (ave = 0.78516220)\n",
      "Loss_G = 1.44564676 (ave = 1.41994150)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.255267637255747, value max: 0.6368342041969299\n",
      "D grad l2-norm: 7.538139832697864, value max: 0.7604796290397644\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.016s / 5 iters, (0.003118)\n",
      "Loss_D = 0.75558579 (ave = 0.78791996)\n",
      "Loss_G = 1.40664244 (ave = 1.41578169)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.371791278879211, value max: 0.673241376876831\n",
      "D grad l2-norm: 7.38152331701999, value max: 0.7514395713806152\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 0.69434273 (ave = 0.78556130)\n",
      "Loss_G = 1.38802457 (ave = 1.40045376)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.460839869043582, value max: 0.6806192398071289\n",
      "D grad l2-norm: 7.293993538069255, value max: 0.7464714050292969\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.014s / 5 iters, (0.002754)\n",
      "Loss_D = 0.93257558 (ave = 0.82411596)\n",
      "Loss_G = 1.34891605 (ave = 1.36560669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.233941741505822, value max: 0.6249164342880249\n",
      "D grad l2-norm: 6.965051124972132, value max: 0.7366201281547546\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.73055422 (ave = 0.80282180)\n",
      "Loss_G = 1.34771943 (ave = 1.35872841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.145096745447507, value max: 0.5939532518386841\n",
      "D grad l2-norm: 7.016904834351737, value max: 0.7671597003936768\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 0.80181444 (ave = 0.81141266)\n",
      "Loss_G = 1.35536885 (ave = 1.36667886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.73225153448391, value max: 0.5441763401031494\n",
      "D grad l2-norm: 6.727738575718013, value max: 0.7608282566070557\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001574)\n",
      "Loss_D = 0.74306560 (ave = 0.80092177)\n",
      "Loss_G = 1.36596537 (ave = 1.37098041)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.790202864396901, value max: 0.49685120582580566\n",
      "D grad l2-norm: 6.776938316987959, value max: 0.7866500616073608\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001550)\n",
      "Loss_D = 0.87873065 (ave = 0.81715343)\n",
      "Loss_G = 1.32200491 (ave = 1.34581525)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.787923292658698, value max: 0.4812939167022705\n",
      "D grad l2-norm: 6.520527028591148, value max: 0.7430498600006104\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.780s / 5 iters, (0.156)\tData load 0.700s / 5 iters, (0.139936)\n",
      "Loss_D = 0.83553648 (ave = 0.82899495)\n",
      "Loss_G = 1.28207242 (ave = 1.28666394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.929013898206983, value max: 0.5359053611755371\n",
      "D grad l2-norm: 6.529438554607214, value max: 0.7328055500984192\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 0.87970281 (ave = 0.84936653)\n",
      "Loss_G = 1.26881695 (ave = 1.27658620)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.951785572379023, value max: 0.5694506764411926\n",
      "D grad l2-norm: 6.556661994433031, value max: 0.7177962064743042\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.81012022 (ave = 0.85881238)\n",
      "Loss_G = 1.25205135 (ave = 1.24999924)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.634361732687371, value max: 0.5576751828193665\n",
      "D grad l2-norm: 6.3107357075552795, value max: 0.7094197869300842\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001597)\n",
      "Loss_D = 0.93517983 (ave = 0.87371246)\n",
      "Loss_G = 1.26568961 (ave = 1.26478202)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.842949039204256, value max: 0.5701740384101868\n",
      "D grad l2-norm: 6.519413078425412, value max: 0.7136188745498657\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.70030713 (ave = 0.83926848)\n",
      "Loss_G = 1.26620388 (ave = 1.25722201)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.972961181026542, value max: 0.572030246257782\n",
      "D grad l2-norm: 6.588739156432892, value max: 0.7135579586029053\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 0.83112276 (ave = 0.86734595)\n",
      "Loss_G = 1.25297606 (ave = 1.24143159)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.934355292790359, value max: 0.5550392866134644\n",
      "D grad l2-norm: 6.518681532798826, value max: 0.7099408507347107\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.86280429 (ave = 0.87515304)\n",
      "Loss_G = 1.25132966 (ave = 1.23990414)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.86115851449882, value max: 0.524203360080719\n",
      "D grad l2-norm: 6.500379548041831, value max: 0.7096697092056274\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.015s / 5 iters, (0.003082)\n",
      "Loss_D = 0.83195657 (ave = 0.87391186)\n",
      "Loss_G = 1.23917997 (ave = 1.25216920)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.665224504558568, value max: 0.49281761050224304\n",
      "D grad l2-norm: 6.5587347180805065, value max: 0.7068442702293396\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001735)\n",
      "Loss_D = 0.77781761 (ave = 0.85145800)\n",
      "Loss_G = 1.29118538 (ave = 1.27423546)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.5023852839589935, value max: 0.48581740260124207\n",
      "D grad l2-norm: 6.464715570971446, value max: 0.7222477197647095\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.017s / 5 iters, (0.003352)\n",
      "Loss_D = 0.75382972 (ave = 0.83878008)\n",
      "Loss_G = 1.30363441 (ave = 1.30808024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.66393513770551, value max: 0.5011497735977173\n",
      "D grad l2-norm: 6.442492505402533, value max: 0.7258910536766052\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.858s / 5 iters, (0.172)\tData load 0.811s / 5 iters, (0.162180)\n",
      "Loss_D = 0.76786530 (ave = 0.84259456)\n",
      "Loss_G = 1.30142128 (ave = 1.30507481)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.916005358203636, value max: 0.5537815093994141\n",
      "D grad l2-norm: 6.570135919899405, value max: 0.7244641780853271\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001569)\n",
      "Loss_D = 0.92235446 (ave = 0.86986675)\n",
      "Loss_G = 1.26495481 (ave = 1.27537863)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.94964301988326, value max: 0.5873989462852478\n",
      "D grad l2-norm: 6.608434587255273, value max: 0.7151941657066345\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.82983911 (ave = 0.85633186)\n",
      "Loss_G = 1.28689253 (ave = 1.27631674)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.710863702652309, value max: 0.5907213687896729\n",
      "D grad l2-norm: 6.585769941000872, value max: 0.7207614779472351\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001545)\n",
      "Loss_D = 0.92706877 (ave = 0.85945295)\n",
      "Loss_G = 1.32507634 (ave = 1.29192519)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.542999776206848, value max: 0.5974477529525757\n",
      "D grad l2-norm: 6.584422369415623, value max: 0.7311842441558838\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.014s / 5 iters, (0.002864)\n",
      "Loss_D = 0.89384675 (ave = 0.84331576)\n",
      "Loss_G = 1.33960557 (ave = 1.31231520)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.449618124400917, value max: 0.577666163444519\n",
      "D grad l2-norm: 6.609510257640999, value max: 0.7355484962463379\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 0.71322632 (ave = 0.80550524)\n",
      "Loss_G = 1.38004637 (ave = 1.34116564)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.318926849906029, value max: 0.5889221429824829\n",
      "D grad l2-norm: 6.5592135356919, value max: 0.745651125907898\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.64235348 (ave = 0.78105824)\n",
      "Loss_G = 1.39361274 (ave = 1.36973710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.005623460243726, value max: 0.5973426103591919\n",
      "D grad l2-norm: 6.4379952090577515, value max: 0.7491849064826965\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001593)\n",
      "Loss_D = 0.75872803 (ave = 0.78207327)\n",
      "Loss_G = 1.43266654 (ave = 1.40821836)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.012368960277641, value max: 0.6488388776779175\n",
      "D grad l2-norm: 6.474981865699525, value max: 0.7585490942001343\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.82170773 (ave = 0.77741551)\n",
      "Loss_G = 1.44303346 (ave = 1.41427958)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.271560462368333, value max: 0.6672141551971436\n",
      "D grad l2-norm: 6.594207039190667, value max: 0.7616740465164185\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001731)\n",
      "Loss_D = 0.64398903 (ave = 0.74978719)\n",
      "Loss_G = 1.41059911 (ave = 1.41031926)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.9920015513208815, value max: 0.678292989730835\n",
      "D grad l2-norm: 6.299219714030281, value max: 0.753779947757721\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.769s / 5 iters, (0.154)\tData load 0.697s / 5 iters, (0.139408)\n",
      "Loss_D = 0.75092947 (ave = 0.76039311)\n",
      "Loss_G = 1.42081094 (ave = 1.41553464)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.997385677112515, value max: 0.701202929019928\n",
      "D grad l2-norm: 6.198268998741571, value max: 0.7555007934570312\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 0.84486914 (ave = 0.76556890)\n",
      "Loss_G = 1.40391767 (ave = 1.41696875)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.0098975789901665, value max: 0.7306535840034485\n",
      "D grad l2-norm: 6.195963452565515, value max: 0.751286506652832\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.83660835 (ave = 0.76823994)\n",
      "Loss_G = 1.37962854 (ave = 1.40806797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.871782716194095, value max: 0.7439606785774231\n",
      "D grad l2-norm: 5.960408067610237, value max: 0.7461252212524414\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003334)\n",
      "Loss_D = 0.79703510 (ave = 0.76341157)\n",
      "Loss_G = 1.37466359 (ave = 1.37608354)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.984986123542642, value max: 0.7259124517440796\n",
      "D grad l2-norm: 5.96430712960917, value max: 0.7446002960205078\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.017s / 5 iters, (0.003472)\n",
      "Loss_D = 0.72015417 (ave = 0.75477254)\n",
      "Loss_G = 1.34517539 (ave = 1.34476371)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.965213134374153, value max: 0.7261279821395874\n",
      "D grad l2-norm: 5.707111614273429, value max: 0.7366312146186829\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.009s / 5 iters, (0.001760)\n",
      "Loss_D = 0.78959334 (ave = 0.77355387)\n",
      "Loss_G = 1.31079662 (ave = 1.31100547)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.034837062002012, value max: 0.7171629071235657\n",
      "D grad l2-norm: 5.587223629262578, value max: 0.7262505888938904\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.017s / 5 iters, (0.003373)\n",
      "Loss_D = 0.68425733 (ave = 0.77405256)\n",
      "Loss_G = 1.27309155 (ave = 1.27518668)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.114254650617889, value max: 0.7084290981292725\n",
      "D grad l2-norm: 5.485013428434404, value max: 0.7168206572532654\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001711)\n",
      "Loss_D = 0.76568687 (ave = 0.80210550)\n",
      "Loss_G = 1.23435545 (ave = 1.23773913)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.02826392179008, value max: 0.6773115396499634\n",
      "D grad l2-norm: 5.295832794561226, value max: 0.7058306932449341\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.016s / 5 iters, (0.003268)\n",
      "Loss_D = 0.70538062 (ave = 0.81171885)\n",
      "Loss_G = 1.18350697 (ave = 1.19699018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.636904328782291, value max: 0.6286162734031677\n",
      "D grad l2-norm: 4.9468467640835865, value max: 0.6895940899848938\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001785)\n",
      "Loss_D = 0.83751249 (ave = 0.84622804)\n",
      "Loss_G = 1.17012477 (ave = 1.17324412)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.44976449233521, value max: 0.5725300908088684\n",
      "D grad l2-norm: 4.8855396037258245, value max: 0.6860140562057495\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.697s / 5 iters, (0.139)\tData load 0.642s / 5 iters, (0.128450)\n",
      "Loss_D = 0.85376728 (ave = 0.85167193)\n",
      "Loss_G = 1.15091562 (ave = 1.16421852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.099395513787982, value max: 0.5211939811706543\n",
      "D grad l2-norm: 4.670255235800998, value max: 0.6802893280982971\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.90075356 (ave = 0.86313407)\n",
      "Loss_G = 1.12749767 (ave = 1.14354639)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.150737142665095, value max: 0.4891762137413025\n",
      "D grad l2-norm: 4.528458984449938, value max: 0.6725707650184631\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001522)\n",
      "Loss_D = 0.85788727 (ave = 0.87059311)\n",
      "Loss_G = 1.10869956 (ave = 1.11329834)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.185900700047181, value max: 0.4599933922290802\n",
      "D grad l2-norm: 4.35045851574114, value max: 0.6664304137229919\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004529)\n",
      "Loss_D = 0.87919784 (ave = 0.88611099)\n",
      "Loss_G = 1.04722917 (ave = 1.06909018)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.3211438413172125, value max: 0.433084636926651\n",
      "D grad l2-norm: 4.267629757956402, value max: 0.644936203956604\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.017s / 5 iters, (0.003337)\n",
      "Loss_D = 0.87286270 (ave = 0.91842217)\n",
      "Loss_G = 1.00252831 (ave = 1.02546816)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.306494924232858, value max: 0.4043656289577484\n",
      "D grad l2-norm: 4.100915776208681, value max: 0.6285061836242676\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 0.86208463 (ave = 0.94285111)\n",
      "Loss_G = 0.95886314 (ave = 0.97894449)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.587349039367531, value max: 0.40579983592033386\n",
      "D grad l2-norm: 4.095322152686189, value max: 0.611552357673645\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 0.98469234 (ave = 1.00554035)\n",
      "Loss_G = 0.92252994 (ave = 0.93797425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.488485548923639, value max: 0.4229126572608948\n",
      "D grad l2-norm: 3.8825925901753338, value max: 0.5967280864715576\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.012s / 5 iters, (0.002348)\n",
      "Loss_D = 1.08876479 (ave = 1.06243187)\n",
      "Loss_G = 0.82820272 (ave = 0.87356604)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.339033661479965, value max: 0.41519027948379517\n",
      "D grad l2-norm: 3.6528048939179074, value max: 0.557826817035675\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001578)\n",
      "Loss_D = 1.14474833 (ave = 1.11636636)\n",
      "Loss_G = 0.78337920 (ave = 0.82646996)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.356889561319239, value max: 0.42245087027549744\n",
      "D grad l2-norm: 3.5640382596767948, value max: 0.5387085676193237\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 1.18498290 (ave = 1.15497091)\n",
      "Loss_G = 0.77109659 (ave = 0.78626814)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.228112800549574, value max: 0.4510956406593323\n",
      "D grad l2-norm: 3.4695496547654936, value max: 0.532970666885376\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 8\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.005s / 5 iters, (0.001100)\n",
      "Loss_D = 1.40364325 (ave = 1.40450051)\n",
      "Loss_G = 0.69580019 (ave = 0.69720532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9680752232316503, value max: 0.031297411769628525\n",
      "D grad l2-norm: 0.6929220302609785, value max: 0.5013232231140137\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.434s / 5 iters, (0.087)\tData load 0.382s / 5 iters, (0.076432)\n",
      "Loss_D = 1.39336777 (ave = 1.39339700)\n",
      "Loss_G = 0.69343346 (ave = 0.69453382)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9620337572106655, value max: 0.022362153977155685\n",
      "D grad l2-norm: 0.69271242388378, value max: 0.5001411437988281\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.539s / 5 iters, (0.108)\tData load 0.443s / 5 iters, (0.088662)\n",
      "Loss_D = 1.37592566 (ave = 1.38191791)\n",
      "Loss_G = 0.69086170 (ave = 0.69202758)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9673481545572127, value max: 0.02217712625861168\n",
      "D grad l2-norm: 0.6900721521957873, value max: 0.4988541007041931\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.373s / 5 iters, (0.075)\tData load 0.320s / 5 iters, (0.064028)\n",
      "Loss_D = 1.37480569 (ave = 1.37268345)\n",
      "Loss_G = 0.68992281 (ave = 0.69034584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.96321142646966, value max: 0.023473026230931282\n",
      "D grad l2-norm: 0.6912873463065038, value max: 0.49838292598724365\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.610s / 5 iters, (0.122)\tData load 0.513s / 5 iters, (0.102624)\n",
      "Loss_D = 1.36596107 (ave = 1.36287551)\n",
      "Loss_G = 0.68934774 (ave = 0.68954425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9596273364960554, value max: 0.025946058332920074\n",
      "D grad l2-norm: 0.6928718327556271, value max: 0.4980947971343994\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.532s / 5 iters, (0.106)\tData load 0.475s / 5 iters, (0.094949)\n",
      "Loss_D = 1.35462701 (ave = 1.35276918)\n",
      "Loss_G = 0.68823421 (ave = 0.68830013)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962367898998767, value max: 0.021358579397201538\n",
      "D grad l2-norm: 0.6943107541437871, value max: 0.49753549695014954\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.411s / 5 iters, (0.082)\tData load 0.356s / 5 iters, (0.071111)\n",
      "Loss_D = 1.33105958 (ave = 1.34171734)\n",
      "Loss_G = 0.68738651 (ave = 0.68766891)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9651832979299589, value max: 0.019683171063661575\n",
      "D grad l2-norm: 0.6981432524575829, value max: 0.49710914492607117\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.483s / 5 iters, (0.097)\tData load 0.373s / 5 iters, (0.074564)\n",
      "Loss_D = 1.34041858 (ave = 1.33482208)\n",
      "Loss_G = 0.68752742 (ave = 0.68780329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.968359872834162, value max: 0.027003740891814232\n",
      "D grad l2-norm: 0.7020167072568443, value max: 0.49717965722084045\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.486s / 5 iters, (0.097)\tData load 0.380s / 5 iters, (0.076034)\n",
      "Loss_D = 1.31882834 (ave = 1.32445350)\n",
      "Loss_G = 0.68802541 (ave = 0.68773597)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9648699394354164, value max: 0.02109886333346367\n",
      "D grad l2-norm: 0.7071851222488782, value max: 0.4974302649497986\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.554s / 5 iters, (0.111)\tData load 0.465s / 5 iters, (0.093037)\n",
      "Loss_D = 1.31487250 (ave = 1.31639802)\n",
      "Loss_G = 0.68777913 (ave = 0.68754139)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9648112552362726, value max: 0.037420980632305145\n",
      "D grad l2-norm: 0.7135529247804613, value max: 0.4973049759864807\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.738s / 5 iters, (0.148)\tData load 0.683s / 5 iters, (0.136653)\n",
      "Loss_D = 1.31218863 (ave = 1.30913155)\n",
      "Loss_G = 0.68853080 (ave = 0.68800166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9710798915060345, value max: 0.03473425656557083\n",
      "D grad l2-norm: 0.71980672480227, value max: 0.49768340587615967\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 1.28334987 (ave = 1.29827604)\n",
      "Loss_G = 0.68835449 (ave = 0.68808217)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9628500471166057, value max: 0.03828677907586098\n",
      "D grad l2-norm: 0.7266288590970038, value max: 0.49759382009506226\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001694)\n",
      "Loss_D = 1.28088844 (ave = 1.29111798)\n",
      "Loss_G = 0.68896580 (ave = 0.68892008)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9711785340771281, value max: 0.03372582048177719\n",
      "D grad l2-norm: 0.7321714593854088, value max: 0.4978998005390167\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 1.28292274 (ave = 1.28479602)\n",
      "Loss_G = 0.68914205 (ave = 0.68944571)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9710219973986823, value max: 0.03793191909790039\n",
      "D grad l2-norm: 0.740460323697004, value max: 0.4979879558086395\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001578)\n",
      "Loss_D = 1.27853131 (ave = 1.27756793)\n",
      "Loss_G = 0.69021708 (ave = 0.68973389)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9762159232192179, value max: 0.034728411585092545\n",
      "D grad l2-norm: 0.7466245825467167, value max: 0.4985279440879822\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.26780701 (ave = 1.26953740)\n",
      "Loss_G = 0.69095868 (ave = 0.69083606)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.971348750719475, value max: 0.03606974333524704\n",
      "D grad l2-norm: 0.7543075229858369, value max: 0.4988989233970642\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001589)\n",
      "Loss_D = 1.24815416 (ave = 1.26099706)\n",
      "Loss_G = 0.69260061 (ave = 0.69169502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9757484022701021, value max: 0.03962932527065277\n",
      "D grad l2-norm: 0.7629468838000794, value max: 0.4997207224369049\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001572)\n",
      "Loss_D = 1.25846481 (ave = 1.25609741)\n",
      "Loss_G = 0.69352841 (ave = 0.69266435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9796899664388832, value max: 0.036267638206481934\n",
      "D grad l2-norm: 0.7739003732385245, value max: 0.5001835823059082\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.026s / 5 iters, (0.005175)\n",
      "Loss_D = 1.24671292 (ave = 1.24832110)\n",
      "Loss_G = 0.69513059 (ave = 0.69431031)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9792110693716135, value max: 0.033628031611442566\n",
      "D grad l2-norm: 0.7808064705501168, value max: 0.5009833574295044\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.012s / 5 iters, (0.002485)\n",
      "Loss_D = 1.23120952 (ave = 1.24017944)\n",
      "Loss_G = 0.69649583 (ave = 0.69590216)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9797622641558098, value max: 0.043356750160455704\n",
      "D grad l2-norm: 0.7924520674880344, value max: 0.5016644597053528\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.837s / 5 iters, (0.167)\tData load 0.785s / 5 iters, (0.157013)\n",
      "Loss_D = 1.23728395 (ave = 1.23447495)\n",
      "Loss_G = 0.69881982 (ave = 0.69789710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9769245263368701, value max: 0.04053238779306412\n",
      "D grad l2-norm: 0.80214493330975, value max: 0.5028212070465088\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.138s / 5 iters, (0.028)\tData load 0.032s / 5 iters, (0.006437)\n",
      "Loss_D = 1.21190143 (ave = 1.22527626)\n",
      "Loss_G = 0.70106727 (ave = 0.70022053)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.976998295183417, value max: 0.04252094030380249\n",
      "D grad l2-norm: 0.8149155166381941, value max: 0.5039330124855042\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.012s / 5 iters, (0.002392)\n",
      "Loss_D = 1.20934057 (ave = 1.21837032)\n",
      "Loss_G = 0.70319694 (ave = 0.70262733)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9853047186997798, value max: 0.03950387239456177\n",
      "D grad l2-norm: 0.8270169863272502, value max: 0.5049866437911987\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 1.20978069 (ave = 1.21263840)\n",
      "Loss_G = 0.70645803 (ave = 0.70532832)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9907048149910738, value max: 0.038918256759643555\n",
      "D grad l2-norm: 0.8386180115725008, value max: 0.5065978169441223\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001750)\n",
      "Loss_D = 1.18266773 (ave = 1.20249114)\n",
      "Loss_G = 0.71055025 (ave = 0.70905548)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9869581633343054, value max: 0.03941350430250168\n",
      "D grad l2-norm: 0.8536196835232367, value max: 0.5086156129837036\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.013s / 5 iters, (0.002560)\n",
      "Loss_D = 1.17977595 (ave = 1.19612401)\n",
      "Loss_G = 0.71248472 (ave = 0.71208879)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9901914360269229, value max: 0.04959508031606674\n",
      "D grad l2-norm: 0.8672108463377561, value max: 0.5095606446266174\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 1.20609784 (ave = 1.19307027)\n",
      "Loss_G = 0.71730828 (ave = 0.71526394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9884533553757993, value max: 0.0398043617606163\n",
      "D grad l2-norm: 0.8785006821369142, value max: 0.5119193196296692\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 1.16425371 (ave = 1.18128321)\n",
      "Loss_G = 0.72076786 (ave = 0.71913514)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9910666079917063, value max: 0.04106944799423218\n",
      "D grad l2-norm: 0.8957963295935387, value max: 0.5135998725891113\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 1.16643894 (ave = 1.17505364)\n",
      "Loss_G = 0.72335553 (ave = 0.72235085)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9947019195170421, value max: 0.046882063150405884\n",
      "D grad l2-norm: 0.9087949530598721, value max: 0.5148578882217407\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 1.18225038 (ave = 1.17058163)\n",
      "Loss_G = 0.72773135 (ave = 0.72686658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9980413251815355, value max: 0.04423173516988754\n",
      "D grad l2-norm: 0.9286490388892358, value max: 0.5169740319252014\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.695s / 5 iters, (0.139)\tData load 0.636s / 5 iters, (0.127181)\n",
      "Loss_D = 1.18090677 (ave = 1.16409206)\n",
      "Loss_G = 0.73175204 (ave = 0.73007077)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0006395848973524, value max: 0.05500021576881409\n",
      "D grad l2-norm: 0.943284759728668, value max: 0.5189025402069092\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.017s / 5 iters, (0.003481)\n",
      "Loss_D = 1.16305399 (ave = 1.15558293)\n",
      "Loss_G = 0.73734546 (ave = 0.73557976)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0052444933583478, value max: 0.0486922487616539\n",
      "D grad l2-norm: 0.9608771613530049, value max: 0.521589994430542\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 1.13177514 (ave = 1.14449823)\n",
      "Loss_G = 0.74330282 (ave = 0.74062668)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9975019861991388, value max: 0.04419907554984093\n",
      "D grad l2-norm: 0.9797882582463245, value max: 0.5244346261024475\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001706)\n",
      "Loss_D = 1.11907923 (ave = 1.13394697)\n",
      "Loss_G = 0.74858755 (ave = 0.74707795)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0018906105197982, value max: 0.05186915397644043\n",
      "D grad l2-norm: 1.002918145393259, value max: 0.5269392132759094\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001704)\n",
      "Loss_D = 1.09699202 (ave = 1.12401013)\n",
      "Loss_G = 0.75664073 (ave = 0.75272714)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0082830752532406, value max: 0.04531706124544144\n",
      "D grad l2-norm: 1.0207890247100646, value max: 0.5307303071022034\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001694)\n",
      "Loss_D = 1.10184431 (ave = 1.11475394)\n",
      "Loss_G = 0.76330948 (ave = 0.76031195)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.006450797069041, value max: 0.040157511830329895\n",
      "D grad l2-norm: 1.0403959214114347, value max: 0.5338440537452698\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 1.11410487 (ave = 1.10581486)\n",
      "Loss_G = 0.77292162 (ave = 0.76862503)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.007524886446478, value max: 0.0515642985701561\n",
      "D grad l2-norm: 1.0608124879003753, value max: 0.5383064150810242\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.10107303 (ave = 1.09475553)\n",
      "Loss_G = 0.77972448 (ave = 0.77539929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0161884926743903, value max: 0.044760942459106445\n",
      "D grad l2-norm: 1.0926708478384655, value max: 0.5414353013038635\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 1.06971800 (ave = 1.08084903)\n",
      "Loss_G = 0.78879398 (ave = 0.78494545)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0176399248692884, value max: 0.05144761875271797\n",
      "D grad l2-norm: 1.115235351039603, value max: 0.5455780029296875\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.029s / 5 iters, (0.005732)\n",
      "Loss_D = 1.03947282 (ave = 1.06659620)\n",
      "Loss_G = 0.79803103 (ave = 0.79340640)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0293703552272153, value max: 0.06536859273910522\n",
      "D grad l2-norm: 1.141398549725344, value max: 0.5497515201568604\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.870s / 5 iters, (0.174)\tData load 0.818s / 5 iters, (0.163666)\n",
      "Loss_D = 1.08389473 (ave = 1.06141279)\n",
      "Loss_G = 0.80929351 (ave = 0.80458405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0361385508998961, value max: 0.08098428696393967\n",
      "D grad l2-norm: 1.160706581367135, value max: 0.5547915697097778\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 1.01129794 (ave = 1.04068274)\n",
      "Loss_G = 0.81375211 (ave = 0.81118263)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0631760154123895, value max: 0.09184159338474274\n",
      "D grad l2-norm: 1.1965090313660316, value max: 0.5567719340324402\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.04313838 (ave = 1.03505545)\n",
      "Loss_G = 0.82517672 (ave = 0.82085577)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.059664516113598, value max: 0.09071904420852661\n",
      "D grad l2-norm: 1.223021916254526, value max: 0.561799943447113\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 1.04994106 (ave = 1.02494075)\n",
      "Loss_G = 0.83329105 (ave = 0.83046526)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.082453154367396, value max: 0.10834594070911407\n",
      "D grad l2-norm: 1.2467565832871332, value max: 0.5653436779975891\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001687)\n",
      "Loss_D = 1.03127015 (ave = 1.01257887)\n",
      "Loss_G = 0.84460545 (ave = 0.83919954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.086086905641622, value max: 0.1161850094795227\n",
      "D grad l2-norm: 1.2821735264281948, value max: 0.5702309012413025\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 1.01065576 (ave = 0.99995580)\n",
      "Loss_G = 0.84999055 (ave = 0.84721663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1198674063338618, value max: 0.12915541231632233\n",
      "D grad l2-norm: 1.3122675660945011, value max: 0.5725380182266235\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.021s / 5 iters, (0.004214)\n",
      "Loss_D = 0.97218609 (ave = 0.98482906)\n",
      "Loss_G = 0.85620940 (ave = 0.85490807)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1324488485304525, value max: 0.1447337567806244\n",
      "D grad l2-norm: 1.335445126514068, value max: 0.5751705765724182\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 1.02389371 (ave = 0.98206717)\n",
      "Loss_G = 0.86400735 (ave = 0.86317097)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1408502953736717, value max: 0.1473664790391922\n",
      "D grad l2-norm: 1.3487115279648723, value max: 0.5784779191017151\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.92612970 (ave = 0.96243428)\n",
      "Loss_G = 0.87167823 (ave = 0.86917574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1562276022041875, value max: 0.13830837607383728\n",
      "D grad l2-norm: 1.3729883234967406, value max: 0.581684947013855\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 0.91447127 (ave = 0.95152601)\n",
      "Loss_G = 0.88047659 (ave = 0.87809565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.17254073523283, value max: 0.13667933642864227\n",
      "D grad l2-norm: 1.397817209502907, value max: 0.585341215133667\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.725s / 5 iters, (0.145)\tData load 0.672s / 5 iters, (0.134498)\n",
      "Loss_D = 0.98729050 (ave = 0.95272990)\n",
      "Loss_G = 0.88704121 (ave = 0.88440336)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1833352495883949, value max: 0.1443859040737152\n",
      "D grad l2-norm: 1.3996572225922452, value max: 0.5880536437034607\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 0.92241371 (ave = 0.93593874)\n",
      "Loss_G = 0.89156467 (ave = 0.88958633)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.194249041143473, value max: 0.138065367937088\n",
      "D grad l2-norm: 1.417253745796318, value max: 0.5898870825767517\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.012s / 5 iters, (0.002467)\n",
      "Loss_D = 0.90967542 (ave = 0.92709559)\n",
      "Loss_G = 0.89639950 (ave = 0.89449804)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.196194095120853, value max: 0.12763285636901855\n",
      "D grad l2-norm: 1.4090343989679845, value max: 0.5918880701065063\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 0.92213166 (ave = 0.92117451)\n",
      "Loss_G = 0.90048295 (ave = 0.89783132)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2073441708218635, value max: 0.12663224339485168\n",
      "D grad l2-norm: 1.4136565471533642, value max: 0.5935423970222473\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 0.93867826 (ave = 0.91800420)\n",
      "Loss_G = 0.90333605 (ave = 0.90157306)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2315392550661952, value max: 0.1279597282409668\n",
      "D grad l2-norm: 1.4180267900991959, value max: 0.594702959060669\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 5 iters, (0.026)\tData load 0.018s / 5 iters, (0.003665)\n",
      "Loss_D = 0.87037575 (ave = 0.90404754)\n",
      "Loss_G = 0.89937347 (ave = 0.89859372)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2523412525289732, value max: 0.1264006495475769\n",
      "D grad l2-norm: 1.4136861219299486, value max: 0.5930593609809875\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.136s / 5 iters, (0.027)\tData load 0.030s / 5 iters, (0.006000)\n",
      "Loss_D = 0.90272903 (ave = 0.90506269)\n",
      "Loss_G = 0.89673412 (ave = 0.89630584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2729881781613677, value max: 0.1301482915878296\n",
      "D grad l2-norm: 1.4108181261354793, value max: 0.5919992923736572\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.022s / 5 iters, (0.004446)\n",
      "Loss_D = 0.90249527 (ave = 0.90328007)\n",
      "Loss_G = 0.89274126 (ave = 0.89135797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2914603393212072, value max: 0.13304942846298218\n",
      "D grad l2-norm: 1.414073783146944, value max: 0.5903639197349548\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001679)\n",
      "Loss_D = 0.95801878 (ave = 0.90943756)\n",
      "Loss_G = 0.88365465 (ave = 0.88585652)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3079056399091011, value max: 0.13561402261257172\n",
      "D grad l2-norm: 1.4064075807455305, value max: 0.5865799784660339\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001533)\n",
      "Loss_D = 0.91495895 (ave = 0.90323812)\n",
      "Loss_G = 0.87661409 (ave = 0.87723848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3369772347282605, value max: 0.13484813272953033\n",
      "D grad l2-norm: 1.4084858224204841, value max: 0.5836738348007202\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.662s / 5 iters, (0.132)\tData load 0.605s / 5 iters, (0.121034)\n",
      "Loss_D = 0.89660394 (ave = 0.90154365)\n",
      "Loss_G = 0.87008679 (ave = 0.87146455)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3792906967736813, value max: 0.14571784436702728\n",
      "D grad l2-norm: 1.4087997250073956, value max: 0.5809339284896851\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.012s / 5 iters, (0.002385)\n",
      "Loss_D = 0.86288381 (ave = 0.89965190)\n",
      "Loss_G = 0.85849017 (ave = 0.86259019)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4431040613158104, value max: 0.16794759035110474\n",
      "D grad l2-norm: 1.4292297737339525, value max: 0.5759726762771606\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001552)\n",
      "Loss_D = 0.90748322 (ave = 0.91124741)\n",
      "Loss_G = 0.84376287 (ave = 0.85104002)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5156587234949805, value max: 0.18664537370204926\n",
      "D grad l2-norm: 1.452691267445242, value max: 0.5696123838424683\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001574)\n",
      "Loss_D = 0.93034899 (ave = 0.92282507)\n",
      "Loss_G = 0.82829356 (ave = 0.83487649)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.580242818987782, value max: 0.20372597873210907\n",
      "D grad l2-norm: 1.4804736366097522, value max: 0.5628758072853088\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001559)\n",
      "Loss_D = 0.89556909 (ave = 0.93126204)\n",
      "Loss_G = 0.81771809 (ave = 0.82152791)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6159085672336493, value max: 0.2261287420988083\n",
      "D grad l2-norm: 1.5216361780588061, value max: 0.5581477284431458\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.96022630 (ave = 0.94634185)\n",
      "Loss_G = 0.80435127 (ave = 0.80504860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6572677064637615, value max: 0.2425137609243393\n",
      "D grad l2-norm: 1.5778330672288143, value max: 0.5521566271781921\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 1.00767899 (ave = 0.95728277)\n",
      "Loss_G = 0.80787683 (ave = 0.80527412)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6683729437731776, value max: 0.2516827881336212\n",
      "D grad l2-norm: 1.6347442576708968, value max: 0.5536497831344604\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001556)\n",
      "Loss_D = 1.04212606 (ave = 0.96076888)\n",
      "Loss_G = 0.80303758 (ave = 0.80836413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7375197740290491, value max: 0.2673734724521637\n",
      "D grad l2-norm: 1.717772333829758, value max: 0.551445484161377\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001560)\n",
      "Loss_D = 0.90667713 (ave = 0.94359440)\n",
      "Loss_G = 0.81952709 (ave = 0.81412116)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7853363572376062, value max: 0.2815246284008026\n",
      "D grad l2-norm: 1.7671623068070657, value max: 0.5587792992591858\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.017s / 5 iters, (0.003449)\n",
      "Loss_D = 0.93152559 (ave = 0.93937383)\n",
      "Loss_G = 0.82847929 (ave = 0.82873148)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8872646521264234, value max: 0.30303430557250977\n",
      "D grad l2-norm: 1.859698869839945, value max: 0.5625718235969543\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.831s / 5 iters, (0.166)\tData load 0.726s / 5 iters, (0.145243)\n",
      "Loss_D = 0.95127130 (ave = 0.94019980)\n",
      "Loss_G = 0.84081274 (ave = 0.84122100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9816878444341977, value max: 0.313609778881073\n",
      "D grad l2-norm: 1.9546933975090446, value max: 0.5679490566253662\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004611)\n",
      "Loss_D = 0.86840928 (ave = 0.92550224)\n",
      "Loss_G = 0.85629773 (ave = 0.85055945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.07622681519652, value max: 0.3169037103652954\n",
      "D grad l2-norm: 2.03162366703811, value max: 0.5746467113494873\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 0.92594528 (ave = 0.92615390)\n",
      "Loss_G = 0.86894518 (ave = 0.85686158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.128423732549103, value max: 0.3053882420063019\n",
      "D grad l2-norm: 2.1245719684919924, value max: 0.5799868106842041\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 0.92863339 (ave = 0.92002460)\n",
      "Loss_G = 0.87820196 (ave = 0.87344662)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.235328868725816, value max: 0.307801216840744\n",
      "D grad l2-norm: 2.2281531474494005, value max: 0.5835556387901306\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001603)\n",
      "Loss_D = 0.97084761 (ave = 0.91981875)\n",
      "Loss_G = 0.89337391 (ave = 0.88694582)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.303073457133717, value max: 0.2880805432796478\n",
      "D grad l2-norm: 2.308088403452358, value max: 0.5898001790046692\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.91753167 (ave = 0.90810728)\n",
      "Loss_G = 0.90699351 (ave = 0.90159746)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4559023747566417, value max: 0.33181819319725037\n",
      "D grad l2-norm: 2.442920623786308, value max: 0.5952749252319336\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.011s / 5 iters, (0.002270)\n",
      "Loss_D = 0.92909920 (ave = 0.90125006)\n",
      "Loss_G = 0.90572876 (ave = 0.91415263)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.536744860856233, value max: 0.3489553928375244\n",
      "D grad l2-norm: 2.4600145042772374, value max: 0.59428870677948\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.017s / 5 iters, (0.003360)\n",
      "Loss_D = 0.93169725 (ave = 0.90790220)\n",
      "Loss_G = 0.91805941 (ave = 0.91161188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6308296658304124, value max: 0.3709297776222229\n",
      "D grad l2-norm: 2.5558523775753694, value max: 0.5997120141983032\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001626)\n",
      "Loss_D = 0.99507332 (ave = 0.91927816)\n",
      "Loss_G = 0.91438514 (ave = 0.90867105)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.701188468364175, value max: 0.3625221252441406\n",
      "D grad l2-norm: 2.634929419077165, value max: 0.5982507467269897\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001609)\n",
      "Loss_D = 0.94599986 (ave = 0.92397677)\n",
      "Loss_G = 0.91568232 (ave = 0.91062680)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:34:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.7576947617939793, value max: 0.35659658908843994\n",
      "D grad l2-norm: 2.7091120907306743, value max: 0.5981199741363525\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.713s / 5 iters, (0.143)\tData load 0.659s / 5 iters, (0.131896)\n",
      "Loss_D = 0.93874335 (ave = 0.92461858)\n",
      "Loss_G = 0.92763311 (ave = 0.91274219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.7703897123840147, value max: 0.35476842522621155\n",
      "D grad l2-norm: 2.7735995319636393, value max: 0.6032867431640625\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 1.00156772 (ave = 0.93635032)\n",
      "Loss_G = 0.92535543 (ave = 0.91767052)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8198792724383424, value max: 0.35063040256500244\n",
      "D grad l2-norm: 2.880128929975063, value max: 0.6020838618278503\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.024s / 5 iters, (0.004772)\n",
      "Loss_D = 0.90044892 (ave = 0.92128181)\n",
      "Loss_G = 0.93288219 (ave = 0.92438552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8547229493017396, value max: 0.34419748187065125\n",
      "D grad l2-norm: 2.9848667837178615, value max: 0.6051462292671204\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.014s / 5 iters, (0.002883)\n",
      "Loss_D = 0.83510870 (ave = 0.90335455)\n",
      "Loss_G = 0.95945144 (ave = 0.95377969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8929578479514, value max: 0.3237425982952118\n",
      "D grad l2-norm: 3.0574243992524206, value max: 0.6155858039855957\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001838)\n",
      "Loss_D = 0.86875141 (ave = 0.89868772)\n",
      "Loss_G = 0.98999941 (ave = 0.97449219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1010981577308034, value max: 0.3232196569442749\n",
      "D grad l2-norm: 3.2447325144762456, value max: 0.6270955204963684\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.87141424 (ave = 0.90403632)\n",
      "Loss_G = 0.95769066 (ave = 0.96995829)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.477049067467584, value max: 0.3098861277103424\n",
      "D grad l2-norm: 3.364045020181022, value max: 0.6139886379241943\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.91738927 (ave = 0.92794435)\n",
      "Loss_G = 0.93592334 (ave = 0.95389053)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6526438344389054, value max: 0.3275144696235657\n",
      "D grad l2-norm: 3.413592337472753, value max: 0.6059113144874573\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001709)\n",
      "Loss_D = 0.94608814 (ave = 0.95673916)\n",
      "Loss_G = 0.93084806 (ave = 0.92860397)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.692757636616677, value max: 0.31226474046707153\n",
      "D grad l2-norm: 3.4777701177872795, value max: 0.603387176990509\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 1.07263255 (ave = 0.98928531)\n",
      "Loss_G = 0.93863291 (ave = 0.93746550)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7388758484948452, value max: 0.2960480749607086\n",
      "D grad l2-norm: 3.609410518504082, value max: 0.6065131425857544\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 0.89983010 (ave = 0.96165577)\n",
      "Loss_G = 0.96757942 (ave = 0.96526474)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7018682118858233, value max: 0.2919832468032837\n",
      "D grad l2-norm: 3.720419022381164, value max: 0.6174959540367126\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.000s / 5 iters, (0.200)\tData load 0.951s / 5 iters, (0.190237)\n",
      "Loss_D = 1.03363323 (ave = 0.96829320)\n",
      "Loss_G = 1.01480639 (ave = 0.99680190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6946293079162733, value max: 0.2939381003379822\n",
      "D grad l2-norm: 3.86700361573087, value max: 0.6353961825370789\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.95192027 (ave = 0.94091464)\n",
      "Loss_G = 1.03476691 (ave = 1.02748549)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.8476506559324424, value max: 0.34157878160476685\n",
      "D grad l2-norm: 4.017992624048355, value max: 0.6430695652961731\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001585)\n",
      "Loss_D = 0.85888779 (ave = 0.93098787)\n",
      "Loss_G = 1.08363020 (ave = 1.05520027)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.945137737244251, value max: 0.3708880543708801\n",
      "D grad l2-norm: 4.171740182494544, value max: 0.6595761179924011\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.84662563 (ave = 0.91424727)\n",
      "Loss_G = 1.09909141 (ave = 1.09166834)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.101407201269624, value max: 0.3863232433795929\n",
      "D grad l2-norm: 4.395074297443385, value max: 0.6650828719139099\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 0.89963186 (ave = 0.91697184)\n",
      "Loss_G = 1.12843215 (ave = 1.12213852)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.094732222026658, value max: 0.3761715888977051\n",
      "D grad l2-norm: 4.460662460770735, value max: 0.6751917600631714\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001784)\n",
      "Loss_D = 0.93021846 (ave = 0.91261380)\n",
      "Loss_G = 1.16354644 (ave = 1.14581597)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.210084217682983, value max: 0.3793107867240906\n",
      "D grad l2-norm: 4.664052004991479, value max: 0.6859838962554932\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 0.77647197 (ave = 0.88181195)\n",
      "Loss_G = 1.19583440 (ave = 1.17723269)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.439765317617666, value max: 0.39448001980781555\n",
      "D grad l2-norm: 4.875063421297995, value max: 0.6958858370780945\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.95347786 (ave = 0.89811977)\n",
      "Loss_G = 1.19485354 (ave = 1.19067595)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.632294250378277, value max: 0.421490341424942\n",
      "D grad l2-norm: 4.958153459904663, value max: 0.6955848932266235\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 0.86393100 (ave = 0.88859608)\n",
      "Loss_G = 1.21491337 (ave = 1.20652339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.804746608524588, value max: 0.42480042576789856\n",
      "D grad l2-norm: 5.177204435661158, value max: 0.7018885612487793\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.90793991 (ave = 0.88902649)\n",
      "Loss_G = 1.23909461 (ave = 1.22100573)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.975657729192448, value max: 0.4285493493080139\n",
      "D grad l2-norm: 5.446339242039338, value max: 0.708790123462677\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.706s / 5 iters, (0.141)\tData load 0.659s / 5 iters, (0.131710)\n",
      "Loss_D = 0.83102399 (ave = 0.86869813)\n",
      "Loss_G = 1.25576615 (ave = 1.24449790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.115320289448586, value max: 0.46699607372283936\n",
      "D grad l2-norm: 5.525701821271919, value max: 0.7135657668113708\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.83279079 (ave = 0.86270951)\n",
      "Loss_G = 1.28101301 (ave = 1.26025362)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.48631829273497, value max: 0.4510868191719055\n",
      "D grad l2-norm: 5.799162588083757, value max: 0.7201094031333923\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.010s / 5 iters, (0.001974)\n",
      "Loss_D = 0.85605228 (ave = 0.86844491)\n",
      "Loss_G = 1.25547290 (ave = 1.26110287)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.705255565982729, value max: 0.4600129723548889\n",
      "D grad l2-norm: 5.835835772630061, value max: 0.7129082083702087\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001767)\n",
      "Loss_D = 0.96578610 (ave = 0.89296511)\n",
      "Loss_G = 1.22319078 (ave = 1.23665307)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.686828114115177, value max: 0.48066291213035583\n",
      "D grad l2-norm: 5.862396542008458, value max: 0.7037912011146545\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.017s / 5 iters, (0.003336)\n",
      "Loss_D = 0.74287033 (ave = 0.86252146)\n",
      "Loss_G = 1.25357342 (ave = 1.23965130)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.732606844535579, value max: 0.45145007967948914\n",
      "D grad l2-norm: 6.028038983209814, value max: 0.7123693823814392\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.017s / 5 iters, (0.003356)\n",
      "Loss_D = 0.87641037 (ave = 0.87787738)\n",
      "Loss_G = 1.25591564 (ave = 1.24955509)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.757972502239079, value max: 0.4832768142223358\n",
      "D grad l2-norm: 6.2230141160195425, value max: 0.7132397890090942\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.92888355 (ave = 0.88406080)\n",
      "Loss_G = 1.28100789 (ave = 1.27058511)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.817900716520434, value max: 0.5095266699790955\n",
      "D grad l2-norm: 6.36215628333328, value max: 0.7199274301528931\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 0.80159122 (ave = 0.86179518)\n",
      "Loss_G = 1.32986712 (ave = 1.31250963)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.819053493687487, value max: 0.5228398442268372\n",
      "D grad l2-norm: 6.5484565962401735, value max: 0.7330036759376526\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.009s / 5 iters, (0.001743)\n",
      "Loss_D = 0.85372829 (ave = 0.85498569)\n",
      "Loss_G = 1.33497930 (ave = 1.33739574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.905670111802619, value max: 0.5071691274642944\n",
      "D grad l2-norm: 6.628284300771372, value max: 0.7346107363700867\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.141s / 5 iters, (0.028)\tData load 0.015s / 5 iters, (0.003086)\n",
      "Loss_D = 0.74821758 (ave = 0.83603424)\n",
      "Loss_G = 1.37927663 (ave = 1.35434337)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.9361634392300955, value max: 0.4603934586048126\n",
      "D grad l2-norm: 6.828993971863268, value max: 0.7462121248245239\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.789s / 5 iters, (0.158)\tData load 0.734s / 5 iters, (0.146803)\n",
      "Loss_D = 0.88323098 (ave = 0.84706724)\n",
      "Loss_G = 1.39684844 (ave = 1.38883636)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.98686334102086, value max: 0.4633843004703522\n",
      "D grad l2-norm: 6.944729348074275, value max: 0.7505508661270142\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 0.89318824 (ave = 0.83886566)\n",
      "Loss_G = 1.39587641 (ave = 1.40587208)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.108150955114862, value max: 0.4465716779232025\n",
      "D grad l2-norm: 7.0339767839431415, value max: 0.7502988576889038\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.87347502 (ave = 0.83683748)\n",
      "Loss_G = 1.41883790 (ave = 1.41726530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.362608996622435, value max: 0.469490647315979\n",
      "D grad l2-norm: 7.017967450520136, value max: 0.7551218867301941\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 0.83814937 (ave = 0.84150454)\n",
      "Loss_G = 1.41520643 (ave = 1.40666728)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.85063354136274, value max: 0.49322402477264404\n",
      "D grad l2-norm: 7.190767486913032, value max: 0.7536433339118958\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001598)\n",
      "Loss_D = 0.84189367 (ave = 0.86179221)\n",
      "Loss_G = 1.36031938 (ave = 1.36212072)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.029167433815327, value max: 0.4913398325443268\n",
      "D grad l2-norm: 7.24766217211717, value max: 0.7400907278060913\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001677)\n",
      "Loss_D = 0.86984766 (ave = 0.87975239)\n",
      "Loss_G = 1.35804915 (ave = 1.36630385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.892729858076562, value max: 0.46739161014556885\n",
      "D grad l2-norm: 7.115246101806237, value max: 0.7392184734344482\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001681)\n",
      "Loss_D = 0.79654646 (ave = 0.88324010)\n",
      "Loss_G = 1.35329056 (ave = 1.33930049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.093346589067375, value max: 0.4636063575744629\n",
      "D grad l2-norm: 7.2186490049051795, value max: 0.7377042174339294\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.026s / 5 iters, (0.005112)\n",
      "Loss_D = 0.95150447 (ave = 0.91946313)\n",
      "Loss_G = 1.34111655 (ave = 1.34420340)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.2410067536059, value max: 0.47817137837409973\n",
      "D grad l2-norm: 7.2819344879204175, value max: 0.7347301244735718\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.018s / 5 iters, (0.003503)\n",
      "Loss_D = 0.93426991 (ave = 0.93502042)\n",
      "Loss_G = 1.33280063 (ave = 1.33225892)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.588194020386715, value max: 0.5171532034873962\n",
      "D grad l2-norm: 7.3879830176383585, value max: 0.7332091331481934\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 0.90629435 (ave = 0.95657318)\n",
      "Loss_G = 1.30723548 (ave = 1.30615768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.967025509696741, value max: 0.6158270835876465\n",
      "D grad l2-norm: 7.473891036406287, value max: 0.7250676155090332\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.940s / 5 iters, (0.188)\tData load 0.815s / 5 iters, (0.162940)\n",
      "Loss_D = 0.98998332 (ave = 0.99958620)\n",
      "Loss_G = 1.25185561 (ave = 1.28724024)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.93874657089517, value max: 0.6578480005264282\n",
      "D grad l2-norm: 7.3371789866278565, value max: 0.7085356116294861\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.009s / 5 iters, (0.001754)\n",
      "Loss_D = 1.02052641 (ave = 1.02877589)\n",
      "Loss_G = 1.26522660 (ave = 1.27500610)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.891106541732879, value max: 0.6987888813018799\n",
      "D grad l2-norm: 7.3238113967177885, value max: 0.7143149375915527\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.010s / 5 iters, (0.002030)\n",
      "Loss_D = 1.05080771 (ave = 1.04103434)\n",
      "Loss_G = 1.25085711 (ave = 1.24207261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.88051268485242, value max: 0.7756245136260986\n",
      "D grad l2-norm: 7.383406303174542, value max: 0.708808183670044\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001526)\n",
      "Loss_D = 0.97538692 (ave = 1.05524862)\n",
      "Loss_G = 1.28219545 (ave = 1.26102095)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.204048943070234, value max: 0.8101674318313599\n",
      "D grad l2-norm: 7.723261928830048, value max: 0.718352735042572\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.11119795 (ave = 1.07782972)\n",
      "Loss_G = 1.23206949 (ave = 1.25325100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.023763273405738, value max: 0.8075112104415894\n",
      "D grad l2-norm: 7.467066770173135, value max: 0.703703761100769\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 1.10618806 (ave = 1.10558665)\n",
      "Loss_G = 1.21672261 (ave = 1.24293938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.108372309941629, value max: 0.8470235466957092\n",
      "D grad l2-norm: 7.649934824184848, value max: 0.6990116238594055\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 1.13726687 (ave = 1.11809340)\n",
      "Loss_G = 1.27717125 (ave = 1.26328330)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.061496201015858, value max: 0.8571935892105103\n",
      "D grad l2-norm: 7.668153664250992, value max: 0.7161908745765686\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 1.21849918 (ave = 1.12329478)\n",
      "Loss_G = 1.24082685 (ave = 1.24714367)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.132001042136348, value max: 0.8524527549743652\n",
      "D grad l2-norm: 7.832581052327851, value max: 0.724777340888977\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 1.21726871 (ave = 1.12757483)\n",
      "Loss_G = 1.27173758 (ave = 1.27037265)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.106693956899939, value max: 0.7939137816429138\n",
      "D grad l2-norm: 7.928236493686128, value max: 0.7517487406730652\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 1.12025762 (ave = 1.11412921)\n",
      "Loss_G = 1.29211938 (ave = 1.27361598)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.922024966305554, value max: 0.7169910073280334\n",
      "D grad l2-norm: 7.86110413080831, value max: 0.7592694163322449\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.737s / 5 iters, (0.147)\tData load 0.662s / 5 iters, (0.132444)\n",
      "Loss_D = 0.94683945 (ave = 1.08577048)\n",
      "Loss_G = 1.34280491 (ave = 1.31430106)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.193994704083343, value max: 0.6891549825668335\n",
      "D grad l2-norm: 8.16369131014802, value max: 0.7830638885498047\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.010s / 5 iters, (0.002080)\n",
      "Loss_D = 1.04305112 (ave = 1.10164207)\n",
      "Loss_G = 1.33767533 (ave = 1.31696084)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.10620769132737, value max: 0.5935807824134827\n",
      "D grad l2-norm: 8.190300538620425, value max: 0.7833179235458374\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 1.35316181 (ave = 1.13519599)\n",
      "Loss_G = 1.36174107 (ave = 1.32352157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.072799633492638, value max: 0.5159807205200195\n",
      "D grad l2-norm: 8.276303838884935, value max: 0.7802179455757141\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 1.22412658 (ave = 1.10801632)\n",
      "Loss_G = 1.33238983 (ave = 1.32214584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.86303790044922, value max: 0.4811548888683319\n",
      "D grad l2-norm: 8.157830160857378, value max: 0.7593874335289001\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 1.08024096 (ave = 1.08589799)\n",
      "Loss_G = 1.34822917 (ave = 1.33728740)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.052622723662513, value max: 0.5190379619598389\n",
      "D grad l2-norm: 8.345283877656438, value max: 0.7638086676597595\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 1.11291385 (ave = 1.08275981)\n",
      "Loss_G = 1.36914635 (ave = 1.35877278)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.111989385141436, value max: 0.5286421179771423\n",
      "D grad l2-norm: 8.446269957902548, value max: 0.7698396444320679\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 1.01460254 (ave = 1.06058884)\n",
      "Loss_G = 1.36366236 (ave = 1.36361651)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.819603032921024, value max: 0.4974871277809143\n",
      "D grad l2-norm: 8.402494299535078, value max: 0.7660927772521973\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 1.03472865 (ave = 1.04958744)\n",
      "Loss_G = 1.38407075 (ave = 1.38708773)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.578831643020106, value max: 0.5048106908798218\n",
      "D grad l2-norm: 8.463156957156642, value max: 0.7829828858375549\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.115s / 5 iters, (0.023)\tData load 0.010s / 5 iters, (0.002094)\n",
      "Loss_D = 0.89750087 (ave = 1.00522296)\n",
      "Loss_G = 1.43860912 (ave = 1.40673223)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.289599422101927, value max: 0.4866044223308563\n",
      "D grad l2-norm: 8.563974161628428, value max: 0.8042962551116943\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 1.06608713 (ave = 0.99418297)\n",
      "Loss_G = 1.48682582 (ave = 1.45540750)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.108335856860846, value max: 0.46901974081993103\n",
      "D grad l2-norm: 8.47951198096843, value max: 0.7963184714317322\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 2.848s / 5 iters, (0.570)\tData load 2.798s / 5 iters, (0.559502)\n",
      "Loss_D = 1.02914238 (ave = 0.96250458)\n",
      "Loss_G = 1.46365237 (ave = 1.48399532)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.368671336659159, value max: 0.4591229557991028\n",
      "D grad l2-norm: 8.709142119017645, value max: 0.7965491414070129\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.70314789 (ave = 0.91381065)\n",
      "Loss_G = 1.47960341 (ave = 1.49233394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.587320513173329, value max: 0.4993939995765686\n",
      "D grad l2-norm: 8.539566341682338, value max: 0.7708160877227783\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.105s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001659)\n",
      "Loss_D = 0.86800230 (ave = 0.92848269)\n",
      "Loss_G = 1.42996442 (ave = 1.45915787)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.073677769012635, value max: 0.5380662083625793\n",
      "D grad l2-norm: 8.655642292111592, value max: 0.777725100517273\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 1.01238966 (ave = 0.95836613)\n",
      "Loss_G = 1.40955389 (ave = 1.39828584)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.041678028270047, value max: 0.543053925037384\n",
      "D grad l2-norm: 8.478302007414872, value max: 0.7618570327758789\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001675)\n",
      "Loss_D = 0.89859563 (ave = 0.94744295)\n",
      "Loss_G = 1.38265502 (ave = 1.37880888)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.893492025067143, value max: 0.5085901618003845\n",
      "D grad l2-norm: 8.380789602461967, value max: 0.7461286187171936\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.93417305 (ave = 0.94539678)\n",
      "Loss_G = 1.38954616 (ave = 1.38098078)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.000570583656371, value max: 0.4997386336326599\n",
      "D grad l2-norm: 8.584772412074722, value max: 0.7479450702667236\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 0.77355373 (ave = 0.90714214)\n",
      "Loss_G = 1.39630532 (ave = 1.39807248)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.982292261419307, value max: 0.4852740168571472\n",
      "D grad l2-norm: 8.466611013189715, value max: 0.7496953010559082\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001734)\n",
      "Loss_D = 0.96380270 (ave = 0.92356786)\n",
      "Loss_G = 1.41901195 (ave = 1.39177754)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.838870479439928, value max: 0.5108789801597595\n",
      "D grad l2-norm: 8.358212252026783, value max: 0.7546387910842896\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 0.86849773 (ave = 0.89049245)\n",
      "Loss_G = 1.40215039 (ave = 1.40818076)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.628222394661042, value max: 0.5215438604354858\n",
      "D grad l2-norm: 8.258803188338398, value max: 0.751751720905304\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.013s / 5 iters, (0.002591)\n",
      "Loss_D = 0.89764374 (ave = 0.86698778)\n",
      "Loss_G = 1.46413279 (ave = 1.43758471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.598583659548696, value max: 0.5442683100700378\n",
      "D grad l2-norm: 8.261713413214556, value max: 0.7682901620864868\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.748s / 5 iters, (0.150)\tData load 0.695s / 5 iters, (0.139094)\n",
      "Loss_D = 0.92019182 (ave = 0.84534850)\n",
      "Loss_G = 1.47669518 (ave = 1.45438545)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.587773408592318, value max: 0.5486862063407898\n",
      "D grad l2-norm: 8.281704396713605, value max: 0.7868616580963135\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 0.86577660 (ave = 0.81556935)\n",
      "Loss_G = 1.50385368 (ave = 1.48195951)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.678917607279669, value max: 0.5478295087814331\n",
      "D grad l2-norm: 8.41340781785759, value max: 0.810989499092102\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.87220627 (ave = 0.79465504)\n",
      "Loss_G = 1.52126551 (ave = 1.50577765)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.711250885072566, value max: 0.5088802576065063\n",
      "D grad l2-norm: 8.291664906182607, value max: 0.7965297698974609\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001697)\n",
      "Loss_D = 0.73520458 (ave = 0.76535672)\n",
      "Loss_G = 1.50792265 (ave = 1.50569541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.088661784587817, value max: 0.5230967998504639\n",
      "D grad l2-norm: 8.359057769636756, value max: 0.845199704170227\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 0.75675321 (ave = 0.75644903)\n",
      "Loss_G = 1.49038529 (ave = 1.50073917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.982992554740483, value max: 0.5552674531936646\n",
      "D grad l2-norm: 8.075718590752059, value max: 0.8613715171813965\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 0.74021018 (ave = 0.75087894)\n",
      "Loss_G = 1.49145150 (ave = 1.48091166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.954642160522085, value max: 0.556982159614563\n",
      "D grad l2-norm: 7.9699141204705635, value max: 0.888944149017334\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.017s / 5 iters, (0.003436)\n",
      "Loss_D = 0.80748355 (ave = 0.75989007)\n",
      "Loss_G = 1.41874540 (ave = 1.44794195)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.109400027223645, value max: 0.5896191000938416\n",
      "D grad l2-norm: 7.869113992483641, value max: 0.9100126624107361\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.142s / 5 iters, (0.028)\tData load 0.023s / 5 iters, (0.004571)\n",
      "Loss_D = 0.79532456 (ave = 0.75850710)\n",
      "Loss_G = 1.44034016 (ave = 1.43874462)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.176457703972703, value max: 0.6182062029838562\n",
      "D grad l2-norm: 7.853544484270929, value max: 0.9362343549728394\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 5 iters, (0.025)\tData load 0.017s / 5 iters, (0.003385)\n",
      "Loss_D = 0.81866670 (ave = 0.76693113)\n",
      "Loss_G = 1.41476238 (ave = 1.42490220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.85002781652712, value max: 0.6185082793235779\n",
      "D grad l2-norm: 7.7152705317340935, value max: 0.9306553602218628\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.026s / 5 iters, (0.005241)\n",
      "Loss_D = 0.75698406 (ave = 0.74245042)\n",
      "Loss_G = 1.44582200 (ave = 1.43290074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.419027998870219, value max: 0.5662156343460083\n",
      "D grad l2-norm: 7.524148640547847, value max: 0.9241631627082825\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.842s / 5 iters, (0.168)\tData load 0.740s / 5 iters, (0.147999)\n",
      "Loss_D = 0.71487951 (ave = 0.72203701)\n",
      "Loss_G = 1.49827659 (ave = 1.45709624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.410246713087189, value max: 0.6104684472084045\n",
      "D grad l2-norm: 7.782974401631189, value max: 0.9617577791213989\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001708)\n",
      "Loss_D = 0.70306945 (ave = 0.70799174)\n",
      "Loss_G = 1.45455194 (ave = 1.47382660)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.0660663523269305, value max: 0.5855684280395508\n",
      "D grad l2-norm: 7.51457201063, value max: 0.9184340834617615\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.76657009 (ave = 0.70361776)\n",
      "Loss_G = 1.50115538 (ave = 1.49745848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.0299105327668965, value max: 0.5996450185775757\n",
      "D grad l2-norm: 7.429248960313609, value max: 0.9062139391899109\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 0.73004854 (ave = 0.69437526)\n",
      "Loss_G = 1.51647174 (ave = 1.50321345)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.60877331048335, value max: 0.6166216135025024\n",
      "D grad l2-norm: 7.767954640225898, value max: 0.9329687356948853\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.65289450 (ave = 0.68620181)\n",
      "Loss_G = 1.46369016 (ave = 1.47568812)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.486334591393199, value max: 0.6159200072288513\n",
      "D grad l2-norm: 7.473071855976387, value max: 0.870987594127655\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001678)\n",
      "Loss_D = 0.68780935 (ave = 0.69835259)\n",
      "Loss_G = 1.43701208 (ave = 1.44895637)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.674420120576, value max: 0.6706494092941284\n",
      "D grad l2-norm: 7.5155585733980175, value max: 0.8404783010482788\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001603)\n",
      "Loss_D = 0.88604182 (ave = 0.73269125)\n",
      "Loss_G = 1.38128018 (ave = 1.43069220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.645294509778963, value max: 0.6664738059043884\n",
      "D grad l2-norm: 7.291901285410986, value max: 0.7657995820045471\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 0.73375952 (ave = 0.72235658)\n",
      "Loss_G = 1.38812637 (ave = 1.41080329)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.061076896694129, value max: 0.6536163687705994\n",
      "D grad l2-norm: 7.429599610724062, value max: 0.7455939650535583\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.011s / 5 iters, (0.002166)\n",
      "Loss_D = 0.75789315 (ave = 0.74047114)\n",
      "Loss_G = 1.37024856 (ave = 1.37146280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.236545041211981, value max: 0.6287086606025696\n",
      "D grad l2-norm: 7.494743111421392, value max: 0.7418993711471558\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001575)\n",
      "Loss_D = 0.83341324 (ave = 0.76524667)\n",
      "Loss_G = 1.39370692 (ave = 1.35641458)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.449481866492928, value max: 0.6398999691009521\n",
      "D grad l2-norm: 7.587722798684634, value max: 0.7615614533424377\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.798s / 5 iters, (0.160)\tData load 0.751s / 5 iters, (0.150293)\n",
      "Loss_D = 0.74253970 (ave = 0.76906214)\n",
      "Loss_G = 1.38135445 (ave = 1.37413917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.560141137482992, value max: 0.6755395531654358\n",
      "D grad l2-norm: 7.612517939710812, value max: 0.7836718559265137\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001670)\n",
      "Loss_D = 0.79518402 (ave = 0.78774475)\n",
      "Loss_G = 1.33723569 (ave = 1.35035701)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.685736794135357, value max: 0.6871699690818787\n",
      "D grad l2-norm: 7.559315437200345, value max: 0.7858833074569702\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001742)\n",
      "Loss_D = 0.76951724 (ave = 0.79828620)\n",
      "Loss_G = 1.32324111 (ave = 1.33018732)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.680926258122856, value max: 0.7304149270057678\n",
      "D grad l2-norm: 7.495057196316401, value max: 0.7857118844985962\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.018s / 5 iters, (0.003661)\n",
      "Loss_D = 0.88224852 (ave = 0.81874605)\n",
      "Loss_G = 1.33105063 (ave = 1.33543501)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.84283466133025, value max: 0.7912341356277466\n",
      "D grad l2-norm: 7.735273281615148, value max: 0.8196290135383606\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.89977396 (ave = 0.83287458)\n",
      "Loss_G = 1.26468718 (ave = 1.31111367)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.808118851374239, value max: 0.8376105427742004\n",
      "D grad l2-norm: 7.555351343888366, value max: 0.8092372417449951\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.78792787 (ave = 0.84010431)\n",
      "Loss_G = 1.29345715 (ave = 1.29477882)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.046154821235282, value max: 0.8985795378684998\n",
      "D grad l2-norm: 7.605580739548519, value max: 0.8366475105285645\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.007s / 5 iters, (0.001465)\n",
      "Loss_D = 0.86139739 (ave = 0.87511141)\n",
      "Loss_G = 1.22869563 (ave = 1.26326618)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.233422186159123, value max: 0.946837306022644\n",
      "D grad l2-norm: 7.466410162955255, value max: 0.8164198398590088\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.020s / 5 iters, (0.004057)\n",
      "Loss_D = 0.87426627 (ave = 0.89578828)\n",
      "Loss_G = 1.23926115 (ave = 1.24068792)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.64386481037843, value max: 0.9864902496337891\n",
      "D grad l2-norm: 7.581333759216338, value max: 0.8245766758918762\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001638)\n",
      "Loss_D = 0.92669141 (ave = 0.94592898)\n",
      "Loss_G = 1.16205621 (ave = 1.20169868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.376124929737388, value max: 0.9932969808578491\n",
      "D grad l2-norm: 7.222861264390248, value max: 0.7651824951171875\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.77589881 (ave = 0.95635686)\n",
      "Loss_G = 1.16763365 (ave = 1.17021244)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.556935264771646, value max: 1.0055261850357056\n",
      "D grad l2-norm: 7.218522777655234, value max: 0.7475007772445679\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.693s / 5 iters, (0.139)\tData load 0.643s / 5 iters, (0.128591)\n",
      "Loss_D = 1.07498538 (ave = 1.02356986)\n",
      "Loss_G = 1.13738370 (ave = 1.15072172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.812738390015978, value max: 1.0144667625427246\n",
      "D grad l2-norm: 7.262688282610188, value max: 0.724445641040802\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 0.99442691 (ave = 1.04226940)\n",
      "Loss_G = 1.12317562 (ave = 1.11868436)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.356573169421038, value max: 0.9633972644805908\n",
      "D grad l2-norm: 6.973512886203205, value max: 0.6678217649459839\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001566)\n",
      "Loss_D = 0.91659200 (ave = 1.05344331)\n",
      "Loss_G = 1.14850640 (ave = 1.11158929)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.61796843532935, value max: 0.9082527160644531\n",
      "D grad l2-norm: 7.3337966612867325, value max: 0.6806707978248596\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.037s / 5 iters, (0.007392)\n",
      "Loss_D = 1.08433294 (ave = 1.07526326)\n",
      "Loss_G = 1.12234664 (ave = 1.11530638)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.84383128533537, value max: 0.8034759759902954\n",
      "D grad l2-norm: 6.950384873344531, value max: 0.6689831614494324\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 1.01091075 (ave = 1.08245995)\n",
      "Loss_G = 1.16314602 (ave = 1.12363122)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.802740579597392, value max: 0.7489069104194641\n",
      "D grad l2-norm: 7.17780439260974, value max: 0.6821129322052002\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 1.00081336 (ave = 1.07439423)\n",
      "Loss_G = 1.14376390 (ave = 1.15034308)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.62171957979124, value max: 0.6763590574264526\n",
      "D grad l2-norm: 7.059301037521496, value max: 0.677008867263794\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 1.03397095 (ave = 1.08174603)\n",
      "Loss_G = 1.14388263 (ave = 1.15688515)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.606277036646345, value max: 0.6034213900566101\n",
      "D grad l2-norm: 7.055316077024465, value max: 0.6766465306282043\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.94597369 (ave = 1.07921139)\n",
      "Loss_G = 1.12901914 (ave = 1.13529425)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.822280269280864, value max: 0.6230915784835815\n",
      "D grad l2-norm: 7.245051022950963, value max: 0.6716723442077637\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 1.27909708 (ave = 1.13551893)\n",
      "Loss_G = 1.12461376 (ave = 1.12491045)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.688908485571034, value max: 0.6292586922645569\n",
      "D grad l2-norm: 7.094487465807848, value max: 0.6693769097328186\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 1.16509581 (ave = 1.13001750)\n",
      "Loss_G = 1.11762619 (ave = 1.10966101)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.332683339561989, value max: 0.6189990043640137\n",
      "D grad l2-norm: 6.963721350602089, value max: 0.6669607162475586\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.973s / 5 iters, (0.195)\tData load 0.920s / 5 iters, (0.184034)\n",
      "Loss_D = 1.07502151 (ave = 1.12787147)\n",
      "Loss_G = 1.08522093 (ave = 1.10644393)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.721052421768059, value max: 0.5929098129272461\n",
      "D grad l2-norm: 6.7243987522113695, value max: 0.6576012969017029\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 1.23225427 (ave = 1.14019876)\n",
      "Loss_G = 1.09857213 (ave = 1.11970298)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.6821165497906545, value max: 0.5885111093521118\n",
      "D grad l2-norm: 6.743410797052555, value max: 0.6624137759208679\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 1.04704690 (ave = 1.11131546)\n",
      "Loss_G = 1.11933148 (ave = 1.11969857)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.375805209242777, value max: 0.5779131054878235\n",
      "D grad l2-norm: 6.620440258128286, value max: 0.6700429916381836\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 1.47649300 (ave = 1.15798433)\n",
      "Loss_G = 1.13574278 (ave = 1.14222507)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.146816718975014, value max: 0.5352877378463745\n",
      "D grad l2-norm: 6.607513074523628, value max: 0.6747499108314514\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 1.11824346 (ave = 1.10407875)\n",
      "Loss_G = 1.13429737 (ave = 1.12751455)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.165636558223707, value max: 0.5041506290435791\n",
      "D grad l2-norm: 6.676074233566568, value max: 0.6736636757850647\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 1.17945778 (ave = 1.10073867)\n",
      "Loss_G = 1.14086795 (ave = 1.13591380)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.172149092730298, value max: 0.4829074442386627\n",
      "D grad l2-norm: 6.625677985638093, value max: 0.6769833564758301\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001594)\n",
      "Loss_D = 1.12516642 (ave = 1.09023955)\n",
      "Loss_G = 1.12559104 (ave = 1.14675305)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.103319594255714, value max: 0.5248884558677673\n",
      "D grad l2-norm: 6.512553837199714, value max: 0.6713084578514099\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001763)\n",
      "Loss_D = 1.24247336 (ave = 1.11113698)\n",
      "Loss_G = 1.14770269 (ave = 1.13648243)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.877663187966969, value max: 0.5216104388237\n",
      "D grad l2-norm: 6.373883519478913, value max: 0.678831160068512\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 1.12680006 (ave = 1.08039916)\n",
      "Loss_G = 1.16485834 (ave = 1.15553322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.878335609041608, value max: 0.5076279640197754\n",
      "D grad l2-norm: 6.442309130951617, value max: 0.6843892335891724\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 1.15575421 (ave = 1.07278230)\n",
      "Loss_G = 1.18119788 (ave = 1.16449206)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.953041855644401, value max: 0.5269525051116943\n",
      "D grad l2-norm: 6.386393563041171, value max: 0.6888163685798645\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 9\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.005s / 5 iters, (0.001089)\n",
      "Loss_D = 1.36533737 (ave = 1.37143643)\n",
      "Loss_G = 0.65796173 (ave = 0.65869712)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9647411754998508, value max: 0.025646645575761795\n",
      "D grad l2-norm: 0.635899739977554, value max: 0.48209211230278015\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.693s / 5 iters, (0.139)\tData load 0.559s / 5 iters, (0.111856)\n",
      "Loss_D = 1.35464048 (ave = 1.36056123)\n",
      "Loss_G = 0.65672195 (ave = 0.65733854)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9592392021140501, value max: 0.032687824219465256\n",
      "D grad l2-norm: 0.6367856370755932, value max: 0.4814490079879761\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.439s / 5 iters, (0.088)\tData load 0.392s / 5 iters, (0.078300)\n",
      "Loss_D = 1.34958375 (ave = 1.35049739)\n",
      "Loss_G = 0.65571809 (ave = 0.65655298)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9646219080228114, value max: 0.02305976115167141\n",
      "D grad l2-norm: 0.6388161459834529, value max: 0.48092886805534363\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.449s / 5 iters, (0.090)\tData load 0.401s / 5 iters, (0.080177)\n",
      "Loss_D = 1.31993747 (ave = 1.33738275)\n",
      "Loss_G = 0.65388548 (ave = 0.65484498)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9683317334075637, value max: 0.023851502686738968\n",
      "D grad l2-norm: 0.6401876393773948, value max: 0.479976087808609\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.474s / 5 iters, (0.095)\tData load 0.427s / 5 iters, (0.085383)\n",
      "Loss_D = 1.31183589 (ave = 1.32782118)\n",
      "Loss_G = 0.65411919 (ave = 0.65439322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9636660277899721, value max: 0.025740714743733406\n",
      "D grad l2-norm: 0.6401910293532125, value max: 0.4800969660282135\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.505s / 5 iters, (0.101)\tData load 0.395s / 5 iters, (0.079062)\n",
      "Loss_D = 1.30363297 (ave = 1.31786828)\n",
      "Loss_G = 0.65371615 (ave = 0.65372068)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9665621107123202, value max: 0.03407367318868637\n",
      "D grad l2-norm: 0.6451836574435044, value max: 0.4798881709575653\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.466s / 5 iters, (0.093)\tData load 0.399s / 5 iters, (0.079829)\n",
      "Loss_D = 1.29695487 (ave = 1.30805149)\n",
      "Loss_G = 0.65273523 (ave = 0.65351385)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9581075497714554, value max: 0.02679683454334736\n",
      "D grad l2-norm: 0.6496908815420289, value max: 0.4793764054775238\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.406s / 5 iters, (0.081)\tData load 0.351s / 5 iters, (0.070203)\n",
      "Loss_D = 1.28497553 (ave = 1.29865031)\n",
      "Loss_G = 0.65282696 (ave = 0.65332071)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9703120875290594, value max: 0.025484124198555946\n",
      "D grad l2-norm: 0.6548663228215579, value max: 0.47942450642585754\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.398s / 5 iters, (0.080)\tData load 0.334s / 5 iters, (0.066793)\n",
      "Loss_D = 1.28390527 (ave = 1.29028380)\n",
      "Loss_G = 0.65439534 (ave = 0.65395123)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9683044112372673, value max: 0.02860868349671364\n",
      "D grad l2-norm: 0.6567406808875808, value max: 0.48024091124534607\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.427s / 5 iters, (0.085)\tData load 0.366s / 5 iters, (0.073209)\n",
      "Loss_D = 1.28612232 (ave = 1.28227906)\n",
      "Loss_G = 0.65484893 (ave = 0.65415224)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9680542329650536, value max: 0.03267035260796547\n",
      "D grad l2-norm: 0.6620540911050767, value max: 0.48047494888305664\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.781s / 5 iters, (0.156)\tData load 0.728s / 5 iters, (0.145597)\n",
      "Loss_D = 1.27315068 (ave = 1.27310553)\n",
      "Loss_G = 0.65565842 (ave = 0.65508296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9662502110481404, value max: 0.034156911075115204\n",
      "D grad l2-norm: 0.6661240191440512, value max: 0.4808950424194336\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 1.27635384 (ave = 1.26565282)\n",
      "Loss_G = 0.65692651 (ave = 0.65628952)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9688749807716128, value max: 0.03247547149658203\n",
      "D grad l2-norm: 0.6735923498952661, value max: 0.4815537929534912\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.152s / 5 iters, (0.030)\tData load 0.019s / 5 iters, (0.003791)\n",
      "Loss_D = 1.26607752 (ave = 1.25699317)\n",
      "Loss_G = 0.65748024 (ave = 0.65720036)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9742516485258592, value max: 0.03718676418066025\n",
      "D grad l2-norm: 0.6845395947089364, value max: 0.4818393886089325\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.014s / 5 iters, (0.002749)\n",
      "Loss_D = 1.25341535 (ave = 1.24742374)\n",
      "Loss_G = 0.65917844 (ave = 0.65861831)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9692076606459648, value max: 0.03232503682374954\n",
      "D grad l2-norm: 0.6863812606122949, value max: 0.48271849751472473\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.137s / 5 iters, (0.027)\tData load 0.014s / 5 iters, (0.002872)\n",
      "Loss_D = 1.22961080 (ave = 1.23733041)\n",
      "Loss_G = 0.66048717 (ave = 0.66003180)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9659527133714293, value max: 0.03521038964390755\n",
      "D grad l2-norm: 0.6969021461158814, value max: 0.48339203000068665\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.009s / 5 iters, (0.001704)\n",
      "Loss_D = 1.23392105 (ave = 1.23032060)\n",
      "Loss_G = 0.66280824 (ave = 0.66216339)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9631644620359673, value max: 0.03183367848396301\n",
      "D grad l2-norm: 0.7016563343459034, value max: 0.4845891296863556\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.011s / 5 iters, (0.002127)\n",
      "Loss_D = 1.21977329 (ave = 1.22107022)\n",
      "Loss_G = 0.66626585 (ave = 0.66454335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9668372955384396, value max: 0.03706924244761467\n",
      "D grad l2-norm: 0.7075970349554367, value max: 0.4863715171813965\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.021s / 5 iters, (0.004224)\n",
      "Loss_D = 1.24412036 (ave = 1.21643403)\n",
      "Loss_G = 0.66774613 (ave = 0.66676190)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9665325399152577, value max: 0.03589298576116562\n",
      "D grad l2-norm: 0.7187627687172102, value max: 0.4871290922164917\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001711)\n",
      "Loss_D = 1.21686089 (ave = 1.20567412)\n",
      "Loss_G = 0.67070782 (ave = 0.66976715)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9697389675072299, value max: 0.037258755415678024\n",
      "D grad l2-norm: 0.7263136079928126, value max: 0.4886457324028015\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 1.17524242 (ave = 1.19306505)\n",
      "Loss_G = 0.67408788 (ave = 0.67278390)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:25 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9694589949771845, value max: 0.04227852076292038\n",
      "D grad l2-norm: 0.7349638609807554, value max: 0.49036818742752075\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.723s / 5 iters, (0.145)\tData load 0.673s / 5 iters, (0.134636)\n",
      "Loss_D = 1.17199171 (ave = 1.18536303)\n",
      "Loss_G = 0.67701733 (ave = 0.67533292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.97166535343116, value max: 0.04700487479567528\n",
      "D grad l2-norm: 0.7428507981797071, value max: 0.49186015129089355\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001653)\n",
      "Loss_D = 1.17025614 (ave = 1.17758067)\n",
      "Loss_G = 0.68032998 (ave = 0.67943555)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9717911939362869, value max: 0.04250023141503334\n",
      "D grad l2-norm: 0.7516238895113202, value max: 0.4935397207736969\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.014s / 5 iters, (0.002813)\n",
      "Loss_D = 1.19264030 (ave = 1.17302969)\n",
      "Loss_G = 0.68448436 (ave = 0.68268977)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9756915015754151, value max: 0.0423656702041626\n",
      "D grad l2-norm: 0.761117517539166, value max: 0.49563708901405334\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.12273037 (ave = 1.15680521)\n",
      "Loss_G = 0.68785155 (ave = 0.68628513)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9700922470736748, value max: 0.04371777921915054\n",
      "D grad l2-norm: 0.7696183561014106, value max: 0.497330904006958\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001563)\n",
      "Loss_D = 1.17204535 (ave = 1.15615325)\n",
      "Loss_G = 0.69187629 (ave = 0.69015954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9810316927066435, value max: 0.0459052175283432\n",
      "D grad l2-norm: 0.780952185311206, value max: 0.4993478059768677\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 1.17476392 (ave = 1.14892967)\n",
      "Loss_G = 0.69548476 (ave = 0.69383842)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9771811117338054, value max: 0.04326188936829567\n",
      "D grad l2-norm: 0.7927033478035973, value max: 0.5011555552482605\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001559)\n",
      "Loss_D = 1.09689093 (ave = 1.13229303)\n",
      "Loss_G = 0.69942254 (ave = 0.69787579)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9806506868494852, value max: 0.03693736717104912\n",
      "D grad l2-norm: 0.8038660536322902, value max: 0.5031155943870544\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 1.09665322 (ave = 1.12547948)\n",
      "Loss_G = 0.70350790 (ave = 0.70231400)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9827752089659686, value max: 0.04234204441308975\n",
      "D grad l2-norm: 0.8113651752475165, value max: 0.5051369667053223\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 1.09175634 (ave = 1.11721470)\n",
      "Loss_G = 0.70792633 (ave = 0.70695598)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9776437354126654, value max: 0.04193619638681412\n",
      "D grad l2-norm: 0.8245839435441717, value max: 0.5073150992393494\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 1.16709960 (ave = 1.11989360)\n",
      "Loss_G = 0.71290493 (ave = 0.71061021)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:26 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9868394896705958, value max: 0.04541048780083656\n",
      "D grad l2-norm: 0.8331596518321979, value max: 0.5097670555114746\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.934s / 5 iters, (0.187)\tData load 0.871s / 5 iters, (0.174162)\n",
      "Loss_D = 1.11777532 (ave = 1.10675557)\n",
      "Loss_G = 0.71690440 (ave = 0.71575205)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9883079599231575, value max: 0.05342860519886017\n",
      "D grad l2-norm: 0.8410880094006432, value max: 0.5117197036743164\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001752)\n",
      "Loss_D = 1.14095974 (ave = 1.10239744)\n",
      "Loss_G = 0.72098160 (ave = 0.71934917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9894020083892171, value max: 0.0613253153860569\n",
      "D grad l2-norm: 0.8526460318648795, value max: 0.5137051343917847\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001561)\n",
      "Loss_D = 1.15245485 (ave = 1.09828706)\n",
      "Loss_G = 0.72506452 (ave = 0.72391487)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9859182583183329, value max: 0.060988541692495346\n",
      "D grad l2-norm: 0.8562587640194974, value max: 0.5156838297843933\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001558)\n",
      "Loss_D = 1.16091990 (ave = 1.09217362)\n",
      "Loss_G = 0.72987443 (ave = 0.72828407)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9934149918570091, value max: 0.06778398901224136\n",
      "D grad l2-norm: 0.8696548190272763, value max: 0.5180097222328186\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.10719752 (ave = 1.07871575)\n",
      "Loss_G = 0.73382753 (ave = 0.73304919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0021734928722827, value max: 0.07545949518680573\n",
      "D grad l2-norm: 0.8744368465746825, value max: 0.5199073553085327\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 1.10402679 (ave = 1.07129962)\n",
      "Loss_G = 0.73823833 (ave = 0.73664387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0043449127514348, value max: 0.06623197346925735\n",
      "D grad l2-norm: 0.8861049881927563, value max: 0.5220107436180115\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 1.03492379 (ave = 1.05728850)\n",
      "Loss_G = 0.74096662 (ave = 0.73881534)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.011803310664624, value max: 0.07244004309177399\n",
      "D grad l2-norm: 0.8956721437197379, value max: 0.5233128070831299\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001777)\n",
      "Loss_D = 1.03759873 (ave = 1.05183806)\n",
      "Loss_G = 0.74357849 (ave = 0.74305770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0205351266804976, value max: 0.08520713448524475\n",
      "D grad l2-norm: 0.908833217802372, value max: 0.5245576500892639\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 1.02902281 (ave = 1.04504933)\n",
      "Loss_G = 0.74715501 (ave = 0.74604295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.029003199146451, value max: 0.08637846261262894\n",
      "D grad l2-norm: 0.9197090301343208, value max: 0.5262290239334106\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001553)\n",
      "Loss_D = 1.04979348 (ave = 1.04292927)\n",
      "Loss_G = 0.75097400 (ave = 0.74873935)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0336951689391667, value max: 0.08749565482139587\n",
      "D grad l2-norm: 0.9329066684507991, value max: 0.5280466079711914\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.736s / 5 iters, (0.147)\tData load 0.685s / 5 iters, (0.136998)\n",
      "Loss_D = 1.05941761 (ave = 1.03906590)\n",
      "Loss_G = 0.75344521 (ave = 0.75091403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0421444818174703, value max: 0.07883726060390472\n",
      "D grad l2-norm: 0.9510433919843146, value max: 0.5292113423347473\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001769)\n",
      "Loss_D = 1.06025112 (ave = 1.03474270)\n",
      "Loss_G = 0.75651693 (ave = 0.75568458)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.047437633962943, value max: 0.08372201025485992\n",
      "D grad l2-norm: 0.9620728341479658, value max: 0.530646800994873\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.013s / 5 iters, (0.002607)\n",
      "Loss_D = 1.05456328 (ave = 1.02836778)\n",
      "Loss_G = 0.76021194 (ave = 0.75796502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0542152630704196, value max: 0.08934182673692703\n",
      "D grad l2-norm: 0.9779518905361015, value max: 0.532371997833252\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.011s / 5 iters, (0.002197)\n",
      "Loss_D = 0.97245038 (ave = 1.01260978)\n",
      "Loss_G = 0.76323104 (ave = 0.76212585)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0651720331054704, value max: 0.0902353897690773\n",
      "D grad l2-norm: 1.007236870140841, value max: 0.5337750315666199\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 1.03060842 (ave = 1.01550014)\n",
      "Loss_G = 0.76848674 (ave = 0.76679806)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0664777969380432, value max: 0.08941695839166641\n",
      "D grad l2-norm: 1.0205333712523081, value max: 0.5361984968185425\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.96365678 (ave = 0.99948282)\n",
      "Loss_G = 0.77243650 (ave = 0.77129166)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.071245742403417, value max: 0.08494775742292404\n",
      "D grad l2-norm: 1.0420939719903017, value max: 0.5380375981330872\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.016s / 5 iters, (0.003133)\n",
      "Loss_D = 1.02076149 (ave = 1.00169256)\n",
      "Loss_G = 0.78182471 (ave = 0.77852676)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0798265767047603, value max: 0.08874203264713287\n",
      "D grad l2-norm: 1.0652783061371702, value max: 0.5423550605773926\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 0.94164979 (ave = 0.98616945)\n",
      "Loss_G = 0.79135704 (ave = 0.78657622)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0742564434751414, value max: 0.09382820874452591\n",
      "D grad l2-norm: 1.0844373929573734, value max: 0.5467010736465454\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001700)\n",
      "Loss_D = 0.93949968 (ave = 0.97590058)\n",
      "Loss_G = 0.79816639 (ave = 0.79518737)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0834902259514951, value max: 0.10038980841636658\n",
      "D grad l2-norm: 1.1136786108993475, value max: 0.5497581362724304\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.016s / 5 iters, (0.003207)\n",
      "Loss_D = 0.96246421 (ave = 0.97126113)\n",
      "Loss_G = 0.80835545 (ave = 0.80400894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0839790407682826, value max: 0.10512898862361908\n",
      "D grad l2-norm: 1.130058022707434, value max: 0.5542930364608765\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.772s / 5 iters, (0.154)\tData load 0.720s / 5 iters, (0.143972)\n",
      "Loss_D = 0.93789506 (ave = 0.96009341)\n",
      "Loss_G = 0.81554580 (ave = 0.81272426)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.114464876888779, value max: 0.11373603343963623\n",
      "D grad l2-norm: 1.1865187954050198, value max: 0.5575181841850281\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001747)\n",
      "Loss_D = 0.94042182 (ave = 0.95313380)\n",
      "Loss_G = 0.82674968 (ave = 0.82146630)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1211142894555477, value max: 0.12248561531305313\n",
      "D grad l2-norm: 1.2102575352921914, value max: 0.5624303817749023\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.94508994 (ave = 0.94566828)\n",
      "Loss_G = 0.83387589 (ave = 0.83142177)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1581030477712662, value max: 0.13495083153247833\n",
      "D grad l2-norm: 1.2422047827800333, value max: 0.5654948949813843\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.87026477 (ave = 0.92984450)\n",
      "Loss_G = 0.84058291 (ave = 0.83740679)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1943459982173734, value max: 0.1387924700975418\n",
      "D grad l2-norm: 1.2925786836457012, value max: 0.5683603286743164\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001587)\n",
      "Loss_D = 0.89080167 (ave = 0.92750775)\n",
      "Loss_G = 0.84544587 (ave = 0.84353840)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2419311679705773, value max: 0.14941106736660004\n",
      "D grad l2-norm: 1.3408116244694739, value max: 0.5705041289329529\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 0.89730042 (ave = 0.92551867)\n",
      "Loss_G = 0.84918398 (ave = 0.84945091)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2909812883438592, value max: 0.16321390867233276\n",
      "D grad l2-norm: 1.3860323899840725, value max: 0.5720723271369934\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001590)\n",
      "Loss_D = 0.93203378 (ave = 0.92680255)\n",
      "Loss_G = 0.85900718 (ave = 0.85462899)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3111900609531473, value max: 0.15719760954380035\n",
      "D grad l2-norm: 1.4295134108728518, value max: 0.5762360095977783\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.014s / 5 iters, (0.002834)\n",
      "Loss_D = 0.91914868 (ave = 0.92155493)\n",
      "Loss_G = 0.85791755 (ave = 0.85726774)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3677878713701337, value max: 0.15477751195430756\n",
      "D grad l2-norm: 1.4878566349964548, value max: 0.575806200504303\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.020s / 5 iters, (0.003999)\n",
      "Loss_D = 0.91225719 (ave = 0.92219539)\n",
      "Loss_G = 0.86225110 (ave = 0.86185983)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3862833792780143, value max: 0.15934744477272034\n",
      "D grad l2-norm: 1.5160722920253265, value max: 0.5775701999664307\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 0.93287861 (ave = 0.92375654)\n",
      "Loss_G = 0.86711329 (ave = 0.86488731)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4387390104827769, value max: 0.16283553838729858\n",
      "D grad l2-norm: 1.5853241176887114, value max: 0.5796444416046143\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.761s / 5 iters, (0.152)\tData load 0.692s / 5 iters, (0.138435)\n",
      "Loss_D = 0.94680405 (ave = 0.92481315)\n",
      "Loss_G = 0.86972427 (ave = 0.87093892)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4555309953470337, value max: 0.15614579617977142\n",
      "D grad l2-norm: 1.5937985917090844, value max: 0.5807166695594788\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 0.92857885 (ave = 0.92239214)\n",
      "Loss_G = 0.87426776 (ave = 0.87287465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5016687575073342, value max: 0.15511424839496613\n",
      "D grad l2-norm: 1.6286726481252303, value max: 0.5826283693313599\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.88690156 (ave = 0.91727414)\n",
      "Loss_G = 0.87410158 (ave = 0.87426522)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5318922161655621, value max: 0.16019311547279358\n",
      "D grad l2-norm: 1.6478503253651449, value max: 0.5824951529502869\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.121s / 5 iters, (0.024)\tData load 0.018s / 5 iters, (0.003595)\n",
      "Loss_D = 0.95915723 (ave = 0.93029329)\n",
      "Loss_G = 0.86963284 (ave = 0.86969783)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.568846174382783, value max: 0.17464540898799896\n",
      "D grad l2-norm: 1.6820704577985288, value max: 0.5805953741073608\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.016s / 5 iters, (0.003157)\n",
      "Loss_D = 0.94225383 (ave = 0.93058010)\n",
      "Loss_G = 0.86522824 (ave = 0.86892945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.598442520268668, value max: 0.1744423806667328\n",
      "D grad l2-norm: 1.706350341804957, value max: 0.5787246227264404\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.85667670 (ave = 0.92384545)\n",
      "Loss_G = 0.86602378 (ave = 0.86782753)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.667284008566727, value max: 0.17501050233840942\n",
      "D grad l2-norm: 1.7145943194480302, value max: 0.5789391398429871\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 0.85775650 (ave = 0.93311125)\n",
      "Loss_G = 0.84458745 (ave = 0.85330863)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.811994434649764, value max: 0.1898515671491623\n",
      "D grad l2-norm: 1.730618984268517, value max: 0.5694735050201416\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.019s / 5 iters, (0.003721)\n",
      "Loss_D = 0.92032164 (ave = 0.95938679)\n",
      "Loss_G = 0.82876122 (ave = 0.83802663)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9509866501803463, value max: 0.22913767397403717\n",
      "D grad l2-norm: 1.7560462504189795, value max: 0.5626311302185059\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001693)\n",
      "Loss_D = 1.00522256 (ave = 0.99373175)\n",
      "Loss_G = 0.79977298 (ave = 0.81025699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0773125051331216, value max: 0.24431759119033813\n",
      "D grad l2-norm: 1.7763557970216346, value max: 0.5494561791419983\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 1.16311812 (ave = 1.05580211)\n",
      "Loss_G = 0.74514830 (ave = 0.76294837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1721863641837347, value max: 0.2677566409111023\n",
      "D grad l2-norm: 1.7579827850631045, value max: 0.5234572291374207\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.685s / 5 iters, (0.137)\tData load 0.629s / 5 iters, (0.125891)\n",
      "Loss_D = 1.20248783 (ave = 1.11600924)\n",
      "Loss_G = 0.70862466 (ave = 0.72061237)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.2127354484955544, value max: 0.2711504399776459\n",
      "D grad l2-norm: 1.759311904182677, value max: 0.5060274600982666\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 1.12146413 (ave = 1.13584585)\n",
      "Loss_G = 0.67901611 (ave = 0.68948311)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.141236188495525, value max: 0.26698607206344604\n",
      "D grad l2-norm: 1.758440642429748, value max: 0.4908173978328705\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001523)\n",
      "Loss_D = 1.08024740 (ave = 1.15705965)\n",
      "Loss_G = 0.67551136 (ave = 0.67994298)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0858901813742388, value max: 0.2498677670955658\n",
      "D grad l2-norm: 1.8206131030145034, value max: 0.4894215762615204\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001756)\n",
      "Loss_D = 1.11560047 (ave = 1.15584173)\n",
      "Loss_G = 0.70804530 (ave = 0.70051528)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9863839080181118, value max: 0.24441692233085632\n",
      "D grad l2-norm: 1.8975175449749517, value max: 0.5055494904518127\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 5 iters, (0.022)\tData load 0.026s / 5 iters, (0.005222)\n",
      "Loss_D = 1.03257000 (ave = 1.12697940)\n",
      "Loss_G = 0.74823374 (ave = 0.73922616)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9773340345522104, value max: 0.23532357811927795\n",
      "D grad l2-norm: 2.030651435416163, value max: 0.5253456234931946\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 1.01678097 (ave = 1.09115975)\n",
      "Loss_G = 0.80290753 (ave = 0.78424124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9531416525152765, value max: 0.2240486741065979\n",
      "D grad l2-norm: 2.1527858309411787, value max: 0.5508298873901367\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 0.94846630 (ave = 1.04609382)\n",
      "Loss_G = 0.85566890 (ave = 0.83332349)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9712234561515645, value max: 0.20227275788784027\n",
      "D grad l2-norm: 2.2837325038503784, value max: 0.5737749934196472\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 0.89237678 (ave = 1.01130664)\n",
      "Loss_G = 0.89648074 (ave = 0.87677449)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.024815384832998, value max: 0.19184166193008423\n",
      "D grad l2-norm: 2.4321709102217057, value max: 0.591058611869812\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002249)\n",
      "Loss_D = 0.96245611 (ave = 0.98938429)\n",
      "Loss_G = 0.94359738 (ave = 0.92828063)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.092711413723493, value max: 0.19864217936992645\n",
      "D grad l2-norm: 2.5694678426884754, value max: 0.6097978353500366\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 1.06787229 (ave = 0.97780546)\n",
      "Loss_G = 1.00094759 (ave = 0.98281041)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1146075452313027, value max: 0.22221191227436066\n",
      "D grad l2-norm: 2.718638720057642, value max: 0.6319133043289185\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.930s / 5 iters, (0.186)\tData load 0.880s / 5 iters, (0.176079)\n",
      "Loss_D = 0.83760488 (ave = 0.91967375)\n",
      "Loss_G = 1.03756034 (ave = 1.02400730)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.099554588739873, value max: 0.25905776023864746\n",
      "D grad l2-norm: 2.793817617579076, value max: 0.6451539397239685\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.015s / 5 iters, (0.003090)\n",
      "Loss_D = 0.87615466 (ave = 0.89736463)\n",
      "Loss_G = 1.09648371 (ave = 1.08017225)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1831851003204634, value max: 0.26935163140296936\n",
      "D grad l2-norm: 2.9533372221652514, value max: 0.665459394454956\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001534)\n",
      "Loss_D = 0.84611952 (ave = 0.87445138)\n",
      "Loss_G = 1.13337910 (ave = 1.11815083)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.291232921391482, value max: 0.2906292676925659\n",
      "D grad l2-norm: 3.029820804514948, value max: 0.6774473190307617\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001511)\n",
      "Loss_D = 0.96908015 (ave = 0.87166462)\n",
      "Loss_G = 1.15933311 (ave = 1.15419140)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4264168497155953, value max: 0.3145250380039215\n",
      "D grad l2-norm: 3.1059817824622997, value max: 0.6857047080993652\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001537)\n",
      "Loss_D = 1.02866936 (ave = 0.86794949)\n",
      "Loss_G = 1.17557633 (ave = 1.16778822)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.5147341620872523, value max: 0.3287760615348816\n",
      "D grad l2-norm: 3.163499519676305, value max: 0.6903994679450989\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001577)\n",
      "Loss_D = 0.85323524 (ave = 0.84155769)\n",
      "Loss_G = 1.17204618 (ave = 1.17296565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.709332478079411, value max: 0.36820289492607117\n",
      "D grad l2-norm: 3.2757506108954337, value max: 0.6893537044525146\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 0.85766864 (ave = 0.84209718)\n",
      "Loss_G = 1.16549003 (ave = 1.17085474)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.750204169003049, value max: 0.39130955934524536\n",
      "D grad l2-norm: 3.2248321472168158, value max: 0.6873666644096375\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 0.99272436 (ave = 0.86059381)\n",
      "Loss_G = 1.14851439 (ave = 1.16237066)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.953807640456824, value max: 0.4219757616519928\n",
      "D grad l2-norm: 3.2500094839792872, value max: 0.6818755865097046\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.73648030 (ave = 0.83755590)\n",
      "Loss_G = 1.15077829 (ave = 1.15022416)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.099880308044728, value max: 0.45003676414489746\n",
      "D grad l2-norm: 3.2495586186331655, value max: 0.6824414134025574\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.016s / 5 iters, (0.003297)\n",
      "Loss_D = 0.86420166 (ave = 0.86823933)\n",
      "Loss_G = 1.10351872 (ave = 1.11755059)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.279872898111535, value max: 0.46280139684677124\n",
      "D grad l2-norm: 3.2582280214576533, value max: 0.6670284867286682\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.700s / 5 iters, (0.140)\tData load 0.648s / 5 iters, (0.129658)\n",
      "Loss_D = 0.89868772 (ave = 0.89561282)\n",
      "Loss_G = 1.08616412 (ave = 1.08573673)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.367924289686014, value max: 0.4572363495826721\n",
      "D grad l2-norm: 3.2732292804132057, value max: 0.66119384765625\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001711)\n",
      "Loss_D = 0.85814035 (ave = 0.90648570)\n",
      "Loss_G = 1.04716659 (ave = 1.05433307)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4699121312334222, value max: 0.4511236250400543\n",
      "D grad l2-norm: 3.255311285669493, value max: 0.6474868059158325\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001616)\n",
      "Loss_D = 0.98592937 (ave = 0.94547360)\n",
      "Loss_G = 1.02030861 (ave = 1.03169942)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4896276506750223, value max: 0.43037253618240356\n",
      "D grad l2-norm: 3.1646137410806268, value max: 0.6376248598098755\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 0.98883510 (ave = 0.97809241)\n",
      "Loss_G = 0.99360758 (ave = 0.99972154)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.588231559742574, value max: 0.4108732342720032\n",
      "D grad l2-norm: 3.155022791450133, value max: 0.6281744837760925\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 0.98005813 (ave = 0.99756359)\n",
      "Loss_G = 0.96137339 (ave = 0.97294931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.656108676324274, value max: 0.38043102622032166\n",
      "D grad l2-norm: 3.188850252004421, value max: 0.6151324510574341\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001676)\n",
      "Loss_D = 1.19125986 (ave = 1.04561255)\n",
      "Loss_G = 0.96068466 (ave = 0.95649153)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6350565410170064, value max: 0.37554341554641724\n",
      "D grad l2-norm: 3.2045237996643174, value max: 0.6155499815940857\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.116s / 5 iters, (0.023)\tData load 0.013s / 5 iters, (0.002572)\n",
      "Loss_D = 1.08747435 (ave = 1.04394522)\n",
      "Loss_G = 0.95333701 (ave = 0.94516270)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6806220791664708, value max: 0.38923439383506775\n",
      "D grad l2-norm: 3.2970834075488016, value max: 0.6124287247657776\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 1.12446618 (ave = 1.05847256)\n",
      "Loss_G = 0.95594609 (ave = 0.95289707)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.862414808552048, value max: 0.41023769974708557\n",
      "D grad l2-norm: 3.444557203027652, value max: 0.613304853439331\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.025s / 5 iters, (0.004980)\n",
      "Loss_D = 1.13733864 (ave = 1.06311843)\n",
      "Loss_G = 0.95127159 (ave = 0.95866108)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.925707734073206, value max: 0.41150200366973877\n",
      "D grad l2-norm: 3.505698270901263, value max: 0.6111829280853271\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.139s / 5 iters, (0.028)\tData load 0.025s / 5 iters, (0.005061)\n",
      "Loss_D = 1.08598936 (ave = 1.06627772)\n",
      "Loss_G = 0.97433341 (ave = 0.97745289)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.001951225357898, value max: 0.4129808247089386\n",
      "D grad l2-norm: 3.5982770712196164, value max: 0.6192173957824707\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.766s / 5 iters, (0.153)\tData load 0.714s / 5 iters, (0.142848)\n",
      "Loss_D = 1.17981589 (ave = 1.08097435)\n",
      "Loss_G = 0.97519612 (ave = 0.98694817)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.207937484914579, value max: 0.4088854491710663\n",
      "D grad l2-norm: 3.7402688940669995, value max: 0.6194382905960083\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 0.93608111 (ave = 1.07416950)\n",
      "Loss_G = 0.96200264 (ave = 0.96408470)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.200975862967713, value max: 0.3891698122024536\n",
      "D grad l2-norm: 3.787770746131366, value max: 0.6133639812469482\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 1.14116120 (ave = 1.11064641)\n",
      "Loss_G = 0.97177047 (ave = 0.96711991)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.308804029826242, value max: 0.3852754533290863\n",
      "D grad l2-norm: 4.054928874497209, value max: 0.6179673671722412\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001566)\n",
      "Loss_D = 1.06894422 (ave = 1.10094950)\n",
      "Loss_G = 0.99940026 (ave = 0.98164582)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.260032505411264, value max: 0.38625913858413696\n",
      "D grad l2-norm: 4.243434163363914, value max: 0.6282449960708618\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 1.09826684 (ave = 1.10081782)\n",
      "Loss_G = 1.04855835 (ave = 1.01858491)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.187362606116643, value max: 0.3757208585739136\n",
      "D grad l2-norm: 4.463233911919867, value max: 0.6461786031723022\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001557)\n",
      "Loss_D = 0.92988288 (ave = 1.05884311)\n",
      "Loss_G = 1.09692979 (ave = 1.07093561)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.221794478737369, value max: 0.35361039638519287\n",
      "D grad l2-norm: 4.66143401779755, value max: 0.6626018285751343\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001579)\n",
      "Loss_D = 0.93367505 (ave = 1.04488339)\n",
      "Loss_G = 1.14408278 (ave = 1.11887417)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.314336993874047, value max: 0.3378317058086395\n",
      "D grad l2-norm: 4.936861256362125, value max: 0.6791096329689026\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 1.07557154 (ave = 1.04549632)\n",
      "Loss_G = 1.17600131 (ave = 1.17496948)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.33088250274537, value max: 0.31127458810806274\n",
      "D grad l2-norm: 5.0985756043189765, value max: 0.7037262916564941\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 1.02973151 (ave = 1.02706242)\n",
      "Loss_G = 1.22160459 (ave = 1.21429837)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.352343162194854, value max: 0.2874624729156494\n",
      "D grad l2-norm: 5.304953418051662, value max: 0.7249688506126404\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.011s / 5 iters, (0.002230)\n",
      "Loss_D = 1.10237312 (ave = 1.01798121)\n",
      "Loss_G = 1.28563678 (ave = 1.26320200)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.256368500795657, value max: 0.2671054005622864\n",
      "D grad l2-norm: 5.414249828000218, value max: 0.736142635345459\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.721s / 5 iters, (0.144)\tData load 0.673s / 5 iters, (0.134619)\n",
      "Loss_D = 1.11441875 (ave = 0.99858298)\n",
      "Loss_G = 1.30568564 (ave = 1.29979029)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.262242974791861, value max: 0.27829915285110474\n",
      "D grad l2-norm: 5.5605353429448465, value max: 0.7287579774856567\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.016s / 5 iters, (0.003152)\n",
      "Loss_D = 0.83070993 (ave = 0.94874669)\n",
      "Loss_G = 1.35375452 (ave = 1.33279581)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.3833052248527435, value max: 0.3006660044193268\n",
      "D grad l2-norm: 5.880551543350268, value max: 0.7410913705825806\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.016s / 5 iters, (0.003275)\n",
      "Loss_D = 0.90268201 (ave = 0.94137020)\n",
      "Loss_G = 1.38904381 (ave = 1.38423126)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.415628290700041, value max: 0.3311433494091034\n",
      "D grad l2-norm: 5.823349787273056, value max: 0.7491305470466614\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.103s / 5 iters, (0.021)\tData load 0.027s / 5 iters, (0.005321)\n",
      "Loss_D = 1.05155444 (ave = 0.94890255)\n",
      "Loss_G = 1.39928925 (ave = 1.39227710)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.406576398352305, value max: 0.3277376592159271\n",
      "D grad l2-norm: 5.782086654550284, value max: 0.7515307068824768\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.010s / 5 iters, (0.001965)\n",
      "Loss_D = 0.97697139 (ave = 0.92854846)\n",
      "Loss_G = 1.41781092 (ave = 1.40421784)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.671026257148225, value max: 0.3478833734989166\n",
      "D grad l2-norm: 6.054421109658043, value max: 0.7559567093849182\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.85290170 (ave = 0.90552143)\n",
      "Loss_G = 1.40390873 (ave = 1.41752841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.7672763370404905, value max: 0.3684523403644562\n",
      "D grad l2-norm: 5.973520295891837, value max: 0.7529566884040833\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.104s / 5 iters, (0.021)\tData load 0.010s / 5 iters, (0.001977)\n",
      "Loss_D = 0.90597159 (ave = 0.90940726)\n",
      "Loss_G = 1.42664289 (ave = 1.41853690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.919456724772531, value max: 0.36262646317481995\n",
      "D grad l2-norm: 6.07238642546673, value max: 0.758169949054718\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 0.79110134 (ave = 0.89110111)\n",
      "Loss_G = 1.41241372 (ave = 1.41468785)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.0884671874529435, value max: 0.4002152681350708\n",
      "D grad l2-norm: 6.034995219125066, value max: 0.7547561526298523\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.009s / 5 iters, (0.001770)\n",
      "Loss_D = 0.96104902 (ave = 0.90977777)\n",
      "Loss_G = 1.39233756 (ave = 1.41266513)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.13059027845853, value max: 0.41040700674057007\n",
      "D grad l2-norm: 5.943347715240401, value max: 0.7499268651008606\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.82223606 (ave = 0.89378378)\n",
      "Loss_G = 1.37055802 (ave = 1.38273361)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.16151767813742, value max: 0.4150993824005127\n",
      "D grad l2-norm: 5.8655500690827695, value max: 0.7444080710411072\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.683s / 5 iters, (0.137)\tData load 0.636s / 5 iters, (0.127206)\n",
      "Loss_D = 0.78352654 (ave = 0.89038508)\n",
      "Loss_G = 1.41207397 (ave = 1.39062212)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.355438521117979, value max: 0.4252554178237915\n",
      "D grad l2-norm: 5.999867710996685, value max: 0.7541664838790894\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 0.96654135 (ave = 0.91390911)\n",
      "Loss_G = 1.37228715 (ave = 1.36906362)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.150480933241117, value max: 0.40758755803108215\n",
      "D grad l2-norm: 5.648383290702096, value max: 0.7442553639411926\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 1.12057352 (ave = 0.93493254)\n",
      "Loss_G = 1.31457841 (ave = 1.33258698)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.056814140901655, value max: 0.39997103810310364\n",
      "D grad l2-norm: 5.414364581307641, value max: 0.7287922501564026\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.026s / 5 iters, (0.005168)\n",
      "Loss_D = 0.81470454 (ave = 0.90882185)\n",
      "Loss_G = 1.30802345 (ave = 1.31492822)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.155532329539629, value max: 0.3978913426399231\n",
      "D grad l2-norm: 5.37855530529037, value max: 0.7274273633956909\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001628)\n",
      "Loss_D = 0.96473348 (ave = 0.93632298)\n",
      "Loss_G = 1.30242062 (ave = 1.28313694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.4401727123774295, value max: 0.3922494947910309\n",
      "D grad l2-norm: 5.501691846416037, value max: 0.7251121997833252\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.87798417 (ave = 0.93929340)\n",
      "Loss_G = 1.23936200 (ave = 1.25818717)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.4065200050765965, value max: 0.3859197199344635\n",
      "D grad l2-norm: 5.256505698369779, value max: 0.7075799107551575\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.95530617 (ave = 0.97259274)\n",
      "Loss_G = 1.18008685 (ave = 1.22416861)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.719376247873518, value max: 0.41314950585365295\n",
      "D grad l2-norm: 5.298394486343799, value max: 0.68929123878479\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 0.96629089 (ave = 1.00486897)\n",
      "Loss_G = 1.17269194 (ave = 1.16960001)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.738429900959673, value max: 0.4150160551071167\n",
      "D grad l2-norm: 5.2871629227561945, value max: 0.6859806180000305\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001667)\n",
      "Loss_D = 1.05697846 (ave = 1.03746266)\n",
      "Loss_G = 1.13642454 (ave = 1.14770327)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.321669059159836, value max: 0.38564929366111755\n",
      "D grad l2-norm: 5.066651301715151, value max: 0.6749633550643921\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001746)\n",
      "Loss_D = 1.09183753 (ave = 1.04292122)\n",
      "Loss_G = 1.13811505 (ave = 1.14950867)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.209598898528158, value max: 0.3730863630771637\n",
      "D grad l2-norm: 5.180474137810706, value max: 0.675408124923706\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.898s / 5 iters, (0.180)\tData load 0.826s / 5 iters, (0.165155)\n",
      "Loss_D = 1.08870876 (ave = 1.03094258)\n",
      "Loss_G = 1.18974328 (ave = 1.17045321)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.037866587783035, value max: 0.3986794352531433\n",
      "D grad l2-norm: 5.269879108503996, value max: 0.6927720308303833\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 0.91189623 (ave = 0.99136435)\n",
      "Loss_G = 1.23902309 (ave = 1.21369340)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.96634317881242, value max: 0.40213775634765625\n",
      "D grad l2-norm: 5.4139594091868, value max: 0.7075422406196594\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.010s / 5 iters, (0.002078)\n",
      "Loss_D = 0.89944190 (ave = 0.96991824)\n",
      "Loss_G = 1.25305796 (ave = 1.24299541)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.776081128011598, value max: 0.408362478017807\n",
      "D grad l2-norm: 5.36033901708285, value max: 0.7126929759979248\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001589)\n",
      "Loss_D = 1.01603091 (ave = 0.96582320)\n",
      "Loss_G = 1.32494414 (ave = 1.29522219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.696444484661138, value max: 0.3886306583881378\n",
      "D grad l2-norm: 5.483198739077524, value max: 0.7322967052459717\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 0.81403375 (ave = 0.91548196)\n",
      "Loss_G = 1.30729532 (ave = 1.30196514)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.682084870813153, value max: 0.3824934959411621\n",
      "D grad l2-norm: 5.567780609733733, value max: 0.7272350192070007\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 1.03486383 (ave = 0.92652574)\n",
      "Loss_G = 1.33737838 (ave = 1.33019292)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.449008408200486, value max: 0.3669408857822418\n",
      "D grad l2-norm: 5.452121996564712, value max: 0.7355708479881287\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 0.81720960 (ave = 0.87907178)\n",
      "Loss_G = 1.36906004 (ave = 1.36379347)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.489174196470678, value max: 0.3440805673599243\n",
      "D grad l2-norm: 5.521036507373975, value max: 0.7442177534103394\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 0.90200239 (ave = 0.86650027)\n",
      "Loss_G = 1.40101182 (ave = 1.39300678)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.504681948157757, value max: 0.3239298462867737\n",
      "D grad l2-norm: 5.4426404014867815, value max: 0.7519546747207642\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 0.88103074 (ave = 0.85319966)\n",
      "Loss_G = 1.39124870 (ave = 1.39074233)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.654300023676206, value max: 0.30463191866874695\n",
      "D grad l2-norm: 5.428578078875411, value max: 0.7494707703590393\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.66565406 (ave = 0.81550972)\n",
      "Loss_G = 1.36441731 (ave = 1.36569939)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.9504362161346895, value max: 0.3828223645687103\n",
      "D grad l2-norm: 5.472118774959804, value max: 0.7426788210868835\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.736s / 5 iters, (0.147)\tData load 0.684s / 5 iters, (0.136880)\n",
      "Loss_D = 0.81613922 (ave = 0.83530304)\n",
      "Loss_G = 1.32050669 (ave = 1.34257228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.3177308259677485, value max: 0.44985032081604004\n",
      "D grad l2-norm: 5.465742444662257, value max: 0.7311211228370667\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 0.88050222 (ave = 0.85478921)\n",
      "Loss_G = 1.26198554 (ave = 1.28832574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.552795110580204, value max: 0.49751394987106323\n",
      "D grad l2-norm: 5.328381749416638, value max: 0.71498703956604\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001552)\n",
      "Loss_D = 0.88859743 (ave = 0.87243941)\n",
      "Loss_G = 1.20487833 (ave = 1.23877413)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.820376548118609, value max: 0.5417488217353821\n",
      "D grad l2-norm: 5.25118796829435, value max: 0.6984527111053467\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001590)\n",
      "Loss_D = 0.88253045 (ave = 0.90069923)\n",
      "Loss_G = 1.15425503 (ave = 1.16676536)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.965091423770347, value max: 0.5533552765846252\n",
      "D grad l2-norm: 5.238543495231674, value max: 0.6819484829902649\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.012s / 5 iters, (0.002308)\n",
      "Loss_D = 0.86708033 (ave = 0.91816344)\n",
      "Loss_G = 1.11500549 (ave = 1.13084764)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.53752705966433, value max: 0.5644485354423523\n",
      "D grad l2-norm: 4.953263983783713, value max: 0.6697803139686584\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 1.01424265 (ave = 0.94719943)\n",
      "Loss_G = 1.13623273 (ave = 1.13375146)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.667471311662328, value max: 0.5837918519973755\n",
      "D grad l2-norm: 5.059930465975224, value max: 0.6765312552452087\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001869)\n",
      "Loss_D = 0.94444340 (ave = 0.93330544)\n",
      "Loss_G = 1.12647223 (ave = 1.13256969)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.730546836296544, value max: 0.6011748909950256\n",
      "D grad l2-norm: 5.050320513894712, value max: 0.6737291216850281\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.149s / 5 iters, (0.030)\tData load 0.046s / 5 iters, (0.009192)\n",
      "Loss_D = 0.92475349 (ave = 0.93349390)\n",
      "Loss_G = 1.13037825 (ave = 1.13136084)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.967513006421494, value max: 0.5970836281776428\n",
      "D grad l2-norm: 5.160097869460609, value max: 0.6743581295013428\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.017s / 5 iters, (0.003435)\n",
      "Loss_D = 0.99464399 (ave = 0.95696567)\n",
      "Loss_G = 1.10640264 (ave = 1.11345258)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.9726972436929975, value max: 0.5930535793304443\n",
      "D grad l2-norm: 5.068673340194067, value max: 0.6659955382347107\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.008s / 5 iters, (0.001616)\n",
      "Loss_D = 1.02741098 (ave = 0.97340467)\n",
      "Loss_G = 1.11101758 (ave = 1.09865363)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.648335492040829, value max: 0.5584901571273804\n",
      "D grad l2-norm: 4.941095249548235, value max: 0.6685455441474915\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.821s / 5 iters, (0.164)\tData load 0.769s / 5 iters, (0.153762)\n",
      "Loss_D = 1.02882862 (ave = 0.97271242)\n",
      "Loss_G = 1.11170983 (ave = 1.11216037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.754250708959098, value max: 0.5452772378921509\n",
      "D grad l2-norm: 5.112266473181825, value max: 0.6682698726654053\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 1.00724542 (ave = 0.96267850)\n",
      "Loss_G = 1.13676631 (ave = 1.11065474)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.52225307652562, value max: 0.5190977454185486\n",
      "D grad l2-norm: 4.966376700630237, value max: 0.6767439246177673\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.021s / 5 iters, (0.004184)\n",
      "Loss_D = 0.85695696 (ave = 0.94890983)\n",
      "Loss_G = 1.15214574 (ave = 1.13048162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.614171506102746, value max: 0.4857781231403351\n",
      "D grad l2-norm: 5.1807461257265315, value max: 0.6819819211959839\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 0.93062842 (ave = 0.94321400)\n",
      "Loss_G = 1.15918505 (ave = 1.16467168)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.527711529285545, value max: 0.46232178807258606\n",
      "D grad l2-norm: 5.173956425234971, value max: 0.6834896206855774\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 1.13481236 (ave = 0.96308519)\n",
      "Loss_G = 1.19723630 (ave = 1.18444788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.470530435902504, value max: 0.44659173488616943\n",
      "D grad l2-norm: 5.171168903044284, value max: 0.6955883502960205\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001540)\n",
      "Loss_D = 0.97359657 (ave = 0.94239329)\n",
      "Loss_G = 1.18101251 (ave = 1.19406924)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.606303827231512, value max: 0.4384704530239105\n",
      "D grad l2-norm: 5.285239694083229, value max: 0.6901466250419617\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001561)\n",
      "Loss_D = 1.02725327 (ave = 0.94698584)\n",
      "Loss_G = 1.19098294 (ave = 1.19125295)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.844721082169226, value max: 0.42210087180137634\n",
      "D grad l2-norm: 5.405455493868857, value max: 0.6932151317596436\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 0.99733710 (ave = 0.95240235)\n",
      "Loss_G = 1.16629052 (ave = 1.17324862)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.935051663651842, value max: 0.39937588572502136\n",
      "D grad l2-norm: 5.371819425688463, value max: 0.6858157515525818\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001675)\n",
      "Loss_D = 0.96959114 (ave = 0.96381975)\n",
      "Loss_G = 1.15604866 (ave = 1.15523038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.731852898632085, value max: 0.38532307744026184\n",
      "D grad l2-norm: 5.267428316221337, value max: 0.6823343634605408\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 0.86125958 (ave = 0.95533420)\n",
      "Loss_G = 1.16387975 (ave = 1.16347878)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.315373746891789, value max: 0.3603239357471466\n",
      "D grad l2-norm: 5.0176219012077725, value max: 0.6851531267166138\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.779s / 5 iters, (0.156)\tData load 0.729s / 5 iters, (0.145771)\n",
      "Loss_D = 0.96516180 (ave = 0.95734632)\n",
      "Loss_G = 1.17714334 (ave = 1.16416202)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.445494513212675, value max: 0.33103135228157043\n",
      "D grad l2-norm: 5.162044584366025, value max: 0.6902036666870117\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.017s / 5 iters, (0.003381)\n",
      "Loss_D = 0.87752163 (ave = 0.94801265)\n",
      "Loss_G = 1.15130889 (ave = 1.16456249)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.635674939080839, value max: 0.3563416600227356\n",
      "D grad l2-norm: 5.12361095897046, value max: 0.6810562014579773\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.141s / 5 iters, (0.028)\tData load 0.024s / 5 iters, (0.004839)\n",
      "Loss_D = 0.97949630 (ave = 0.97137243)\n",
      "Loss_G = 1.13336039 (ave = 1.13627226)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.9386289483773735, value max: 0.4193262755870819\n",
      "D grad l2-norm: 5.10003157897643, value max: 0.6749469041824341\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.009s / 5 iters, (0.001720)\n",
      "Loss_D = 0.93228340 (ave = 0.99847902)\n",
      "Loss_G = 1.09236526 (ave = 1.08863604)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.891919368714719, value max: 0.45155206322669983\n",
      "D grad l2-norm: 4.98105572249168, value max: 0.6606630682945251\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.133s / 5 iters, (0.027)\tData load 0.010s / 5 iters, (0.001990)\n",
      "Loss_D = 1.16835582 (ave = 1.04868364)\n",
      "Loss_G = 1.05521607 (ave = 1.07380712)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.744142001364425, value max: 0.4729810655117035\n",
      "D grad l2-norm: 4.852359139083363, value max: 0.6476737260818481\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.026s / 5 iters, (0.005196)\n",
      "Loss_D = 1.05420315 (ave = 1.04022707)\n",
      "Loss_G = 1.03353655 (ave = 1.04907317)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.718756558872325, value max: 0.47184988856315613\n",
      "D grad l2-norm: 4.871307722502567, value max: 0.6409295201301575\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001813)\n",
      "Loss_D = 1.14951813 (ave = 1.05585039)\n",
      "Loss_G = 1.03985453 (ave = 1.05021398)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.688065166345839, value max: 0.4890374541282654\n",
      "D grad l2-norm: 4.84493227651097, value max: 0.6433916091918945\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.007s / 5 iters, (0.001496)\n",
      "Loss_D = 1.00649142 (ave = 1.03905001)\n",
      "Loss_G = 1.04046845 (ave = 1.05669467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.727568290863656, value max: 0.4875733256340027\n",
      "D grad l2-norm: 4.859056217132186, value max: 0.6426605582237244\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.016s / 5 iters, (0.003261)\n",
      "Loss_D = 1.07315040 (ave = 1.04401944)\n",
      "Loss_G = 1.06494248 (ave = 1.05741572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.953652605925277, value max: 0.49036353826522827\n",
      "D grad l2-norm: 5.064732336258328, value max: 0.6507076621055603\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001592)\n",
      "Loss_D = 1.05610394 (ave = 1.04877696)\n",
      "Loss_G = 1.08436823 (ave = 1.06957695)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.101392413950892, value max: 0.5012763142585754\n",
      "D grad l2-norm: 5.147607045610132, value max: 0.6582729816436768\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.664s / 5 iters, (0.133)\tData load 0.610s / 5 iters, (0.122090)\n",
      "Loss_D = 0.87857348 (ave = 1.02415222)\n",
      "Loss_G = 1.08239830 (ave = 1.07664552)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.162546083098578, value max: 0.511012077331543\n",
      "D grad l2-norm: 5.253613983569499, value max: 0.6570658683776855\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 1.14964664 (ave = 1.04891964)\n",
      "Loss_G = 1.09089863 (ave = 1.09873734)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.246369972250893, value max: 0.5492182374000549\n",
      "D grad l2-norm: 5.392009346053697, value max: 0.659427285194397\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.95187235 (ave = 1.01978874)\n",
      "Loss_G = 1.14417768 (ave = 1.12175853)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.203757000484192, value max: 0.5655196905136108\n",
      "D grad l2-norm: 5.484321320272393, value max: 0.676735520362854\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.05092072 (ave = 1.01677508)\n",
      "Loss_G = 1.16010857 (ave = 1.15264239)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.127286929799553, value max: 0.5743990540504456\n",
      "D grad l2-norm: 5.560457887497409, value max: 0.6819847822189331\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.012s / 5 iters, (0.002346)\n",
      "Loss_D = 1.07334018 (ave = 0.99993749)\n",
      "Loss_G = 1.20968509 (ave = 1.19772263)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.1084880051269215, value max: 0.5827969312667847\n",
      "D grad l2-norm: 5.695601371092729, value max: 0.6972939372062683\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001456)\n",
      "Loss_D = 0.87902617 (ave = 0.95841599)\n",
      "Loss_G = 1.22366536 (ave = 1.22559419)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.158188741568859, value max: 0.5711824893951416\n",
      "D grad l2-norm: 5.747322558310655, value max: 0.7133071422576904\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001560)\n",
      "Loss_D = 1.07536948 (ave = 0.97014682)\n",
      "Loss_G = 1.26813042 (ave = 1.25581729)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.355741295061886, value max: 0.5641509294509888\n",
      "D grad l2-norm: 6.059764733555091, value max: 0.7625305652618408\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001637)\n",
      "Loss_D = 1.00314307 (ave = 0.94878626)\n",
      "Loss_G = 1.25348079 (ave = 1.26219647)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.446430892409693, value max: 0.5687831044197083\n",
      "D grad l2-norm: 6.110858486806078, value max: 0.7643510699272156\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001673)\n",
      "Loss_D = 0.88896495 (ave = 0.93084353)\n",
      "Loss_G = 1.28814483 (ave = 1.28688240)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.558054014633257, value max: 0.5520378947257996\n",
      "D grad l2-norm: 6.191735620252137, value max: 0.7886519432067871\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001690)\n",
      "Loss_D = 0.91311234 (ave = 0.93204184)\n",
      "Loss_G = 1.30596352 (ave = 1.28482370)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.387573909987085, value max: 0.539035439491272\n",
      "D grad l2-norm: 6.059034527321388, value max: 0.7773760557174683\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.805s / 5 iters, (0.161)\tData load 0.709s / 5 iters, (0.141866)\n",
      "Loss_D = 1.06683254 (ave = 0.95480857)\n",
      "Loss_G = 1.29536200 (ave = 1.30063436)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.5308804133567095, value max: 0.5481076240539551\n",
      "D grad l2-norm: 6.220427284593774, value max: 0.7914035320281982\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 5 iters, (0.026)\tData load 0.018s / 5 iters, (0.003556)\n",
      "Loss_D = 0.80182457 (ave = 0.92156695)\n",
      "Loss_G = 1.30254269 (ave = 1.27494621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.549102167409128, value max: 0.5672498941421509\n",
      "D grad l2-norm: 6.227719769267227, value max: 0.7847797870635986\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.109s / 5 iters, (0.022)\tData load 0.026s / 5 iters, (0.005222)\n",
      "Loss_D = 0.82419431 (ave = 0.93477238)\n",
      "Loss_G = 1.27830267 (ave = 1.27197943)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.463618560804006, value max: 0.5804193019866943\n",
      "D grad l2-norm: 6.036873387555347, value max: 0.7513561844825745\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.098s / 5 iters, (0.020)\tData load 0.011s / 5 iters, (0.002105)\n",
      "Loss_D = 1.07791054 (ave = 0.97924997)\n",
      "Loss_G = 1.23035920 (ave = 1.25175512)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.441715070926795, value max: 0.5985032916069031\n",
      "D grad l2-norm: 5.783393459003957, value max: 0.7036982178688049\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 0.95992261 (ave = 0.98845392)\n",
      "Loss_G = 1.17982030 (ave = 1.18870950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.432726685749322, value max: 0.6039825081825256\n",
      "D grad l2-norm: 5.668395649316274, value max: 0.6875195503234863\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001668)\n",
      "Loss_D = 1.11391068 (ave = 1.04058682)\n",
      "Loss_G = 1.13153541 (ave = 1.14809866)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.410215730179698, value max: 0.5775681734085083\n",
      "D grad l2-norm: 5.573115643019211, value max: 0.6733526587486267\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 1.12203848 (ave = 1.06549103)\n",
      "Loss_G = 1.10113728 (ave = 1.11236267)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.43100100201279, value max: 0.5840103030204773\n",
      "D grad l2-norm: 5.358840720493804, value max: 0.6616992354393005\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 0.96467286 (ave = 1.07718772)\n",
      "Loss_G = 1.05360270 (ave = 1.06543550)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.460457579203461, value max: 0.5600081086158752\n",
      "D grad l2-norm: 5.141712789613339, value max: 0.6450448632240295\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001570)\n",
      "Loss_D = 1.06229985 (ave = 1.13380859)\n",
      "Loss_G = 0.99683559 (ave = 1.01622181)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.310606474124762, value max: 0.5203477144241333\n",
      "D grad l2-norm: 5.007942742884861, value max: 0.6265722513198853\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002258)\n",
      "Loss_D = 1.28615105 (ave = 1.19350731)\n",
      "Loss_G = 0.95817655 (ave = 0.98254162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.916475725760073, value max: 0.4733198285102844\n",
      "D grad l2-norm: 4.860691949704757, value max: 0.6106417775154114\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.736s / 5 iters, (0.147)\tData load 0.676s / 5 iters, (0.135143)\n",
      "Loss_D = 1.15905046 (ave = 1.19252489)\n",
      "Loss_G = 1.00165939 (ave = 0.97542770)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.7767312274073115, value max: 0.4685671031475067\n",
      "D grad l2-norm: 4.938730360903171, value max: 0.6277465224266052\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 1.30541277 (ave = 1.20354331)\n",
      "Loss_G = 1.01171207 (ave = 0.99038364)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.814162631491261, value max: 0.4594924747943878\n",
      "D grad l2-norm: 5.083332653879826, value max: 0.6311584115028381\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001640)\n",
      "Loss_D = 1.14087021 (ave = 1.18308427)\n",
      "Loss_G = 0.97317117 (ave = 0.99168860)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.4576690755653114, value max: 0.43738701939582825\n",
      "D grad l2-norm: 4.8376827164965, value max: 0.6183696985244751\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 1.10588837 (ave = 1.16739600)\n",
      "Loss_G = 0.99669957 (ave = 1.00495049)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.361443941708865, value max: 0.4305264353752136\n",
      "D grad l2-norm: 4.875281026969469, value max: 0.6266165971755981\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 1.28632116 (ave = 1.18803251)\n",
      "Loss_G = 1.04271984 (ave = 1.02517655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.285475628435941, value max: 0.42383426427841187\n",
      "D grad l2-norm: 4.93714409253055, value max: 0.6433600783348083\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.98986179 (ave = 1.12935091)\n",
      "Loss_G = 1.08458102 (ave = 1.05102470)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.416239743688186, value max: 0.4633297622203827\n",
      "D grad l2-norm: 5.027503567488074, value max: 0.6579928398132324\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001627)\n",
      "Loss_D = 1.32403433 (ave = 1.16470373)\n",
      "Loss_G = 1.04241109 (ave = 1.07521348)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.37865698292994, value max: 0.5207779407501221\n",
      "D grad l2-norm: 4.842471720735738, value max: 0.6413856744766235\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001788)\n",
      "Loss_D = 1.09423447 (ave = 1.12164440)\n",
      "Loss_G = 1.06708145 (ave = 1.07300162)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.332517510339184, value max: 0.5511683821678162\n",
      "D grad l2-norm: 4.858047026023725, value max: 0.6511307954788208\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003365)\n",
      "Loss_D = 1.23034859 (ave = 1.12816677)\n",
      "Loss_G = 1.06146348 (ave = 1.07677574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.342728646460662, value max: 0.5840946435928345\n",
      "D grad l2-norm: 4.9152429682661065, value max: 0.6486070156097412\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001549)\n",
      "Loss_D = 1.05676532 (ave = 1.09936154)\n",
      "Loss_G = 1.10838842 (ave = 1.08867784)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.434004488237895, value max: 0.6155548691749573\n",
      "D grad l2-norm: 5.045967444538763, value max: 0.6645907759666443\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 10\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.006s / 5 iters, (0.001198)\n",
      "Loss_D = 1.39101040 (ave = 1.39133794)\n",
      "Loss_G = 0.71693045 (ave = 0.71805009)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.962616296319989, value max: 0.019807778298854828\n",
      "D grad l2-norm: 0.698119172529464, value max: 0.5117496252059937\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.415s / 5 iters, (0.083)\tData load 0.356s / 5 iters, (0.071152)\n",
      "Loss_D = 1.37018061 (ave = 1.37075717)\n",
      "Loss_G = 0.71342456 (ave = 0.71490952)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9659237017076191, value max: 0.019895054399967194\n",
      "D grad l2-norm: 0.6961177792701374, value max: 0.5100345611572266\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.390s / 5 iters, (0.078)\tData load 0.340s / 5 iters, (0.068093)\n",
      "Loss_D = 1.32100272 (ave = 1.34753420)\n",
      "Loss_G = 0.71079147 (ave = 0.71192743)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9626665453729581, value max: 0.019603757187724113\n",
      "D grad l2-norm: 0.6981517080357377, value max: 0.5087425708770752\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.473s / 5 iters, (0.095)\tData load 0.426s / 5 iters, (0.085112)\n",
      "Loss_D = 1.31521559 (ave = 1.33104820)\n",
      "Loss_G = 0.70821410 (ave = 0.70935535)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9651753428239118, value max: 0.019961077719926834\n",
      "D grad l2-norm: 0.6981137067842055, value max: 0.507474422454834\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.712s / 5 iters, (0.142)\tData load 0.593s / 5 iters, (0.118693)\n",
      "Loss_D = 1.30692494 (ave = 1.31453936)\n",
      "Loss_G = 0.70706022 (ave = 0.70760436)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9684543253048407, value max: 0.029348254203796387\n",
      "D grad l2-norm: 0.7010911705136572, value max: 0.506905734539032\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.410s / 5 iters, (0.082)\tData load 0.359s / 5 iters, (0.071880)\n",
      "Loss_D = 1.29650378 (ave = 1.29914081)\n",
      "Loss_G = 0.70577991 (ave = 0.70617555)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9653731181308387, value max: 0.022689983248710632\n",
      "D grad l2-norm: 0.7021559348806353, value max: 0.5062741637229919\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.405s / 5 iters, (0.081)\tData load 0.356s / 5 iters, (0.071293)\n",
      "Loss_D = 1.27351093 (ave = 1.28293548)\n",
      "Loss_G = 0.70448196 (ave = 0.70480756)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9606220448700395, value max: 0.034841712564229965\n",
      "D grad l2-norm: 0.70819551513702, value max: 0.5056313276290894\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.463s / 5 iters, (0.093)\tData load 0.409s / 5 iters, (0.081838)\n",
      "Loss_D = 1.28948307 (ave = 1.27177076)\n",
      "Loss_G = 0.70416564 (ave = 0.70421156)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9673940214503628, value max: 0.023498833179473877\n",
      "D grad l2-norm: 0.7161010878874738, value max: 0.5054749250411987\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.475s / 5 iters, (0.095)\tData load 0.362s / 5 iters, (0.072466)\n",
      "Loss_D = 1.23039818 (ave = 1.25217264)\n",
      "Loss_G = 0.70304370 (ave = 0.70335357)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9606086113167711, value max: 0.030754659324884415\n",
      "D grad l2-norm: 0.7235348604893129, value max: 0.5049176216125488\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.621s / 5 iters, (0.124)\tData load 0.540s / 5 iters, (0.107972)\n",
      "Loss_D = 1.23462141 (ave = 1.24142518)\n",
      "Loss_G = 0.70351976 (ave = 0.70312588)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9715560514840066, value max: 0.03169050067663193\n",
      "D grad l2-norm: 0.7309515212190744, value max: 0.505151093006134\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.723s / 5 iters, (0.145)\tData load 0.677s / 5 iters, (0.135384)\n",
      "Loss_D = 1.23079467 (ave = 1.22982075)\n",
      "Loss_G = 0.70377988 (ave = 0.70323923)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9722592826169364, value max: 0.035842686891555786\n",
      "D grad l2-norm: 0.739302970225957, value max: 0.505279541015625\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001636)\n",
      "Loss_D = 1.23358250 (ave = 1.21948225)\n",
      "Loss_G = 0.70286691 (ave = 0.70316658)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9740773208721247, value max: 0.03280036523938179\n",
      "D grad l2-norm: 0.7536978422996089, value max: 0.5048261880874634\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001549)\n",
      "Loss_D = 1.21932149 (ave = 1.20698185)\n",
      "Loss_G = 0.70468777 (ave = 0.70395567)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9704225969109547, value max: 0.04053163155913353\n",
      "D grad l2-norm: 0.7596599578921991, value max: 0.5057267546653748\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001536)\n",
      "Loss_D = 1.18548965 (ave = 1.19286952)\n",
      "Loss_G = 0.70708662 (ave = 0.70537273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9745347650575406, value max: 0.03729794919490814\n",
      "D grad l2-norm: 0.7690578564101546, value max: 0.5069100856781006\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001517)\n",
      "Loss_D = 1.17069077 (ave = 1.18107774)\n",
      "Loss_G = 0.70675772 (ave = 0.70635172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9809649174514962, value max: 0.04545207694172859\n",
      "D grad l2-norm: 0.7780437814075658, value max: 0.5067452192306519\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001571)\n",
      "Loss_D = 1.15884590 (ave = 1.17032692)\n",
      "Loss_G = 0.70979011 (ave = 0.70830524)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9844401826517913, value max: 0.04303843900561333\n",
      "D grad l2-norm: 0.7898224135755465, value max: 0.50823575258255\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 1.14949024 (ave = 1.15947294)\n",
      "Loss_G = 0.71062380 (ave = 0.71019194)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9882685737363487, value max: 0.03598158434033394\n",
      "D grad l2-norm: 0.8018613356388236, value max: 0.5086426734924316\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.129s / 5 iters, (0.026)\tData load 0.018s / 5 iters, (0.003676)\n",
      "Loss_D = 1.14528811 (ave = 1.15056343)\n",
      "Loss_G = 0.71248680 (ave = 0.71191766)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.988509252704632, value max: 0.04761369898915291\n",
      "D grad l2-norm: 0.8185540616391543, value max: 0.5095558166503906\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 1.11581731 (ave = 1.13725822)\n",
      "Loss_G = 0.71660137 (ave = 0.71510895)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.995120129000711, value max: 0.05293529853224754\n",
      "D grad l2-norm: 0.8268097595958752, value max: 0.5115653276443481\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 1.11592054 (ave = 1.12870960)\n",
      "Loss_G = 0.72050321 (ave = 0.71887690)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9927951787700184, value max: 0.04778989031910896\n",
      "D grad l2-norm: 0.8452141187068274, value max: 0.513472318649292\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.843s / 5 iters, (0.169)\tData load 0.777s / 5 iters, (0.155475)\n",
      "Loss_D = 1.13831949 (ave = 1.12188895)\n",
      "Loss_G = 0.72605485 (ave = 0.72306699)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9899102586474184, value max: 0.0442984476685524\n",
      "D grad l2-norm: 0.85703195492881, value max: 0.5161595940589905\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 1.09982538 (ave = 1.10868657)\n",
      "Loss_G = 0.72948778 (ave = 0.72746278)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9944459191168847, value max: 0.05224418640136719\n",
      "D grad l2-norm: 0.8734584977478009, value max: 0.517814040184021\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001643)\n",
      "Loss_D = 1.08749461 (ave = 1.09655919)\n",
      "Loss_G = 0.73468614 (ave = 0.73233252)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9884768189612769, value max: 0.05051122605800629\n",
      "D grad l2-norm: 0.8954509607765891, value max: 0.5203114748001099\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.014s / 5 iters, (0.002759)\n",
      "Loss_D = 1.08622265 (ave = 1.08637059)\n",
      "Loss_G = 0.73979646 (ave = 0.73848172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9987424198050778, value max: 0.051356472074985504\n",
      "D grad l2-norm: 0.9170127201792228, value max: 0.5227639675140381\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.049s / 5 iters, (0.010)\tData load 0.007s / 5 iters, (0.001495)\n",
      "Loss_D = 1.08107877 (ave = 1.07616448)\n",
      "Loss_G = 0.74800026 (ave = 0.74555261)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.990622827204086, value max: 0.04811055585741997\n",
      "D grad l2-norm: 0.9310858662791022, value max: 0.5266526937484741\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001453)\n",
      "Loss_D = 1.02074492 (ave = 1.05747833)\n",
      "Loss_G = 0.75732803 (ave = 0.75258694)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9914884203545564, value max: 0.05619985610246658\n",
      "D grad l2-norm: 0.943876598324869, value max: 0.5310478806495667\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001714)\n",
      "Loss_D = 1.05879283 (ave = 1.05164752)\n",
      "Loss_G = 0.76535451 (ave = 0.76170359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9931895389302817, value max: 0.052956148982048035\n",
      "D grad l2-norm: 0.9722625163469915, value max: 0.5348043441772461\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001617)\n",
      "Loss_D = 1.07795489 (ave = 1.04215941)\n",
      "Loss_G = 0.77138001 (ave = 0.76968365)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9923098735293423, value max: 0.06080595776438713\n",
      "D grad l2-norm: 0.9914784265512308, value max: 0.537592351436615\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 1.02598536 (ave = 1.02472193)\n",
      "Loss_G = 0.78131264 (ave = 0.77783229)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0027854767312059, value max: 0.06100998818874359\n",
      "D grad l2-norm: 1.0194039031442228, value max: 0.5421630144119263\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001593)\n",
      "Loss_D = 1.03818691 (ave = 1.01504741)\n",
      "Loss_G = 0.79145908 (ave = 0.78776236)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:58 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0009497318294998, value max: 0.06689448654651642\n",
      "D grad l2-norm: 1.0347561005113124, value max: 0.5467871427536011\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.658s / 5 iters, (0.132)\tData load 0.613s / 5 iters, (0.122535)\n",
      "Loss_D = 1.04316294 (ave = 1.00386240)\n",
      "Loss_G = 0.79940724 (ave = 0.79657100)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0104285064651684, value max: 0.08532892167568207\n",
      "D grad l2-norm: 1.0658353983651525, value max: 0.5503702759742737\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001532)\n",
      "Loss_D = 1.01989198 (ave = 0.98882577)\n",
      "Loss_G = 0.81263769 (ave = 0.80762607)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0074622600644156, value max: 0.08253563940525055\n",
      "D grad l2-norm: 1.0795690049923479, value max: 0.5562918782234192\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.014s / 5 iters, (0.002838)\n",
      "Loss_D = 1.01037323 (ave = 0.97596580)\n",
      "Loss_G = 0.82183272 (ave = 0.81658219)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0142733792252134, value max: 0.08099410682916641\n",
      "D grad l2-norm: 1.1117472172191392, value max: 0.560344934463501\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.026s / 5 iters, (0.005103)\n",
      "Loss_D = 0.97341335 (ave = 0.95936645)\n",
      "Loss_G = 0.83383143 (ave = 0.82827116)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0134366238958905, value max: 0.08637689799070358\n",
      "D grad l2-norm: 1.1255089781521597, value max: 0.565582275390625\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.99061358 (ave = 0.94955225)\n",
      "Loss_G = 0.83944011 (ave = 0.83720471)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0392947362306861, value max: 0.0961175188422203\n",
      "D grad l2-norm: 1.157520939006133, value max: 0.5680018663406372\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 0.96907878 (ave = 0.93634298)\n",
      "Loss_G = 0.85099387 (ave = 0.84794815)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.046891237352503, value max: 0.09764622151851654\n",
      "D grad l2-norm: 1.1783442787353444, value max: 0.5729714632034302\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001611)\n",
      "Loss_D = 0.88548982 (ave = 0.91493737)\n",
      "Loss_G = 0.86011177 (ave = 0.85643491)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0539691338688537, value max: 0.09272105991840363\n",
      "D grad l2-norm: 1.2030462941019486, value max: 0.5768415331840515\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 0.87657315 (ave = 0.90324469)\n",
      "Loss_G = 0.86919016 (ave = 0.86569446)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0628516825530767, value max: 0.10794972628355026\n",
      "D grad l2-norm: 1.2160095218861553, value max: 0.5806615352630615\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 0.91360986 (ave = 0.89749968)\n",
      "Loss_G = 0.87708795 (ave = 0.87410434)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:35:59 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0800306737942496, value max: 0.10924894362688065\n",
      "D grad l2-norm: 1.2317762265895549, value max: 0.5839696526527405\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 0.90784764 (ave = 0.88789980)\n",
      "Loss_G = 0.88337398 (ave = 0.88057581)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:00 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0901272006009979, value max: 0.11221612989902496\n",
      "D grad l2-norm: 1.2441918298503274, value max: 0.5865679979324341\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 1.030s / 5 iters, (0.206)\tData load 0.980s / 5 iters, (0.195907)\n",
      "Loss_D = 0.87672138 (ave = 0.87630036)\n",
      "Loss_G = 0.88461411 (ave = 0.88457705)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1139218037472898, value max: 0.12038464844226837\n",
      "D grad l2-norm: 1.2773135094296275, value max: 0.5870651006698608\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 0.86808980 (ave = 0.86734775)\n",
      "Loss_G = 0.89319062 (ave = 0.88939487)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1224615453466817, value max: 0.11058731377124786\n",
      "D grad l2-norm: 1.2838594335624356, value max: 0.5905864834785461\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001612)\n",
      "Loss_D = 0.81694257 (ave = 0.85366012)\n",
      "Loss_G = 0.89427263 (ave = 0.89429637)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1485250447145485, value max: 0.10233161598443985\n",
      "D grad l2-norm: 1.3159350344165899, value max: 0.5910401344299316\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 0.83775604 (ave = 0.84975311)\n",
      "Loss_G = 0.89880025 (ave = 0.89774578)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.156056861718559, value max: 0.10388532280921936\n",
      "D grad l2-norm: 1.3088190381208857, value max: 0.5928833484649658\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.012s / 5 iters, (0.002317)\n",
      "Loss_D = 0.84214509 (ave = 0.84466904)\n",
      "Loss_G = 0.90396589 (ave = 0.90176702)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.171369668132896, value max: 0.11141624301671982\n",
      "D grad l2-norm: 1.3244068130303597, value max: 0.5949716567993164\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.096s / 5 iters, (0.019)\tData load 0.011s / 5 iters, (0.002284)\n",
      "Loss_D = 0.87146318 (ave = 0.84420552)\n",
      "Loss_G = 0.89965683 (ave = 0.90168700)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2044409671277794, value max: 0.1210961639881134\n",
      "D grad l2-norm: 1.34903337942409, value max: 0.5932178497314453\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 0.83399785 (ave = 0.83426286)\n",
      "Loss_G = 0.90149814 (ave = 0.90179344)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2385418312372694, value max: 0.13507547974586487\n",
      "D grad l2-norm: 1.35653700322805, value max: 0.5939562320709229\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002303)\n",
      "Loss_D = 0.78997242 (ave = 0.82677315)\n",
      "Loss_G = 0.90061831 (ave = 0.90044075)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2528740054443979, value max: 0.1442967802286148\n",
      "D grad l2-norm: 1.3616227484728727, value max: 0.5935742855072021\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 0.83655035 (ave = 0.83062806)\n",
      "Loss_G = 0.89665663 (ave = 0.89861299)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2756143852563675, value max: 0.1516636162996292\n",
      "D grad l2-norm: 1.3777994338724353, value max: 0.5919667482376099\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001647)\n",
      "Loss_D = 0.81221426 (ave = 0.82693772)\n",
      "Loss_G = 0.89201659 (ave = 0.89698228)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:01 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3044569607850947, value max: 0.15435056388378143\n",
      "D grad l2-norm: 1.3925847677854917, value max: 0.590025782585144\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.722s / 5 iters, (0.144)\tData load 0.671s / 5 iters, (0.134108)\n",
      "Loss_D = 0.82284260 (ave = 0.82782153)\n",
      "Loss_G = 0.88837844 (ave = 0.89178554)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3190535640012906, value max: 0.1551293283700943\n",
      "D grad l2-norm: 1.3832768707590843, value max: 0.5885094404220581\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.81529582 (ave = 0.82812818)\n",
      "Loss_G = 0.88398057 (ave = 0.88726386)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3496619871315276, value max: 0.1686018705368042\n",
      "D grad l2-norm: 1.3828439110840374, value max: 0.5866968631744385\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.019s / 5 iters, (0.003826)\n",
      "Loss_D = 0.85259539 (ave = 0.83248826)\n",
      "Loss_G = 0.87494862 (ave = 0.88337790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3891691326598954, value max: 0.17538724839687347\n",
      "D grad l2-norm: 1.3889479853272824, value max: 0.5829648375511169\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 5 iters, (0.026)\tData load 0.015s / 5 iters, (0.002905)\n",
      "Loss_D = 0.82137722 (ave = 0.82999185)\n",
      "Loss_G = 0.87060612 (ave = 0.87522433)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4155555837265945, value max: 0.17314711213111877\n",
      "D grad l2-norm: 1.412529746945934, value max: 0.5810772180557251\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.016s / 5 iters, (0.003274)\n",
      "Loss_D = 0.83729184 (ave = 0.83751118)\n",
      "Loss_G = 0.85833210 (ave = 0.86451374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.459583164004406, value max: 0.1727735847234726\n",
      "D grad l2-norm: 1.420493623902436, value max: 0.575810432434082\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.84737659 (ave = 0.84415160)\n",
      "Loss_G = 0.84890246 (ave = 0.85131689)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.49105165553504, value max: 0.17994095385074615\n",
      "D grad l2-norm: 1.437306736883652, value max: 0.5717360973358154\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.132s / 5 iters, (0.026)\tData load 0.017s / 5 iters, (0.003372)\n",
      "Loss_D = 0.89835191 (ave = 0.86025131)\n",
      "Loss_G = 0.83883232 (ave = 0.84419788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:02 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5222082750885273, value max: 0.1788526028394699\n",
      "D grad l2-norm: 1.449032569889502, value max: 0.5674911141395569\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.120s / 5 iters, (0.024)\tData load 0.017s / 5 iters, (0.003303)\n",
      "Loss_D = 0.81095189 (ave = 0.85493222)\n",
      "Loss_G = 0.83354735 (ave = 0.83570499)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.529692158701189, value max: 0.17571401596069336\n",
      "D grad l2-norm: 1.4596747875745948, value max: 0.565184473991394\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.016s / 5 iters, (0.003158)\n",
      "Loss_D = 0.84027672 (ave = 0.86560451)\n",
      "Loss_G = 0.82315296 (ave = 0.82939667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5431595924515187, value max: 0.1601565033197403\n",
      "D grad l2-norm: 1.485024612032954, value max: 0.5605035424232483\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001693)\n",
      "Loss_D = 0.83766520 (ave = 0.87036241)\n",
      "Loss_G = 0.82080877 (ave = 0.81788256)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5961517747977785, value max: 0.16885803639888763\n",
      "D grad l2-norm: 1.5436163611092242, value max: 0.5595026612281799\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.727s / 5 iters, (0.145)\tData load 0.672s / 5 iters, (0.134385)\n",
      "Loss_D = 0.93605202 (ave = 0.88752465)\n",
      "Loss_G = 0.81033278 (ave = 0.81787437)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6171723662535942, value max: 0.16672490537166595\n",
      "D grad l2-norm: 1.570211346615998, value max: 0.5546571016311646\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 0.93824041 (ave = 0.88863748)\n",
      "Loss_G = 0.81042433 (ave = 0.81331140)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:03 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.646680556731955, value max: 0.1861095279455185\n",
      "D grad l2-norm: 1.6131646105247415, value max: 0.554826021194458\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001649)\n",
      "Loss_D = 0.90444875 (ave = 0.88780422)\n",
      "Loss_G = 0.81649280 (ave = 0.81467359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6739236139744518, value max: 0.19427165389060974\n",
      "D grad l2-norm: 1.6439512226564288, value max: 0.5574951767921448\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.89492393 (ave = 0.89019769)\n",
      "Loss_G = 0.81940925 (ave = 0.81746451)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.7309553682167191, value max: 0.21068519353866577\n",
      "D grad l2-norm: 1.6754906558197458, value max: 0.5586320161819458\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 0.85249037 (ave = 0.88748893)\n",
      "Loss_G = 0.82270509 (ave = 0.81844535)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8177655896514504, value max: 0.21576599776744843\n",
      "D grad l2-norm: 1.7389505441354958, value max: 0.5602037310600281\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001769)\n",
      "Loss_D = 1.03425860 (ave = 0.91621804)\n",
      "Loss_G = 0.81057149 (ave = 0.81611848)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9064146885397093, value max: 0.21392863988876343\n",
      "D grad l2-norm: 1.8055015232457226, value max: 0.5546683073043823\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.014s / 5 iters, (0.002854)\n",
      "Loss_D = 0.83306515 (ave = 0.89581668)\n",
      "Loss_G = 0.79987466 (ave = 0.80624255)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9146943549631221, value max: 0.19155047833919525\n",
      "D grad l2-norm: 1.8500092434500095, value max: 0.5498964190483093\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001682)\n",
      "Loss_D = 0.92045450 (ave = 0.90710512)\n",
      "Loss_G = 0.81588793 (ave = 0.80880450)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9239234891036028, value max: 0.18192091584205627\n",
      "D grad l2-norm: 1.9073484873486735, value max: 0.5568894743919373\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 0.80837369 (ave = 0.89530783)\n",
      "Loss_G = 0.82803553 (ave = 0.82344810)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.960334025869291, value max: 0.18187659978866577\n",
      "D grad l2-norm: 1.9790743995041644, value max: 0.5623811483383179\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 0.85603905 (ave = 0.89567213)\n",
      "Loss_G = 0.84100127 (ave = 0.83562086)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:04 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.038550183997799, value max: 0.21119755506515503\n",
      "D grad l2-norm: 2.032962649451469, value max: 0.5679701566696167\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.761s / 5 iters, (0.152)\tData load 0.684s / 5 iters, (0.136744)\n",
      "Loss_D = 0.83256739 (ave = 0.88614211)\n",
      "Loss_G = 0.85093671 (ave = 0.84500061)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.157599644431917, value max: 0.21897456049919128\n",
      "D grad l2-norm: 2.168905707345869, value max: 0.5723329782485962\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.124s / 5 iters, (0.025)\tData load 0.009s / 5 iters, (0.001774)\n",
      "Loss_D = 0.88610542 (ave = 0.88896853)\n",
      "Loss_G = 0.86211634 (ave = 0.85925266)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.203299929738777, value max: 0.2102675437927246\n",
      "D grad l2-norm: 2.2595361689697113, value max: 0.5769059658050537\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003328)\n",
      "Loss_D = 0.88814211 (ave = 0.88240411)\n",
      "Loss_G = 0.87706387 (ave = 0.87511548)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3563782592721045, value max: 0.23273634910583496\n",
      "D grad l2-norm: 2.4061538569950036, value max: 0.5831073522567749\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002259)\n",
      "Loss_D = 0.84719932 (ave = 0.87489041)\n",
      "Loss_G = 0.89586967 (ave = 0.88757594)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4971853824962817, value max: 0.2612575888633728\n",
      "D grad l2-norm: 2.514217703556276, value max: 0.5907742381095886\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001715)\n",
      "Loss_D = 0.96142519 (ave = 0.89153339)\n",
      "Loss_G = 0.90011382 (ave = 0.89794067)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.5960593859793275, value max: 0.267326682806015\n",
      "D grad l2-norm: 2.6486945289830843, value max: 0.5926953554153442\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.016s / 5 iters, (0.003241)\n",
      "Loss_D = 0.98250329 (ave = 0.88971889)\n",
      "Loss_G = 0.92947894 (ave = 0.91712790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.5496778070099637, value max: 0.2718939781188965\n",
      "D grad l2-norm: 2.7586269141377993, value max: 0.6043815612792969\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 0.90212464 (ave = 0.86438884)\n",
      "Loss_G = 0.96262944 (ave = 0.94554764)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6069665104206887, value max: 0.265080988407135\n",
      "D grad l2-norm: 2.94513999125175, value max: 0.6171317100524902\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 0.84964848 (ave = 0.84393147)\n",
      "Loss_G = 0.99146187 (ave = 0.98969715)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8036610600215455, value max: 0.2811583876609802\n",
      "D grad l2-norm: 3.188378677765055, value max: 0.6279095411300659\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001658)\n",
      "Loss_D = 0.85543406 (ave = 0.82738582)\n",
      "Loss_G = 1.06302524 (ave = 1.03469970)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8391167895680707, value max: 0.3108832836151123\n",
      "D grad l2-norm: 3.3348149488691967, value max: 0.6535302996635437\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001587)\n",
      "Loss_D = 0.82501626 (ave = 0.80957515)\n",
      "Loss_G = 1.08599544 (ave = 1.06220703)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:05 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.03385023323519, value max: 0.3443243205547333\n",
      "D grad l2-norm: 3.509880432672291, value max: 0.660925567150116\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.651s / 5 iters, (0.130)\tData load 0.602s / 5 iters, (0.120400)\n",
      "Loss_D = 0.75553215 (ave = 0.79860830)\n",
      "Loss_G = 1.09865713 (ave = 1.09161055)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.215203105784941, value max: 0.36391890048980713\n",
      "D grad l2-norm: 3.764434591935774, value max: 0.6654911637306213\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.009s / 5 iters, (0.001706)\n",
      "Loss_D = 0.66008687 (ave = 0.77345157)\n",
      "Loss_G = 1.13856649 (ave = 1.11519957)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2228877565166734, value max: 0.36656442284584045\n",
      "D grad l2-norm: 3.9579649256880294, value max: 0.678519606590271\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.107s / 5 iters, (0.021)\tData load 0.009s / 5 iters, (0.001788)\n",
      "Loss_D = 0.62898779 (ave = 0.75900193)\n",
      "Loss_G = 1.19854653 (ave = 1.16711609)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.3422312737701234, value max: 0.3820502460002899\n",
      "D grad l2-norm: 4.127600866412234, value max: 0.6971576809883118\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001623)\n",
      "Loss_D = 0.78063494 (ave = 0.76576900)\n",
      "Loss_G = 1.21712899 (ave = 1.20423467)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.537328252176979, value max: 0.3833167254924774\n",
      "D grad l2-norm: 4.395682817041293, value max: 0.7022226452827454\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.80207884 (ave = 0.75685903)\n",
      "Loss_G = 1.24483728 (ave = 1.23519220)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.566786922500819, value max: 0.38931989669799805\n",
      "D grad l2-norm: 4.4337569953561, value max: 0.7108076214790344\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 0.65109116 (ave = 0.73631057)\n",
      "Loss_G = 1.25191164 (ave = 1.24857912)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:06 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.83980499087996, value max: 0.3731343448162079\n",
      "D grad l2-norm: 4.688656061486255, value max: 0.7125160098075867\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001587)\n",
      "Loss_D = 0.72571152 (ave = 0.74398781)\n",
      "Loss_G = 1.26778471 (ave = 1.25790768)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.8944051197788534, value max: 0.36628711223602295\n",
      "D grad l2-norm: 4.67514931548411, value max: 0.7169979214668274\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001652)\n",
      "Loss_D = 0.69911683 (ave = 0.74241349)\n",
      "Loss_G = 1.25947547 (ave = 1.26421518)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.029330777743275, value max: 0.3488723039627075\n",
      "D grad l2-norm: 4.824949816695475, value max: 0.7146411538124084\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.70397699 (ave = 0.74102131)\n",
      "Loss_G = 1.28721833 (ave = 1.27928817)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.191768329859889, value max: 0.36219170689582825\n",
      "D grad l2-norm: 5.0198473539570365, value max: 0.7220547795295715\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001522)\n",
      "Loss_D = 0.63614529 (ave = 0.73422701)\n",
      "Loss_G = 1.28873253 (ave = 1.28377395)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:07 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.332546182759499, value max: 0.3636196255683899\n",
      "D grad l2-norm: 5.130405503887799, value max: 0.7226304411888123\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.918s / 5 iters, (0.184)\tData load 0.848s / 5 iters, (0.169539)\n",
      "Loss_D = 0.97603637 (ave = 0.78281285)\n",
      "Loss_G = 1.30171251 (ave = 1.28159728)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.570080950512134, value max: 0.3967307209968567\n",
      "D grad l2-norm: 5.269444147672979, value max: 0.7259136438369751\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.79947871 (ave = 0.77106370)\n",
      "Loss_G = 1.29085553 (ave = 1.28659465)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.509282719733879, value max: 0.41945362091064453\n",
      "D grad l2-norm: 5.227616721493511, value max: 0.7230845093727112\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.71573442 (ave = 0.75741829)\n",
      "Loss_G = 1.30700374 (ave = 1.29378574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.591642054946189, value max: 0.4622710347175598\n",
      "D grad l2-norm: 5.426077748322911, value max: 0.7278552651405334\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001609)\n",
      "Loss_D = 0.78566062 (ave = 0.76204170)\n",
      "Loss_G = 1.34937334 (ave = 1.32859874)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.734607881814832, value max: 0.48242613673210144\n",
      "D grad l2-norm: 5.617143423727038, value max: 0.7392600178718567\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001639)\n",
      "Loss_D = 0.67318088 (ave = 0.74084246)\n",
      "Loss_G = 1.36923754 (ave = 1.35611324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.856601095041232, value max: 0.5296697020530701\n",
      "D grad l2-norm: 5.719309956757997, value max: 0.7445587515830994\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 0.79460382 (ave = 0.74974689)\n",
      "Loss_G = 1.36665332 (ave = 1.37349968)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.067600913304056, value max: 0.5617652535438538\n",
      "D grad l2-norm: 5.90477951647283, value max: 0.7430098652839661\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001574)\n",
      "Loss_D = 0.71733284 (ave = 0.73765255)\n",
      "Loss_G = 1.38848662 (ave = 1.38695793)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.3340970157127146, value max: 0.6009647846221924\n",
      "D grad l2-norm: 6.044159132440718, value max: 0.7488301396369934\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.79201806 (ave = 0.75319929)\n",
      "Loss_G = 1.35677195 (ave = 1.38067050)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.655885088477653, value max: 0.6381272673606873\n",
      "D grad l2-norm: 6.1075201085201725, value max: 0.7406636476516724\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001608)\n",
      "Loss_D = 0.76868057 (ave = 0.76602350)\n",
      "Loss_G = 1.37006021 (ave = 1.36493189)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.81185612397556, value max: 0.6491702198982239\n",
      "D grad l2-norm: 6.139042496923354, value max: 0.7436843514442444\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 0.77340496 (ave = 0.77749578)\n",
      "Loss_G = 1.32175577 (ave = 1.32389705)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:08 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.727525675145534, value max: 0.6233854293823242\n",
      "D grad l2-norm: 5.9089406943578675, value max: 0.7302775382995605\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.720s / 5 iters, (0.144)\tData load 0.671s / 5 iters, (0.134283)\n",
      "Loss_D = 0.86411345 (ave = 0.80564454)\n",
      "Loss_G = 1.29332566 (ave = 1.29972391)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.770118897179233, value max: 0.6024059057235718\n",
      "D grad l2-norm: 5.863139627120031, value max: 0.7226678729057312\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001593)\n",
      "Loss_D = 0.74276549 (ave = 0.81086947)\n",
      "Loss_G = 1.25051224 (ave = 1.24464417)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.056578456299872, value max: 0.5842341184616089\n",
      "D grad l2-norm: 5.857740846386173, value max: 0.7098645567893982\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001554)\n",
      "Loss_D = 0.94696796 (ave = 0.86836450)\n",
      "Loss_G = 1.19729602 (ave = 1.22181633)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.378116313109167, value max: 0.5760493874549866\n",
      "D grad l2-norm: 5.792949992212437, value max: 0.6920837163925171\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 5 iters, (0.022)\tData load 0.018s / 5 iters, (0.003605)\n",
      "Loss_D = 0.88968563 (ave = 0.90067616)\n",
      "Loss_G = 1.13244128 (ave = 1.14939859)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.445018986981103, value max: 0.529900848865509\n",
      "D grad l2-norm: 5.61646569456417, value max: 0.6708073019981384\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 1.11225867 (ave = 0.97825559)\n",
      "Loss_G = 1.09298635 (ave = 1.09806950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.5018764102140585, value max: 0.5076439380645752\n",
      "D grad l2-norm: 5.591734018308015, value max: 0.658278226852417\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001533)\n",
      "Loss_D = 0.96132767 (ave = 0.99531914)\n",
      "Loss_G = 1.06394470 (ave = 1.06493530)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.416203741997864, value max: 0.4998902678489685\n",
      "D grad l2-norm: 5.540607865156716, value max: 0.6472272872924805\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.140s / 5 iters, (0.028)\tData load 0.037s / 5 iters, (0.007443)\n",
      "Loss_D = 1.19665384 (ave = 1.03838720)\n",
      "Loss_G = 1.09466350 (ave = 1.07823176)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:09 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.516585713426265, value max: 0.5312520861625671\n",
      "D grad l2-norm: 5.804124226590492, value max: 0.6717150211334229\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 5 iters, (0.023)\tData load 0.009s / 5 iters, (0.001728)\n",
      "Loss_D = 0.92639434 (ave = 1.00872743)\n",
      "Loss_G = 1.09505928 (ave = 1.08221285)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.523468346082569, value max: 0.576000988483429\n",
      "D grad l2-norm: 5.997206679695172, value max: 0.7013028264045715\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 5 iters, (0.024)\tData load 0.015s / 5 iters, (0.002940)\n",
      "Loss_D = 0.90361404 (ave = 1.00631686)\n",
      "Loss_G = 1.14786518 (ave = 1.12617965)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.581018306756357, value max: 0.6402372121810913\n",
      "D grad l2-norm: 6.272584623332588, value max: 0.7532858848571777\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.92674220 (ave = 0.98720977)\n",
      "Loss_G = 1.18248463 (ave = 1.17467728)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.377352356557805, value max: 0.6549882292747498\n",
      "D grad l2-norm: 6.2081148783463895, value max: 0.7450276613235474\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.684s / 5 iters, (0.137)\tData load 0.605s / 5 iters, (0.121082)\n",
      "Loss_D = 0.92085302 (ave = 0.96582314)\n",
      "Loss_G = 1.22596931 (ave = 1.21569254)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.53854218493958, value max: 0.6794075965881348\n",
      "D grad l2-norm: 6.4334763361691145, value max: 0.7699176073074341\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 1.03775907 (ave = 0.98030146)\n",
      "Loss_G = 1.26772070 (ave = 1.23906782)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:10 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.70113803616135, value max: 0.6817067861557007\n",
      "D grad l2-norm: 6.758387764015409, value max: 0.7979551553726196\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 0.90306205 (ave = 0.94638559)\n",
      "Loss_G = 1.27809834 (ave = 1.27611415)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.611828519287301, value max: 0.6999179720878601\n",
      "D grad l2-norm: 6.91544001689047, value max: 0.7865345478057861\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 0.79797834 (ave = 0.91705320)\n",
      "Loss_G = 1.33258438 (ave = 1.31371899)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.5579359937947075, value max: 0.6832758188247681\n",
      "D grad l2-norm: 7.162633414383167, value max: 0.7917935252189636\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 0.91057503 (ave = 0.90449610)\n",
      "Loss_G = 1.39191139 (ave = 1.35856745)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.212666323752109, value max: 0.6418205499649048\n",
      "D grad l2-norm: 7.133664245428338, value max: 0.7771559357643127\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001662)\n",
      "Loss_D = 0.79033005 (ave = 0.86876718)\n",
      "Loss_G = 1.46419847 (ave = 1.42762122)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.126961328964155, value max: 0.6082539558410645\n",
      "D grad l2-norm: 7.5049052128128055, value max: 0.7987284064292908\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001645)\n",
      "Loss_D = 0.81962526 (ave = 0.84398727)\n",
      "Loss_G = 1.52835107 (ave = 1.50688982)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.005189267379053, value max: 0.5934129953384399\n",
      "D grad l2-norm: 7.561963522113377, value max: 0.785344123840332\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001675)\n",
      "Loss_D = 0.96278983 (ave = 0.83557714)\n",
      "Loss_G = 1.53796029 (ave = 1.53649356)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.173720710836794, value max: 0.5797095894813538\n",
      "D grad l2-norm: 7.714629842423431, value max: 0.7926844358444214\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.012s / 5 iters, (0.002329)\n",
      "Loss_D = 0.72289312 (ave = 0.79318697)\n",
      "Loss_G = 1.58970022 (ave = 1.57256322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.3349525579081485, value max: 0.5271678566932678\n",
      "D grad l2-norm: 8.025230929242891, value max: 0.8319675326347351\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.016s / 5 iters, (0.003231)\n",
      "Loss_D = 0.77653205 (ave = 0.78495417)\n",
      "Loss_G = 1.60322058 (ave = 1.59752054)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:11 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.337245849037955, value max: 0.4901088774204254\n",
      "D grad l2-norm: 8.007385897187008, value max: 0.8271902799606323\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.827s / 5 iters, (0.165)\tData load 0.704s / 5 iters, (0.140816)\n",
      "Loss_D = 0.73417842 (ave = 0.76508390)\n",
      "Loss_G = 1.62746215 (ave = 1.60843346)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.316179198600638, value max: 0.4503621757030487\n",
      "D grad l2-norm: 8.217365405135892, value max: 0.8404915928840637\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.130s / 5 iters, (0.026)\tData load 0.026s / 5 iters, (0.005253)\n",
      "Loss_D = 0.67612141 (ave = 0.74557014)\n",
      "Loss_G = 1.66587126 (ave = 1.64488158)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.217755642075858, value max: 0.4173448085784912\n",
      "D grad l2-norm: 8.402895393696632, value max: 0.854234516620636\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.131s / 5 iters, (0.026)\tData load 0.046s / 5 iters, (0.009293)\n",
      "Loss_D = 0.85556537 (ave = 0.75089844)\n",
      "Loss_G = 1.72698092 (ave = 1.70941212)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.163241921488054, value max: 0.4372333586215973\n",
      "D grad l2-norm: 8.369438226039115, value max: 0.8561131954193115\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.119s / 5 iters, (0.024)\tData load 0.025s / 5 iters, (0.005036)\n",
      "Loss_D = 0.69052887 (ave = 0.72015312)\n",
      "Loss_G = 1.71521783 (ave = 1.72386897)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.617100558616094, value max: 0.4624299108982086\n",
      "D grad l2-norm: 8.44150358646592, value max: 0.845611572265625\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001625)\n",
      "Loss_D = 0.68953520 (ave = 0.72337289)\n",
      "Loss_G = 1.67382538 (ave = 1.67587926)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.019025363226544, value max: 0.5130960941314697\n",
      "D grad l2-norm: 8.486048633362282, value max: 0.8439704775810242\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.007s / 5 iters, (0.001457)\n",
      "Loss_D = 0.75804102 (ave = 0.73886027)\n",
      "Loss_G = 1.60382891 (ave = 1.64573965)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.88464323633639, value max: 0.5219309329986572\n",
      "D grad l2-norm: 8.254923665994063, value max: 0.8191547989845276\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002252)\n",
      "Loss_D = 0.64641905 (ave = 0.73328334)\n",
      "Loss_G = 1.61645305 (ave = 1.60465381)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.065436111437127, value max: 0.5249618887901306\n",
      "D grad l2-norm: 8.350421564692365, value max: 0.8289287686347961\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001593)\n",
      "Loss_D = 0.69899046 (ave = 0.75233246)\n",
      "Loss_G = 1.57687068 (ave = 1.57744374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.12966889886239, value max: 0.5152003169059753\n",
      "D grad l2-norm: 8.365606354119649, value max: 0.8160978555679321\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 0.83769083 (ave = 0.77691323)\n",
      "Loss_G = 1.54467344 (ave = 1.56161280)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:12 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.181529472129574, value max: 0.5214592814445496\n",
      "D grad l2-norm: 8.140991828863225, value max: 0.7857637405395508\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 1.00011873 (ave = 0.81297137)\n",
      "Loss_G = 1.47511399 (ave = 1.51509604)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.5754187522556125, value max: 0.511104941368103\n",
      "D grad l2-norm: 8.260479970939484, value max: 0.7838236689567566\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.660s / 5 iters, (0.132)\tData load 0.611s / 5 iters, (0.122275)\n",
      "Loss_D = 0.64514989 (ave = 0.78948890)\n",
      "Loss_G = 1.46578288 (ave = 1.49679439)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.510882509365507, value max: 0.4941084384918213\n",
      "D grad l2-norm: 8.285525171069104, value max: 0.7841081619262695\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001811)\n",
      "Loss_D = 0.61262500 (ave = 0.78446127)\n",
      "Loss_G = 1.49637806 (ave = 1.47844284)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.549307812767734, value max: 0.4894551932811737\n",
      "D grad l2-norm: 8.373309194079564, value max: 0.7859830260276794\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.010s / 5 iters, (0.002042)\n",
      "Loss_D = 0.64552289 (ave = 0.79664871)\n",
      "Loss_G = 1.53280079 (ave = 1.50905762)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.816008526768232, value max: 0.47597959637641907\n",
      "D grad l2-norm: 8.55918056855427, value max: 0.7853963375091553\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001629)\n",
      "Loss_D = 0.70758176 (ave = 0.79556044)\n",
      "Loss_G = 1.54422224 (ave = 1.51181927)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:13 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.725782718559845, value max: 0.47857406735420227\n",
      "D grad l2-norm: 8.612982396408546, value max: 0.7825887203216553\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001716)\n",
      "Loss_D = 0.68941677 (ave = 0.78468338)\n",
      "Loss_G = 1.56900120 (ave = 1.54383721)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.451947161522521, value max: 0.49126309156417847\n",
      "D grad l2-norm: 8.710150986177245, value max: 0.7889925241470337\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001666)\n",
      "Loss_D = 0.94014299 (ave = 0.79511769)\n",
      "Loss_G = 1.59272087 (ave = 1.59008701)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.423359970774956, value max: 0.5161857604980469\n",
      "D grad l2-norm: 8.746346697719002, value max: 0.7933253049850464\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 0.79431677 (ave = 0.75794092)\n",
      "Loss_G = 1.62792730 (ave = 1.61737103)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.701397494213775, value max: 0.5187872052192688\n",
      "D grad l2-norm: 9.191155346042592, value max: 0.8400179743766785\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.71830887 (ave = 0.73539797)\n",
      "Loss_G = 1.68807030 (ave = 1.65624621)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.690494324006387, value max: 0.572007954120636\n",
      "D grad l2-norm: 9.298848179560556, value max: 0.8985540866851807\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001698)\n",
      "Loss_D = 0.67725039 (ave = 0.71080348)\n",
      "Loss_G = 1.71579587 (ave = 1.70352561)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.423246706851762, value max: 0.593013346195221\n",
      "D grad l2-norm: 8.99532694640255, value max: 0.9063199758529663\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001642)\n",
      "Loss_D = 0.66202408 (ave = 0.69635439)\n",
      "Loss_G = 1.73740387 (ave = 1.72457938)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:14 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.8620852481764265, value max: 0.6229516863822937\n",
      "D grad l2-norm: 9.293560115365798, value max: 0.9349333047866821\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.911s / 5 iters, (0.182)\tData load 0.840s / 5 iters, (0.167943)\n",
      "Loss_D = 0.69079471 (ave = 0.68841994)\n",
      "Loss_G = 1.69840777 (ave = 1.70821483)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.862181734673013, value max: 0.6382254958152771\n",
      "D grad l2-norm: 9.10746968130548, value max: 0.8815661668777466\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.075s / 5 iters, (0.015)\tData load 0.012s / 5 iters, (0.002339)\n",
      "Loss_D = 0.77442348 (ave = 0.68694803)\n",
      "Loss_G = 1.72736740 (ave = 1.70411444)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.933581821917051, value max: 0.6441869735717773\n",
      "D grad l2-norm: 9.2432262851095, value max: 0.8733065128326416\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001597)\n",
      "Loss_D = 0.72225404 (ave = 0.67510895)\n",
      "Loss_G = 1.72483265 (ave = 1.71727693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.861324080996465, value max: 0.6240490078926086\n",
      "D grad l2-norm: 9.207099896225117, value max: 0.8329492211341858\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001641)\n",
      "Loss_D = 0.79422307 (ave = 0.67937429)\n",
      "Loss_G = 1.69073951 (ave = 1.71520157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.894462659203017, value max: 0.5838402509689331\n",
      "D grad l2-norm: 8.978943962079263, value max: 0.8114039301872253\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001643)\n",
      "Loss_D = 0.67860717 (ave = 0.66158302)\n",
      "Loss_G = 1.69080985 (ave = 1.68722494)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.363422822519215, value max: 0.6228997707366943\n",
      "D grad l2-norm: 9.196952224639606, value max: 0.8131848573684692\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 0.78418863 (ave = 0.68481404)\n",
      "Loss_G = 1.64937150 (ave = 1.65520945)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.46955437668424, value max: 0.6938493847846985\n",
      "D grad l2-norm: 8.984921265657679, value max: 0.8058228492736816\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001626)\n",
      "Loss_D = 0.50660926 (ave = 0.66373680)\n",
      "Loss_G = 1.58019876 (ave = 1.60905993)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.70983461538908, value max: 0.7392783164978027\n",
      "D grad l2-norm: 8.972730512771385, value max: 0.8115856647491455\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001609)\n",
      "Loss_D = 0.67742085 (ave = 0.70398848)\n",
      "Loss_G = 1.55296552 (ave = 1.58890631)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.685960230517493, value max: 0.7603661417961121\n",
      "D grad l2-norm: 8.655688224042612, value max: 0.7862465977668762\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 0.65994149 (ave = 0.72385509)\n",
      "Loss_G = 1.48200607 (ave = 1.52412894)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.164830477097215, value max: 0.781941831111908\n",
      "D grad l2-norm: 8.735400574693253, value max: 0.778127908706665\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.019s / 5 iters, (0.003859)\n",
      "Loss_D = 0.91929257 (ave = 0.79233509)\n",
      "Loss_G = 1.45009899 (ave = 1.47472050)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:15 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.250925876260938, value max: 0.7468197345733643\n",
      "D grad l2-norm: 8.717060402929397, value max: 0.7565757036209106\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.726s / 5 iters, (0.145)\tData load 0.676s / 5 iters, (0.135272)\n",
      "Loss_D = 0.71017992 (ave = 0.79635242)\n",
      "Loss_G = 1.39910758 (ave = 1.43906016)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.811144597005617, value max: 0.6879920363426208\n",
      "D grad l2-norm: 8.418240458952866, value max: 0.7470521926879883\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 0.78213847 (ave = 0.82551427)\n",
      "Loss_G = 1.43493605 (ave = 1.42568173)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.923145222251113, value max: 0.6969718933105469\n",
      "D grad l2-norm: 8.632943329190649, value max: 0.7547317147254944\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.05728328 (ave = 0.88414959)\n",
      "Loss_G = 1.42583764 (ave = 1.41852038)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.905714154924256, value max: 0.6883482336997986\n",
      "D grad l2-norm: 8.74752315571303, value max: 0.7529043555259705\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 0.91264099 (ave = 0.88852727)\n",
      "Loss_G = 1.42440534 (ave = 1.39466510)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.796873039809192, value max: 0.6796452403068542\n",
      "D grad l2-norm: 8.701764022170913, value max: 0.7519062757492065\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.011s / 5 iters, (0.002221)\n",
      "Loss_D = 0.85094613 (ave = 0.90043703)\n",
      "Loss_G = 1.38587642 (ave = 1.38126249)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.699741898733356, value max: 0.6795704960823059\n",
      "D grad l2-norm: 8.546809112660242, value max: 0.7416486144065857\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.023s / 5 iters, (0.004591)\n",
      "Loss_D = 1.13333607 (ave = 0.95809258)\n",
      "Loss_G = 1.31557763 (ave = 1.34715655)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.94568699840927, value max: 0.6647723913192749\n",
      "D grad l2-norm: 8.713180815099546, value max: 0.7408725023269653\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 1.18751061 (ave = 0.99507746)\n",
      "Loss_G = 1.33623445 (ave = 1.34746144)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.743573653967893, value max: 0.600941002368927\n",
      "D grad l2-norm: 8.572051304513606, value max: 0.7540892362594604\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001559)\n",
      "Loss_D = 1.11907375 (ave = 0.98880568)\n",
      "Loss_G = 1.32699287 (ave = 1.34847932)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:16 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.48874127113767, value max: 0.5483735203742981\n",
      "D grad l2-norm: 8.476856491579335, value max: 0.7562987208366394\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001634)\n",
      "Loss_D = 0.90842497 (ave = 0.95988784)\n",
      "Loss_G = 1.38985670 (ave = 1.35124042)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.611656630994126, value max: 0.4945656657218933\n",
      "D grad l2-norm: 9.033891849709644, value max: 0.8358613848686218\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.117s / 5 iters, (0.023)\tData load 0.008s / 5 iters, (0.001692)\n",
      "Loss_D = 0.89242131 (ave = 0.93786761)\n",
      "Loss_G = 1.43679559 (ave = 1.41775358)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.292642756716424, value max: 0.4905039370059967\n",
      "D grad l2-norm: 9.065694265810631, value max: 0.8632017970085144\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.774s / 5 iters, (0.155)\tData load 0.725s / 5 iters, (0.145056)\n",
      "Loss_D = 0.87549913 (ave = 0.91620378)\n",
      "Loss_G = 1.51073360 (ave = 1.49268947)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:17 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.092938612037823, value max: 0.4921366274356842\n",
      "D grad l2-norm: 8.97611921085524, value max: 0.8805471658706665\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.77949649 (ave = 0.88130490)\n",
      "Loss_G = 1.55743349 (ave = 1.53750296)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.271446318686973, value max: 0.5056613683700562\n",
      "D grad l2-norm: 9.314507808303789, value max: 0.9186497926712036\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.022s / 5 iters, (0.004397)\n",
      "Loss_D = 0.73972666 (ave = 0.85114868)\n",
      "Loss_G = 1.55705082 (ave = 1.55344701)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.255515815343946, value max: 0.5115368366241455\n",
      "D grad l2-norm: 9.240324204530593, value max: 0.9007906913757324\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 0.66613424 (ave = 0.83032359)\n",
      "Loss_G = 1.57465160 (ave = 1.57660930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.598731630779946, value max: 0.5510039925575256\n",
      "D grad l2-norm: 9.457411930314993, value max: 0.918951690196991\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 0.75383919 (ave = 0.83273418)\n",
      "Loss_G = 1.58879745 (ave = 1.58218403)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.713029835352938, value max: 0.5678210258483887\n",
      "D grad l2-norm: 9.304485148197486, value max: 0.9042054414749146\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001549)\n",
      "Loss_D = 1.00913596 (ave = 0.85641915)\n",
      "Loss_G = 1.55392885 (ave = 1.57216499)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.960444033185901, value max: 0.5997369885444641\n",
      "D grad l2-norm: 9.352238093985308, value max: 0.8939749002456665\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.89768267 (ave = 0.83594801)\n",
      "Loss_G = 1.53937972 (ave = 1.54079523)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.962184504042588, value max: 0.6411224603652954\n",
      "D grad l2-norm: 9.174920903500194, value max: 0.8575946092605591\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001631)\n",
      "Loss_D = 1.04654789 (ave = 0.84656733)\n",
      "Loss_G = 1.50667095 (ave = 1.51383572)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.757847060501549, value max: 0.6569791436195374\n",
      "D grad l2-norm: 8.817729444776942, value max: 0.806771993637085\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001614)\n",
      "Loss_D = 0.61628026 (ave = 0.78699130)\n",
      "Loss_G = 1.50686240 (ave = 1.49611893)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.688957014831631, value max: 0.6586872935295105\n",
      "D grad l2-norm: 8.662496908945464, value max: 0.783358097076416\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001610)\n",
      "Loss_D = 0.80716276 (ave = 0.80290704)\n",
      "Loss_G = 1.51593149 (ave = 1.50212500)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:18 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.757867772328549, value max: 0.6682652235031128\n",
      "D grad l2-norm: 8.657246799946796, value max: 0.8269700407981873\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.750s / 5 iters, (0.150)\tData load 0.693s / 5 iters, (0.138549)\n",
      "Loss_D = 0.81946659 (ave = 0.80312831)\n",
      "Loss_G = 1.47138786 (ave = 1.47545097)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.658133936754506, value max: 0.6350816488265991\n",
      "D grad l2-norm: 8.2590408585756, value max: 0.8278557062149048\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.016s / 5 iters, (0.003265)\n",
      "Loss_D = 0.75240171 (ave = 0.80007707)\n",
      "Loss_G = 1.43860650 (ave = 1.43393600)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.654625891991945, value max: 0.6395397782325745\n",
      "D grad l2-norm: 8.007651689304284, value max: 0.8462461829185486\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.014s / 5 iters, (0.002762)\n",
      "Loss_D = 0.81649756 (ave = 0.80673280)\n",
      "Loss_G = 1.38674104 (ave = 1.40411372)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.719977736744942, value max: 0.6610828638076782\n",
      "D grad l2-norm: 7.84523623474128, value max: 0.8659882545471191\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.009s / 5 iters, (0.001701)\n",
      "Loss_D = 0.73401773 (ave = 0.81016321)\n",
      "Loss_G = 1.34005117 (ave = 1.36494687)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.426855083402657, value max: 0.6019891500473022\n",
      "D grad l2-norm: 7.5838806127847125, value max: 0.8617098927497864\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.025s / 5 iters, (0.005090)\n",
      "Loss_D = 1.02836287 (ave = 0.84824533)\n",
      "Loss_G = 1.31383610 (ave = 1.34693015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.136701568545902, value max: 0.5848716497421265\n",
      "D grad l2-norm: 7.260432449432412, value max: 0.8569587469100952\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.018s / 5 iters, (0.003670)\n",
      "Loss_D = 0.83970833 (ave = 0.82205293)\n",
      "Loss_G = 1.34313154 (ave = 1.34130695)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.175769736155754, value max: 0.6283015608787537\n",
      "D grad l2-norm: 7.161993035782346, value max: 0.8819665312767029\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.010s / 5 iters, (0.001941)\n",
      "Loss_D = 0.71196783 (ave = 0.80454626)\n",
      "Loss_G = 1.31664979 (ave = 1.31929877)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.521896177706056, value max: 0.6286358833312988\n",
      "D grad l2-norm: 7.133735478846083, value max: 0.8726251125335693\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001646)\n",
      "Loss_D = 0.83285773 (ave = 0.83217567)\n",
      "Loss_G = 1.29129851 (ave = 1.27392356)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.500812540420407, value max: 0.6287194490432739\n",
      "D grad l2-norm: 7.029940167139023, value max: 0.8516485691070557\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001579)\n",
      "Loss_D = 0.91844893 (ave = 0.85635852)\n",
      "Loss_G = 1.25072157 (ave = 1.26325822)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:19 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.267794070380395, value max: 0.597745418548584\n",
      "D grad l2-norm: 6.921895515520794, value max: 0.8300965428352356\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.025s / 5 iters, (0.005003)\n",
      "Loss_D = 0.92074955 (ave = 0.84153258)\n",
      "Loss_G = 1.27778912 (ave = 1.25984035)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.97719078278766, value max: 0.6117414236068726\n",
      "D grad l2-norm: 6.919316706288971, value max: 0.837239146232605\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.682s / 5 iters, (0.136)\tData load 0.629s / 5 iters, (0.125790)\n",
      "Loss_D = 0.83956242 (ave = 0.81836137)\n",
      "Loss_G = 1.31100845 (ave = 1.29002273)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 7.927301415213196, value max: 0.6119638085365295\n",
      "D grad l2-norm: 7.047534538373941, value max: 0.8456332087516785\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 0.77764773 (ave = 0.79020250)\n",
      "Loss_G = 1.33729315 (ave = 1.32037146)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.155344449371587, value max: 0.6651539206504822\n",
      "D grad l2-norm: 7.201927358201803, value max: 0.8401211500167847\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 1.02178299 (ave = 0.81493918)\n",
      "Loss_G = 1.31249022 (ave = 1.33255374)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.338350406413493, value max: 0.7338641881942749\n",
      "D grad l2-norm: 7.033278116090493, value max: 0.7576113939285278\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 0.75460541 (ave = 0.78462135)\n",
      "Loss_G = 1.31103122 (ave = 1.31218412)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:20 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.4763586179687, value max: 0.7912219762802124\n",
      "D grad l2-norm: 7.119035901855722, value max: 0.7246684432029724\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001650)\n",
      "Loss_D = 0.74579811 (ave = 0.78942690)\n",
      "Loss_G = 1.30505049 (ave = 1.30569580)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.32750700366227, value max: 0.757668137550354\n",
      "D grad l2-norm: 7.052971309562042, value max: 0.7239859700202942\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001729)\n",
      "Loss_D = 0.79681468 (ave = 0.78240545)\n",
      "Loss_G = 1.32545090 (ave = 1.32409506)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.46303692220306, value max: 0.7854112386703491\n",
      "D grad l2-norm: 7.158362750295108, value max: 0.7284218072891235\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.081s / 5 iters, (0.016)\tData load 0.016s / 5 iters, (0.003164)\n",
      "Loss_D = 0.76834130 (ave = 0.78414245)\n",
      "Loss_G = 1.34420967 (ave = 1.31947565)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.392370233198323, value max: 0.7413090467453003\n",
      "D grad l2-norm: 7.093176926485707, value max: 0.7337965965270996\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 0.67153311 (ave = 0.76673847)\n",
      "Loss_G = 1.28610146 (ave = 1.30574627)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.28324430597698, value max: 0.7453727126121521\n",
      "D grad l2-norm: 7.026436767749459, value max: 0.7197854518890381\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 0.83324695 (ave = 0.78565235)\n",
      "Loss_G = 1.32171059 (ave = 1.33716807)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.495286627221958, value max: 0.7633368968963623\n",
      "D grad l2-norm: 7.383178943321847, value max: 0.72928386926651\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 0.64389861 (ave = 0.75430791)\n",
      "Loss_G = 1.37655413 (ave = 1.35428727)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:21 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.432255982511256, value max: 0.8013069033622742\n",
      "D grad l2-norm: 7.501836356353873, value max: 0.7431908845901489\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.820s / 5 iters, (0.164)\tData load 0.761s / 5 iters, (0.152174)\n",
      "Loss_D = 0.77051824 (ave = 0.76075193)\n",
      "Loss_G = 1.37890565 (ave = 1.37055168)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.376209907973292, value max: 0.7690590620040894\n",
      "D grad l2-norm: 7.475584537216696, value max: 0.7437653541564941\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.093s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001768)\n",
      "Loss_D = 0.88028842 (ave = 0.77493774)\n",
      "Loss_G = 1.42010474 (ave = 1.38835492)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.933511519612084, value max: 0.7859293818473816\n",
      "D grad l2-norm: 7.8768235115255285, value max: 0.7520965933799744\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.111s / 5 iters, (0.022)\tData load 0.017s / 5 iters, (0.003383)\n",
      "Loss_D = 0.67838800 (ave = 0.75654482)\n",
      "Loss_G = 1.40419245 (ave = 1.38897488)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.212755147466856, value max: 0.7956189513206482\n",
      "D grad l2-norm: 8.013985242292714, value max: 0.7484952211380005\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.007s / 5 iters, (0.001471)\n",
      "Loss_D = 0.54006124 (ave = 0.73989437)\n",
      "Loss_G = 1.34835196 (ave = 1.38443928)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.005685157303034, value max: 0.7489022016525269\n",
      "D grad l2-norm: 7.849583246861765, value max: 0.736088752746582\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001574)\n",
      "Loss_D = 0.77586937 (ave = 0.78151554)\n",
      "Loss_G = 1.38181686 (ave = 1.38501415)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.948673006613818, value max: 0.6921359896659851\n",
      "D grad l2-norm: 7.899323294758758, value max: 0.7433159351348877\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001738)\n",
      "Loss_D = 0.75032127 (ave = 0.77831302)\n",
      "Loss_G = 1.39773047 (ave = 1.38817868)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.12944186795723, value max: 0.636766254901886\n",
      "D grad l2-norm: 8.165395720397296, value max: 0.7473545670509338\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.80221677 (ave = 0.78632239)\n",
      "Loss_G = 1.40101743 (ave = 1.37913477)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.111365069953738, value max: 0.6103551983833313\n",
      "D grad l2-norm: 8.0464158602142, value max: 0.7479031085968018\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 0.79075247 (ave = 0.79140524)\n",
      "Loss_G = 1.36088371 (ave = 1.39412510)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.489796948891467, value max: 0.6115838289260864\n",
      "D grad l2-norm: 8.13254006012499, value max: 0.7375110983848572\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001624)\n",
      "Loss_D = 0.67844546 (ave = 0.78911889)\n",
      "Loss_G = 1.39963746 (ave = 1.35784688)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 9.073037047195182, value max: 0.5515425205230713\n",
      "D grad l2-norm: 8.083789739588958, value max: 0.7473855018615723\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001613)\n",
      "Loss_D = 0.72340107 (ave = 0.80184597)\n",
      "Loss_G = 1.33925378 (ave = 1.36350982)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:22 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 8.85354401557667, value max: 0.6049658060073853\n",
      "D grad l2-norm: 7.934148070799674, value max: 0.7329256534576416\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üîÅ TSCV for Asset 11\n",
      "üì¶ Fold 1 | Train: 300, Val: 100\n",
      "G #parameters:  51092\n",
      "D #parameters:  38401\n",
      "Using device: cpu\n",
      "epoch: [1/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.005s / 5 iters, (0.001093)\n",
      "Loss_D = 1.41430712 (ave = 1.38804834)\n",
      "Loss_G = 0.72098368 (ave = 0.72317646)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9742199052572827, value max: 0.02852720208466053\n",
      "D grad l2-norm: 0.7137661299556233, value max: 0.5137222409248352\n",
      "epoch: [2/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.490s / 5 iters, (0.098)\tData load 0.434s / 5 iters, (0.086731)\n",
      "Loss_D = 1.36273873 (ave = 1.36381619)\n",
      "Loss_G = 0.71592218 (ave = 0.71788175)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:23 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9715449554399418, value max: 0.03442145138978958\n",
      "D grad l2-norm: 0.7107110440794957, value max: 0.5112552642822266\n",
      "epoch: [3/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.466s / 5 iters, (0.093)\tData load 0.393s / 5 iters, (0.078656)\n",
      "Loss_D = 1.34405255 (ave = 1.34650548)\n",
      "Loss_G = 0.71103233 (ave = 0.71244670)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:24 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9703421670742072, value max: 0.030453093349933624\n",
      "D grad l2-norm: 0.7057957091091412, value max: 0.5088595151901245\n",
      "epoch: [4/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 3.015s / 5 iters, (0.603)\tData load 2.965s / 5 iters, (0.592961)\n",
      "Loss_D = 1.32123923 (ave = 1.33088727)\n",
      "Loss_G = 0.70799500 (ave = 0.70910132)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9703483039370476, value max: 0.028957979753613472\n",
      "D grad l2-norm: 0.7090791090920727, value max: 0.5073645114898682\n",
      "epoch: [5/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.384s / 5 iters, (0.077)\tData load 0.329s / 5 iters, (0.065766)\n",
      "Loss_D = 1.32386398 (ave = 1.31916308)\n",
      "Loss_G = 0.70532799 (ave = 0.70602438)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:27 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9785298639185463, value max: 0.04351099953055382\n",
      "D grad l2-norm: 0.7081529906282131, value max: 0.5060505867004395\n",
      "epoch: [6/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.370s / 5 iters, (0.074)\tData load 0.320s / 5 iters, (0.063997)\n",
      "Loss_D = 1.32800663 (ave = 1.30972338)\n",
      "Loss_G = 0.70235741 (ave = 0.70334626)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9744887795905197, value max: 0.028171923011541367\n",
      "D grad l2-norm: 0.7119039187411679, value max: 0.5045788288116455\n",
      "epoch: [7/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.479s / 5 iters, (0.096)\tData load 0.429s / 5 iters, (0.085826)\n",
      "Loss_D = 1.31726050 (ave = 1.29861193)\n",
      "Loss_G = 0.69975775 (ave = 0.70086755)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:28 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9716016571396726, value max: 0.034617308527231216\n",
      "D grad l2-norm: 0.7146747958489201, value max: 0.5032883286476135\n",
      "epoch: [8/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.501s / 5 iters, (0.100)\tData load 0.416s / 5 iters, (0.083133)\n",
      "Loss_D = 1.28198624 (ave = 1.28560977)\n",
      "Loss_G = 0.69826323 (ave = 0.69910069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9743867358660644, value max: 0.038832977414131165\n",
      "D grad l2-norm: 0.715789152472741, value max: 0.5025467872619629\n",
      "epoch: [9/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.552s / 5 iters, (0.110)\tData load 0.506s / 5 iters, (0.101162)\n",
      "Loss_D = 1.28750134 (ave = 1.27794275)\n",
      "Loss_G = 0.69683343 (ave = 0.69759221)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:29 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9700386269339164, value max: 0.03926853835582733\n",
      "D grad l2-norm: 0.7210745939043516, value max: 0.5018349885940552\n",
      "epoch: [10/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.420s / 5 iters, (0.084)\tData load 0.330s / 5 iters, (0.066061)\n",
      "Loss_D = 1.23401046 (ave = 1.26441340)\n",
      "Loss_G = 0.69672036 (ave = 0.69674639)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9819517011376135, value max: 0.03579051047563553\n",
      "D grad l2-norm: 0.7256700511470039, value max: 0.5017794370651245\n",
      "Epoch 10 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 10 FID Score: 0.000000\n",
      "epoch: [11/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.724s / 5 iters, (0.145)\tData load 0.669s / 5 iters, (0.133836)\n",
      "Loss_D = 1.24223685 (ave = 1.25828929)\n",
      "Loss_G = 0.69580412 (ave = 0.69590527)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9755814797315097, value max: 0.03525921329855919\n",
      "D grad l2-norm: 0.7315908605516467, value max: 0.5013198256492615\n",
      "epoch: [12/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 1.27883554 (ave = 1.25599713)\n",
      "Loss_G = 0.69609326 (ave = 0.69520234)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9759322788828628, value max: 0.03875976428389549\n",
      "D grad l2-norm: 0.7333183373694978, value max: 0.5014652013778687\n",
      "epoch: [13/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001597)\n",
      "Loss_D = 1.25609994 (ave = 1.24690211)\n",
      "Loss_G = 0.69542992 (ave = 0.69515506)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:30 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.980526886521239, value max: 0.0427144356071949\n",
      "D grad l2-norm: 0.7434650213118811, value max: 0.5011348128318787\n",
      "epoch: [14/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001602)\n",
      "Loss_D = 1.25831723 (ave = 1.24059114)\n",
      "Loss_G = 0.69686127 (ave = 0.69633406)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9759505647213228, value max: 0.03715051710605621\n",
      "D grad l2-norm: 0.7498532263441406, value max: 0.5018491744995117\n",
      "epoch: [15/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 5 iters, (0.017)\tData load 0.020s / 5 iters, (0.003964)\n",
      "Loss_D = 1.23864520 (ave = 1.23204591)\n",
      "Loss_G = 0.69743109 (ave = 0.69689279)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9816893907624495, value max: 0.0403619222342968\n",
      "D grad l2-norm: 0.7542409413038975, value max: 0.502130389213562\n",
      "epoch: [16/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.018s / 5 iters, (0.003617)\n",
      "Loss_D = 1.28411162 (ave = 1.23164415)\n",
      "Loss_G = 0.69844472 (ave = 0.69797394)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9748967695825006, value max: 0.04235764220356941\n",
      "D grad l2-norm: 0.7628504680161892, value max: 0.5026355981826782\n",
      "epoch: [17/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.126s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004571)\n",
      "Loss_D = 1.21662879 (ave = 1.21735833)\n",
      "Loss_G = 0.69973063 (ave = 0.69923376)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9835942425543851, value max: 0.04331915080547333\n",
      "D grad l2-norm: 0.7702639658445142, value max: 0.5032732486724854\n",
      "epoch: [18/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.123s / 5 iters, (0.025)\tData load 0.016s / 5 iters, (0.003178)\n",
      "Loss_D = 1.20669711 (ave = 1.21026571)\n",
      "Loss_G = 0.70130247 (ave = 0.70078536)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9809817064030201, value max: 0.04510205239057541\n",
      "D grad l2-norm: 0.7786343567014915, value max: 0.5040545463562012\n",
      "epoch: [19/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.122s / 5 iters, (0.024)\tData load 0.026s / 5 iters, (0.005150)\n",
      "Loss_D = 1.19130874 (ave = 1.20291860)\n",
      "Loss_G = 0.70389396 (ave = 0.70299795)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9814192586054492, value max: 0.04095710068941116\n",
      "D grad l2-norm: 0.7879225714507267, value max: 0.5053344368934631\n",
      "epoch: [20/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.086s / 5 iters, (0.017)\tData load 0.020s / 5 iters, (0.003909)\n",
      "Loss_D = 1.21771443 (ave = 1.20058775)\n",
      "Loss_G = 0.70717931 (ave = 0.70565335)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:31 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.979088189405965, value max: 0.0379275381565094\n",
      "D grad l2-norm: 0.7945613545002385, value max: 0.5069597959518433\n",
      "Epoch 20 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 20 FID Score: 0.000000\n",
      "epoch: [21/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.745s / 5 iters, (0.149)\tData load 0.678s / 5 iters, (0.135552)\n",
      "Loss_D = 1.23635364 (ave = 1.19745443)\n",
      "Loss_G = 0.70967251 (ave = 0.70787930)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9795307147623322, value max: 0.036953750997781754\n",
      "D grad l2-norm: 0.8054528351971176, value max: 0.5081868171691895\n",
      "epoch: [22/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001574)\n",
      "Loss_D = 1.20159602 (ave = 1.18717353)\n",
      "Loss_G = 0.71169996 (ave = 0.71082196)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9800730651699829, value max: 0.038131777197122574\n",
      "D grad l2-norm: 0.8144648056645069, value max: 0.5091832280158997\n",
      "epoch: [23/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001561)\n",
      "Loss_D = 1.14545584 (ave = 1.17460651)\n",
      "Loss_G = 0.71443224 (ave = 0.71385386)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9788607456807967, value max: 0.04426347836852074\n",
      "D grad l2-norm: 0.8238307331116956, value max: 0.5105203986167908\n",
      "epoch: [24/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 1.12421989 (ave = 1.16546385)\n",
      "Loss_G = 0.71898627 (ave = 0.71773614)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9775347388732923, value max: 0.044006165117025375\n",
      "D grad l2-norm: 0.8326415602588416, value max: 0.5127434134483337\n",
      "epoch: [25/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001582)\n",
      "Loss_D = 1.25327826 (ave = 1.17576597)\n",
      "Loss_G = 0.72259963 (ave = 0.72187401)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.984311956951637, value max: 0.04572945460677147\n",
      "D grad l2-norm: 0.8447366372297911, value max: 0.51450115442276\n",
      "epoch: [26/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001734)\n",
      "Loss_D = 1.20295072 (ave = 1.16335492)\n",
      "Loss_G = 0.72736973 (ave = 0.72523574)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.985684472441985, value max: 0.04540922865271568\n",
      "D grad l2-norm: 0.8486586280616487, value max: 0.5168107748031616\n",
      "epoch: [27/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001562)\n",
      "Loss_D = 1.15002942 (ave = 1.15040154)\n",
      "Loss_G = 0.73171753 (ave = 0.73010483)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9858727770995589, value max: 0.04993581026792526\n",
      "D grad l2-norm: 0.8588611325326478, value max: 0.5189036130905151\n",
      "epoch: [28/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 1.19367194 (ave = 1.14990835)\n",
      "Loss_G = 0.73554933 (ave = 0.73433838)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.989567207589566, value max: 0.055473692715168\n",
      "D grad l2-norm: 0.8697583647299018, value max: 0.52074134349823\n",
      "epoch: [29/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.014s / 5 iters, (0.002714)\n",
      "Loss_D = 1.11208594 (ave = 1.13397934)\n",
      "Loss_G = 0.73965353 (ave = 0.73866707)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9865528083845427, value max: 0.05217139422893524\n",
      "D grad l2-norm: 0.8762687838865266, value max: 0.5227024555206299\n",
      "epoch: [30/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.051s / 5 iters, (0.010)\tData load 0.007s / 5 iters, (0.001396)\n",
      "Loss_D = 1.09546685 (ave = 1.12618780)\n",
      "Loss_G = 0.74340570 (ave = 0.74165556)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:32 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 0.9913547436347092, value max: 0.05475303903222084\n",
      "D grad l2-norm: 0.8847611004455803, value max: 0.5244884490966797\n",
      "Epoch 30 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 30 FID Score: 0.000000\n",
      "epoch: [31/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.752s / 5 iters, (0.150)\tData load 0.702s / 5 iters, (0.140396)\n",
      "Loss_D = 1.13817227 (ave = 1.12659066)\n",
      "Loss_G = 0.74629641 (ave = 0.74531684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0023919421915084, value max: 0.0561097152531147\n",
      "D grad l2-norm: 0.8888578386000697, value max: 0.5258627533912659\n",
      "epoch: [32/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.029s / 5 iters, (0.005836)\n",
      "Loss_D = 1.15193129 (ave = 1.12255983)\n",
      "Loss_G = 0.74953657 (ave = 0.74849702)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0063442632823434, value max: 0.06261452287435532\n",
      "D grad l2-norm: 0.8979108250962748, value max: 0.5273881554603577\n",
      "epoch: [33/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.077s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003356)\n",
      "Loss_D = 1.20301259 (ave = 1.12421892)\n",
      "Loss_G = 0.75202483 (ave = 0.75156319)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0108278437378004, value max: 0.060736656188964844\n",
      "D grad l2-norm: 0.9080871768249457, value max: 0.528569221496582\n",
      "epoch: [34/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.012s / 5 iters, (0.002471)\n",
      "Loss_D = 1.10019970 (ave = 1.10755186)\n",
      "Loss_G = 0.75254923 (ave = 0.75239691)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:33 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0222742125574078, value max: 0.05583631992340088\n",
      "D grad l2-norm: 0.9225925831900826, value max: 0.5288055539131165\n",
      "epoch: [35/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.022s / 5 iters, (0.004461)\n",
      "Loss_D = 1.13240170 (ave = 1.10741932)\n",
      "Loss_G = 0.75662881 (ave = 0.75527781)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0222541999069912, value max: 0.058248862624168396\n",
      "D grad l2-norm: 0.9260448841799289, value max: 0.5307214260101318\n",
      "epoch: [36/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.017s / 5 iters, (0.003372)\n",
      "Loss_D = 1.14864993 (ave = 1.10631590)\n",
      "Loss_G = 0.75528330 (ave = 0.75581081)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0295688681625654, value max: 0.060919299721717834\n",
      "D grad l2-norm: 0.9362662247198754, value max: 0.5300889015197754\n",
      "epoch: [37/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001595)\n",
      "Loss_D = 1.10197687 (ave = 1.09801662)\n",
      "Loss_G = 0.75864846 (ave = 0.75798857)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0283462048674452, value max: 0.06564103066921234\n",
      "D grad l2-norm: 0.9428690775073728, value max: 0.5316653847694397\n",
      "epoch: [38/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001564)\n",
      "Loss_D = 1.10786223 (ave = 1.09523382)\n",
      "Loss_G = 0.76056677 (ave = 0.75897794)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.038075702495371, value max: 0.06624361872673035\n",
      "D grad l2-norm: 0.9595295428954111, value max: 0.5325611233711243\n",
      "epoch: [39/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.080s / 5 iters, (0.016)\tData load 0.011s / 5 iters, (0.002224)\n",
      "Loss_D = 1.04775047 (ave = 1.08333671)\n",
      "Loss_G = 0.76404232 (ave = 0.76175908)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.047171585937474, value max: 0.07244513183832169\n",
      "D grad l2-norm: 0.9675450842511586, value max: 0.5341777205467224\n",
      "epoch: [40/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001651)\n",
      "Loss_D = 1.06341755 (ave = 1.08111668)\n",
      "Loss_G = 0.76324153 (ave = 0.76268821)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:34 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.051382490388942, value max: 0.07349993288516998\n",
      "D grad l2-norm: 0.9861644951162195, value max: 0.5338013768196106\n",
      "Epoch 40 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 40 FID Score: 0.000000\n",
      "epoch: [41/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.653s / 5 iters, (0.131)\tData load 0.602s / 5 iters, (0.120444)\n",
      "Loss_D = 1.10793781 (ave = 1.08365588)\n",
      "Loss_G = 0.77137792 (ave = 0.76766188)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.053351038194557, value max: 0.07403863966464996\n",
      "D grad l2-norm: 0.9897723343152662, value max: 0.5375885367393494\n",
      "epoch: [42/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 1.15067029 (ave = 1.08439827)\n",
      "Loss_G = 0.77261090 (ave = 0.77040086)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0583160822201931, value max: 0.08460090309381485\n",
      "D grad l2-norm: 1.0072082296099762, value max: 0.5381476283073425\n",
      "epoch: [43/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001671)\n",
      "Loss_D = 1.05787814 (ave = 1.06888366)\n",
      "Loss_G = 0.77849537 (ave = 0.77543715)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0645229824440672, value max: 0.0771440714597702\n",
      "D grad l2-norm: 1.0188334543335522, value max: 0.5408597588539124\n",
      "epoch: [44/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001590)\n",
      "Loss_D = 1.07202590 (ave = 1.06537242)\n",
      "Loss_G = 0.77774131 (ave = 0.77766025)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0734581791910043, value max: 0.09082817286252975\n",
      "D grad l2-norm: 1.0287312817181435, value max: 0.5404714941978455\n",
      "epoch: [45/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.009s / 5 iters, (0.001870)\n",
      "Loss_D = 1.04263043 (ave = 1.05707362)\n",
      "Loss_G = 0.78336459 (ave = 0.78087124)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0704452059284821, value max: 0.07956156879663467\n",
      "D grad l2-norm: 1.030063406549854, value max: 0.5430918335914612\n",
      "epoch: [46/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.085s / 5 iters, (0.017)\tData load 0.016s / 5 iters, (0.003109)\n",
      "Loss_D = 0.97826731 (ave = 1.04363508)\n",
      "Loss_G = 0.78546995 (ave = 0.78347286)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0881240763633546, value max: 0.07970062643289566\n",
      "D grad l2-norm: 1.0487990693048603, value max: 0.5440298318862915\n",
      "epoch: [47/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.018s / 5 iters, (0.003689)\n",
      "Loss_D = 1.00305665 (ave = 1.04350619)\n",
      "Loss_G = 0.79102129 (ave = 0.78695989)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0945238531534027, value max: 0.08625883609056473\n",
      "D grad l2-norm: 1.0644646098598294, value max: 0.5465542078018188\n",
      "epoch: [48/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001709)\n",
      "Loss_D = 1.08525729 (ave = 1.04731841)\n",
      "Loss_G = 0.79130268 (ave = 0.79094402)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.0996994602902526, value max: 0.08809562772512436\n",
      "D grad l2-norm: 1.0803744745582318, value max: 0.5466756820678711\n",
      "epoch: [49/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001672)\n",
      "Loss_D = 1.10081148 (ave = 1.04357650)\n",
      "Loss_G = 0.79656690 (ave = 0.79661669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1066945140595967, value max: 0.07932758331298828\n",
      "D grad l2-norm: 1.0822561964432331, value max: 0.549049973487854\n",
      "epoch: [50/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 1.09188223 (ave = 1.03585154)\n",
      "Loss_G = 0.80191553 (ave = 0.80025409)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:35 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1069886547145875, value max: 0.08096203207969666\n",
      "D grad l2-norm: 1.0942595485160638, value max: 0.5514661073684692\n",
      "Epoch 50 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 50 FID Score: 0.000000\n",
      "epoch: [51/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.949s / 5 iters, (0.190)\tData load 0.899s / 5 iters, (0.179848)\n",
      "Loss_D = 1.06936967 (ave = 1.02739710)\n",
      "Loss_G = 0.80530047 (ave = 0.80376577)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1292653539916506, value max: 0.08639100939035416\n",
      "D grad l2-norm: 1.1156182116149744, value max: 0.5529772639274597\n",
      "epoch: [52/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 1.02599430 (ave = 1.01670856)\n",
      "Loss_G = 0.81332976 (ave = 0.80939684)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1301143886935867, value max: 0.08792853355407715\n",
      "D grad l2-norm: 1.1229587929472609, value max: 0.5565463900566101\n",
      "epoch: [53/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.084s / 5 iters, (0.017)\tData load 0.021s / 5 iters, (0.004124)\n",
      "Loss_D = 1.03948271 (ave = 1.01210996)\n",
      "Loss_G = 0.81607842 (ave = 0.81295863)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1418452319519548, value max: 0.10198711603879929\n",
      "D grad l2-norm: 1.1291111464616967, value max: 0.5577492713928223\n",
      "epoch: [54/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.008s / 5 iters, (0.001661)\n",
      "Loss_D = 0.97796535 (ave = 0.99968097)\n",
      "Loss_G = 0.81815571 (ave = 0.81452235)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.162980146224184, value max: 0.10940718650817871\n",
      "D grad l2-norm: 1.1469560829508192, value max: 0.5586696863174438\n",
      "epoch: [55/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001635)\n",
      "Loss_D = 0.96672726 (ave = 0.99406813)\n",
      "Loss_G = 0.82042032 (ave = 0.81660340)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:36 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.1923660872026294, value max: 0.12914307415485382\n",
      "D grad l2-norm: 1.172822009768523, value max: 0.5596675276756287\n",
      "epoch: [56/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001536)\n",
      "Loss_D = 0.97702849 (ave = 0.99186867)\n",
      "Loss_G = 0.82109559 (ave = 0.82043624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2037506021629973, value max: 0.13565750420093536\n",
      "D grad l2-norm: 1.187913521904377, value max: 0.559968113899231\n",
      "epoch: [57/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001579)\n",
      "Loss_D = 0.97265589 (ave = 0.98937142)\n",
      "Loss_G = 0.82099658 (ave = 0.82085266)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2246784548434504, value max: 0.1343717873096466\n",
      "D grad l2-norm: 1.1961173894141304, value max: 0.5598920583724976\n",
      "epoch: [58/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.010s / 5 iters, (0.001954)\n",
      "Loss_D = 1.00175536 (ave = 0.98963099)\n",
      "Loss_G = 0.82056516 (ave = 0.82215199)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.2630001152536356, value max: 0.14854180812835693\n",
      "D grad l2-norm: 1.2083223065171111, value max: 0.5596811771392822\n",
      "epoch: [59/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 0.97880304 (ave = 0.98680429)\n",
      "Loss_G = 0.81569105 (ave = 0.82193773)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3027595643347194, value max: 0.1633520871400833\n",
      "D grad l2-norm: 1.236126836024373, value max: 0.5574966669082642\n",
      "epoch: [60/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 0.90241194 (ave = 0.97681296)\n",
      "Loss_G = 0.82046592 (ave = 0.81938324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:37 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3208852115724878, value max: 0.1647724211215973\n",
      "D grad l2-norm: 1.2435616516954262, value max: 0.5596266388893127\n",
      "Epoch 60 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 60 FID Score: 0.000000\n",
      "epoch: [61/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.738s / 5 iters, (0.148)\tData load 0.687s / 5 iters, (0.137308)\n",
      "Loss_D = 1.05263209 (ave = 0.99690530)\n",
      "Loss_G = 0.81385136 (ave = 0.81652759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3476589787296354, value max: 0.15517976880073547\n",
      "D grad l2-norm: 1.2710491237906676, value max: 0.5566647052764893\n",
      "epoch: [62/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001709)\n",
      "Loss_D = 1.02412021 (ave = 0.99476911)\n",
      "Loss_G = 0.81233978 (ave = 0.81382687)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3594007463641722, value max: 0.1587572693824768\n",
      "D grad l2-norm: 1.2901983745581627, value max: 0.5559723377227783\n",
      "epoch: [63/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.058s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 0.88672680 (ave = 0.97990283)\n",
      "Loss_G = 0.81144464 (ave = 0.81260208)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3779732436514711, value max: 0.16197068989276886\n",
      "D grad l2-norm: 1.3118952670573807, value max: 0.5555967092514038\n",
      "epoch: [64/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 1.02603734 (ave = 0.99788382)\n",
      "Loss_G = 0.80979109 (ave = 0.81121910)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3977983260589688, value max: 0.14878280460834503\n",
      "D grad l2-norm: 1.3465817543188314, value max: 0.5548027157783508\n",
      "epoch: [65/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.011s / 5 iters, (0.002279)\n",
      "Loss_D = 0.99712890 (ave = 0.99426785)\n",
      "Loss_G = 0.80897796 (ave = 0.80934666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.404599954666358, value max: 0.15177321434020996\n",
      "D grad l2-norm: 1.3734987395570724, value max: 0.554419755935669\n",
      "epoch: [66/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001621)\n",
      "Loss_D = 1.01380193 (ave = 0.99566524)\n",
      "Loss_G = 0.81692469 (ave = 0.81250881)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.3836188496594986, value max: 0.14428561925888062\n",
      "D grad l2-norm: 1.3922251575991726, value max: 0.5579875111579895\n",
      "epoch: [67/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.082s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001615)\n",
      "Loss_D = 1.00720167 (ave = 0.99194410)\n",
      "Loss_G = 0.81451660 (ave = 0.81603359)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4301119814877843, value max: 0.14019262790679932\n",
      "D grad l2-norm: 1.4801224408051197, value max: 0.5569186806678772\n",
      "epoch: [68/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.094s / 5 iters, (0.019)\tData load 0.017s / 5 iters, (0.003483)\n",
      "Loss_D = 1.09463918 (ave = 0.99795183)\n",
      "Loss_G = 0.83311898 (ave = 0.82986915)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.419243287440666, value max: 0.1285887211561203\n",
      "D grad l2-norm: 1.4885138044841333, value max: 0.5650460720062256\n",
      "epoch: [69/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 1.00990093 (ave = 0.97970893)\n",
      "Loss_G = 0.84422958 (ave = 0.83962725)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.4234104175718985, value max: 0.12461356073617935\n",
      "D grad l2-norm: 1.5346697015067812, value max: 0.5698773264884949\n",
      "epoch: [70/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.108s / 5 iters, (0.022)\tData load 0.008s / 5 iters, (0.001685)\n",
      "Loss_D = 1.00576282 (ave = 0.97365241)\n",
      "Loss_G = 0.85838908 (ave = 0.85214387)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:38 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.450686470267812, value max: 0.1254919171333313\n",
      "D grad l2-norm: 1.5824303684841106, value max: 0.5758782029151917\n",
      "Epoch 70 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 70 FID Score: 0.000000\n",
      "epoch: [71/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.796s / 5 iters, (0.159)\tData load 0.749s / 5 iters, (0.149749)\n",
      "Loss_D = 0.98049831 (ave = 0.95939111)\n",
      "Loss_G = 0.87585926 (ave = 0.86750871)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.486516515789192, value max: 0.13966502249240875\n",
      "D grad l2-norm: 1.622599211494431, value max: 0.583256721496582\n",
      "epoch: [72/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001654)\n",
      "Loss_D = 0.87134558 (ave = 0.93902857)\n",
      "Loss_G = 0.87936503 (ave = 0.87903110)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.5967588253633191, value max: 0.14785459637641907\n",
      "D grad l2-norm: 1.6922455182794953, value max: 0.5846266150474548\n",
      "epoch: [73/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001586)\n",
      "Loss_D = 0.85397291 (ave = 0.93471410)\n",
      "Loss_G = 0.88296646 (ave = 0.88519256)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.6862571169552623, value max: 0.1550503671169281\n",
      "D grad l2-norm: 1.7400396988612954, value max: 0.586031973361969\n",
      "epoch: [74/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 0.97407317 (ave = 0.95212705)\n",
      "Loss_G = 0.88476515 (ave = 0.88847941)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.750535323615777, value max: 0.16170164942741394\n",
      "D grad l2-norm: 1.759821644046271, value max: 0.5867511034011841\n",
      "epoch: [75/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 0.96944571 (ave = 0.95347406)\n",
      "Loss_G = 0.88139504 (ave = 0.88369337)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.8702684081023229, value max: 0.1810457706451416\n",
      "D grad l2-norm: 1.8297871581367091, value max: 0.5853038430213928\n",
      "epoch: [76/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.102s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001601)\n",
      "Loss_D = 1.05623031 (ave = 0.97286340)\n",
      "Loss_G = 0.87806249 (ave = 0.88033797)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 1.9382888305357564, value max: 0.21020923554897308\n",
      "D grad l2-norm: 1.8522385022641314, value max: 0.5838274955749512\n",
      "epoch: [77/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001589)\n",
      "Loss_D = 0.92100805 (ave = 0.96462919)\n",
      "Loss_G = 0.88221174 (ave = 0.87910624)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.0208335931017998, value max: 0.2160051167011261\n",
      "D grad l2-norm: 1.9290365866475354, value max: 0.5853732824325562\n",
      "epoch: [78/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001633)\n",
      "Loss_D = 0.90965843 (ave = 0.96509792)\n",
      "Loss_G = 0.87843704 (ave = 0.87297375)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.059547063416176, value max: 0.22861707210540771\n",
      "D grad l2-norm: 1.97743670364573, value max: 0.5837688446044922\n",
      "epoch: [79/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 0.98058581 (ave = 0.98104290)\n",
      "Loss_G = 0.87779552 (ave = 0.87906015)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:39 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1064790664024824, value max: 0.24622482061386108\n",
      "D grad l2-norm: 2.056121635425572, value max: 0.5836769342422485\n",
      "epoch: [80/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001556)\n",
      "Loss_D = 0.85094464 (ave = 0.96320565)\n",
      "Loss_G = 0.89182138 (ave = 0.88336599)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.1177544743411882, value max: 0.2527344822883606\n",
      "D grad l2-norm: 2.12539247300424, value max: 0.5894160270690918\n",
      "Epoch 80 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 80 FID Score: 0.000000\n",
      "epoch: [81/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.726s / 5 iters, (0.145)\tData load 0.670s / 5 iters, (0.133903)\n",
      "Loss_D = 0.97942305 (ave = 0.97786063)\n",
      "Loss_G = 0.90408552 (ave = 0.89763759)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.187877425782399, value max: 0.2545955777168274\n",
      "D grad l2-norm: 2.2065880324293645, value max: 0.5941829681396484\n",
      "epoch: [82/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.099s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001558)\n",
      "Loss_D = 0.98212731 (ave = 0.97601104)\n",
      "Loss_G = 0.90725327 (ave = 0.90556718)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.30075974563379, value max: 0.25991877913475037\n",
      "D grad l2-norm: 2.3018714243514067, value max: 0.5954054594039917\n",
      "epoch: [83/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.015s / 5 iters, (0.002974)\n",
      "Loss_D = 0.83976519 (ave = 0.96390578)\n",
      "Loss_G = 0.90697831 (ave = 0.90409441)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.3979378295217373, value max: 0.2740011513233185\n",
      "D grad l2-norm: 2.3571409501821865, value max: 0.5954025983810425\n",
      "epoch: [84/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.018s / 5 iters, (0.003501)\n",
      "Loss_D = 0.97545558 (ave = 0.98769974)\n",
      "Loss_G = 0.90595353 (ave = 0.90455865)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:40 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.4536265599649947, value max: 0.27074646949768066\n",
      "D grad l2-norm: 2.39739398293981, value max: 0.5950157642364502\n",
      "epoch: [85/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.125s / 5 iters, (0.025)\tData load 0.023s / 5 iters, (0.004582)\n",
      "Loss_D = 0.90000486 (ave = 0.99247693)\n",
      "Loss_G = 0.88598871 (ave = 0.89394975)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.594709874084401, value max: 0.2640247046947479\n",
      "D grad l2-norm: 2.4716351490499333, value max: 0.5866364240646362\n",
      "epoch: [86/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.014s / 5 iters, (0.002868)\n",
      "Loss_D = 1.18376255 (ave = 1.04340930)\n",
      "Loss_G = 0.87296957 (ave = 0.87084956)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6646143675514122, value max: 0.23704786598682404\n",
      "D grad l2-norm: 2.525031834292911, value max: 0.5812028646469116\n",
      "epoch: [87/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.015s / 5 iters, (0.003025)\n",
      "Loss_D = 0.95947754 (ave = 1.03903100)\n",
      "Loss_G = 0.85445035 (ave = 0.85779381)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.700215674589134, value max: 0.2565597891807556\n",
      "D grad l2-norm: 2.6047554747741266, value max: 0.5730481147766113\n",
      "epoch: [88/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.023s / 5 iters, (0.004549)\n",
      "Loss_D = 1.09532547 (ave = 1.07105768)\n",
      "Loss_G = 0.86370450 (ave = 0.86035612)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.6589256033270474, value max: 0.27669861912727356\n",
      "D grad l2-norm: 2.653090076730506, value max: 0.5773573517799377\n",
      "epoch: [89/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.112s / 5 iters, (0.022)\tData load 0.009s / 5 iters, (0.001735)\n",
      "Loss_D = 0.99942362 (ave = 1.06132674)\n",
      "Loss_G = 0.86464328 (ave = 0.87256669)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.7860203866483424, value max: 0.29064732789993286\n",
      "D grad l2-norm: 2.8569824671100497, value max: 0.5777546167373657\n",
      "epoch: [90/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.009s / 5 iters, (0.001881)\n",
      "Loss_D = 1.06601882 (ave = 1.05997975)\n",
      "Loss_G = 0.91761106 (ave = 0.90389357)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:41 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.8013745368460388, value max: 0.29286280274391174\n",
      "D grad l2-norm: 3.012301551142769, value max: 0.5995998382568359\n",
      "Epoch 90 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 90 FID Score: 0.000000\n",
      "epoch: [91/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.676s / 5 iters, (0.135)\tData load 0.627s / 5 iters, (0.125496)\n",
      "Loss_D = 1.03372145 (ave = 1.04407842)\n",
      "Loss_G = 0.95461982 (ave = 0.93344297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.795191747288319, value max: 0.2842850089073181\n",
      "D grad l2-norm: 3.1261176294332786, value max: 0.6140528321266174\n",
      "epoch: [92/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001618)\n",
      "Loss_D = 1.12324011 (ave = 1.03829279)\n",
      "Loss_G = 0.97596866 (ave = 0.97110704)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.895860339492286, value max: 0.2894614338874817\n",
      "D grad l2-norm: 3.2302114492824328, value max: 0.6222420930862427\n",
      "epoch: [93/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001565)\n",
      "Loss_D = 0.81781828 (ave = 0.99222112)\n",
      "Loss_G = 1.01550364 (ave = 1.00942764)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 2.9868026170271844, value max: 0.30410510301589966\n",
      "D grad l2-norm: 3.3976920954357603, value max: 0.636658787727356\n",
      "epoch: [94/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001584)\n",
      "Loss_D = 0.91689968 (ave = 0.99554188)\n",
      "Loss_G = 1.05640972 (ave = 1.03532646)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.0431899274003844, value max: 0.3052453398704529\n",
      "D grad l2-norm: 3.5300432589960735, value max: 0.6512896418571472\n",
      "epoch: [95/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001777)\n",
      "Loss_D = 0.97962809 (ave = 0.99932667)\n",
      "Loss_G = 1.06914330 (ave = 1.06118271)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.0432980704697834, value max: 0.2959335446357727\n",
      "D grad l2-norm: 3.57838902321176, value max: 0.6558167934417725\n",
      "epoch: [96/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001603)\n",
      "Loss_D = 1.06287289 (ave = 1.00542346)\n",
      "Loss_G = 1.09199560 (ave = 1.08779788)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1133157118217794, value max: 0.29041552543640137\n",
      "D grad l2-norm: 3.7314828070741544, value max: 0.6635189056396484\n",
      "epoch: [97/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.078s / 5 iters, (0.016)\tData load 0.008s / 5 iters, (0.001509)\n",
      "Loss_D = 0.90649527 (ave = 0.97994179)\n",
      "Loss_G = 1.12786269 (ave = 1.11712341)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.1296287421327382, value max: 0.3182247579097748\n",
      "D grad l2-norm: 3.764745933641757, value max: 0.675354540348053\n",
      "epoch: [98/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.015s / 5 iters, (0.002984)\n",
      "Loss_D = 0.89738953 (ave = 0.97063885)\n",
      "Loss_G = 1.15121984 (ave = 1.15010917)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.413899816297074, value max: 0.34975868463516235\n",
      "D grad l2-norm: 3.924575415262241, value max: 0.6826789975166321\n",
      "epoch: [99/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.017s / 5 iters, (0.003380)\n",
      "Loss_D = 0.93949008 (ave = 0.97941123)\n",
      "Loss_G = 1.13325727 (ave = 1.14813671)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.477836936716145, value max: 0.3652500808238983\n",
      "D grad l2-norm: 3.8124514443170177, value max: 0.6768767237663269\n",
      "epoch: [100/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001588)\n",
      "Loss_D = 0.98037136 (ave = 0.99705216)\n",
      "Loss_G = 1.12682939 (ave = 1.13054609)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:42 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.548331744536981, value max: 0.3593587875366211\n",
      "D grad l2-norm: 3.7915166846607025, value max: 0.6747816205024719\n",
      "Epoch 100 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 100 FID Score: 0.000000\n",
      "epoch: [101/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.860s / 5 iters, (0.172)\tData load 0.768s / 5 iters, (0.153563)\n",
      "Loss_D = 1.07475710 (ave = 1.02923838)\n",
      "Loss_G = 1.09472132 (ave = 1.10833075)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.8484478946439307, value max: 0.378589928150177\n",
      "D grad l2-norm: 3.9374219906147805, value max: 0.6634886860847473\n",
      "epoch: [102/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.095s / 5 iters, (0.019)\tData load 0.009s / 5 iters, (0.001764)\n",
      "Loss_D = 1.16642666 (ave = 1.05788109)\n",
      "Loss_G = 1.08250999 (ave = 1.09045050)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7998809095593082, value max: 0.397871732711792\n",
      "D grad l2-norm: 3.7918917112016683, value max: 0.6593634486198425\n",
      "epoch: [103/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.074s / 5 iters, (0.015)\tData load 0.015s / 5 iters, (0.003012)\n",
      "Loss_D = 1.20195651 (ave = 1.08269625)\n",
      "Loss_G = 1.05649495 (ave = 1.06384957)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.845809541536741, value max: 0.3999687731266022\n",
      "D grad l2-norm: 3.8494660908665677, value max: 0.650212287902832\n",
      "epoch: [104/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.076s / 5 iters, (0.015)\tData load 0.017s / 5 iters, (0.003314)\n",
      "Loss_D = 1.14985895 (ave = 1.09170210)\n",
      "Loss_G = 1.05705607 (ave = 1.05189693)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.808496348660862, value max: 0.39855167269706726\n",
      "D grad l2-norm: 3.8851781729412256, value max: 0.6505478024482727\n",
      "epoch: [105/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001462)\n",
      "Loss_D = 1.15607190 (ave = 1.09476249)\n",
      "Loss_G = 1.06398594 (ave = 1.05289841)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:43 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7692360995010876, value max: 0.3649906814098358\n",
      "D grad l2-norm: 3.899992391658828, value max: 0.6527369022369385\n",
      "epoch: [106/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001501)\n",
      "Loss_D = 1.06533098 (ave = 1.08547237)\n",
      "Loss_G = 1.05163872 (ave = 1.05523243)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6793554173343734, value max: 0.34509479999542236\n",
      "D grad l2-norm: 3.880198448308179, value max: 0.6486035585403442\n",
      "epoch: [107/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001686)\n",
      "Loss_D = 1.16060495 (ave = 1.09354708)\n",
      "Loss_G = 1.08311367 (ave = 1.07129729)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.625981566706128, value max: 0.31400030851364136\n",
      "D grad l2-norm: 3.9305615949600528, value max: 0.6596697568893433\n",
      "epoch: [108/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 1.06048298 (ave = 1.07105370)\n",
      "Loss_G = 1.08729994 (ave = 1.08033435)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.60255219634923, value max: 0.30914294719696045\n",
      "D grad l2-norm: 3.947216095850886, value max: 0.6610428690910339\n",
      "epoch: [109/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001683)\n",
      "Loss_D = 1.05492151 (ave = 1.06470459)\n",
      "Loss_G = 1.11900115 (ave = 1.10895858)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.70492756425898, value max: 0.29128170013427734\n",
      "D grad l2-norm: 4.1174731603911345, value max: 0.6720489859580994\n",
      "epoch: [110/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001590)\n",
      "Loss_D = 0.92604601 (ave = 1.03725488)\n",
      "Loss_G = 1.12530828 (ave = 1.12101026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.632528138248159, value max: 0.2724192440509796\n",
      "D grad l2-norm: 4.129578801552132, value max: 0.6740875244140625\n",
      "Epoch 110 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 110 FID Score: 0.000000\n",
      "epoch: [111/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.687s / 5 iters, (0.137)\tData load 0.635s / 5 iters, (0.127014)\n",
      "Loss_D = 1.04617560 (ave = 1.03629024)\n",
      "Loss_G = 1.16158426 (ave = 1.14280446)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:44 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.586193199875192, value max: 0.2726660370826721\n",
      "D grad l2-norm: 4.16732037624097, value max: 0.6858364343643188\n",
      "epoch: [112/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.140s / 5 iters, (0.028)\tData load 0.029s / 5 iters, (0.005707)\n",
      "Loss_D = 0.92648375 (ave = 1.00587313)\n",
      "Loss_G = 1.17213070 (ave = 1.16505308)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.570018772147674, value max: 0.2855614721775055\n",
      "D grad l2-norm: 4.286482655361528, value max: 0.689108669757843\n",
      "epoch: [113/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.071s / 5 iters, (0.014)\tData load 0.013s / 5 iters, (0.002602)\n",
      "Loss_D = 0.94061220 (ave = 0.98960415)\n",
      "Loss_G = 1.21518624 (ave = 1.19799955)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4247617755765485, value max: 0.2744762599468231\n",
      "D grad l2-norm: 4.274924457870525, value max: 0.7023003101348877\n",
      "epoch: [114/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001747)\n",
      "Loss_D = 1.04707706 (ave = 0.98015360)\n",
      "Loss_G = 1.24830008 (ave = 1.23344700)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4170830406916686, value max: 0.2850278615951538\n",
      "D grad l2-norm: 4.437101409572491, value max: 0.7121208906173706\n",
      "epoch: [115/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001669)\n",
      "Loss_D = 0.87748480 (ave = 0.93039023)\n",
      "Loss_G = 1.29033673 (ave = 1.27048891)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2582570652038156, value max: 0.289397269487381\n",
      "D grad l2-norm: 4.4817166465898595, value max: 0.7239595055580139\n",
      "epoch: [116/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001730)\n",
      "Loss_D = 0.91347051 (ave = 0.91043942)\n",
      "Loss_G = 1.34856284 (ave = 1.32786186)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.2106772674524766, value max: 0.27472126483917236\n",
      "D grad l2-norm: 4.538198416566248, value max: 0.7395308017730713\n",
      "epoch: [117/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001705)\n",
      "Loss_D = 0.92645615 (ave = 0.88054461)\n",
      "Loss_G = 1.39337552 (ave = 1.36901820)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.464180978286717, value max: 0.2935316562652588\n",
      "D grad l2-norm: 4.84863886967428, value max: 0.751090407371521\n",
      "epoch: [118/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001753)\n",
      "Loss_D = 0.78792000 (ave = 0.83860548)\n",
      "Loss_G = 1.39598787 (ave = 1.39689589)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.3126912491517997, value max: 0.3113447427749634\n",
      "D grad l2-norm: 4.563542019923719, value max: 0.7517976760864258\n",
      "epoch: [119/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001655)\n",
      "Loss_D = 0.72056675 (ave = 0.81202970)\n",
      "Loss_G = 1.43304765 (ave = 1.42427115)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.4927883942585582, value max: 0.3171522915363312\n",
      "D grad l2-norm: 4.656146660737562, value max: 0.7605836987495422\n",
      "epoch: [120/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.083s / 5 iters, (0.017)\tData load 0.010s / 5 iters, (0.002084)\n",
      "Loss_D = 0.70074463 (ave = 0.79612008)\n",
      "Loss_G = 1.41148615 (ave = 1.42592874)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:45 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.6549322522923964, value max: 0.342035174369812\n",
      "D grad l2-norm: 4.587779605026456, value max: 0.7552585601806641\n",
      "Epoch 120 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 120 FID Score: 0.000000\n",
      "epoch: [121/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.940s / 5 iters, (0.188)\tData load 0.889s / 5 iters, (0.177805)\n",
      "Loss_D = 0.79383922 (ave = 0.80045856)\n",
      "Loss_G = 1.39987171 (ave = 1.41647365)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7426220717352945, value max: 0.35684138536453247\n",
      "D grad l2-norm: 4.502007066326444, value max: 0.7524392008781433\n",
      "epoch: [122/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001703)\n",
      "Loss_D = 0.71523988 (ave = 0.78654071)\n",
      "Loss_G = 1.38759196 (ave = 1.39899950)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.807987696550488, value max: 0.3713529109954834\n",
      "D grad l2-norm: 4.361441672550373, value max: 0.7493493556976318\n",
      "epoch: [123/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 0.78259206 (ave = 0.79299811)\n",
      "Loss_G = 1.34679854 (ave = 1.36346405)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.152475334093304, value max: 0.38548004627227783\n",
      "D grad l2-norm: 4.387936711312267, value max: 0.7387255430221558\n",
      "epoch: [124/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001564)\n",
      "Loss_D = 0.65874481 (ave = 0.78996472)\n",
      "Loss_G = 1.33577812 (ave = 1.33878324)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.203585568739932, value max: 0.4024030268192291\n",
      "D grad l2-norm: 4.236491967329517, value max: 0.7360036373138428\n",
      "epoch: [125/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.066s / 5 iters, (0.013)\tData load 0.011s / 5 iters, (0.002260)\n",
      "Loss_D = 0.83419347 (ave = 0.82384944)\n",
      "Loss_G = 1.25010550 (ave = 1.28012776)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.478616528071902, value max: 0.40782150626182556\n",
      "D grad l2-norm: 4.243163369057183, value max: 0.7121919989585876\n",
      "epoch: [126/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001573)\n",
      "Loss_D = 0.90459251 (ave = 0.85156198)\n",
      "Loss_G = 1.20370305 (ave = 1.23860824)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.467428271604377, value max: 0.40423911809921265\n",
      "D grad l2-norm: 4.0593538960767335, value max: 0.6985152959823608\n",
      "epoch: [127/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.011s / 5 iters, (0.002284)\n",
      "Loss_D = 0.88303626 (ave = 0.86946701)\n",
      "Loss_G = 1.15961611 (ave = 1.18175886)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:46 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.462552083734711, value max: 0.4327623248100281\n",
      "D grad l2-norm: 4.085592106342977, value max: 0.6847434639930725\n",
      "epoch: [128/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001600)\n",
      "Loss_D = 0.88701278 (ave = 0.88114572)\n",
      "Loss_G = 1.17309427 (ave = 1.16558230)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.18357304570246, value max: 0.43696945905685425\n",
      "D grad l2-norm: 3.9511355693401087, value max: 0.6892167329788208\n",
      "epoch: [129/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.011s / 5 iters, (0.002287)\n",
      "Loss_D = 0.86520141 (ave = 0.87427540)\n",
      "Loss_G = 1.17867327 (ave = 1.16737819)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.17939763570721, value max: 0.44788673520088196\n",
      "D grad l2-norm: 4.042125763327474, value max: 0.6911050081253052\n",
      "epoch: [130/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001702)\n",
      "Loss_D = 0.74758506 (ave = 0.85416547)\n",
      "Loss_G = 1.19084275 (ave = 1.18112032)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.098401390074738, value max: 0.4517039656639099\n",
      "D grad l2-norm: 3.983948878624196, value max: 0.6947728991508484\n",
      "Epoch 130 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 130 FID Score: 0.000000\n",
      "epoch: [131/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.731s / 5 iters, (0.146)\tData load 0.677s / 5 iters, (0.135323)\n",
      "Loss_D = 0.93311620 (ave = 0.88067894)\n",
      "Loss_G = 1.17526364 (ave = 1.18064060)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.214355492340056, value max: 0.4427846372127533\n",
      "D grad l2-norm: 4.007758209894133, value max: 0.6895623207092285\n",
      "epoch: [132/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001722)\n",
      "Loss_D = 0.83317089 (ave = 0.87200420)\n",
      "Loss_G = 1.15233505 (ave = 1.15964537)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:47 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.3445664924305, value max: 0.4342467188835144\n",
      "D grad l2-norm: 3.9574900478354227, value max: 0.6820367574691772\n",
      "epoch: [133/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.106s / 5 iters, (0.021)\tData load 0.008s / 5 iters, (0.001696)\n",
      "Loss_D = 0.93599010 (ave = 0.90008377)\n",
      "Loss_G = 1.12408984 (ave = 1.13304474)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.493517014764298, value max: 0.40734463930130005\n",
      "D grad l2-norm: 3.9843899553623014, value max: 0.6724940538406372\n",
      "epoch: [134/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.110s / 5 iters, (0.022)\tData load 0.018s / 5 iters, (0.003614)\n",
      "Loss_D = 0.94175017 (ave = 0.92254338)\n",
      "Loss_G = 1.07499099 (ave = 1.09028890)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.246658561596405, value max: 0.3839017450809479\n",
      "D grad l2-norm: 3.79866739132222, value max: 0.6560363173484802\n",
      "epoch: [135/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.114s / 5 iters, (0.023)\tData load 0.023s / 5 iters, (0.004695)\n",
      "Loss_D = 0.83234352 (ave = 0.92182057)\n",
      "Loss_G = 1.06146312 (ave = 1.07033074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.089568873986092, value max: 0.3582180142402649\n",
      "D grad l2-norm: 3.741039547769034, value max: 0.6510661840438843\n",
      "epoch: [136/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.142s / 5 iters, (0.028)\tData load 0.023s / 5 iters, (0.004631)\n",
      "Loss_D = 0.95208859 (ave = 0.95129465)\n",
      "Loss_G = 1.05848777 (ave = 1.06072187)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9243113957407063, value max: 0.39024117588996887\n",
      "D grad l2-norm: 3.7275525495775264, value max: 0.6502258777618408\n",
      "epoch: [137/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.135s / 5 iters, (0.027)\tData load 0.015s / 5 iters, (0.003040)\n",
      "Loss_D = 1.04231215 (ave = 0.96015511)\n",
      "Loss_G = 1.07272065 (ave = 1.06592081)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.89368875208435, value max: 0.40607932209968567\n",
      "D grad l2-norm: 3.7979301395324185, value max: 0.6557824611663818\n",
      "epoch: [138/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.140s / 5 iters, (0.028)\tData load 0.024s / 5 iters, (0.004801)\n",
      "Loss_D = 1.07265425 (ave = 0.95486563)\n",
      "Loss_G = 1.06288159 (ave = 1.05794988)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.8895457835019367, value max: 0.4242872893810272\n",
      "D grad l2-norm: 3.8129047076905946, value max: 0.6517966389656067\n",
      "epoch: [139/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.079s / 5 iters, (0.016)\tData load 0.013s / 5 iters, (0.002590)\n",
      "Loss_D = 1.03257740 (ave = 0.94791979)\n",
      "Loss_G = 1.04980302 (ave = 1.06458747)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.851976252885332, value max: 0.4407441318035126\n",
      "D grad l2-norm: 3.762301838927883, value max: 0.6474167108535767\n",
      "epoch: [140/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002499)\n",
      "Loss_D = 0.98936403 (ave = 0.93794645)\n",
      "Loss_G = 1.08337593 (ave = 1.07439954)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:48 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.024610914401749, value max: 0.4430318772792816\n",
      "D grad l2-norm: 3.9373159921206624, value max: 0.6581286787986755\n",
      "Epoch 140 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 140 FID Score: 0.000000\n",
      "epoch: [141/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.698s / 5 iters, (0.140)\tData load 0.650s / 5 iters, (0.129966)\n",
      "Loss_D = 0.85783315 (ave = 0.92027746)\n",
      "Loss_G = 1.05985749 (ave = 1.06926322)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.171429944256203, value max: 0.44208937883377075\n",
      "D grad l2-norm: 4.072370985271103, value max: 0.6504509449005127\n",
      "epoch: [142/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001552)\n",
      "Loss_D = 0.96581787 (ave = 0.93022633)\n",
      "Loss_G = 1.08412647 (ave = 1.08553026)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.016829088446596, value max: 0.4166063964366913\n",
      "D grad l2-norm: 4.081092896449723, value max: 0.6596869230270386\n",
      "epoch: [143/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001599)\n",
      "Loss_D = 0.79146063 (ave = 0.89663410)\n",
      "Loss_G = 1.11881030 (ave = 1.10901506)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9932429443034363, value max: 0.37621375918388367\n",
      "D grad l2-norm: 4.220044572965213, value max: 0.6714198589324951\n",
      "epoch: [144/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001580)\n",
      "Loss_D = 0.83097726 (ave = 0.88115120)\n",
      "Loss_G = 1.16965270 (ave = 1.15394521)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.020321766225179, value max: 0.3501591086387634\n",
      "D grad l2-norm: 4.414557929686407, value max: 0.6876521706581116\n",
      "epoch: [145/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001532)\n",
      "Loss_D = 0.86311728 (ave = 0.86838095)\n",
      "Loss_G = 1.21221530 (ave = 1.20360010)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9005970808091743, value max: 0.3297223150730133\n",
      "D grad l2-norm: 4.438617776860144, value max: 0.7011268138885498\n",
      "epoch: [146/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001591)\n",
      "Loss_D = 0.90109837 (ave = 0.85231420)\n",
      "Loss_G = 1.25110769 (ave = 1.24665246)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9848974308441223, value max: 0.3178050220012665\n",
      "D grad l2-norm: 4.607129127575377, value max: 0.7125230431556702\n",
      "epoch: [147/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.072s / 5 iters, (0.014)\tData load 0.008s / 5 iters, (0.001695)\n",
      "Loss_D = 0.77466559 (ave = 0.82257854)\n",
      "Loss_G = 1.27829576 (ave = 1.25954247)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.08331437457196, value max: 0.3412300944328308\n",
      "D grad l2-norm: 4.585262677087577, value max: 0.7201118469238281\n",
      "epoch: [148/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.073s / 5 iters, (0.015)\tData load 0.008s / 5 iters, (0.001674)\n",
      "Loss_D = 0.86570132 (ave = 0.82656686)\n",
      "Loss_G = 1.27894461 (ave = 1.28072667)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:49 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.201431515704973, value max: 0.37809300422668457\n",
      "D grad l2-norm: 4.733941031642108, value max: 0.7206711173057556\n",
      "epoch: [149/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.050s / 5 iters, (0.010)\tData load 0.007s / 5 iters, (0.001488)\n",
      "Loss_D = 0.79092741 (ave = 0.80713245)\n",
      "Loss_G = 1.30590391 (ave = 1.29799895)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.1878320094537, value max: 0.41548991203308105\n",
      "D grad l2-norm: 4.6877397093468245, value max: 0.7276107668876648\n",
      "epoch: [150/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001408)\n",
      "Loss_D = 0.81853330 (ave = 0.80900186)\n",
      "Loss_G = 1.27903676 (ave = 1.28535023)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.302457626808394, value max: 0.4563830494880676\n",
      "D grad l2-norm: 4.6333082998915165, value max: 0.7203856706619263\n",
      "Epoch 150 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 150 FID Score: 0.000000\n",
      "epoch: [151/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.711s / 5 iters, (0.142)\tData load 0.664s / 5 iters, (0.132743)\n",
      "Loss_D = 0.95937455 (ave = 0.83082936)\n",
      "Loss_G = 1.26102674 (ave = 1.26809838)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.38813100547431, value max: 0.4796757996082306\n",
      "D grad l2-norm: 4.5931831288531475, value max: 0.7152357697486877\n",
      "epoch: [152/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.007s / 5 iters, (0.001426)\n",
      "Loss_D = 0.90768182 (ave = 0.82784151)\n",
      "Loss_G = 1.23098040 (ave = 1.25099466)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.423701798316438, value max: 0.5009298920631409\n",
      "D grad l2-norm: 4.467557902532161, value max: 0.7066165804862976\n",
      "epoch: [153/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.053s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001565)\n",
      "Loss_D = 0.82646132 (ave = 0.82707890)\n",
      "Loss_G = 1.22864616 (ave = 1.22783058)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.638924547048151, value max: 0.5200854539871216\n",
      "D grad l2-norm: 4.51924578385547, value max: 0.7057114839553833\n",
      "epoch: [154/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001619)\n",
      "Loss_D = 0.76457882 (ave = 0.83145483)\n",
      "Loss_G = 1.16289222 (ave = 1.19302902)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:50 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.581769028677814, value max: 0.5346323251724243\n",
      "D grad l2-norm: 4.232364529081, value max: 0.6855993270874023\n",
      "epoch: [155/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001566)\n",
      "Loss_D = 0.95637429 (ave = 0.87012973)\n",
      "Loss_G = 1.15333319 (ave = 1.15788934)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.566990007205967, value max: 0.5080969929695129\n",
      "D grad l2-norm: 4.170628711694505, value max: 0.6824345588684082\n",
      "epoch: [156/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001609)\n",
      "Loss_D = 0.90924197 (ave = 0.87377310)\n",
      "Loss_G = 1.10854590 (ave = 1.13981297)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.6566935259881514, value max: 0.5238057971000671\n",
      "D grad l2-norm: 4.062476873365561, value max: 0.6676852703094482\n",
      "epoch: [157/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.091s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001663)\n",
      "Loss_D = 0.82494915 (ave = 0.88286595)\n",
      "Loss_G = 1.07820427 (ave = 1.10287919)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.779206698421337, value max: 0.5380393862724304\n",
      "D grad l2-norm: 4.046427175253544, value max: 0.6570689082145691\n",
      "epoch: [158/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001550)\n",
      "Loss_D = 0.91283083 (ave = 0.92688673)\n",
      "Loss_G = 1.05223536 (ave = 1.06548729)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.763841430889261, value max: 0.5318933725357056\n",
      "D grad l2-norm: 3.9251138565294283, value max: 0.6481157541275024\n",
      "epoch: [159/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.087s / 5 iters, (0.017)\tData load 0.008s / 5 iters, (0.001567)\n",
      "Loss_D = 0.94675475 (ave = 0.95297025)\n",
      "Loss_G = 1.00366688 (ave = 1.03361666)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.626279083548654, value max: 0.5087803602218628\n",
      "D grad l2-norm: 3.7881078201757705, value max: 0.630966067314148\n",
      "epoch: [160/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.088s / 5 iters, (0.018)\tData load 0.008s / 5 iters, (0.001589)\n",
      "Loss_D = 0.97028971 (ave = 0.98197699)\n",
      "Loss_G = 0.97956842 (ave = 0.99067229)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:51 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.525505339889217, value max: 0.4908945560455322\n",
      "D grad l2-norm: 3.7445672687073563, value max: 0.6213196516036987\n",
      "Epoch 160 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 160 FID Score: 0.000000\n",
      "epoch: [161/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.818s / 5 iters, (0.164)\tData load 0.771s / 5 iters, (0.154158)\n",
      "Loss_D = 0.94715965 (ave = 0.99967623)\n",
      "Loss_G = 0.99621630 (ave = 0.98075235)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.474671623111346, value max: 0.4721571207046509\n",
      "D grad l2-norm: 3.752891284378654, value max: 0.6272838711738586\n",
      "epoch: [162/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.054s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001606)\n",
      "Loss_D = 1.05570173 (ave = 1.03181540)\n",
      "Loss_G = 0.96963686 (ave = 0.97957940)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.246884214335018, value max: 0.43032562732696533\n",
      "D grad l2-norm: 3.7013078893093874, value max: 0.6176430583000183\n",
      "epoch: [163/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001580)\n",
      "Loss_D = 0.86568761 (ave = 1.01158729)\n",
      "Loss_G = 1.00060081 (ave = 0.97582625)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.143068735280443, value max: 0.39890819787979126\n",
      "D grad l2-norm: 3.776307060928446, value max: 0.6293396353721619\n",
      "epoch: [164/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.089s / 5 iters, (0.018)\tData load 0.009s / 5 iters, (0.001852)\n",
      "Loss_D = 1.01468635 (ave = 1.03196282)\n",
      "Loss_G = 0.98375607 (ave = 0.98817338)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.99042333258406, value max: 0.3727121949195862\n",
      "D grad l2-norm: 3.733155955610441, value max: 0.6230489015579224\n",
      "epoch: [165/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.012s / 5 iters, (0.002379)\n",
      "Loss_D = 1.06458235 (ave = 1.03334413)\n",
      "Loss_G = 1.01824641 (ave = 1.00269763)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.88551204031085, value max: 0.3538326919078827\n",
      "D grad l2-norm: 3.828528594879047, value max: 0.6357417702674866\n",
      "epoch: [166/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.10926270 (ave = 1.03575230)\n",
      "Loss_G = 1.03581762 (ave = 1.02556486)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.7982236476029656, value max: 0.3208017349243164\n",
      "D grad l2-norm: 4.006144843705805, value max: 0.6430137753486633\n",
      "epoch: [167/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001590)\n",
      "Loss_D = 1.00558960 (ave = 0.99429306)\n",
      "Loss_G = 1.09121358 (ave = 1.07584236)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.645207600108177, value max: 0.3042527437210083\n",
      "D grad l2-norm: 4.060092201138018, value max: 0.6620627045631409\n",
      "epoch: [168/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001582)\n",
      "Loss_D = 0.92446613 (ave = 0.96541305)\n",
      "Loss_G = 1.14588594 (ave = 1.11940293)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.77130192149597, value max: 0.3177107572555542\n",
      "D grad l2-norm: 4.275012185290372, value max: 0.6801251769065857\n",
      "epoch: [169/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001589)\n",
      "Loss_D = 1.03513336 (ave = 0.95495720)\n",
      "Loss_G = 1.19202709 (ave = 1.16877069)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 3.9045867251823467, value max: 0.3445594310760498\n",
      "D grad l2-norm: 4.388670084542938, value max: 0.6943962574005127\n",
      "epoch: [170/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.052s / 5 iters, (0.010)\tData load 0.008s / 5 iters, (0.001510)\n",
      "Loss_D = 1.04906750 (ave = 0.94133675)\n",
      "Loss_G = 1.21306229 (ave = 1.19395931)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:52 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.092549268132476, value max: 0.371494323015213\n",
      "D grad l2-norm: 4.630633530992646, value max: 0.7006204724311829\n",
      "Epoch 170 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 170 FID Score: 0.000000\n",
      "epoch: [171/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.735s / 5 iters, (0.147)\tData load 0.687s / 5 iters, (0.137459)\n",
      "Loss_D = 0.72727621 (ave = 0.88804245)\n",
      "Loss_G = 1.21244681 (ave = 1.21377172)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.318403553189778, value max: 0.38600924611091614\n",
      "D grad l2-norm: 4.833301594577004, value max: 0.7009944915771484\n",
      "epoch: [172/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.118s / 5 iters, (0.024)\tData load 0.008s / 5 iters, (0.001657)\n",
      "Loss_D = 0.80387104 (ave = 0.88401635)\n",
      "Loss_G = 1.27489269 (ave = 1.24087052)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.456511031992398, value max: 0.40799006819725037\n",
      "D grad l2-norm: 4.974658391956293, value max: 0.7188969850540161\n",
      "epoch: [173/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.070s / 5 iters, (0.014)\tData load 0.015s / 5 iters, (0.002981)\n",
      "Loss_D = 0.84369606 (ave = 0.88564689)\n",
      "Loss_G = 1.26621008 (ave = 1.25295489)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.645285772690191, value max: 0.45227333903312683\n",
      "D grad l2-norm: 4.942785984734736, value max: 0.7162850499153137\n",
      "epoch: [174/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.127s / 5 iters, (0.025)\tData load 0.008s / 5 iters, (0.001688)\n",
      "Loss_D = 0.86189234 (ave = 0.88813976)\n",
      "Loss_G = 1.26658714 (ave = 1.25816643)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 4.979296120350573, value max: 0.47831326723098755\n",
      "D grad l2-norm: 5.144852608972251, value max: 0.7164271473884583\n",
      "epoch: [175/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.128s / 5 iters, (0.026)\tData load 0.009s / 5 iters, (0.001751)\n",
      "Loss_D = 0.79238558 (ave = 0.88175465)\n",
      "Loss_G = 1.25419474 (ave = 1.25812995)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:53 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.073515813084753, value max: 0.5192438364028931\n",
      "D grad l2-norm: 5.074311029003199, value max: 0.7129932641983032\n",
      "epoch: [176/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.097s / 5 iters, (0.019)\tData load 0.013s / 5 iters, (0.002628)\n",
      "Loss_D = 0.94565272 (ave = 0.90820042)\n",
      "Loss_G = 1.22910643 (ave = 1.24087203)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.370320136260029, value max: 0.5620126724243164\n",
      "D grad l2-norm: 5.139919669365696, value max: 0.7050617337226868\n",
      "epoch: [177/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.061s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001648)\n",
      "Loss_D = 0.97964805 (ave = 0.92564918)\n",
      "Loss_G = 1.22654641 (ave = 1.22865157)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.547942714507948, value max: 0.586644172668457\n",
      "D grad l2-norm: 5.16008530194166, value max: 0.7039980888366699\n",
      "epoch: [178/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.069s / 5 iters, (0.014)\tData load 0.009s / 5 iters, (0.001703)\n",
      "Loss_D = 0.87773955 (ave = 0.92990330)\n",
      "Loss_G = 1.18903494 (ave = 1.20926149)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.937261896737853, value max: 0.6257497072219849\n",
      "D grad l2-norm: 5.27141701196789, value max: 0.6919655799865723\n",
      "epoch: [179/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.101s / 5 iters, (0.020)\tData load 0.023s / 5 iters, (0.004674)\n",
      "Loss_D = 0.96154851 (ave = 0.96095927)\n",
      "Loss_G = 1.16986752 (ave = 1.17309656)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.124778297773973, value max: 0.6777502298355103\n",
      "D grad l2-norm: 5.2168008768902485, value max: 0.6858137249946594\n",
      "epoch: [180/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.062s / 5 iters, (0.012)\tData load 0.009s / 5 iters, (0.001724)\n",
      "Loss_D = 1.11067176 (ave = 1.00603800)\n",
      "Loss_G = 1.11396766 (ave = 1.14692001)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:54 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.315336180762025, value max: 0.7252057194709778\n",
      "D grad l2-norm: 5.181771737757571, value max: 0.6675277948379517\n",
      "Epoch 180 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 180 FID Score: 0.000000\n",
      "epoch: [181/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.722s / 5 iters, (0.144)\tData load 0.674s / 5 iters, (0.134814)\n",
      "Loss_D = 0.93980777 (ave = 1.00679463)\n",
      "Loss_G = 1.08724034 (ave = 1.10635772)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.294609528481623, value max: 0.7592225670814514\n",
      "D grad l2-norm: 5.0262453773668785, value max: 0.657638669013977\n",
      "epoch: [182/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.057s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001605)\n",
      "Loss_D = 1.09833288 (ave = 1.05917497)\n",
      "Loss_G = 1.06476879 (ave = 1.07155907)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.402124786615009, value max: 0.8188981413841248\n",
      "D grad l2-norm: 4.931720142742217, value max: 0.6506985425949097\n",
      "epoch: [183/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.100s / 5 iters, (0.020)\tData load 0.008s / 5 iters, (0.001620)\n",
      "Loss_D = 0.90841681 (ave = 1.06641179)\n",
      "Loss_G = 1.06637180 (ave = 1.06814098)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.207608646131599, value max: 0.8069244623184204\n",
      "D grad l2-norm: 4.840469447386238, value max: 0.6506876945495605\n",
      "epoch: [184/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.092s / 5 iters, (0.018)\tData load 0.021s / 5 iters, (0.004160)\n",
      "Loss_D = 1.12393856 (ave = 1.11036575)\n",
      "Loss_G = 1.02328932 (ave = 1.03530915)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.083394510017532, value max: 0.7920260429382324\n",
      "D grad l2-norm: 4.773171365036406, value max: 0.6361019611358643\n",
      "epoch: [185/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001644)\n",
      "Loss_D = 1.12531900 (ave = 1.13508730)\n",
      "Loss_G = 1.03864884 (ave = 1.03743181)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 6.079668488834908, value max: 0.779686450958252\n",
      "D grad l2-norm: 4.778747084433031, value max: 0.6417347192764282\n",
      "epoch: [186/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001746)\n",
      "Loss_D = 1.26532114 (ave = 1.16530912)\n",
      "Loss_G = 1.02642274 (ave = 1.02330461)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.737466735591269, value max: 0.7236839532852173\n",
      "D grad l2-norm: 4.597972613596527, value max: 0.6369929313659668\n",
      "epoch: [187/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.065s / 5 iters, (0.013)\tData load 0.009s / 5 iters, (0.001784)\n",
      "Loss_D = 1.17548776 (ave = 1.17624290)\n",
      "Loss_G = 0.98655140 (ave = 0.99161178)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.709759210666421, value max: 0.6916308999061584\n",
      "D grad l2-norm: 4.492974444125057, value max: 0.6227709054946899\n",
      "epoch: [188/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.063s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001665)\n",
      "Loss_D = 1.28768730 (ave = 1.20352707)\n",
      "Loss_G = 0.95049989 (ave = 0.97462234)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.353870093479907, value max: 0.611743688583374\n",
      "D grad l2-norm: 4.259026713306458, value max: 0.6087437272071838\n",
      "epoch: [189/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001632)\n",
      "Loss_D = 1.23210716 (ave = 1.21317585)\n",
      "Loss_G = 0.96555090 (ave = 0.95003955)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.39486279160484, value max: 0.5948984622955322\n",
      "D grad l2-norm: 4.3106835445448715, value max: 0.6147818565368652\n",
      "epoch: [190/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.060s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001691)\n",
      "Loss_D = 1.07800770 (ave = 1.20598834)\n",
      "Loss_G = 0.96648103 (ave = 0.94825631)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:55 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.051485942542376, value max: 0.5377224087715149\n",
      "D grad l2-norm: 4.180606035020013, value max: 0.6153041124343872\n",
      "Epoch 190 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 190 FID Score: 0.000000\n",
      "epoch: [191/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.931s / 5 iters, (0.186)\tData load 0.882s / 5 iters, (0.176315)\n",
      "Loss_D = 1.16604865 (ave = 1.21069131)\n",
      "Loss_G = 0.96792543 (ave = 0.94672502)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.1011602829613905, value max: 0.5006143450737\n",
      "D grad l2-norm: 4.303495338060241, value max: 0.6156090497970581\n",
      "epoch: [192/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.064s / 5 iters, (0.013)\tData load 0.007s / 5 iters, (0.001495)\n",
      "Loss_D = 1.45439100 (ave = 1.24805698)\n",
      "Loss_G = 0.97683543 (ave = 0.97328074)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.124946500753651, value max: 0.4683700501918793\n",
      "D grad l2-norm: 4.327211501006233, value max: 0.6197856068611145\n",
      "epoch: [193/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.018s / 5 iters, (0.003602)\n",
      "Loss_D = 1.36258233 (ave = 1.23841801)\n",
      "Loss_G = 0.98268104 (ave = 0.98427974)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.327512072952338, value max: 0.4461875855922699\n",
      "D grad l2-norm: 4.482554517670937, value max: 0.6224220991134644\n",
      "epoch: [194/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001596)\n",
      "Loss_D = 1.34696794 (ave = 1.22340529)\n",
      "Loss_G = 1.00527883 (ave = 0.99919028)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.220229936758347, value max: 0.3971879780292511\n",
      "D grad l2-norm: 4.487931063560053, value max: 0.6310305595397949\n",
      "epoch: [195/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.067s / 5 iters, (0.013)\tData load 0.008s / 5 iters, (0.001616)\n",
      "Loss_D = 0.88073158 (ave = 1.14541447)\n",
      "Loss_G = 1.01500726 (ave = 1.00834790)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.159677266250515, value max: 0.3701130747795105\n",
      "D grad l2-norm: 4.670219401750884, value max: 0.635295569896698\n",
      "epoch: [196/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.055s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001630)\n",
      "Loss_D = 1.20465446 (ave = 1.15414655)\n",
      "Loss_G = 1.08056676 (ave = 1.05589037)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.09096806923052, value max: 0.387879878282547\n",
      "D grad l2-norm: 4.814589527770176, value max: 0.6576569080352783\n",
      "epoch: [197/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.059s / 5 iters, (0.012)\tData load 0.008s / 5 iters, (0.001607)\n",
      "Loss_D = 1.12619114 (ave = 1.10659022)\n",
      "Loss_G = 1.15455937 (ave = 1.12722561)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:56 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.133696740866472, value max: 0.40840592980384827\n",
      "D grad l2-norm: 4.996272068283518, value max: 0.6827612519264221\n",
      "epoch: [198/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.056s / 5 iters, (0.011)\tData load 0.008s / 5 iters, (0.001660)\n",
      "Loss_D = 0.90070927 (ave = 1.03352864)\n",
      "Loss_G = 1.17968118 (ave = 1.17877009)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.155552473239632, value max: 0.42270368337631226\n",
      "D grad l2-norm: 5.213072190327972, value max: 0.6910867094993591\n",
      "epoch: [199/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.090s / 5 iters, (0.018)\tData load 0.013s / 5 iters, (0.002687)\n",
      "Loss_D = 0.85179543 (ave = 0.99228411)\n",
      "Loss_G = 1.24431860 (ave = 1.21484411)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.129921741115655, value max: 0.43308138847351074\n",
      "D grad l2-norm: 5.382094891554319, value max: 0.7098719477653503\n",
      "epoch: [200/200] iteration: [5/5]\tLearning rate: 0.0001\n",
      "Time 0.068s / 5 iters, (0.014)\tData load 0.015s / 5 iters, (0.002947)\n",
      "Loss_D = 0.85516030 (ave = 0.95965338)\n",
      "Loss_G = 1.30031812 (ave = 1.28116307)\n",
      "Loss_GN = 0.00000000 (ave = 0.00000000)\n",
      "\n",
      "2025-05-25 20:36:57 -----------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "G grad l2-norm: 5.148840754192402, value max: 0.43558555841445923\n",
      "D grad l2-norm: 5.441785154640044, value max: 0.72608882188797\n",
      "Epoch 200 Inception Score: mean 0.000000 std 0.000000\n",
      "Epoch 200 FID Score: 0.000000\n",
      "üìÑ All metrics saved to 'price_level_evaluation_metrics.csv'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-912826524160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;31m# üì¶ Generate Boxplots for Each Asset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "!pip install torch easydict\n",
    "\n",
    "# üì¶ Environment Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from easydict import EasyDict\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from scipy.stats import skew, kurtosis, jarque_bera, ks_2samp\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# üìà Load and Preprocess Data\n",
    "# Fit scaler on returns\n",
    "raw_df = pd.read_csv(\"raw (FX + EQ).csv\").dropna()\n",
    "raw_returns = raw_df.pct_change().dropna().values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(raw_returns)\n",
    "\n",
    "\n",
    "class FXEQGenerator(nn.Module):\n",
    "    def __init__(self, z_size=100, out_dim=20*1):  # 1 asset\n",
    "        super(FXEQGenerator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_size, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z).view(-1, 20, 1)\n",
    "\n",
    "\n",
    "\n",
    "class FXEQDiscriminator(nn.Module):\n",
    "    def __init__(self, in_dim=20*1):\n",
    "        super(FXEQDiscriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "\n",
    "class FXEQDataset(Dataset):\n",
    "    def __init__(self, csv_path, window_size=20, scaler=None, asset_index=0, split='train', split_ratio=0.65):\n",
    "        self.data = pd.read_csv(csv_path).dropna()\n",
    "        self.returns = self.data.pct_change().dropna().values[:, asset_index]  # ‚Üê Only one asset\n",
    "        self.returns = self.returns.reshape(-1, 1)  # keep 2D for scaler\n",
    "\n",
    "        # Split index\n",
    "        split_point = int(len(self.returns) * split_ratio)\n",
    "        if split == 'train':\n",
    "            self.returns = self.returns[:split_point]\n",
    "        elif split == 'test':\n",
    "            self.returns = self.returns[split_point:]\n",
    "\n",
    "        if scaler is not None:\n",
    "            self.returns = scaler.transform(self.returns)\n",
    "\n",
    "        self.returns = self.returns.squeeze()  # back to 1D\n",
    "        self.window_size = window_size\n",
    "        self.samples = [self.returns[i:i+window_size] for i in range(len(self.returns) - window_size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.samples[idx], dtype=torch.float32).unsqueeze(1)  # shape: [window, 1]\n",
    "\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint'):\n",
    "    torch.save(state, filename + '.pth.tar')\n",
    "\n",
    "def to_tensor(x):\n",
    "    return x.clone().detach().to(device)\n",
    "\n",
    "\n",
    "def parse():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \"\"\"\n",
    "    Hyper-parameter for Stochastic Gradient Hamiltonian Monte Carlo\n",
    "    \"\"\"\n",
    "    parser.add_argument('--sghmc_alpha', default=0.01, type=int, dest='sghmc_alpha', help='number of generators')\n",
    "    parser.add_argument('--g_noise_loss_lambda', default=3e-2, type=float, dest='g_noise_loss_lambda')\n",
    "    parser.add_argument('--d_noise_loss_lambda', default=3e-2, type=float, dest='d_noise_loss_lambda')\n",
    "    parser.add_argument('--d_hist_loss_lambda', default=1.0, type=float, dest='d_hist_loss_lambda')\n",
    "    \"\"\"\n",
    "    GAN objectives\n",
    "    NS: original GAN (Non-saturating version)\n",
    "    MM: original GAN (Min-max version)\n",
    "    W: Wasserstein GAN\n",
    "    LS: Least-Square GAN\n",
    "    \"\"\"\n",
    "    parser.add_argument('--gan_obj', default='NS', type=str, dest='gan_obj', help='[NS | MM | LS | W]')\n",
    "\n",
    "    \"\"\"\n",
    "    Paths\n",
    "    \"\"\"\n",
    "    parser.add_argument('--dataset', default='fxeq', type=str, dest='dataset',\n",
    "                        help='dataset: [cifar10, stl10, imagenet]')\n",
    "    parser.add_argument('--save_dir', default='none', type=str, dest='save_dir', help='save_path')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def construct_model(args, config):\n",
    "    '''\n",
    "    :param args: Experiment Information\n",
    "    :param config: Neural Network Architecture Configurations\n",
    "    :return:\n",
    "        G: generator structure\n",
    "        D: discriminator structure\n",
    "    '''\n",
    "    D_unbound_output = args.gan_obj in ['W', 'LS']\n",
    "    if config.image_size == 32:\n",
    "        G = multi_generator_32(z_size=config.z_size, out_size=config.channel_size, ngf=config.ngf,\n",
    "                               num_gens=config.num_gens).to(device)\n",
    "        D = multi_discriminator_with_history(in_size=config.channel_size, ndf=config.ndf, num_discs=config.num_discs,\n",
    "                                             unbound_output=D_unbound_output).to(device)\n",
    "    if config.image_size == 48:\n",
    "        G = multi_generator_48(z_size=config.z_size, out_size=config.channel_size, ngf=config.ngf,\n",
    "                               num_gens=config.num_gens).to(device)\n",
    "        D = multi_discriminator_48_with_history(in_size=config.channel_size, ndf=config.ndf, num_discs=config.num_discs,\n",
    "                                                unbound_output=D_unbound_output).to(device)\n",
    "    if args.dataset == 'fxeq':\n",
    "        G = FXEQGenerator(z_size=config.z_size).to(device)\n",
    "        D = FXEQDiscriminator().to(device)\n",
    "\n",
    "\n",
    "    print('G #parameters: ', count_parameters(G))\n",
    "    print('D #parameters: ', count_parameters(D))\n",
    "    return G, D\n",
    "\n",
    "\n",
    "def train_net(G, D, args, config):\n",
    "    is_multi_g = hasattr(G, 'gs')\n",
    "    is_multi_d = hasattr(D, 'ds') or hasattr(D, 'forward_by_hist')\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    noise_std = np.sqrt(2 * args.sghmc_alpha)\n",
    "    G_noise_sampler = [get_sghmc_noise(g) for g in G.gs] if is_multi_g else [get_sghmc_noise(G)]\n",
    "    D_noise_sampler = get_sghmc_noise(D)\n",
    "\n",
    "    if args.save_dir == 'none':\n",
    "        args.save_dir = './dump/train_{}_{}'.format(args.dataset, args.gan_obj)\n",
    "\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=config.get_dataset(),\n",
    "        batch_size=config.batch_size, shuffle=True,\n",
    "        num_workers=config.workers, pin_memory=True)\n",
    "\n",
    "    # setup loss function\n",
    "    criterion_bce = nn.BCEWithLogitsLoss().to(device)\n",
    "    criterion_mse = nn.MSELoss().to(device)\n",
    "    if args.gan_obj == 'NS':\n",
    "        phi_1 = lambda dreal, lreal, lfake: criterion_bce(dreal, lreal)\n",
    "        phi_2 = lambda dfake, lreal, lfake: criterion_bce(dfake, lfake)\n",
    "        phi_3 = lambda dfake, lreal, lfake: criterion_bce(dfake, lreal)\n",
    "    elif args.gan_obj == 'MM':\n",
    "        phi_1 = lambda dreal, lreal, lfake: criterion_bce(dreal, lreal)\n",
    "        phi_2 = lambda dfake, lreal, lfake: criterion_bce(dfake, lfake)\n",
    "        phi_3 = lambda dfake, lreal, lfake: - criterion_bce(dfake, lfake)\n",
    "    elif args.gan_obj == 'LS':\n",
    "        phi_1 = lambda dreal, lreal, lfake: criterion_mse(dreal, lreal)\n",
    "        phi_2 = lambda dfake, lreal, lfake: criterion_mse(dfake, lfake)\n",
    "        phi_3 = lambda dfake, lreal, lfake: criterion_mse(dfake, lreal)\n",
    "    elif args.gan_obj == 'W':\n",
    "        phi_1 = lambda dreal, lreal, lfake: - dreal.mean()\n",
    "        phi_2 = lambda dfake, lreal, lfake: dfake.mean()\n",
    "        phi_3 = lambda dfake, lreal, lfake: - dfake.mean()\n",
    "\n",
    "    num_gs = len(getattr(G, 'gs', [G]))\n",
    "    num_ds = getattr(D, 'n_ds', 1)\n",
    "\n",
    "    # setup optimizer\n",
    "    optimizerD = torch.optim.Adam(D.parameters(), lr=config.base_lr, betas=(config.beta1, 0.999))\n",
    "    optimizerG = torch.optim.Adam(G.parameters(), lr=config.base_lr, betas=(config.beta1, 0.999))\n",
    "\n",
    "    # setup some varibles\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    D_losses = AverageMeter()\n",
    "    G_losses = AverageMeter()\n",
    "    G_n_losses = AverageMeter()\n",
    "\n",
    "    fixed_noise = torch.randn(100, config.z_size)\n",
    "    with torch.no_grad():\n",
    "        fixed_noise = Variable(fixed_noise.to(device))\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    D.train()\n",
    "    G.train()\n",
    "\n",
    "    D_loss_list = []\n",
    "    G_loss_list = []\n",
    "    G_loss_by_hist_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for epoch in range(config.epoches):\n",
    "        i = 0\n",
    "        for input in train_loader:\n",
    "\n",
    "            '''\n",
    "                Update D network:\n",
    "            '''\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            batch_size = input.size(0)\n",
    "            g_batch_size = config.g_batch_size\n",
    "            assert g_batch_size >= batch_size\n",
    "\n",
    "            input_var = Variable(input.to(device))\n",
    "\n",
    "            # Train discriminator with real data\n",
    "            label_real = torch.ones(max(batch_size, g_batch_size))\n",
    "            label_real_var = Variable(label_real.to(device))\n",
    "\n",
    "            D_real_result = D(input_var).squeeze()\n",
    "            D_real_loss = phi_1(D_real_result, label_real_var[:batch_size], None)\n",
    "\n",
    "            # Train discriminator with fake data\n",
    "            label_fake = torch.zeros(g_batch_size)\n",
    "            label_fake_var = Variable(label_fake.to(device))\n",
    "\n",
    "            noise = torch.randn((g_batch_size, config.z_size)).to(device)\n",
    "            noise_var = Variable(noise.to(device))\n",
    "            G_result = G(noise_var)\n",
    "\n",
    "            D_fake_result = D(G_result).squeeze()\n",
    "            D_fake_loss = phi_2(D_fake_result, None, label_fake_var)\n",
    "\n",
    "            # Back propagation\n",
    "            D_train_loss = D_real_loss + D_fake_loss\n",
    "            D_losses.update(D_train_loss.item())\n",
    "            D_noise_loss = args.d_noise_loss_lambda * noise_loss(model=D, noise_sampler=D_noise_sampler,\n",
    "                                                                 alpha=noise_std)\n",
    "            D_train_loss += D_noise_loss\n",
    "\n",
    "            if args.gan_obj == 'W':\n",
    "                gradient_penalty = calc_gradient_penalty(D, input_var.data, G_result[:batch_size].data)\n",
    "                D_train_loss += gradient_penalty\n",
    "\n",
    "            D.zero_grad()\n",
    "            D_train_loss.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            '''\n",
    "                Update G network:\n",
    "            '''\n",
    "            noise = torch.randn((g_batch_size, config.z_size)).to(device)\n",
    "            noise_var = Variable(noise.to(device))\n",
    "            G_result = G(noise_var)\n",
    "\n",
    "            D_fake_result = D(G_result).squeeze()\n",
    "            G_train_loss = phi_3(D_fake_result, label_real_var, label_fake_var)\n",
    "\n",
    "            G_losses.update(G_train_loss.item())\n",
    "\n",
    "            G_noise_loss = args.g_noise_loss_lambda * noise_loss(model=G, noise_sampler=G_noise_sampler[0], alpha=noise_std)\n",
    "\n",
    "            G_train_loss += G_noise_loss\n",
    "\n",
    "            if is_multi_d and hasattr(D, 'forward_by_hist'):\n",
    "                D_fake_result_hist = D.forward_by_hist(G_result).squeeze()\n",
    "                G_train_loss_by_hist = phi_3(D_fake_result_hist, label_real_var, label_fake_var)\n",
    "                G_train_loss += G_train_loss_by_hist * args.d_hist_loss_lambda\n",
    "                G_n_losses.update(G_train_loss_by_hist.item())\n",
    "\n",
    "\n",
    "            # Back propagation\n",
    "            D.zero_grad()\n",
    "            G.zero_grad()\n",
    "            G_train_loss.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            \n",
    "                # print(F.l1_loss(D.ds.weight.data, D.ds_hist_avg.weight.data))\n",
    "            if is_multi_d and hasattr(D, 'update_hist') and i % 10 == 0:\n",
    "                D.update_hist()\n",
    "\n",
    "\n",
    "            if (i + 1) % config.display == 0:\n",
    "                print_log_2(epoch + 1, config.epoches, i + 1, len(train_loader), config.base_lr,\n",
    "                            config.display, batch_time, data_time, D_losses, G_losses, G_n_losses)\n",
    "                batch_time.reset()\n",
    "                data_time.reset()\n",
    "            elif (i + 1) == len(train_loader):\n",
    "                print_log_2(epoch + 1, config.epoches, i + 1, len(train_loader), config.base_lr,\n",
    "                            (i + 1) % config.display, batch_time, data_time, D_losses, G_losses, G_n_losses)\n",
    "                batch_time.reset()\n",
    "                data_time.reset()\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        D_loss_list.append(D_losses.avg)\n",
    "        G_loss_list.append(G_losses.avg)\n",
    "        G_loss_by_hist_list.append(G_n_losses.avg)\n",
    "\n",
    "        D_losses.reset()\n",
    "        G_losses.reset()\n",
    "        G_n_losses.reset()\n",
    "\n",
    "        if (epoch + 1) < config.dump_ep:\n",
    "            plot_result(G, fixed_noise, config.image_size, epoch + 1, args.save_dir, is_gray=(config.channel_size == 1))\n",
    "            plot_loss_my(D_loss_list, G_loss_list, G_loss_by_hist_list, epoch + 1, config.epoches, args.save_dir)\n",
    "\n",
    "        if (epoch + 1) % config.dump_ep == 0:\n",
    "            # plt the generate images and loss curve\n",
    "            plot_result(G, fixed_noise, config.image_size, epoch + 1, args.save_dir, is_gray=(config.channel_size == 1))\n",
    "            plot_loss_my(D_loss_list, G_loss_list, G_loss_by_hist_list, epoch + 1, config.epoches, args.save_dir)\n",
    "            # save the D and G.\n",
    "            save_checkpoint({'epoch': epoch, 'state_dict': D.state_dict(), },\n",
    "                            os.path.join(args.save_dir, 'D_epoch_{}'.format(epoch)))\n",
    "            save_checkpoint({'epoch': epoch, 'state_dict': G.state_dict(), },\n",
    "                            os.path.join(args.save_dir, 'G_epoch_{}'.format(epoch)))\n",
    "            torch.save(G.state_dict(), os.path.join(args.save_dir, 'gen_model.pt'))\n",
    "\n",
    "\n",
    "        # monitoring gradient behavior & clip if needed\n",
    "        tmp = grad_info(G.parameters())\n",
    "        print('G grad l2-norm: {}, value max: {}'.format(tmp[0], tmp[1]))\n",
    "        tmp = grad_info(D.parameters())\n",
    "        print('D grad l2-norm: {}, value max: {}'.format(tmp[0], tmp[1]))\n",
    "\n",
    "        nn.utils.clip_grad_norm_(parameters=G.parameters(), max_norm=100, norm_type=2)\n",
    "        nn.utils.clip_grad_norm_(parameters=D.parameters(), max_norm=500, norm_type=2)\n",
    "\n",
    "        if (epoch + 1) % config.dump_ep == 0:\n",
    "            batch_size = 100\n",
    "            total_size = 5000\n",
    "            x = []\n",
    "            for i in range(total_size // batch_size):\n",
    "                noise = torch.randn((g_batch_size, config.z_size)).to(device)\n",
    "                noise_var = Variable(noise.to(device))\n",
    "                G_result = G(noise_var)\n",
    "                x.append(G_result.detach().cpu().numpy())\n",
    "            x = np.concatenate(x, axis=0)\n",
    "            imgs = x\n",
    "            # m, v = get_inception_score(images=imgs)\n",
    "            m, v = 0, 0\n",
    "            # fid = get_fid_score(images=imgs)\n",
    "            fid = 0\n",
    "            print('Epoch {} Inception Score: mean {:.6f} std {:.6f}'.format(epoch + 1, m, v))\n",
    "            print('Epoch {} FID Score: {:.6f}'.format(epoch + 1, fid))\n",
    "\n",
    "            score_list.append([epoch + 1, m, v, fid])\n",
    "            plot_scores(score_list, args.save_dir)\n",
    "\n",
    "\n",
    "def time_series_cv_split(data, window_size=20, train_size=0.65, val_window=100, step=50):\n",
    "    n = len(data)\n",
    "    split_point = int(n * train_size)\n",
    "    splits = []\n",
    "\n",
    "    for start in range(0, split_point - window_size - val_window + 1, step):\n",
    "        train_end = start + window_size\n",
    "        val_end = train_end + val_window\n",
    "\n",
    "        if val_end > n:\n",
    "            break\n",
    "\n",
    "        train_data = data[start:train_end]\n",
    "        val_data = data[train_end:val_end]\n",
    "        splits.append((train_data.copy(), val_data.copy()))\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n",
    "\n",
    "def noise_loss(model,\n",
    "               noise_sampler,\n",
    "               alpha):\n",
    "    loss = 0\n",
    "    for p, n in zip(model.parameters(), noise_sampler):\n",
    "        n.normal_(mean=0, std=alpha)\n",
    "        loss += torch.sum(p * n)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def get_sghmc_noise(model):\n",
    "    return [to_tensor(torch.zeros(p.size())) for p in model.parameters()]\n",
    "\n",
    "\n",
    "# ======================================================================================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\" Computes ans stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def grad_info(parameters):\n",
    "    total_norm = 0\n",
    "    total_abs_max = 0\n",
    "    for p in parameters:\n",
    "        if p.requires_grad:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "            vmax = p.grad.data.abs().max().item()\n",
    "            if vmax > total_abs_max:\n",
    "                total_abs_max = vmax\n",
    "    total_norm = total_norm ** (1. / 2)\n",
    "    return total_norm, total_abs_max\n",
    "\n",
    "\n",
    "\n",
    "def calc_gradient_penalty(netD, real_data, fake_data, gp_lambda=10):\n",
    "    # print real_data.size()\n",
    "    assert len(real_data) == len(fake_data)\n",
    "    alpha = torch.rand(len(real_data), 1, 1, 1)\n",
    "    alpha = alpha.to(device)\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * gp_lambda\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def calc_gradient_penalty_mgan(netD, real_data, fake_data, gp_lambda=10):\n",
    "    # print real_data.size()\n",
    "    assert len(real_data) == len(fake_data)\n",
    "    alpha = torch.rand(len(real_data), 1, 1, 1)\n",
    "    alpha = alpha.to(device)\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates, _ = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * gp_lambda\n",
    "    return gradient_penalty\n",
    "\n",
    "from scipy.stats import skew, kurtosis, jarque_bera, ks_2samp\n",
    "\n",
    "def plot_scores(score_list, save_dir):\n",
    "    x = np.array(score_list)\n",
    "    ep = x[:, 0]\n",
    "    IS = x[:, 1]\n",
    "    IS_std = x[:, 2]\n",
    "    FID = x[:, 3]\n",
    "    fig, ax = plt.subplots(1, 2, sharex='all', figsize=(12, 4.8))\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Inception Score')\n",
    "    ax[1].set_ylabel('FID')\n",
    "    ax[0].plot(ep, IS, 'r-', linewidth=3)\n",
    "    ax[0].plot(ep, IS - IS_std, 'r--', linewidth=1)\n",
    "    ax[0].plot(ep, IS + IS_std, 'r--', linewidth=1)\n",
    "    ax[1].plot(ep, FID, 'r-', linewidth=3)\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, 'score.png'))\n",
    "    plt.close()\n",
    "    np.save(os.path.join(save_dir, 'score.npy'), x)\n",
    "\n",
    "def rolling_window_splits(data, window_size=20, test_size=100, step=10):\n",
    "    splits = []\n",
    "    for start in range(0, len(data) - window_size - test_size, step):\n",
    "        train = data[start:start+window_size]\n",
    "        test = data[start+window_size:start+window_size+test_size]\n",
    "        splits.append((train, test))\n",
    "    return splits\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss_my(d_loss, g_loss, g_loss_hist, num_epoch, epoches, save_dir):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, epoches + 1)\n",
    "    ax.set_ylim(min(np.min(g_loss_hist), min(np.min(g_loss), np.min(d_loss))) - 0.1,\n",
    "                max(np.max(g_loss), np.max(d_loss)) * 1.1)\n",
    "    plt.xlabel('Epoch {}'.format(num_epoch))\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.plot([i for i in range(1, num_epoch + 1)], d_loss, label='Discriminator', color='red', linewidth=3)\n",
    "    plt.plot([i for i in range(1, num_epoch + 1)], g_loss, label='Generator', color='mediumblue', linewidth=3,\n",
    "             alpha=0.5)\n",
    "    plt.plot([i for i in range(1, num_epoch + 1)], g_loss_hist, label='Generator - (hist)', color='green', linewidth=3,\n",
    "             alpha=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'DCGAN_loss_epoch_{}.png'.format(num_epoch)))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_result(G, fixed_noise, image_size, num_epoch, save_dir, is_gray=False, n_series=None):\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        generated = G(fixed_noise).cpu().numpy()  # shape: [batch_size, timesteps, features]\n",
    "\n",
    "    if n_series is None:\n",
    "        n_series = generated.shape[2]  # infer number of series\n",
    "\n",
    "    fig, axes = plt.subplots(n_series, 1, figsize=(12, 2 * n_series), sharex=True)\n",
    "\n",
    "    # Ensure axes is iterable even when n_series == 1\n",
    "    if n_series == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(n_series):\n",
    "        series = generated[0, :, i]\n",
    "        axes[i].plot(series)\n",
    "        axes[i].set_ylabel(f'Series {i+1}')\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Timestep\")\n",
    "    fig.suptitle(f\"Generated Time Series Sample - Epoch {num_epoch}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"time_series_epoch_{num_epoch}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_log_2(epoch, epoches, iteration, iters, learning_rate,\n",
    "                display, batch_time, data_time, D_losses, G_losses, G_n_losses):\n",
    "    print('epoch: [{}/{}] iteration: [{}/{}]\\t'\n",
    "          'Learning rate: {}'.format(epoch, epoches, iteration, iters, learning_rate))\n",
    "    print('Time {batch_time.sum:.3f}s / {0} iters, ({batch_time.avg:.3f})\\t'\n",
    "          'Data load {data_time.sum:.3f}s / {0} iters, ({data_time.avg:3f})\\n'\n",
    "          'Loss_D = {loss_D.val:.8f} (ave = {loss_D.avg:.8f})\\n'\n",
    "          'Loss_G = {loss_G.val:.8f} (ave = {loss_G.avg:.8f})\\n'\n",
    "          'Loss_GN = {loss_GN.val:.8f} (ave = {loss_GN.avg:.8f})\\n'.format(\n",
    "        display, batch_time=batch_time,\n",
    "        data_time=data_time, loss_D=D_losses, loss_G=G_losses, loss_GN=G_n_losses))\n",
    "    print(time.strftime('%Y-%m-%d %H:%M:%S '\n",
    "                        '-----------------------------------------------------------------------------------------------------------------\\n',\n",
    "                        time.localtime()))\n",
    "\n",
    "\n",
    "def generate_synthetic_forecast(G, forecast_horizon=300, n_samples=1, steps_per_pass=20):\n",
    "    n_passes = forecast_horizon // steps_per_pass\n",
    "    all_returns = []\n",
    "\n",
    "    if scaler is None:\n",
    "        raise ValueError(\"Scaler must be provided to inverse transform returns.\")\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_passes):\n",
    "            z = torch.randn(n_samples, 100).to(device)\n",
    "            returns_block = G(z).cpu().numpy()\n",
    "            all_returns.append(returns_block)\n",
    "\n",
    "    returns = np.concatenate(all_returns, axis=1)\n",
    "\n",
    "    # Inverse transform the generated synthetic returns\n",
    "    returns_flat = returns.reshape(-1, returns.shape[2])  # shape: (timesteps * features)\n",
    "    returns_unscaled = scaler.inverse_transform(returns_flat)\n",
    "    returns = returns_unscaled.reshape(returns.shape)  # back to (1, timesteps, features)\n",
    "\n",
    "    \n",
    "    prices = []\n",
    "    for i in range(returns.shape[2]):\n",
    "        series = returns[0, :, i]\n",
    "        series_prices = [LAST_KNOWN_PRICES[i]]\n",
    "        for r in series:\n",
    "            series_prices.append(series_prices[-1] * (1 + r))\n",
    "        prices.append(series_prices[1:])\n",
    "    \n",
    "    df_synthetic = pd.DataFrame(np.array(prices).T, columns=df.columns)\n",
    "    df_synthetic.to_csv(\"synthetic_prices.csv\", index=False)\n",
    "    return df_synthetic\n",
    "\n",
    "def evaluate_synthetic_vs_real(real_returns, synthetic_returns):\n",
    "    results = {\n",
    "        \"Mean_Real\": np.mean(real_returns),\n",
    "        \"Mean_Synthetic\": np.mean(synthetic_returns),\n",
    "        \"Std_Real\": np.std(real_returns),\n",
    "        \"Std_Synthetic\": np.std(synthetic_returns),\n",
    "        \"Skew_Real\": skew(real_returns),\n",
    "        \"Skew_Synthetic\": skew(synthetic_returns),\n",
    "        \"Kurt_Real\": kurtosis(real_returns),\n",
    "        \"Kurt_Synthetic\": kurtosis(synthetic_returns),\n",
    "        \"KS_Distance\": ks_2samp(real_returns, synthetic_returns).statistic,\n",
    "        \"Jarque_Bera_Real\": jarque_bera(real_returns)[0],\n",
    "        \"Jarque_Bera_Synthetic\": jarque_bera(synthetic_returns)[0],\n",
    "    }\n",
    "    return pd.DataFrame([results])\n",
    "\n",
    "\n",
    "\n",
    "config = EasyDict()\n",
    "config.num_gens = 10\n",
    "config.num_discs = 4\n",
    "config.z_size = 100\n",
    "config.channel_size = 1\n",
    "config.ngf = 128\n",
    "config.ndf = 128\n",
    "config.batch_size = 64\n",
    "config.g_batch_size = 128\n",
    "config.base_lr = 0.0001\n",
    "config.beta1 = 0.5\n",
    "config.epoches = 200\n",
    "config.dump_ep = 10\n",
    "config.image_size = 1\n",
    "config.get_dataset = lambda: FXEQDataset(\"raw (FX + EQ).csv\", window_size=20, scaler=scaler)\n",
    "config.display = 800\n",
    "config.workers = 0\n",
    "\n",
    "\n",
    "class Args:\n",
    "    sghmc_alpha = 0.01\n",
    "    g_noise_loss_lambda = 3e-2\n",
    "    d_noise_loss_lambda = 3e-2\n",
    "    d_hist_loss_lambda = 1.0\n",
    "    gan_obj = \"NS\"\n",
    "    dataset = \"fxeq\"\n",
    "    save_dir = \"fxeq_probgan_output\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "joblib.dump(scaler, \"fxeq_returns_scaler.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_df = pd.read_csv(\"raw (FX + EQ).csv\").dropna()\n",
    "raw_returns_all_assets = raw_df.pct_change().dropna().values\n",
    "NUM_ASSETS = 12\n",
    "all_metrics = []  # to hold metric results for all assets and folds\n",
    "\n",
    "for asset_index in range(NUM_ASSETS):\n",
    "    print(f\"üîÅ TSCV for Asset {asset_index}\")\n",
    "    returns = raw_returns_all_assets[:, asset_index].reshape(-1, 1)\n",
    "    scaler = StandardScaler().fit(returns)\n",
    "    returns_scaled = scaler.transform(returns).squeeze()\n",
    "\n",
    "    splits = time_series_cv_split(returns_scaled, window_size=300, val_window=100, step=100)\n",
    "    \n",
    "    for fold, (train_seq, val_seq) in enumerate(splits):\n",
    "        print(f\"üì¶ Fold {fold + 1} | Train: {len(train_seq)}, Val: {len(val_seq)}\")\n",
    "\n",
    "        # Create Datasets for each fold\n",
    "        class FoldDataset(Dataset):\n",
    "            def __init__(self, series, window_size):\n",
    "                self.series = series\n",
    "                self.window_size = window_size\n",
    "                self.samples = [series[i:i+window_size] for i in range(len(series) - window_size)]\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.samples)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                return torch.tensor(self.samples[idx], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "        config.get_dataset = lambda: FoldDataset(train_seq, window_size=20)\n",
    "\n",
    "        # Re-init model per fold\n",
    "        G, D = construct_model(args, config)\n",
    "\n",
    "        # Train model\n",
    "        train_net(G, D, args, config)\n",
    "\n",
    "        # Save results per fold\n",
    "        fold_dir = f\"tscv_asset_{asset_index}/fold_{fold}\"\n",
    "        os.makedirs(fold_dir, exist_ok=True)\n",
    "        torch.save(G.state_dict(), os.path.join(fold_dir, \"G.pt\"))\n",
    "        torch.save(D.state_dict(), os.path.join(fold_dir, \"D.pt\"))\n",
    "        # Evaluate synthetic vs real returns\n",
    "        real_returns_flat = val_seq.flatten()\n",
    "        real_prices = np.cumprod(1 + val_seq.flatten())\n",
    "        G.eval()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, config.z_size).to(device)\n",
    "            synthetic_returns = G(z).cpu().numpy().flatten()\n",
    "        synt_prices = [real_prices[0]]  # start from same point\n",
    "        for r in scaler.inverse_transform(synthetic_returns.reshape(-1, 1)).flatten():\n",
    "            synt_prices.append(synt_prices[-1] * (1 + r))\n",
    "        synt_prices = np.array(synt_prices[1:])\n",
    "        \n",
    "        metrics_df = evaluate_synthetic_vs_real(real_prices, synt_prices)\n",
    "        metrics_df[\"Asset\"] = asset_index\n",
    "        metrics_df[\"Fold\"] = fold\n",
    "        all_metrics.append(metrics_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.concat(all_metrics, ignore_index=True)\n",
    "results_df.to_csv(\"price_level_evaluation_metrics.csv\", index=False)\n",
    "print(\"üìÑ All metrics saved to 'price_level_evaluation_metrics.csv'\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# üì¶ Generate Boxplots for Each Asset\n",
    "def plot_boxplots(real_all, synthetic_all, asset_names=None):\n",
    "    \"\"\"\n",
    "    real_all, synthetic_all: list of arrays, each array is prices for one asset\n",
    "    asset_names: optional list of asset names\n",
    "    \"\"\"\n",
    "    num_assets = len(real_all)\n",
    "    data = []\n",
    "    for i in range(num_assets):\n",
    "        real = real_all[i]\n",
    "        synthetic = synthetic_all[i]\n",
    "        asset = asset_names[i] if asset_names else f\"Asset {i}\"\n",
    "\n",
    "        data.extend([\n",
    "            {\"Asset\": asset, \"Price\": p, \"Type\": \"Real\"} for p in real\n",
    "        ])\n",
    "        data.extend([\n",
    "            {\"Asset\": asset, \"Price\": p, \"Type\": \"Synthetic\"} for p in synthetic\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    sns.boxplot(data=df, x=\"Asset\", y=\"Price\", hue=\"Type\", palette=\"Set2\")\n",
    "    plt.title(\"Boxplots of Real vs Synthetic Prices per Asset\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"price_boxplots_per_asset.png\")\n",
    "    plt.show()\n",
    "\n",
    "# üß± Build arrays of real/synthetic prices across all assets (from LAST_KNOWN_PRICES)\n",
    "real_all = []\n",
    "synthetic_all = []\n",
    "for asset_index in range(NUM_ASSETS):\n",
    "    prices_real = np.cumprod(1 + raw_returns_all_assets[-300:, asset_index])\n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, config.z_size).to(device)\n",
    "        synthetic = G(z).cpu().numpy().flatten()\n",
    "        returns_unscaled = scaler.inverse_transform(synthetic.reshape(-1, 1)).flatten()\n",
    "        prices_synth = [prices_real[0]]\n",
    "        for r in returns_unscaled:\n",
    "            prices_synth.append(prices_synth[-1] * (1 + r))\n",
    "        prices_synth = prices_synth[1:]\n",
    "\n",
    "    real_all.append(prices_real)\n",
    "    synthetic_all.append(prices_synth)\n",
    "\n",
    "plot_boxplots(real_all, synthetic_all)\n",
    "\n",
    "\n",
    "# Plot heatmap of KS distance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ks_matrix = results_df.pivot(index=\"Fold\", columns=\"Asset\", values=\"KS_Distance\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(ks_matrix, annot=True, fmt=\".3f\", cmap=\"coolwarm\")\n",
    "plt.title(\"KS Distance between Real and Synthetic Prices (per Fold/Asset)\")\n",
    "plt.ylabel(\"Fold\")\n",
    "plt.xlabel(\"Asset\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ks_distance_heatmap.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# üîÆ Generate Synthetic Forecast\n",
    "LAST_KNOWN_PRICES = np.array([\n",
    "    15.136, 20.3352, 17.563, 8.6973, 1.1579, 1.3435,\n",
    "    20.716, 141.5, 164.252, 9.95, 30.14, 2004.0\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "G.eval()\n",
    "synthetic_df = generate_synthetic_forecast(G)\n",
    "display(synthetic_df.head())\n",
    "\n",
    "\n",
    "# Extract real returns (e.g., from the validation set)\n",
    "real_returns_flat = val_seq.flatten()  # make sure this exists from TSCV loop\n",
    "\n",
    "# Extract synthetic returns\n",
    "synthetic_returns_flat = returns.flatten()\n",
    "\n",
    "# Evaluate and display\n",
    "metrics_df = evaluate_synthetic_vs_real(real_returns_flat, synthetic_returns_flat)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_dimensionality_reduction(real_all, synthetic_all, method=\"PCA\"):\n",
    "    \"\"\"\n",
    "    real_all, synthetic_all: list of arrays, each of length T\n",
    "    \"\"\"\n",
    "    all_series = []\n",
    "    labels = []\n",
    "\n",
    "    for i, series in enumerate(real_all):\n",
    "        all_series.append(series)\n",
    "        labels.append(f\"Real_{i}\")\n",
    "    for i, series in enumerate(synthetic_all):\n",
    "        all_series.append(series)\n",
    "        labels.append(f\"Synth_{i}\")\n",
    "\n",
    "    X = np.array(all_series)\n",
    "\n",
    "    if method == \"PCA\":\n",
    "        reducer = PCA(n_components=2)\n",
    "    elif method == \"tSNE\":\n",
    "        reducer = TSNE(n_components=2, perplexity=5, learning_rate='auto', init='random', random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'PCA' or 'tSNE'.\")\n",
    "\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"x\": X_reduced[:, 0],\n",
    "        \"y\": X_reduced[:, 1],\n",
    "        \"Type\": [\"Real\"] * len(real_all) + [\"Synthetic\"] * len(synthetic_all),\n",
    "        \"Asset\": [f\"A{i}\" for i in range(len(real_all))] * 2\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df_plot, x=\"x\", y=\"y\", hue=\"Type\", style=\"Asset\", s=100)\n",
    "    plt.title(f\"{method} of Real vs Synthetic Price Trajectories\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{method.lower()}_price_trajectories.png\")\n",
    "    plt.show()\n",
    "\n",
    "# üìà Plot PCA and t-SNE\n",
    "plot_dimensionality_reduction(real_all, synthetic_all, method=\"PCA\")\n",
    "plot_dimensionality_reduction(real_all, synthetic_all, method=\"tSNE\")\n",
    "\n",
    "\n",
    "\n",
    "# Plot again using final generator\n",
    "fixed_noise = torch.randn(1, 100).to(device)\n",
    "plot_result(G, fixed_noise, image_size=1, num_epoch=\"final\", save_dir=\".\", n_series=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
